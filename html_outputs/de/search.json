[
  {
    "objectID": "index.de.html",
    "href": "index.de.html",
    "title": "EpiRhandbook auf Deutsch",
    "section": "",
    "text": "Willkommen",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "index.de.html#r-für-angewandte-epidemiologie-und-öffentliches-gesundheitswesen",
    "href": "index.de.html#r-für-angewandte-epidemiologie-und-öffentliches-gesundheitswesen",
    "title": "EpiRhandbook auf Deutsch",
    "section": "R für angewandte Epidemiologie und öffentliches Gesundheitswesen",
    "text": "R für angewandte Epidemiologie und öffentliches Gesundheitswesen\nVerwendung Dieses Handbuch wurde über 1 Million Mal von 450.000 Menschen auf der ganzen Welt genutzt.\nZielsetzung: Als schnelles R-Code-Referenzhandbuch dienen (online und offline)) mit aufgabenzentrierten Beispielen, die häufige epidemiologische Probleme behandeln.\nDu fängst gerade erst mit R an? Probiere unser kostenlosen interaktiven Tutorien oder synchrone, virtuelle Einführungskurs wird von der US CDC, der WHO und mehr als 75 anderen Gesundheitsbehörden und Epi-Schulungsprogrammen auf der ganzen Welt verwendet.\nSprachen: Französisch (Français), Spanisch (Español), Vietnamesisch (Tiếng Việt), Japanisch (日本), Türkisch (Türkçe), Portugiesisch (Português), Russisch (Русский)\n\n\n\n\n\n\n–&gt;\n\n Geschrieben von Epidemiologen, für Epidemiologen\n:::: {style=“display: flex;”}\n\n\n\n\n\n\n\n\n\n\n\n\n\\\n\n\n\nAngewandte Epi ist eine gemeinnützige Organisation und eine Graswurzelbewegung von Frontline-Epis aus aller Welt. Wir schreiben in unserer Freizeit, um diese Ressource für die Gemeinschaft bereitzustellen. Deine Ermutigung und dein Feedback sind uns sehr willkommen:\n\nBesuche unsere Website und tritt in unsere Kontaktliste ein\ncontact@appliedepi.org tweet @appliedepi, oder LinkedIn\nThemen an unser Github-Repository\n\nWir bieten Live-R-Schulungen an von Dozenten mit jahrzehntelanger Erfahrung in der angewandten Epidemiologie an - schick uns eine E-Mail, um darüber zu sprechen.\n\n::::",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "index.de.html#wie-man-dieses-handbuch-benutzt",
    "href": "index.de.html#wie-man-dieses-handbuch-benutzt",
    "title": "EpiRhandbook auf Deutsch",
    "section": "Wie man dieses Handbuch benutzt",
    "text": "Wie man dieses Handbuch benutzt\n\nDurchsuche die Seiten im Inhaltsverzeichnis oder benutze das Suchfeld\nKlicke auf die “Kopieren”-Symbole, um den Code zu kopieren\nDu kannst folgen mit den Beispieldaten\n\nOffline-Version\nSiehe Anweisungen in der Handbuch und Daten herunterladen Seite.",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "index.de.html#danksagungen",
    "href": "index.de.html#danksagungen",
    "title": "EpiRhandbook auf Deutsch",
    "section": "Danksagungen",
    "text": "Danksagungen\nDieses Handbuch wurde von einer unabhängigen Gruppe von Epidemiologen aus der ganzen Welt erstellt, die auf Erfahrungen mit Organisationen wie lokalen, bundesstaatlichen, provinziellen und nationalen Gesundheitsbehörden, der Weltgesundheitsorganisation (WHO), Ärzte ohne Grenzen (MSF), Krankenhaussystemen und akademischen Einrichtungen zurückgreifen.\nDieses Handbuch ist nicht ein genehmigtes Produkt einer bestimmten Organisation. Obwohl wir uns um Genauigkeit bemühen, übernehmen wir keine Garantie für den Inhalt dieses Buches.\n\nMitwirkende\nHerausgeber: Neale Batra\nAutoren: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen Lin\nGutachter und Unterstützer: Pat Keating, Amrish Baidjoe Annick Lenglet, Margot Charette, Danielly Xavier, Marie-Amélie Degail Chabrat, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao Muianga\nIllustrationen: Calder Fong\n\n\n\n\n\nFinanzierung und Unterstützung\nDieses Buch wurde hauptsächlich von Freiwilligen in tausenden von Stunden erstellt.\nDas Handbuch wurde durch einen COVID-19-Zuschuss für den Aufbau von Kapazitäten von TEPHINET dem globalen Netzwerk der Field Epidemiology Training Programs (FETPs).\nAdministrative Unterstützung leistete das EPIET Alumni Network (EAN), mit besonderem Dank an Annika Wendland. EPIET ist das Europäische Programm für die Ausbildung in der Interventionsepidemiologie.\nBesonderer Dank gilt dem Médecins Sans Frontières (MSF) Operational Centre Amsterdam (OCA) für die Unterstützung bei der Entwicklung dieses Handbuchs.\nDiese Veröffentlichung wurde durch die Kooperationsvereinbarung Nr. NU2GGH001873 unterstützt, die von den Centers for Disease Control and Prevention über TEPHINET, ein Programm der Task Force for Global Health, finanziert wurde. Der Inhalt liegt in der alleinigen Verantwortung der Autorinnen und Autoren und gibt nicht unbedingt die offiziellen Ansichten der Centers for Disease Control and Prevention, des Department of Health and Human Services, der Task Force for Global Health, Inc. oder von TEPHINET wieder.\n\n\nInspiration\nDie zahlreichen Tutorials und Vignetten, die das Wissen für die Entwicklung des Handbuchs lieferten, werden auf den jeweiligen Seiten erwähnt.\nGenerell lieferten die folgenden Quellen Inspirationen für dieses Handbuch:\nDas “R4Epis”-Projekt (eine Zusammenarbeit zwischen MSF und RECON)\nR Epidemien Konsortium (RECON)\nR for Data Science Buch (R4DS)\nbookdown: Bücher und technische Dokumente mit R Markdown verfassen\nNetlify hostet diese Website",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "index.de.html#nutzungsbedingungen-und-beitrag",
    "href": "index.de.html#nutzungsbedingungen-und-beitrag",
    "title": "EpiRhandbook auf Deutsch",
    "section": "Nutzungsbedingungen und Beitrag",
    "text": "Nutzungsbedingungen und Beitrag\n\nLizenz\n Applied Epi Incorporated, 2021 Dieses Werk wird von Applied Epi Incorporated lizenziert unter einer Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nAkademische Kurse und Ausbildungsprogramme für Epidemiologen können uns gerne wegen der Verwendung oder Anpassung dieses Materials kontaktieren (E-Mail contact@appliedepi.org).\n\n\nZitat\nBatra, Neale, et al. The Epidemiologist R Handbook. 2021. \n\n\nBeitrag\nWenn du einen Beitrag zum Inhalt leisten möchtest, kontaktiere uns bitte zuerst über Github Issues oder per E-Mail. Wir sind dabei, einen Zeitplan für Aktualisierungen einzuführen und einen Leitfaden für Beitragszahler zu erstellen.\nBitte beachte, dass das epiRhandbook-Projekt mit einem Verhaltenskodex für Mitwirkende. Wenn du zu diesem Projekt beiträgst, erklärst du dich damit einverstanden, die Bedingungen einzuhalten.",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.de.html",
    "href": "new_pages/editorial_style.de.html",
    "title": "1  Redaktionelle und technische Hinweise",
    "section": "",
    "text": "1.1 Herangehensweise und Stil\nDie potenzielle Zielgruppe für dieses Buch ist groß. Es wird sicherlich von Menschen genutzt werden, die neu in R sind, aber auch von erfahrenen R-Nutzern, die nach Best Practices und Tipps suchen. Es muss also sowohl zugänglich als auch prägnant sein. Unser Ansatz war daher, Folgendes zu bieten gerade genug Text zu erklären, damit auch jemand, der R noch nicht kennt, den Code anwenden und nachvollziehen kann, was der Code macht.\nEin paar andere Punkte:",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Redaktionelle und technische Hinweise</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.de.html#herangehensweise-und-stil",
    "href": "new_pages/editorial_style.de.html#herangehensweise-und-stil",
    "title": "1  Redaktionelle und technische Hinweise",
    "section": "",
    "text": "Dies ist ein Nachschlagewerk für Codes mit relativ kurzen Beispielen - nicht ein umfassendes Lehrbuch über R oder Datenwissenschaft\nDies ist ein R-Handbuch für den Einsatz in der angewandten Epidemiologie - kein Handbuch über die Methoden oder die Wissenschaft der angewandten Epidemiologie\nDies soll ein lebendiges Dokument sein - die optimalen R-Pakete für eine bestimmte Aufgabe ändern sich häufig und wir freuen uns über Diskussionen darüber, welche in diesem Handbuch hervorgehoben werden sollen\n\n\nR-Pakete\nSo viele Auswahlmöglichkeiten\nEiner der schwierigsten Aspekte beim Erlernen von R ist es, zu wissen, welches R-Paket man für eine bestimmte Aufgabe verwenden soll. Es kommt häufig vor, dass man sich durch eine Aufgabe quält und erst später merkt - hey, es gibt ein R-Paket, das all das in einer Befehlszeile erledigt!\nIn diesem Handbuch versuchen wir, dir für jede Aufgabe mindestens zwei Möglichkeiten anzubieten: eine bewährte Methode (wahrscheinlich in Basis R oder tidyverse) und ein spezielles R-Paket, das speziell für diesen Zweck entwickelt wurde. Wir möchten, dass du ein paar Optionen hast, falls du ein bestimmtes Paket nicht herunterladen kannst oder es aus anderen Gründen nicht für dich geeignet ist.\nBei der Auswahl der zu verwendenden Pakete haben wir R-Pakete und -Ansätze bevorzugt, die von der Community getestet und geprüft wurden, die die Anzahl der in einer typischen Arbeitssitzung verwendeten Pakete minimieren, die stabil sind (sich nicht oft ändern) und die die Aufgabe einfach und sauber erledigen\nDieses Handbuch priorisiert generell R-Pakete und Funktionen aus der tidyverse. Tidyverse ist eine Sammlung von R-Paketen, die für die Datenwissenschaft entwickelt wurden und die zugrunde liegende Grammatik und Datenstrukturen teilen. Alle tidyverse-Pakete können über die Funktion “R” installiert oder geladen werden. tidyverse Paket installiert oder geladen werden. Lies mehr auf der tidyverse Website.\nFalls zutreffend, bieten wir auch Code-Optionen mit Basis R - die Pakete und Funktionen, die bei der Installation von R mitgeliefert werden. Wir sind uns bewusst, dass einige der Leser dieses Buches vielleicht kein zuverlässiges Internet haben, um zusätzliche Pakete herunterzuladen.\nFunktionen explizit mit Paketen verknüpfen\nIn R-Tutorials ist es oft frustrierend, wenn eine Funktion im Code gezeigt wird, du aber nicht weißt, aus welchem Paket sie stammt! Wir versuchen, diese Situation zu vermeiden.\nIm Text sind die Paketnamen fett gedruckt (z. B. dplyr) und Funktionen werden wie folgt geschrieben: mutate(). Wir bemühen uns, explizit anzugeben, aus welchem Paket eine Funktion stammt, entweder durch einen Verweis auf das Paket in der Nähe des Textes oder durch die explizite Angabe des Pakets im Code wie hier: dplyr::mutate(). Das sieht vielleicht redundant aus, aber wir tun es absichtlich.\nSiehe die Seite über [R-Grundlagen] um mehr über Pakete und Funktionen zu erfahren.\n\n\nCode-Stil\nIm Handbuch verwenden wir häufig “neue Zeilen”, die unseren Code “lang” erscheinen lassen. Das tun wir aus mehreren Gründen:\n\nWir können erklärende Kommentare schreiben mit # die neben jedem kleinen Teil des Codes stehen\nIm Allgemeinen ist längerer (vertikaler) Code leichter zu lesen.\nEr ist auf einem schmalen Bildschirm leichter zu lesen (kein seitliches Scrollen erforderlich)\nAnhand der Einrückungen kann man leichter erkennen, welche Argumente zu welcher Funktion gehören\n\nInfolgedessen kann der Code, der könnte wie folgt geschrieben werden:\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;%  # group rows by hospital\n  slice_max(date, n = 1, with_ties = F) # if there's a tie (of date), take the first row\n\n…wird so geschrieben:\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% # group rows by hospital\n  slice_max(\n    date,                # keep row per group with maximum date value \n    n = 1,               # keep only the single highest row \n    with_ties = F)       # if there's a tie (of date), take the first row\n\nR-Code wird im Allgemeinen nicht durch neue Zeilen oder Einrückungen beeinflusst. Wenn du beim Schreiben von Code eine neue Zeile nach einem Komma einleitest, werden automatische Einrückungsmuster angewendet.\nWir verwenden auch viele Leerzeichen (z. B. n = 1 anstelle von n=1), weil das einfacher zu lesen ist. Sei nett zu den Leuten, die deinen Code lesen!\n\n\nNomenklatur\nIn diesem Handbuch beziehen wir uns im Allgemeinen auf “Spalten” und “Zeilen” anstelle von “Variablen” und “Beobachtungen”. Wie in dieser Fibel erklärt “Aufgeräumte Daten” erläutert, bestehen die meisten epidemiologischen statistischen Datensätze strukturell aus Zeilen, Spalten und Werten.\nVariablen enthalten die Werte, die dasselbe zugrundeliegende Attribut messen (z. B. die Altersgruppe, das Ergebnis oder das Datum des Auftretens). Beobachtungen enthalten alle Werte, die an der gleichen Einheit gemessen werden (z. B. eine Person, ein Standort oder eine Laborprobe). Diese Aspekte lassen sich also schwerer greifbar definieren.\nIn “ordentlichen” Datensätzen ist jede Spalte eine Variable, jede Zeile eine Beobachtung und jede Zelle ein einzelner Wert. Manche Datensätze, auf die du triffst, passen jedoch nicht in dieses Schema - ein Datensatz mit “breitem” Format kann eine Variable enthalten, die auf mehrere Spalten aufgeteilt ist (siehe ein Beispiel im Abschnitt [Pivotierung von Daten] Seite). Ebenso können Beobachtungen auf mehrere Zeilen aufgeteilt sein.\nDer größte Teil dieses Handbuchs befasst sich mit der Verwaltung und Umwandlung von Daten. Daher ist der Verweis auf die konkreten Datenstrukturen von Zeilen und Spalten wichtiger als die abstrakteren Beobachtungen und Variablen. Ausnahmen gibt es vor allem auf den Seiten zur Datenanalyse, wo du mehr Verweise auf Variablen und Beobachtungen finden wirst.\n\n\nHinweise\nHier sind die Arten von Hinweisen, die du im Handbuch finden kannst:\nHINWEIS: Dies ist ein Hinweis\nTIPP: Dies ist ein Tipp.\nVORSICHT! Dies ist ein Vorsichtshinweis.\nGEFAHR! Dies ist eine Warnung.",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Redaktionelle und technische Hinweise</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.de.html#redaktionelle-entscheidungen",
    "href": "new_pages/editorial_style.de.html#redaktionelle-entscheidungen",
    "title": "1  Redaktionelle und technische Hinweise",
    "section": "1.2 Redaktionelle Entscheidungen",
    "text": "1.2 Redaktionelle Entscheidungen\nIm Folgenden dokumentieren wir wichtige redaktionelle Entscheidungen zur Auswahl von Paketen und Funktionen. Wenn du anderer Meinung bist oder ein neues Tool vorschlagen möchtest, nimm bitte an einer Diskussion in unserem Github-Seite.\nTabelle der Paket-, Funktions- und anderen redaktionellen Entscheidungen\n\n\n\n\n\n\n\n\n\nThema\nBerücksichtigt\nErgebnis\nKurze Begründung\n\n\n\n\nAllgemeiner Kodierungsansatz\ntidyverse, data.table, Basis\naufgeräumt mit einer Seite über Daten.Tabelle, und Erwähnungen von Basis Alternativen für Leser ohne Internet\ntidyverse Lesbarkeit, Allgemeingültigkeit, meistgelehrt\n\n\nPaket laden\nlibrary(),install.packages(), require(), pacman\npacman\nVerkürzt und vereinfacht den Code für die meisten Anwendungsfälle, in denen mehrere Pakete installiert/geladen werden\n\n\nImport und Export\nrio, viele andere Pakete\nrio\nEinfachheit für viele Dateitypen\n\n\nGruppierung für zusammenfassende Statistiken\ndplyr group_by(), stats aggregate()\ndplyr group_by()\nIm Einklang mit tidyverse Schwerpunkt\n\n\nPivotieren\ntidyr (Pivot-Funktionen), reshape2 (Schmelzen/Gießen), tidyr (ausbreiten/sammeln)\ntidyr (Pivot-Funktionen)\nneu formen2 ist im Ruhestand, tidyr verwendet Pivot-Funktionen ab v1.0.0\n\n\nSaubere Spaltennamen\nlinelist, Hausmeister\nHausmeister\nKonsolidierung von Paketen hervorgehoben\n\n\nEpiweeks\nlubridate, aweek, tsibble, zoo\nlubridate allgemein, die anderen für spezielle Fälle\nlubridate’s Flexibilität, Konsistenz, Paketpflege Aussichten\n\n\nggplot-Etiketten\nlabs(), ggtitle()/ylab()/xlab()\nlabs()\nalle Etiketten an einem Ort, Einfachheit\n\n\nIn Faktor umrechnen\nfactor(), forcats\nforcats\nseine verschiedenen Funktionen auch in Faktor umwandeln im gleichen Befehl\n\n\nEpidemische Kurven\nInzidenz, ggplot2, EpiCurve\nInzidenz2 als schnell, ggplot2 wie detailliert\nVerlässlichkeit\n\n\nVerkettung\npaste(), paste0(), str_glue(), glue()\nstr_glue()\nEinfachere Syntax als Einfügefunktionen; innerhalb stringr",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Redaktionelle und technische Hinweise</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.de.html#wichtige-überarbeitungen",
    "href": "new_pages/editorial_style.de.html#wichtige-überarbeitungen",
    "title": "1  Redaktionelle und technische Hinweise",
    "section": "1.3 Wichtige Überarbeitungen",
    "text": "1.3 Wichtige Überarbeitungen\n\n\n\n\n\n\n\nDatum\nWichtige Änderungen\n\n\n\n\n10. Mai 2021\nVeröffentlichung der Version 1.0.0\n\n\n20 Nov 2022\nVeröffentlichung der Version 1.0.1\n\n\n\nNEWS Mit der Version 1.0.1 wurden die folgenden Änderungen eingeführt:\n\nUpdate auf R Version 4.2\nDatenbereinigung: umgestellt {linelist} auf {matchmaker}, unnötige Zeile entfernt aus case_when() Beispiel\nDaten: umgestellt {linelist} guess_date() zu {parsedate} parse_date()\nPivotierung: leichte Aktualisierung auf pivot_wider() id_cols=\nAnalyse der Umfrage: geschaltet plot_age_pyramid() zu age_pyramid() leichte Änderung des Codes für Auenlandschaften\nWärmeplots: hinzugefügt ungroup() zu agg_weeks chunk\nInteraktive Plots: hinzugefügt ungroup() zum Chunk hinzugefügt, der die agg_weeks so dass expand() wie vorgesehen funktioniert\nZeitreihen: hinzugefügt data.frame() um Objekte innerhalb aller trending::fit() und predict() Befehle\nAnalyse der Kombinationen: Switch case_when() zu ifelse() und füge optionale across() Code für die Aufbereitung der Daten\nÜbertragungsketten: Update auf neuere Version von {epicontacts}",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Redaktionelle und technische Hinweise</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.de.html#sitzungsinformationen-r-rstudio-pakete",
    "href": "new_pages/editorial_style.de.html#sitzungsinformationen-r-rstudio-pakete",
    "title": "1  Redaktionelle und technische Hinweise",
    "section": "1.4 Sitzungsinformationen (R, RStudio, Pakete)",
    "text": "1.4 Sitzungsinformationen (R, RStudio, Pakete)\nIm Folgenden findest du Informationen zu den Versionen von R, RStudio und den R-Paketen, die während dieser Ausgabe des Handbuchs verwendet wurden.\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31 ucrt)\n os       Windows 11 x64 (build 22621)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       Europe/Stockholm\n date     2024-02-21\n pandoc   3.1.11 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.2   2023-12-11 [2] CRAN (R 4.3.2)\n digest        0.6.34  2024-01-11 [2] CRAN (R 4.3.2)\n evaluate      0.23    2023-11-01 [2] CRAN (R 4.3.2)\n fastmap       1.1.1   2023-02-24 [2] CRAN (R 4.3.2)\n htmltools     0.5.7   2023-11-03 [2] CRAN (R 4.3.2)\n htmlwidgets   1.6.4   2023-12-06 [2] CRAN (R 4.3.2)\n jsonlite      1.8.8   2023-12-04 [2] CRAN (R 4.3.2)\n knitr         1.45    2023-10-30 [2] CRAN (R 4.3.2)\n rlang         1.1.3   2024-01-10 [2] CRAN (R 4.3.2)\n rmarkdown     2.25    2023-09-18 [2] CRAN (R 4.3.2)\n rstudioapi    0.15.0  2023-07-07 [2] CRAN (R 4.3.2)\n sessioninfo   1.2.2   2021-12-06 [2] CRAN (R 4.3.2)\n xfun          0.42    2024-02-08 [2] CRAN (R 4.3.2)\n\n [1] C:/Users/ngulu864/AppData/Local/R/win-library/4.3\n [2] C:/Program Files/R/R-4.3.2/library\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Redaktionelle und technische Hinweise</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.de.html",
    "href": "new_pages/data_used.de.html",
    "title": "2  Handbuch und Daten herunterladen",
    "section": "",
    "text": "2.1 Offline-Handbuch herunterladen\nDu kannst die Offline-Version dieses Handbuchs als HTML-Datei herunterladen, so dass du die Datei in deinem Webbrowser ansehen kannst, auch wenn du keinen Internetzugang mehr hast. Wenn du die Offline-Nutzung des Epi R-Handbuchs in Betracht ziehst, gibt es einige Dinge zu beachten:\nEs gibt zwei Möglichkeiten, wie du das Handbuch herunterladen kannst:",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Handbuch und Daten herunterladen</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.de.html#offline-handbuch-herunterladen",
    "href": "new_pages/data_used.de.html#offline-handbuch-herunterladen",
    "title": "2  Handbuch und Daten herunterladen",
    "section": "",
    "text": "Wenn du die Datei öffnest, kann es ein oder zwei Minuten dauern, bis die Bilder und das Inhaltsverzeichnis geladen sind.\nDas Offline-Handbuch hat ein etwas anderes Layout - eine sehr lange Seite mit dem Inhaltsverzeichnis auf der linken Seite. Um nach bestimmten Begriffen zu suchen, benutze Strg+f (Cmd-f)\nSiehe die [Vorgeschlagene Pakete] Seite, um dir bei der Installation der passenden R-Pakete zu helfen, bevor du die Internetverbindung verlierst\nInstalliere unser R-Paket epirhandbook das alle Beispieldaten enthält (Installationsprozess unten beschrieben)\n\n\n\nVerwende den Download-Link\nFür schnellen Zugriff, Rechtsklick auf diesen Link und wähle “Link speichern unter”.\nAuf einem Mac klickst du mit Cmd+Klick. Wenn du ein Handy hast, halte den Link gedrückt und wähle “Link speichern”. Das Handbuch wird auf dein Gerät heruntergeladen. Wenn ein Bildschirm mit unbearbeitetem HTML-Code erscheint, vergewissere dich, dass du die obigen Anweisungen befolgt hast, oder versuche Option 2.\n\n\nVerwende unser R-Paket\nWir bieten ein R-Paket namens epirhandbook. Es enthält eine Funktion download_book() die die Handbuchdatei von unserem Github-Repository auf deinen Computer herunterlädt.\nDieses Paket enthält außerdem eine Funktion get_data() die alle Beispieldaten auf deinen Computer herunterlädt.\nFühre den folgenden Code aus, um unser R-Paket zu installieren epirhandbook von der Github-Repository appliedepi. Dieses Paket ist nicht auf CRAN zu finden, also benutze die spezielle Funktion p_install_gh() um es von Github zu installieren.\n\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nLade nun das Paket zur Verwendung in deiner aktuellen R-Sitzung:\n\n# load the package for use\npacman::p_load(epirhandbook)\n\nAls nächstes führst du die Funktion des Pakets aus download_book() (mit leeren Klammern) aus, um das Handbuch auf deinen Computer herunterzuladen. Wenn du dich in RStudio befindest, wird ein Fenster angezeigt, in dem du einen Speicherort auswählen kannst.\n\n# download the offline handbook to your computer\ndownload_book()",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Handbuch und Daten herunterladen</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.de.html#daten-herunterladen-um-mitzumachen",
    "href": "new_pages/data_used.de.html#daten-herunterladen-um-mitzumachen",
    "title": "2  Handbuch und Daten herunterladen",
    "section": "2.2 Daten herunterladen, um mitzumachen",
    "text": "2.2 Daten herunterladen, um mitzumachen\nUm den Handbuchseiten zu folgen, kannst du die Beispieldaten und -ergebnisse herunterladen.\n\nVerwende unser R-Paket\nDer einfachste Weg, alle Daten herunterzuladen, ist die Installation unseres R-Pakets epirhandbook. Es enthält eine Funktion get_data() die alle Beispieldaten in einem Ordner deiner Wahl auf deinem Computer speichert.\nSo installierst du unser R-Paket epirhandbook zu installieren, führe den folgenden Code aus. Dieses Paket ist nicht auf CRAN, also benutze die Funktion p_install_gh() um es zu installieren. Die Eingabe verweist auf unsere Github-Organisation (“appliedepi”) und die epirhandbook Paket.\n\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nLade nun das Paket zur Verwendung in deiner aktuellen R-Sitzung:\n\n# load the package for use\npacman::p_load(epirhandbook)\n\nAls Nächstes verwendest du die Funktion des Pakets get_data() um die Beispieldaten auf deinen Computer herunterzuladen. Führe aus. get_data(\"all\") um die alle oder gib einen bestimmten Dateinamen und eine Erweiterung in Anführungszeichen an, um nur eine Datei abzurufen.\nDie Daten sind bereits mit dem Paket heruntergeladen worden und müssen nur noch in einen Ordner auf deinem Computer übertragen werden. Es erscheint ein Pop-up-Fenster, in dem du einen Speicherort für den Ordner auswählen kannst. Wir empfehlen dir, einen neuen “Daten”-Ordner zu erstellen, da es etwa 30 Dateien gibt (einschließlich Beispieldaten und Beispielausgaben).\n\n# download all the example data into a folder on your computer\nget_data(\"all\")\n\n# download only the linelist example data into a folder on your computer\nget_data(file = \"linelist_cleaned.rds\")\n\n\n# download a specific file into a folder on your computer\nget_data(\"linelist_cleaned.rds\")\n\nSobald du die get_data()verwendet hast, um eine Datei auf deinem Computer zu speichern, musst du sie noch in R importieren. [Importieren und Exportieren] Seite für weitere Informationen.\nWenn du möchtest, kannst du alle in diesem Handbuch verwendeten Daten in der “Daten”-Ordner unseres Github-Repositorys.\n\n\nEinzeln herunterladen\nBei dieser Option lädst du die Daten Datei für Datei aus unserem Github-Repository herunter, entweder über einen Link oder einen R-Befehl für die jeweilige Datei. Bei einigen Dateitypen gibt es einen Download-Button, während andere über einen R-Befehl heruntergeladen werden können.\n\nFall-Lineliste\nDies ist ein fiktiver Ebola-Ausbruch, der vom Handbuch-Team aus dem ebola_sim Praxisdatensatz in der Ausbrüche Paket.\n\nKlicke, um die “rohe” Linienliste (.xlsx) herunterzuladen. Die “rohe” Fallliste ist ein Excel-Tabellenblatt mit unordentlichen Daten. Verwende sie, um die [Daten bereinigen und Kernfunktionen] Seite.\nKlicke, um die “saubere” Linienliste (.rds) herunterzuladen. Verwende diese Datei für alle anderen Seiten dieses Handbuchs, die die Lineliste verwenden. Eine .rds-Datei ist ein R-spezifischer Dateityp, der die Spaltenklassen beibehält. Dadurch wird sichergestellt, dass du nach dem Import der Daten in R nur minimale Bereinigungen vornehmen musst.\n\nAndere verwandte Dateien:\n\nKlicke, um die “saubere” Linienliste als Excel-Datei herunterzuladen\nEin Teil der Reinigungsseite verwendet ein “Reinigungswörterbuch” (.csv-Datei). Du kannst es direkt in R laden, indem du die folgenden Befehle ausführst:\n\n\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\ncleaning_dict &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/cleaning_dict.csv\")\n\n\n\n2.2.0.1 Daten zur Malaria-Zählung {#data_malaria .unnumbered}\nDiese Daten sind fiktive Zählungen von Malariafällen nach Altersgruppe, Einrichtung und Tag. Eine .rds-Datei ist ein R-spezifischer Dateityp, der die Spaltenklassen beibehält. Dadurch wird sichergestellt, dass du nach dem Import der Daten in R nur minimale Bereinigungen vornehmen musst.\n Klicke zum Herunterladen die Malaria-Zählungsdaten (.rds-Datei) \n\n\nDaten auf der Likert-Skala\nDies sind fiktive Daten aus einer Likert-Umfrage, die auf der Seite über [Demografische Pyramiden und Likert-Skalen]. Du kannst diese Daten direkt in R laden, indem du die folgenden Befehle ausführst:\n\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\nlikert_data &lt;- import(\"https://raw.githubusercontent.com/appliedepi/epirhandbook_eng/master/data/likert_data.csv\")\n\n\n\nFlexdashboard\nNachfolgend sind Links zu der Datei, die mit der Seite auf [Dashboards mit R Markdown]:\n\nUm das R Markdown für das Outbreak Dashboard herunterzuladen, klicke mit der rechten Maustaste auf dieses Link (Cmd+Klick für Mac) und wähle “Link speichern unter”.\nUm das HTML-Dashboard herunterzuladen, klicke mit der rechten Maustaste auf dieses Link (Cmd+Klick für Mac) und wähle “Link speichern unter”.\n\n\n\nKontaktverfolgung\nDie Kontaktverfolgung Seite wurde die Analyse von Daten zur Ermittlung von Kontaktpersonen anhand von Beispieldaten ausGo.Data. Die auf der Seite verwendeten Daten können als .rds-Dateien heruntergeladen werden, indem du auf die folgenden Links klickst:\n Klicke zum Herunterladen die Falluntersuchungsdaten (.rds-Datei) \n Klicken Sie zum Herunterladen die Daten der Kontaktregistrierung (.rds-Datei) \n Klick zum Herunterladen die Daten zur Kontaktverfolgung (.rds-Datei) \nHINWEIS: Strukturierte Daten zur Ermittlung von Kontaktpersonen aus anderer Software (z.B. KoBo, DHIS2 Tracker, CommCare) können anders aussehen. Wenn du alternative Beispieldaten oder Inhalte für diese Seite beisteuern möchtest, bitte kontaktiere uns.\nTIPP: Wenn du Go.Data einsetzt und dich mit der API deiner Instanz verbinden willst, lies die Seite Import und Export (Abschnitt API) und die Go.Data Community of Practice.\n\n\nGIS\nShapefiles haben viele Unterdateien, jede mit einer anderen Dateierweiterung. Eine Datei hat die Endung “.shp”, aber andere können “.dbf”, “.prj” usw. haben.\nDie [GIS-Grundlagen] Seite bietet Links zu denHumanitären Datenaustausch Website, wo du die Shapefiles direkt als gezippte Dateien herunterladen kannst.\nZum Beispiel können die Daten der Gesundheitseinrichtungen heruntergeladen werden hier. Lade “hotosm_sierra_leone_health_facilities_points_shp.zip” herunter. Sobald du sie auf deinem Computer gespeichert hast, entpacke den Ordner. Du wirst mehrere Dateien mit unterschiedlichen Erweiterungen sehen (z.B. “.shp”, “.prj”, “.shx”) - diese müssen alle im selben Ordner auf deinem Computer gespeichert werden. Um sie dann in R zu importieren, gibst du den Dateipfad und den Namen der “.shp”-Datei an st_read() aus dem sfPaket (wie in den [GIS-Grundlagen] Seite beschrieben).\nWenn du Option 1 folgst, um alle Beispieldaten herunterzuladen (über unser R-Paket epirhandbook), sind alle Shapefiles enthalten.\nAlternativ kannst du die Shapefiles auch aus dem “data”-Ordner des R-Handbuchs auf Github herunterladen (siehe den Unterordner “gis”). Beachte jedoch, dass du die Shapefiles herunterladen musst jede Unterdateien einzeln auf deinen Computer herunterladen musst. Klicke in Github auf jede einzelne Datei und lade sie herunter, indem du auf die Schaltfläche “Herunterladen” klickst. Unten siehst du, wie das Shapefile “sle_adm3” aus vielen Dateien besteht, von denen jede einzelne von Github heruntergeladen werden muss.\n\n\n\n\n\n\n\n\n\n\n\nPhylogenetische Bäume\nSiehe die Seite über Phylogenetische Bäume. Newick-Datei des phylogenetischen Baums, der aus der Sequenzierung des gesamten Genoms von 299 Shigella sonnei-Proben und den entsprechenden Probendaten (in eine Textdatei konvertiert) erstellt wurde. Die belgischen Proben und die daraus resultierenden Daten wurden freundlicherweise vom belgischen NRC für Salmonellen und Shigellen im Rahmen eines von einem ECDC EUPHEM Fellow durchgeführten Projekts zur Verfügung gestellt und werden ebenfalls in einem Manuskript veröffentlicht. Die internationalen Daten sind in öffentlichen Datenbanken (ncbi) frei zugänglich und wurden bereits veröffentlicht.\n\nUm die phylogenetische Baumdatei “Shigella_tree.txt” herunterzuladen, rechtsklicke auf diese Link (Cmd+Klick für Mac) und wähle “Link speichern unter”.\nUm die Datei “sample_data_Shigella_tree.csv” mit zusätzlichen Informationen zu jeder Probe herunterzuladen, rechtsklicke auf diesen Link (Cmd+Klick für Mac) und wähle “Link speichern unter”.\nUm den neu erstellten Untergruppenbaum zu sehen, klicke mit der rechten Maustaste auf diesen Link (Cmd+Klick für Mac) und wähle “Link speichern unter”. Die .txt-Datei wird dann auf deinen Computer heruntergeladen.\n\nDu kannst die .txt-Dateien dann importieren mit read.tree() aus dem ape Paket, wie auf der Seite erklärt.\n\nape::read.tree(\"Shigella_tree.txt\")\n\n\n\nStandardisierung\nSiehe die Seite über [Standardisierte Tarife]. Du kannst die Daten direkt aus unserem Github-Repository im Internet mit den folgenden Befehlen in deine R-Sitzung laden:\n\n# install/load the rio package\npacman::p_load(rio) \n\n##############\n# Country A\n##############\n# import demographics for country A directly from Github\nA_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n##############\n# Country B\n##############\n# import demographics for country B directly from Github\nB_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n\n###############\n# Reference Pop\n###############\n# import demographics for country B directly from Github\nstandard_pop_data &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\n\n\n2.2.0.2 Zeitreihen und Erkennung von Ausbrüchen {#data_outbreak .unnumbered}\nSiehe die Seite über [Zeitreihen und Ausbruchserkennung]. Wir verwenden die in Deutschland 2002-2011 gemeldeten Campylobacter-Fälle, die von derÜberwachung R-Paket. (nb. Dieser Datensatz wurde gegenüber dem Original angepasst, indem 3 Monate der Daten von Ende 2011 zu Demonstrationszwecken gelöscht wurden)\n Zum Herunterladen klicken  Campylobacter in Deutschland (.xlsx) \nWir verwenden auch Klimadaten aus Deutschland von 2002-2011 (Temperatur in Grad Celsius und Niederschlag in Millimetern). Diese wurden aus dem Copernicus-Satelliten-Reanalysedatensatz der EU heruntergeladen, indem die ecmwfr Paket heruntergeladen. Du musst alle diese Daten herunterladen und sie mit stars::read_stars() importieren, wie auf der Seite Zeitreihen erklärt.\n Klicke zum Herunterladen  Deutschland Wetter 2002 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2003 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2004 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2005 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2006 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2007 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2008 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2009 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2010 (.nc Datei) \n Klicken Sie zum Herunterladen  Deutschland Wetter 2011 (.nc Datei) \n\n\n2.2.0.3 Umfrage-Analyse {#data_survey .unnumbered}\nFür die Umfrage-Analyse Seite verwenden wir fiktive Mortalitätserhebungsdaten, die auf MSF OCA-Erhebungsvorlagen basieren. Diese fiktiven Daten wurden im Rahmen der “R4Epis”-Projekts.\n Klicken Sie zum Herunterladen  Fiktive Erhebungsdaten (.xlsx) \n Hier klicken zum Herunterladen  Wörterbuch der fiktiven Umfragedaten (.xlsx) \n Zum Herunterladen klicken  Fiktive Umfrage Bevölkerungsdaten (.xlsx) \n\n\n2.2.0.4 Glänzend {#data_shiny .unnumbered}\nDie Seite über [Dashboards mit Shiny] demonstriert den Aufbau einer einfachen App zur Anzeige von Malaria-Daten.\nUm die R-Dateien herunterzuladen, die die Shiny-App erzeugen:\nDu kannst  hier klicken, um die app.R Datei herunterzuladen herunterzuladen, die sowohl den UI- als auch den Server-Code für die Shiny-App enthält.\nDu kannst  hier klicken, um die Datei facility_count_data.rds herunterzuladen herunterzuladen, die Malaria-Daten für die Shiny-App enthält. Beachte, dass du sie eventuell in einem “data”-Ordner speichern musst, damit die here()-Dateipfade richtig funktionieren.\nDu kannst  hier klicken, um die Datei global.R herunterzuladen die vor dem Öffnen der App ausgeführt werden sollte, wie auf der Seite erklärt.\nDu kannst  hier klicken, um die Datei plot_epicurve.R herunterzuladen die von global.R stammt. Beachte, dass du sie eventuell in einem “funcs”-Ordner speichern musst, damit die here()-Dateipfade richtig funktionieren.",
    "crumbs": [
      "Über dieses Buch",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Handbuch und Daten herunterladen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html",
    "href": "new_pages/basics.de.html",
    "title": "3  R Grundlagen",
    "section": "",
    "text": "3.1 Warum R benutzen?\nWie auf der Website R-Projekt-Website ist R eine Programmiersprache und Umgebung für statistische Berechnungen und Grafiken. Sie ist sehr vielseitig, erweiterbar und wird von der Gemeinschaft getragen.\nKosten\nDie Nutzung von R ist kostenlos! In der Community gibt es eine starke Ethik für kostenloses und quelloffenes Material.\nReproduzierbarkeit\nWenn du deine Datenverwaltung und -analyse in einer Programmiersprache durchführst (im Vergleich zu Excel oder einem anderen primär auf Mausklicks basierenden/manuellen Tool), verbessert sich Reproduzierbarkeit macht Fehlererkennung und erleichtert dir die Arbeit.\nGemeinschaft\nDie R-Nutzergemeinschaft ist riesig und kooperativ. Täglich werden neue Pakete und Werkzeuge zur Lösung von realen Problemen entwickelt und von der Nutzergemeinschaft geprüft. Ein Beispiel, R-Ladies ist eine weltweite Organisation, die es sich zur Aufgabe gemacht hat, die Geschlechtervielfalt in der R-Gemeinschaft zu fördern. Sie ist eine der größten Organisationen von R-Nutzern. Wahrscheinlich gibt es auch eine Ortsgruppe in deiner Nähe!",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#schlüsselbegriffe",
    "href": "new_pages/basics.de.html#schlüsselbegriffe",
    "title": "3  R Grundlagen",
    "section": "3.2 Schlüsselbegriffe",
    "text": "3.2 Schlüsselbegriffe\nRStudio - RStudio ist eine grafische Benutzeroberfläche (GUI) zur einfacheren Nutzung von R. Mehr lesen im Abschnitt RStudio.\nObjekte - Alles, was du in R speicherst - Datensätze, Variablen, eine Liste von Ortsnamen, eine Gesamtbevölkerungszahl, sogar Ausgaben wie Diagramme - sind Objekte die einen Namen zugewiesen bekommen und kann referenziert werden in späteren Befehlen. Mehr lesen im Abschnitt Objekte.\nFunktionen - Eine Funktion ist eine Code-Operation, die Eingaben akzeptiert und eine transformierte Ausgabe zurückgibt. Mehr lesen im Abschnitt Funktionen.\nPakete - Ein R-Paket ist ein gemeinsam nutzbares Bündel von Funktionen. Mehr lesen im Abschnitt Pakete.\nSkripte - Ein Skript ist eine Dokumentendatei, die deine Befehle enthält. Mehr lesen im Abschnitt Skripte",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#learning",
    "href": "new_pages/basics.de.html#learning",
    "title": "3  R Grundlagen",
    "section": "3.3 Ressourcen zum Lernen",
    "text": "3.3 Ressourcen zum Lernen\n\nRessourcen innerhalb von RStudio\nHilfe-Dokumentation\nAuf der Registerkarte “Hilfe” von RStudio findest du die Dokumentation zu R-Paketen und bestimmten Funktionen. Diese befindet sich in dem Bereich, der auch Dateien, Diagramme und Pakete enthält (normalerweise im unteren rechten Bereich). Als Abkürzung kannst du auch den Namen eines Pakets oder einer Funktion nach einem Fragezeichen in die R-Konsole eingeben, um die entsprechende Hilfeseite zu öffnen. Setze keine Klammern.\nZum Beispiel: ?filter oder ?diagrammeR.\nInteraktive Tutorials\nEs gibt mehrere Möglichkeiten, R interaktiv zu lernen innerhalb von RStudio.\nRStudio selbst bietet ein Tutorial-Fenster, das von der learnr R-Paket. Installiere einfach dieses Paket und öffne ein Tutorial über die neue Registerkarte “Tutorial” in der oberen rechten RStudio-Leiste (die auch die Registerkarten Umgebung und Verlauf enthält).\nDas R-Paket swirl bietet interaktive Kurse in der R-Konsole an. Installiere und lade dieses Paket und führe dann den Befehl swirl() (leere Klammern) in der R-Konsole aus. Du wirst sehen, dass in der Konsole Eingabeaufforderungen erscheinen. Reagiere, indem du in der Konsole tippst. Sie wird dich durch einen Kurs deiner Wahl führen.\n\n\nCheatsheets\nEs gibt viele PDF-“Cheatsheets” auf der Website RStudio-Website zum Beispiel:\n\nFaktoren mit forcats paket\nTermine und Zeiten mit lubridate paket\nSchnüre mit stringr paket\niterative Operationen mit purrr Paket\nDatenimport\\\nDatenumwandlung Cheatsheet mit dplyr paket\nR Markdown (zum Erstellen von Dokumenten wie PDF, Word, Powerpoint…)\\\nShiny (um interaktive Webanwendungen zu erstellen)\\\nDatenvisualisierung mit ggplot2 paket\nKartographie (GIS)\\\nMerkblatt Paket (interaktive Karten)\\\nPython mit R (netzartig Paket)\n\nDies ist eine Online-Ressource speziell für Excel-Benutzer\n\n\nTwitter\nR hat eine lebendige Twitter-Community, in der du Tipps, Abkürzungen und Neuigkeiten erfahren kannst - folge diesen Accounts:\n\nFolge uns! @epiRhandbook\\\nR Funktion A Tag @rfuntionaday ist eine unglaubliche Ressource\\\nR für Datenwissenschaft @rstats4ds\\\nRStudio @RStudio\\\nRStudio Tipps @rstudiotips\\\nR-Blogger @Rbloggers\\\nR-Ladies @RLadiesGlobal\\\nHadley Wickham @hadleywickham\n\nAuch:\n#epitwitter und #rstats\n\n\nKostenlose Online-Ressourcen\nEin maßgeblicher Text ist das R für Datenwissenschaft Buch von Garrett Grolemund und Hadley Wickham\nDie R4Epis Projekt-Website zielt darauf ab, “standardisierte Tools zur Datenbereinigung, -analyse und -berichterstattung zu entwickeln, die gängige Arten von Ausbrüchen und bevölkerungsbasierten Erhebungen abdecken, die in einem MSF-Notfallszenario durchgeführt werden”. Du findest dort R-Grundlagen-Schulungsmaterial, Vorlagen für RMarkdown-Berichte über Ausbrüche und Erhebungen sowie Tutorials, die dir bei der Einrichtung helfen.\n\n\nAndere Sprachen als Englisch\nMateriales de RStudio en Español\nEinführung in R und Tidyverse (französisch)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#installation",
    "href": "new_pages/basics.de.html#installation",
    "title": "3  R Grundlagen",
    "section": "3.4 Installation",
    "text": "3.4 Installation\n\nR und RStudio\nWie man R installiert\nBesuche diese Website https://www.r-project.org/ und lade die neueste Version von R herunter, die für deinen Computer geeignet ist.\nSo installierst du RStudio\nBesuche diese Website https://rstudio.com/products/rstudio/download/ und lade die neueste kostenlose Desktop-Version von RStudio herunter, die für deinen Computer geeignet ist.\nBerechtigungen\nBeachte, dass du R und RStudio auf einem Laufwerk installieren solltest, auf dem du Lese- und Schreibrechte hast. Andernfalls wird deine Fähigkeit, R-Pakete zu installieren (was häufig vorkommt), beeinträchtigt. Wenn du Probleme hast, versuche RStudio zu öffnen, indem du mit der rechten Maustaste auf das Symbol klickst und “Als Administrator ausführen” auswählst. Weitere Tipps findest du auf der Seite [R auf Netzlaufwerken].\nWie man R und RStudio aktualisiert\nDeine Version von R wird beim Start in der R-Konsole angezeigt. Du kannst auch Folgendes ausführen sessionInfo().\nUm R zu aktualisieren, besuche die oben genannte Website und installiere R neu. Alternativ kannst du die installr Paket (unter Windows) verwenden, indem du installr::updateR(). Dadurch werden Dialogfelder geöffnet, die dir helfen, die neueste R-Version herunterzuladen und deine Pakete auf die neue R-Version zu aktualisieren. Weitere Details findest du in der installr Dokumentation.\nSei dir bewusst, dass die alte R-Version noch auf deinem Computer vorhanden sein wird. Du kannst vorübergehend eine ältere Version (ältere “Installation”) von R ausführen, indem du in RStudio auf “Extras” -&gt; “Globale Optionen” klickst und eine R-Version auswählst. Das kann nützlich sein, wenn du ein Paket verwenden möchtest, das noch nicht für die neueste Version von R aktualisiert wurde.\nUm RStudio zu aktualisieren, kannst du auf die oben genannte Website gehen und RStudio erneut herunterladen. Eine andere Möglichkeit ist, in RStudio auf “Hilfe” -&gt; “Nach Updates suchen” zu klicken, aber das zeigt möglicherweise nicht die allerneuesten Updates an.\nUm zu sehen, welche Versionen von R, RStudio oder Paketen verwendet wurden, als dieses Handbuch erstellt wurde, schaue auf der Seite [Redaktionelle und technische Hinweise].\n\n\nAndere Software, die du kann installieren musst\n\nTinyTeX (zum Kompilieren eines RMarkdown-Dokuments in PDF)\\\nPandoc (zum Kompilieren von RMarkdown-Dokumenten)\\\nRTools (zum Erstellen von Paketen für R)\\\nphantomjs (zum Speichern von Standbildern von animierten Netzwerken, wie z.B. Übertragungsketten)\n\n\nTinyTex\nTinyTex ist eine benutzerdefinierte LaTeX-Distribution, die nützlich ist, wenn du PDFs aus R erstellen willst.\nSiehe https://yihui.org/tinytex/ für weitere Informationen.\nSo installierst du TinyTex aus R:\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n# to uninstall TinyTeX, run tinytex::uninstall_tinytex()\n\n\n\nPandoc\nPandoc ist ein Dokumentenkonverter, eine von R unabhängige Software. Sie ist im Lieferumfang von RStudio enthalten und muss nicht heruntergeladen werden. Es hilft bei der Konvertierung von Rmarkdown-Dokumenten in Formate wie .pdf und fügt komplexe Funktionen hinzu.\n\n\nRTools\nRTools ist eine Sammlung von Software zum Erstellen von Paketen für R\nInstalliere von dieser Website: https://cran.r-project.org/bin/windows/Rtools/\n\n\nphantomjs\nDies wird oft verwendet, um “Screenshots” von Webseiten zu machen. Wenn du zum Beispiel eine Übertragungskette mit epicontacts Paket eine Übertragungskette erstellst, wird eine HTML-Datei erzeugt, die interaktiv und dynamisch ist. Wenn du ein statisches Bild möchtest, kann es sinnvoll sein, die webshot Paket, um diesen Prozess zu automatisieren. Dazu wird das externe Programm “phantomjs” benötigt. Installieren kannst du phantomjs über die Webshot Paket mit dem Befehl webshot::install_phantomjs().",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#rstudio",
    "href": "new_pages/basics.de.html#rstudio",
    "title": "3  R Grundlagen",
    "section": "3.5 RStudio",
    "text": "3.5 RStudio\n\nRStudio Orientierung\nÖffne zunächst RStudio. Da die Icons sehr ähnlich aussehen können, solltest du sicherstellen, dass du das RStudio und nicht R.\nDamit RStudio funktioniert, musst du auch R auf dem Computer installiert haben (siehe oben für die Installationsanweisungen).\nRStudio ist eine Schnittstelle (GUI) zur einfacheren Nutzung von R. Du kannst dir R als den Motor eines Fahrzeugs vorstellen, der die entscheidende Arbeit leistet, und RStudio als die Karosserie des Fahrzeugs (mit Sitzen, Zubehör usw.), die dir hilft, den Motor tatsächlich zu nutzen, um vorwärts zu kommen! Hier findest du den kompletten RStudio-Benutzeroberflächen-Spickzettel (PDF) hier\nIn der Standardeinstellung zeigt RStudio vier rechteckige Fenster an.\n\n\n\n\n\n\n\n\n\n[TIPP: Wenn dein RStudio nur einen linken Bereich anzeigt, liegt das daran, dass du noch keine Skripte geöffnet hast].{style=“color: black;”}\nDas Fenster “Quelle\nIn diesem Bereich, der sich standardmäßig oben links befindet, kannst du deine Daten bearbeiten, ausführen und speichern. Skripte. Skripte enthalten die Befehle, die du ausführen willst. In diesem Bereich können auch Datensätze (Datenrahmen) zur Ansicht angezeigt werden.\nFür Stata-Benutzer ist dieser Bereich ähnlich wie die Fenster Do-file und Data Editor.\nDas R-Konsolen-Fenster\nDie R-Konsole, standardmäßig das linke oder untere linke Fenster in R Studio, ist die Heimat der R-“Engine”. Hier werden die Befehle tatsächlich ausgeführt und nicht-grafische Ausgaben sowie Fehler- und Warnmeldungen angezeigt. Du kannst Befehle direkt in die R-Konsole eingeben und ausführen, aber beachte, dass diese Befehle nicht gespeichert werden, wie es bei der Ausführung von Befehlen aus einem Skript der Fall ist.\nWenn du mit Stata vertraut bist, ist die R-Konsole wie das Befehlsfenster und auch das Ergebnisfenster.\nDas Umgebungsfenster\nDieser Bereich, der sich standardmäßig oben rechts befindet, wird am häufigsten verwendet, um kurze Zusammenfassungen von Objekten in der R-Umgebung in der aktuellen Sitzung. Zu diesen Objekten gehören importierte, geänderte oder erstellte Datensätze, Parameter, die du definiert hast (z. B. eine bestimmte Epi-Woche für die Analyse), oder Vektoren oder Listen, die du während der Analyse definiert hast (z. B. Namen von Regionen). Du kannst auf den Pfeil neben dem Namen eines Datenrahmens klicken, um seine Variablen zu sehen.\nIn Stata ähnelt dies am meisten dem Fenster Variablenmanager.\nDieses Fenster enthält auch Verlauf wo du die Befehle sehen kannst, die du zuvor ausgeführt hast. Es gibt auch eine Registerkarte “Tutorial”, auf der du interaktive R-Tutorials absolvieren kannst, wenn du die learnr Paket installiert hast. Außerdem gibt es einen Bereich “Verbindungen” für externe Verbindungen und einen Bereich “Git”, wenn du dich für eine Schnittstelle zu Github entscheidest.\nPlots, Viewer, Pakete und Hilfefenster\nDer Bereich unten rechts enthält mehrere wichtige Registerkarten. Typische Plot-Grafiken, einschließlich Karten, werden im Plot-Fenster angezeigt. Interaktive oder HTML-Ausgaben werden im Viewer-Fenster angezeigt. Das Hilfe-Fenster zeigt Dokumentation und Hilfedateien an. Das Dateifenster ist ein Browser, mit dem du Dateien öffnen oder löschen kannst. Im Bereich Pakete kannst du R-Pakete anzeigen, installieren, aktualisieren, löschen, laden/entladen und sehen, welche Version des Pakets du hast. Mehr über Pakete erfährst du in der Abschnitt Pakete unten.\nDieser Bereich enthält die Stata-Äquivalente der Fenster Plots Manager und Project Manager.\n\n\nRStudio-Einstellungen\nÄndern Sie die RStudio-Einstellungen und das Aussehen in der Werkzeuge Dropdown-Menü, indem du wählst Globale Optionen. Dort kannst du die Standardeinstellungen ändern, einschließlich Aussehen/Hintergrundfarbe.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nneu starten\nWenn dein R einfriert, kannst du R neu starten, indem du im Menü Sitzung auf “R neu starten” klickst. Das erspart dir das lästige Schließen und Öffnen von RStudio. Dabei wird alles in deiner R-Umgebung gelöscht.\n\n\nTastaturkürzel\nIm Folgenden findest du einige sehr nützliche Tastenkombinationen. Alle Tastaturkürzel für Windows, Max und Linux findest du auf der zweiten Seite dieses RStudio Spickzettel für die Benutzeroberfläche.\n+———————————-+————————+——————————————————————————————————————————–+ | Windows/Linux | Mac | Action | +==================================+========================+================================================================================================================================+ | Esc | Esc | Aktuellen Befehl unterbrechen (nützlich, wenn du versehentlich einen unvollständigen Befehl ausgeführt hast und in der R-Konsole kein “+” sehen kannst) | +———————————-+————————+——————————————————————————————————————————–+ | Strg+s | Cmd+s | Speichern (Skript) | +———————————-+————————+——————————————————————————————————————————–+ | Tab | Tabulator | Auto-Vervollständigen | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Enter | Cmd + Enter | Aktuelle Zeile(n)/Auswahl des Codes ausführen | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Umschalt + C | Cmd + Umschalt + c | die markierten Zeilen kommentieren/unkommentieren | +———————————-+————————+——————————————————————————————————————————–+ | Alt + - | Option + - | Einfügen &lt;- | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Umschalt + m | Cmd + Umschalt + m | Einfügen %&gt;% | +———————————-+————————+——————————————————————————————————————————–+ | Strg + l | Cmd + l | Löschen der R-Konsole | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Alt + b | Cmd + Option + b | Vom Anfang bis zur aktuellen Zeile laufen | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Alt + t | Cmd + Option + t | Den aktuellen Codeabschnitt ausführen (R Markdown) | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Alt + i | Cmd + Shift + r | Codeabschnitt einfügen (in R Markdown) | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Alt + c | Cmd + Option + c | Aktuelles Code-Stück ausführen (R Markdown) | +———————————-+————————+——————————————————————————————————————————–+ | Pfeile nach oben/unten in der R-Konsole | Dasselbe | Umschalten zwischen den zuletzt ausgeführten Befehlen | +———————————-+————————+——————————————————————————————————————————–+ | Umschalttaste + Pfeile nach oben/unten im Skript | Dasselbe | Mehrere Codezeilen auswählen | +———————————-+————————+——————————————————————————————————————————–+ | Strg + f | Cmd + f | Suchen und Ersetzen im aktuellen Skript | +———————————-+————————+——————————————————————————————————————————–+ | Strg + Umschalt + f | Cmd + Umschalt + f | Suchen in Dateien (Suchen/Ersetzen über viele Skripte hinweg) | +———————————-+————————+——————————————————————————————————————————–+ | Alt + l | Cmd + Option + l | Ausgewählten Code einklappen | +———————————-+————————+——————————————————————————————————————————–+ | Shift + Alt + l | Cmd + Shift + Option+l | Ausgewählten Code aufklappen | +———————————-+————————+——————————————————————————————————————————–+\n[TIPP: Benutze beim Tippen die Tabulatortaste, um die Autovervollständigungsfunktion von RStudio zu aktivieren. So kannst du Rechtschreibfehler vermeiden. Drücke beim Tippen die Tabulatortaste, um ein Dropdown-Menü mit wahrscheinlichen Funktionen und Objekten anzuzeigen, die auf dem basieren, was du bisher getippt hast].{style=“color: darkgreen;”}",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#functions",
    "href": "new_pages/basics.de.html#functions",
    "title": "3  R Grundlagen",
    "section": "3.6 Funktionen",
    "text": "3.6 Funktionen\nFunktionen sind das Herzstück von R. Mit Funktionen führst du Aufgaben und Operationen aus. Viele Funktionen werden mit R installiert, viele weitere stehen zum Download bereit in Pakete (erklärt in der Pakete Abschnitt), und du kannst sogar deine eigenen Funktionen schreiben!\nDieser Grundlagenabschnitt über Funktionen erklärt:\n\nWas eine Funktion ist und wie sie funktioniert.\nWelche Funktion Argumente sind?\nWie du Hilfe zum Verständnis einer Funktion bekommst\n\nEin kurzer Hinweis zur Syntax: In diesem Handbuch werden die Funktionen in Code-Text mit offenen Klammern geschrieben, etwa so: filter(). Wie in der Pakete erklärt, werden die Funktionen innerhalb von Pakete. In diesem Handbuch werden die Paketnamen in fett, wie dplyr. Manchmal wird im Beispielcode der Funktionsname explizit mit dem Namen des Pakets verknüpft und mit zwei Doppelpunkten (::) wie hier: dplyr::filter(). Der Zweck dieser Verknüpfung wird im Abschnitt über Pakete erklärt.\n\n\nEinfache Funktionen\nEine Funktion ist wie eine Maschine, die Eingaben erhält, mit diesen Eingaben eine Aktion durchführt und eine Ausgabe erzeugt. Was die Ausgabe ist, hängt von der Funktion ab.\nFunktionen wirken in der Regel auf ein Objekt, das innerhalb der Klammern der Funktion steht. Zum Beispiel kann die Funktion sqrt() berechnet die Quadratwurzel aus einer Zahl:\n\nsqrt(49)\n\n[1] 7\n\n\nDas Objekt, das einer Funktion übergeben wird, kann auch eine Spalte in einem Datensatz sein (siehe die Objekte Abschnitt für weitere Informationen zu allen Arten von Objekten). Da R mehrere Datasets speichern kann, musst du sowohl das Dataset als auch die Spalte angeben. Eine Möglichkeit, dies zu tun, ist die Verwendung der $ Notation, um den Namen des Datensatzes und den Namen der Spalte zu verknüpfen (dataset$column). Im folgenden Beispiel wird die Funktion summary() auf die numerische Spalte angewendet age im Datensatz linelist und die Ausgabe ist eine Zusammenfassung der numerischen und fehlenden Werte der Spalte.\n\n# Print summary statistics of column 'age' in the dataset 'linelist'\nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n\n[HINWEIS: Hinter den Kulissen stellt eine Funktion komplexen zusätzlichen Code dar, der für den Benutzer in einen einfachen Befehl verpackt wurde].{style=“color: black;”}\n\n\n\nFunktionen mit mehreren Argumenten\nFunktionen fragen oft nach mehreren Eingaben, genannt Argumente Die Argumente befinden sich in den Klammern der Funktion, normalerweise durch Kommas getrennt.\n\nEinige Argumente sind erforderlich, damit die Funktion richtig funktioniert, andere sind optional.\nOptionale Argumente haben Standardeinstellungen\\\nArgumente können Zeichen, Zahlen, Logik (TRUE/FALSE) und andere Eingaben annehmen.\n\nHier ist eine lustige fiktive Funktion, die oven_bake() als Beispiel für eine typische Funktion. Sie nimmt ein Eingabeobjekt (z. B. einen Datensatz oder in diesem Beispiel “Teig”) und führt darauf Operationen aus, die durch zusätzliche Argumente (minutes = und temperature =). Die Ausgabe kann auf der Konsole ausgegeben oder mit dem Zuweisungsoperator als Objekt gespeichert werden &lt;-.\n\n\n\n\n\n\n\n\n\nEin realistischeres Beispiel ist die age_pyramid() Befehl erzeugt eine Alterspyramide, die auf definierten Altersgruppen und einer binären Split-Spalte basiert, wie z. B. gender. Die Funktion erhält drei Argumente in Klammern, die durch Kommas getrennt sind. Die Werte, die den Argumenten übergeben werden, bestimmen linelist als den zu verwendenden Datenrahmen, age_cat5 als die zu zählende Spalte und gender als Binärspalte, die für die Aufteilung der Pyramide nach Farbe verwendet wird.\n\n# Create an age pyramid\nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n\n\n\n\n\n\n\n\nDer obige Befehl kann auch wie folgt geschrieben werden, allerdings in einem längeren Stil mit einer neuen Zeile für jedes Argument. Dieser Stil ist leichter zu lesen und es ist einfacher, “Kommentare” zu schreiben mit # zu schreiben, um jeden Teil zu erklären (ausführliche Kommentare sind eine gute Praxis!). Um diesen längeren Befehl auszuführen, kannst du den gesamten Befehl markieren und auf “Ausführen” klicken oder du platzierst den Cursor in der ersten Zeile und drückst dann gleichzeitig die Tasten Strg und Enter.\n\n# Create an age pyramid\nage_pyramid(\n  data = linelist,        # use case linelist\n  age_group = \"age_cat5\", # provide age group column\n  split_by = \"gender\"     # use gender column for two sides of pyramid\n  )\n\n\n\n\n\n\n\n\nDie erste Hälfte einer Argumentzuweisung (z.B. data =) muss nicht angegeben werden, wenn die Argumente in einer bestimmten Reihenfolge geschrieben werden (die in der Dokumentation der Funktion angegeben ist). Der folgende Code erzeugt genau die gleiche Pyramide wie oben, weil die Funktion die Argumentreihenfolge erwartet: Datenrahmen, age_group Variable, split_by Variable.\n\n# This command will produce the exact same graphic as above\nage_pyramid(linelist, \"age_cat5\", \"gender\")\n\nEine komplexere age_pyramid() Befehl könnte die optional Argumente zu:\n\nProportionen anstelle von Zählungen anzeigen (setzen proportional = TRUE wenn der Standardwert FALSE)\\\nLegen Sie die beiden zu verwendenden Farben fest (pal = ist die Abkürzung für “Palette” und wird mit einem Vektor aus zwei Farbnamen geliefert. Siehe die Objekte Seite, wie die Funktion c() einen Vektor erzeugt)\n\n[HINWEIS: Bei Argumenten, die du mit beiden Teilen des Arguments angibst (z. B. proportional = TRUE), spielt ihre Reihenfolge unter allen Argumenten keine Rolle].{style=“color: black;”}\n\nage_pyramid(\n  linelist,                    # use case linelist\n  \"age_cat5\",                  # age group column\n  \"gender\",                    # split by gender\n  proportional = TRUE,         # percents instead of counts\n  pal = c(\"orange\", \"purple\")  # colors\n  )\n\n\n\n\n\n\n\n\n\n\n\nFunktionen schreiben\nR ist eine Sprache, die sich an Funktionen orientiert. Du solltest dich also befähigt fühlen, deine eigenen Funktionen zu schreiben. Das Erstellen von Funktionen bringt mehrere Vorteile mit sich:\n\nSie erleichtern die modulare Programmierung - die Aufteilung des Codes in unabhängige und überschaubare Teile.\nErsetzt das wiederholte Kopieren und Einfügen, das fehleranfällig sein kann\\\nGib Teilen des Codes einprägsame Namen\n\nWie man eine Funktion schreibt, wird ausführlich in der Funktionen schreiben Seite.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#packages",
    "href": "new_pages/basics.de.html#packages",
    "title": "3  R Grundlagen",
    "section": "3.7 Pakete",
    "text": "3.7 Pakete\nPakete enthalten Funktionen.\nEin R-Paket ist ein gemeinsam nutzbares Bündel aus Code und Dokumentation, das vordefinierte Funktionen enthält. Die Nutzer der R-Gemeinschaft entwickeln ständig Pakete für bestimmte Probleme. Es ist sehr wahrscheinlich, dass eines davon dir bei deiner Arbeit helfen kann! Du wirst Hunderte von Paketen installieren und verwenden, wenn du R benutzt.\nBei der Installation enthält R “base” Pakete und Funktionen, die allgemeine elementare Aufgaben erledigen. Viele R-Benutzer erstellen jedoch spezielle Funktionen, die von der R-Gemeinschaft überprüft werden und die du als Paket herunterladen kannst. Paket für deinen eigenen Gebrauch herunterladen kannst. In diesem Handbuch werden die Paketnamen in fett. Einer der schwierigeren Aspekte von R ist, dass es oft viele Funktionen oder Pakete gibt, aus denen du wählen kannst, um eine bestimmte Aufgabe zu erledigen.\n\nInstallieren und laden\nFunktionen sind enthalten in Paketen die aus dem Internet auf deinen Computer heruntergeladen (“installiert”) werden können. Sobald ein Paket heruntergeladen ist, wird es in deiner “Bibliothek” gespeichert. Du kannst dann während deiner aktuellen R-Sitzung auf die darin enthaltenen Funktionen zugreifen, indem du das Paket “lädst”.\nStell dir R als deine persönliche Bibliothek vor Wenn du ein Paket herunterlädst, erhält deine Bibliothek ein neues Buch mit Funktionen, aber jedes Mal, wenn du eine Funktion aus diesem Buch benutzen willst, musst du dieses Buch aus deiner Bibliothek ausleihen (“laden”).\nKurz gesagt: Um die Funktionen in einem R-Paket zu nutzen, müssen 2 Schritte durchgeführt werden:\n\nDas Paket muss installiert (einmal), und\\\nDas Paket muss geladen werden (jede R-Sitzung)\n\n\nDeine Bibliothek\nDeine “Bibliothek” ist eigentlich ein Ordner auf deinem Computer, der einen Ordner für jedes installierte Paket enthält. Finde heraus, wo R auf deinem Computer installiert ist, und suche nach einem Ordner namens “win-library”. Zum Beispiel: R\\win-library\\4.0 (die 4.0 ist die R-Version - für jede R-Version, die du heruntergeladen hast, hast du eine andere Bibliothek).\nDu kannst den Dateipfad zu deiner Bibliothek ausgeben, indem du eingibst .libPaths()(leere Klammern). Dies ist besonders wichtig, wenn du mit [R auf Netzlaufwerken].\n\n\nVon CRAN installieren\nAm häufigsten laden R-Nutzer Pakete von CRAN herunter. CRAN (Comprehensive R Archive Network) ist ein öffentliches Online-Lager für R-Pakete, die von Mitgliedern der R-Community veröffentlicht wurden.\nMachst du dir Sorgen über Viren und Sicherheit, wenn du ein Paket von CRAN herunterlädst? Lies diesen Artikel zu diesem Thema.\n\n\nWie man installiert und lädt\nIn diesem Handbuch empfehlen wir die Verwendung des pacman Paket (kurz für “Paketmanager”). Es bietet eine praktische Funktion p_load() die bei Bedarf ein Paket installiert und für die Verwendung in der aktuellen R-Sitzung lädt.\nDie Syntax ist ganz einfach. Du listest einfach die Namen der Pakete innerhalb der p_load() Klammern auf, getrennt durch Kommas. Dieser Befehl installiert die rio, tidyverse, und hier Pakete, wenn sie noch nicht installiert sind, und lädt sie zur Verwendung. Dies macht die p_load() Ansatz bequem und übersichtlich, wenn du Skripte mit anderen teilst. Beachte, dass bei den Paketnamen zwischen Groß- und Kleinschreibung unterschieden wird.\n\n# Install (if necessary) and load packages for use\npacman::p_load(rio, tidyverse, here)\n\nBeachte, dass wir die folgende Syntax verwendet haben pacman::p_load() verwendet haben, die den Paketnamen explizit schreibt (pacman) vor dem Funktionsnamen (p_load()), verbunden durch zwei Doppelpunkte ::. Diese Syntax ist nützlich, weil sie auch die pacman Paket lädt (vorausgesetzt, es ist bereits installiert).\nEs gibt alternative Basis R-Funktionen, die du oft sehen wirst. Die base R-Funktion für die Installation eines Pakets ist install.packages(). Der Name des zu installierenden Pakets muss in Klammern angegeben werden in Anführungszeichen. Wenn du mehrere Pakete in einem Befehl installieren willst, müssen sie in einem Zeichenvektor aufgeführt werden c().\nHinweis: Dieser Befehl installiert ein Paket, führt aber nicht lädt es nicht zur Verwendung in der aktuellen Sitzung.\n\n# install a single package with base R\ninstall.packages(\"tidyverse\")\n\n# install multiple packages with base R\ninstall.packages(c(\"tidyverse\", \"rio\", \"here\"))\n\nDie Installation kann auch per Mausklick durchgeführt werden, indem du im RStudio-Fenster “Pakete” auf “Installieren” klickst und nach dem gewünschten Paketnamen suchst.\nDie Basis R Funktion zu zu laden ein Paket zur Verwendung zu laden (nachdem es installiert wurde), ist library(). Es kann immer nur ein Paket auf einmal laden (ein weiterer Grund für die Verwendung von p_load()). Du kannst den Paketnamen mit oder ohne Anführungszeichen angeben.\n\n# load packages for use, with base R\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\n\nUm zu überprüfen, ob ein Paket installiert und/oder geladen ist, kannst du den Bereich Pakete in RStudio anzeigen. Wenn das Paket installiert ist, wird es dort mit der Versionsnummer angezeigt. Wenn das Kästchen markiert ist, ist es für die aktuelle Sitzung geladen.\nVon Github installieren\nManchmal musst du ein Paket installieren, das noch nicht bei CRAN verfügbar ist. Oder vielleicht ist das Paket auf CRAN verfügbar, aber du möchtest die Entwicklungsversion mit neuen Funktionen, die in der stabileren, veröffentlichten CRAN-Version noch nicht enthalten sind. Diese werden oft auf der Website zur Verfügung gestellt github.dein einem freien, öffentlich zugänglichen Code-“Repository”. Mehr über Github erfährst du auf der Handbuchseite zu [Versionskontrolle und Zusammenarbeit mit Git und Github].\nUm R-Pakete von Github herunterzuladen, kannst du die Funktion p_load_gh() von pacman das Paket, falls nötig, installieren und für die Verwendung in deiner aktuellen R-Sitzung laden. Eine Alternative zur Installation ist die Verwendung des remotes oder devtools Pakete. Lies mehr über alle pacman Funktionen in der Paket-Dokumentation.\nUm von Github zu installieren, musst du weitere Informationen angeben. Du musst Folgendes angeben:\n\nDie Github-ID des Besitzers des Repositorys\nDer Name des Repositorys, das das Paket enthält.\n(optional) Der Name des “Branch” (spezifische Entwicklungsversion), den du herunterladen möchtest\n\nIn den folgenden Beispielen ist das erste Wort in den Anführungszeichen die Github-ID des Repository-Besitzers, nach dem Schrägstrich steht der Name des Repositorys (der Name des Pakets).\n\n# install/load the epicontacts package from its Github repository\np_load_gh(\"reconhub/epicontacts\")\n\nWenn du von einem anderen “Zweig” (Version) als dem Hauptzweig installieren willst, füge den Namen des Zweigs nach einem “@” hinter dem Namen des Repositorys ein.\n\n# install the \"timeline\" branch of the epicontacts package from Github\np_load_gh(\"reconhub/epicontacts@timeline\")\n\nWenn es keinen Unterschied zwischen der Github-Version und der Version auf deinem Computer gibt, wird nichts unternommen. Du kannst eine Neuinstallation “erzwingen”, indem du stattdessen p_load_current_gh() mit dem Argument update = TRUE. Lies mehr über pacman in diesem Online-Vignette\nAus ZIP oder TAR installieren\nDu kannst das Paket auch von einer URL aus installieren:\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n\nOder du lädst es in einer gezippten Datei auf deinen Computer herunter:\nOption 1: mit install_local() von der Fernbedienungen Paket\n\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\n\nOption 2: mit install.packages() von Basis R, gibt den Dateipfad zur ZIP-Datei an und setzt type = \"source und repos = NULL.\n\ninstall.packages(\"~/Downloads/dplyr-master.zip\", repos=NULL, type=\"source\")\n\n\n\n\nCode-Syntax\nAus Gründen der Übersichtlichkeit wird in diesem Handbuch den Funktionen manchmal der Name ihres Pakets vorangestellt, indem die :: Symbol in der folgenden Weise vorangestellt: package_name::function_name()\nSobald ein Paket für eine Sitzung geladen ist, ist dieser explizite Stil nicht mehr nötig. Man kann einfach verwenden function_name(). Die Angabe des Paketnamens ist jedoch nützlich, wenn ein Funktionsname häufig vorkommt und möglicherweise in mehreren Paketen vorhanden ist (z. B. plot()). Wenn du den Paketnamen angibst, wird das Paket auch geladen, wenn es noch nicht geladen ist.\n\n# This command uses the package \"rio\" and its function \"import()\" to import a dataset\nlinelist &lt;- rio::import(\"linelist.xlsx\", which = \"Sheet1\")\n\n\n\nFunktion Hilfe\nUm mehr über eine Funktion zu erfahren, kannst du sie auf der Registerkarte Hilfe im RStudio unten rechts suchen. Du kannst auch einen Befehl ausführen wie ?thefunctionname (gib den Namen der Funktion nach einem Fragezeichen ein) und die Hilfeseite wird im Hilfefenster angezeigt. Schließlich kannst du auch online nach Ressourcen suchen.\n\n\nPakete aktualisieren\nDu kannst Pakete aktualisieren, indem du sie neu installierst. Du kannst auch auf die grüne Schaltfläche “Aktualisieren” in deinem RStudio-Paketfenster klicken, um zu sehen, welche Pakete neue Versionen haben, die du installieren kannst. Sei dir bewusst, dass dein alter Code möglicherweise aktualisiert werden muss, wenn sich die Funktionsweise einer Funktion grundlegend geändert hat!\n\n\nPakete löschen\nVerwende p_delete() von pacman, oder remove.packages() von Basis R. Alternativ kannst du auch den Ordner suchen, der deine Bibliothek enthält, und diesen Ordner manuell löschen.\n\n\nAbhängigkeiten\nPakete hängen oft von anderen Paketen ab, damit sie funktionieren. Diese werden als Abhängigkeiten bezeichnet. Wenn eine Abhängigkeit nicht installiert werden kann, kann auch das Paket, das von ihr abhängt, nicht installiert werden.\nDie Abhängigkeiten eines Pakets kannst du mit p_depends() und welche Pakete von ihm abhängen mit p_depends_reverse()\n\n\nMaskierte Funktionen\nEs ist nicht ungewöhnlich, dass zwei oder mehr Pakete denselben Funktionsnamen enthalten. Zum Beispiel kann das Paket dplyr hat eine filter() Funktion, aber auch das Paket stats. Die Standard filter() Funktion hängt von der Reihenfolge ab, in der diese Pakete zum ersten Mal in die R-Sitzung geladen werden - die spätere Funktion wird die Standardfunktion für den Befehl filter().\nDu kannst die Reihenfolge in deinem Umgebungsfenster in R Studio überprüfen - klicke auf das Dropdown-Menü für “Globale Umgebung” und sieh dir die Reihenfolge der Pakete an. Funktionen aus Paketen unter auf der Dropdown-Liste maskieren Funktionen desselben Namens in Paketen, die weiter oben in der Dropdown-Liste stehen. Wenn du ein Paket zum ersten Mal lädst, warnt dich R in der Konsole, wenn eine Maskierung stattfindet, aber das kann man leicht übersehen.\n\n\n\n\n\n\n\n\n\nHier sind einige Möglichkeiten, wie du die Maskierung beheben kannst:\n\nGib den Paketnamen im Befehl an. Verwende zum Beispiel dplyr::filter()\\\nÄndern Sie die Reihenfolge, in der die Pakete geladen werden (z. B. innerhalb p_load()), und starte eine neue R-Sitzung\n\n\n\nLösen / Entladen\nUm ein Paket zu lösen (zu entladen), verwende diesen Befehl mit dem richtigen Paketnamen und nur einem Doppelpunkt. Beachte, dass dies die Maskierung möglicherweise nicht auflöst.\n\ndetach(package:PACKAGE_NAME_HERE, unload=TRUE)\n\n\n\nÄltere Version installieren\nSiehe dies Leitfaden um eine ältere Version eines bestimmten Pakets zu installieren.\n\n\nVorgeschlagene Pakete\nSiehe die Seite über [Empfohlene Pakete] findest du eine Liste der Pakete, die wir für den epidemiologischen Alltag empfehlen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#scripts",
    "href": "new_pages/basics.de.html#scripts",
    "title": "3  R Grundlagen",
    "section": "3.8 Skripte",
    "text": "3.8 Skripte\nSkripte sind ein grundlegender Bestandteil der Programmierung. Sie sind Dokumente, die deine Befehle enthalten (z. B. Funktionen zum Erstellen und Ändern von Datensätzen, Drucken von Visualisierungen usw.). Du kannst ein Skript speichern und es später wieder ausführen. Es hat viele Vorteile, wenn du deine Befehle in einem Skript speicherst und ausführst (im Gegensatz zu der Möglichkeit, die Befehle einzeln in die “Befehlszeile” der R-Konsole einzugeben):\n\nÜbertragbarkeit - du kannst deine Arbeit mit anderen teilen, indem du ihnen deine Skripte schickst.\nReproduzierbarkeit - damit du und andere genau wissen, was du gemacht hast\\\nVersionskontrolle - damit du Änderungen, die du selbst oder Kollegen vorgenommen haben, nachverfolgen kannst\\\nKommentare/Anmerkungen - um deinen Kollegen zu erklären, was du getan hast\n\n\nKommentieren\nIn einem Skript kannst du auch Anmerkungen (“Kommentare”) zu deinem R-Code machen. Das Kommentieren ist hilfreich, um dir und anderen Lesern zu erklären, was du tust. Du kannst einen Kommentar hinzufügen, indem du das Rautezeichen (#) eingibst und deinen Kommentar dahinter schreibst. Der kommentierte Text wird in einer anderen Farbe als der R-Code angezeigt.\nJeder Code, der nach dem # geschrieben wird, wird nicht ausgeführt. Daher ist das # vor dem Code auch eine nützliche Methode, um eine Codezeile vorübergehend zu blockieren (“auskommentieren”), wenn du sie nicht löschen willst). Du kannst mehrere Zeilen auf einmal auskommentieren, indem du sie markierst und Strg+Umschalt+c drückst (Cmd+Umschalt+c auf dem Mac).\n\n# A comment can be on a line by itself\n# import data\nlinelist &lt;- import(\"linelist_raw.xlsx\") %&gt;%   # a comment can also come after code\n# filter(age &gt; 50)                          # It can also be used to deactivate / remove a line of code\n  count()\n\n\nAuskommentieren was was du tust und auf warum du es tust.\\\nUnterteile deinen Code in logische Abschnitte\\\nBegleite deinen Code mit einer textlichen Schritt-für-Schritt-Beschreibung dessen, was du tust (z.B. mit nummerierten Schritten)\n\n\n\nStil\nEs ist wichtig, dass du dir deines Coding-Stils bewusst bist - vor allem, wenn du im Team arbeitest. Wir plädieren für die tidyverse Styleguide. Es gibt auch Pakete wie styler und lintr die dir helfen, dich an diesen Stil anzupassen.\nEin paar sehr grundlegende Punkte, um deinen Code für andere lesbar zu machen:\n* Verwende bei der Benennung von Objekten nur Kleinbuchstaben, Zahlen und Unterstriche. _ z.B.. my_data\n* Verwende häufig Leerzeichen, auch um Operatoren herum, z. B. n = 1 und age_new &lt;- age_old + 3\n\n\nBeispiel Skript\nIm Folgenden findest du ein Beispiel für ein kurzes R-Skript. Denk daran: Je besser du deinen Code in den Kommentaren erklärst, desto mehr werden dich deine Kollegen mögen!\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown\nEin R Markdown-Skript ist eine Art von R-Skript, bei dem das Skript selbst wird. ein Ausgabedokument (PDF, Word, HTML, Powerpoint, etc.) wird. Dies sind unglaublich nützliche und vielseitige Werkzeuge, die oft zur Erstellung dynamischer und automatisierter Berichte verwendet werden. Sogar diese Website und dieses Handbuch wurden mit R-Markdown-Skripten erstellt!\nEs sei darauf hingewiesen, dass auch R-Anfänger/innen R Markdown verwenden können - lass dich nicht einschüchtern! Mehr dazu erfährst du auf der Handbuchseite über [Berichte mit R Markdown] Dokumente.\n\n\n\nR-Notebooks\nEs gibt keinen Unterschied zwischen dem Schreiben in einem Rmarkdown und einem R-Notebook. Die Ausführung des Dokuments unterscheidet sich jedoch leicht. Siehe dies Seite für weitere Details.\n\n\n\nGlänzend\nShiny-Apps/Websites sind in einem Skript enthalten, das folgendermaßen benannt werden muss app.R. Diese Datei hat drei Komponenten:\n\nEine Benutzeroberfläche (ui)\\\nEine Serverfunktion\\\nEin Aufruf der shinyApp Funktion\n\nSiehe die Handbuchseite über [Dashboards mit Shiny] oder dieses Online-Tutorial :Shiny-Tutorial\nFrüher wurde die obige Datei in zwei Dateien aufgeteilt (ui.R und server.R)\n\n\nCode falten\nDu kannst Teile des Codes einklappen, damit dein Skript leichter zu lesen ist.\nDazu erstellst du eine Textüberschrift mit #, schreibst deine Überschrift und folgst ihr mit mindestens 4 Bindestrichen (-), Raute (#) oder Gleichheitszeichen (=). Wenn du das getan hast, erscheint ein kleiner Pfeil in der “Rinne” links (neben der Zeilennummer). Du kannst auf diesen Pfeil und den Code darunter klicken, bis die nächste Überschrift eingeklappt wird und an ihrer Stelle ein Doppelpfeil-Symbol erscheint.\nUm den Code zu erweitern, klickst du entweder erneut auf den Pfeil im Zwischenraum oder auf das Doppelpfeil-Symbol. Es gibt auch Tastenkombinationen, die im Abschnitt Abschnitt RStudio auf dieser Seite erklärt werden.\nWenn du Überschriften mit # erstellst, aktivierst du auch das Inhaltsverzeichnis am Ende deines Skripts (siehe unten), das du zur Navigation in deinem Skript verwenden kannst. Du kannst Unterüberschriften erstellen, indem du weitere #-Symbole hinzufügst, zum Beispiel # für primäre, ## für sekundäre und ### für tertiäre Überschriften.\nIm Folgenden findest du zwei Versionen eines Beispielskripts. Links ist das Original mit kommentierten Überschriften. Auf der rechten Seite wurden nach jeder Überschrift vier Bindestriche geschrieben, damit sie eingeklappt werden können. Zwei von ihnen wurden eingeklappt, und du kannst sehen, dass das Inhaltsverzeichnis am unteren Rand nun jeden Abschnitt anzeigt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAndere Bereiche des Codes, die automatisch eingeklappt werden können, sind z. B. “verklammerte” Bereiche mit Klammern { } wie Funktionsdefinitionen oder bedingte Blöcke (if else-Anweisungen). Mehr über die Codefaltung erfährst du in der RStudio Seite.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#arbeitsverzeichnis",
    "href": "new_pages/basics.de.html#arbeitsverzeichnis",
    "title": "3  R Grundlagen",
    "section": "3.9 Arbeitsverzeichnis",
    "text": "3.9 Arbeitsverzeichnis\nDas Arbeitsverzeichnis ist der Stammordner, den R für deine Arbeit verwendet und in dem R standardmäßig nach Dateien sucht und sie speichert. Standardmäßig speichert R neue Dateien und Ausgaben an diesem Ort und sucht hier auch nach zu importierenden Dateien (z. B. Datensätzen).\nDas Arbeitsverzeichnis wird in grauer Schrift oben in der RStudio-Konsole angezeigt. Du kannst das aktuelle Arbeitsverzeichnis auch ausdrucken, indem du getwd() (lass die Klammern leer).\n\n\n\n\n\n\n\n\n\n\nEmpfohlener Ansatz\nSiehe die Seite über [R-Projekte] für Details zu unserer empfohlenen Vorgehensweise bei der Verwaltung deines Arbeitsverzeichnisses.\nEine gängige, effiziente und problemlose Methode zur Verwaltung deines Arbeitsverzeichnisses und deiner Dateipfade ist die Kombination dieser 3 Elemente in einem [R-Projekt][R-Projekte]-orientierter Arbeitsablauf:\n\nEin R Projekt, in dem du alle deine Dateien speicherst (siehe Seite über [R-Projekte])\n\nDie hierPaket, um Dateien zu finden (siehe Seite über [Importieren und Exportieren])\n\nDie rioPaket, um Dateien zu importieren/exportieren (siehe Seite über [Importieren und Exportieren])\n\n\n\n\nPer Befehl einstellen\nBis vor kurzem wurde vielen, die R lernten, beigebracht, ihre Skripte mit einem setwd()Befehl zu beginnen. Bitte erwäge stattdessen, ein [R-Projekt][R-Projekte]-orientierten Arbeitsablauf und lies dieGründe für die Nichtverwendung von setwd(). Kurz gesagt, deine Arbeit wird spezifisch für deinen Computer, die Dateipfade, die zum Importieren und Exportieren von Dateien verwendet werden, werden “brüchig”, und das erschwert die Zusammenarbeit und die Verwendung deines Codes auf anderen Computern erheblich. Es gibt einfache Alternativen!\nWie bereits erwähnt, empfehlen wir diesen Ansatz in den meisten Fällen zwar nicht, aber du kannst den Befehl setwd() mit dem gewünschten Ordner-Dateipfad in Anführungszeichen verwenden, zum Beispiel:\n\nsetwd(\"C:/Documents/R Files/My analysis\")\n\n[GEFAHR! Das Setzen eines Arbeitsverzeichnisses mit setwd() kann spröde sein, wenn der Dateipfad nur für einen bestimmten Computer gilt. Verwende stattdessen Dateipfade relativ zu einem R-Projekt-Stammverzeichnis (mit dem hier Paket). ]{style=“color: red;”}\n\n\n\nManuell einstellen\nUm das Arbeitsverzeichnis manuell festzulegen (das Zeigen-und-Klicken-Äquivalent von setwd()), klickst du auf das Dropdown-Menü Sitzung und wählst “Arbeitsverzeichnis festlegen” und dann “Verzeichnis wählen”. Dadurch wird das Arbeitsverzeichnis für diese spezielle R-Sitzung festgelegt. Hinweis: Wenn du diesen Weg wählst, musst du dies jedes Mal manuell tun, wenn du RStudio öffnest.\n\n\n\nInnerhalb eines R-Projekts\nWenn du ein R-Projekt verwendest, ist das Arbeitsverzeichnis standardmäßig das Stammverzeichnis des R-Projekts, das die “.rproj”-Datei enthält. Dies gilt, wenn du RStudio öffnest, indem du auf “R-Projekt öffnen” klickst (die Datei mit der Erweiterung “.rproj”).\n\n\n\nArbeitsverzeichnis in einem R Markdown\nIn einem R-Markdown-Skript ist das Standardarbeitsverzeichnis der Ordner, in dem die R-Markdown-Datei (.Rmd) gespeichert wird. Wenn du ein R-Projekt verwendest und hier Paket verwenden, gilt dies nicht und das Arbeitsverzeichnis ist here()wie im Abschnitt [R-Projekte] Seite erklärt wird.\nWenn du das Arbeitsverzeichnis eines eigenständigen R-Markdowns (nicht in einem R-Projekt) ändern willst, musst du setwd() verwendest, gilt dies nur für diesen speziellen Codechunk. Um die Änderung für alle Code Chunks in einem R Markdown vorzunehmen, bearbeite den Setup Chunk und füge die root.dir = Parameter hinzu, z. B. wie unten:\n\nknitr::opts_knit$set(root.dir = 'desired/directorypath')\n\nEs ist viel einfacher, einfach den R-Markdown innerhalb eines R-Projekts zu verwenden und die hier Paket zu verwenden.\n\n\n\nDateipfade bereitstellen\nDie vielleicht häufigste Quelle der Frustration für einen R-Anfänger (zumindest auf einem Windows-Rechner) ist die Eingabe eines Dateipfads für den Import oder Export von Daten. Eine ausführliche Erklärung, wie du Dateipfade am besten eingibst, findest du in der [Importieren und Exportieren] Seite, aber hier sind ein paar wichtige Punkte:\nGebrochene Pfade\nIm Folgenden findest du ein Beispiel für einen “absoluten” oder “vollständigen” Dateipfad. Diese Pfade werden wahrscheinlich nicht funktionieren, wenn sie von einem anderen Computer verwendet werden. Eine Ausnahme ist, wenn du ein gemeinsam genutztes Laufwerk oder ein Netzlaufwerk verwendest.\nC:/Users/Name/Document/Analytic Software/R/Projects/Analysis2019/data/March2019.csv  \nSchrägstrich Richtung\nWenn du einen Dateipfad eingibst, achte auf die Richtung der Schrägstriche. Verwende Schrägstriche (/), um die Komponenten zu trennen (“data/provincial.csv”). Für Windows-Benutzer werden die Dateipfade standardmäßig wie folgt angezeigt Schrägstrichen (\\) - du musst also die Richtung der einzelnen Schrägstriche ändern. Wenn du den hierPaket wie in den [R-Projekte] Seite beschrieben ist, spielt die Schrägstrichrichtung keine Rolle.\nRelative Dateipfade\nWir empfehlen generell, stattdessen “relative” Dateipfade anzugeben - das heißt, den Pfad relativ zu dem Stammverzeichnis deines R-Projekts. Du kannst dies mit der Option hierPaket, wie es in den [R-Projekte] Seite erklärt wird. Ein relativer Dateipfad könnte wie folgt aussehen:\n\n# Import csv linelist from the data/linelist/clean/ sub-folders of an R project\nlinelist &lt;- import(here(\"data\", \"clean\", \"linelists\", \"marin_country.csv\"))\n\nAuch wenn du relative Dateipfade innerhalb eines R-Projekts verwendest, kannst du trotzdem absolute Pfade verwenden, um Daten außerhalb deines R-Projekts zu importieren/exportieren.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#objects",
    "href": "new_pages/basics.de.html#objects",
    "title": "3  R Grundlagen",
    "section": "3.10 Objekte",
    "text": "3.10 Objekte\nAlles in R ist ein Objekt, und R ist eine “objektorientierte” Sprache. In diesen Abschnitten wird erklärt:\n\nWie man Objekte erstellt (&lt;-)\nArten von Objekten (z.B. Datenrahmen, Vektoren…)\\\nWie man auf Teilbereiche von Objekten zugreift (z.B. Variablen in einem Datensatz)\\\nKlassen von Objekten (z. B. numerisch, logisch, ganzzahlig, doppelt, Zeichen, Faktor)\n\n\n\nAlles ist ein Objekt\nDieser Abschnitt ist an die R4Epis Projekt.\nAlles, was du in R speicherst - Datensätze, Variablen, eine Liste von Dorfnamen, eine Gesamtbevölkerungszahl, sogar Ausgaben wie Diagramme - sind Objekte die einen Namen zugewiesen bekommen und kann referenziert werden in späteren Befehlen.\nEin Objekt existiert, wenn du ihm einen Wert zugewiesen hast (siehe Abschnitt “Zuweisung” weiter unten). Wenn ihm ein Wert zugewiesen wird, erscheint das Objekt in der Umgebung (siehe den oberen rechten Bereich von RStudio). Es kann dann bearbeitet, manipuliert, verändert und neu definiert werden.\n\n\n\nDas Definieren von Objekten (&lt;-)\nObjekte erstellen indem du ihnen einen Wert zuweist mit dem &lt;- Operator.\nDu kannst dir den Zuweisungsoperator so vorstellen &lt;- als die Worte “ist definiert als”. Zuweisungsbefehle folgen im Allgemeinen einer Standardreihenfolge:\nObjekt_name &lt;- Wert (oder Prozess/Berechnung, die einen Wert erzeugt)\nDu möchtest zum Beispiel die aktuelle epidemiologische Meldewoche als Objekt aufzeichnen, auf das du in einem späteren Code Bezug nehmen kannst. In diesem Beispiel wird das Objekt current_week erstellt, wenn es mit dem Wert \"2018-W10\" zugewiesen wird (die Anführungszeichen machen dies zu einem Zeichenwert). Das Objekt current_week wird dann im RStudio-Umgebungsfenster (oben rechts) angezeigt und kann in späteren Befehlen referenziert werden.\nDie R-Befehle und ihre Ausgabe findest du in den Kästen unten.\n\ncurrent_week &lt;- \"2018-W10\"   # this command creates the object current_week by assigning it a value\ncurrent_week                 # this command prints the current value of current_week object in the console\n\n[1] \"2018-W10\"\n\n\n[HINWEIS: Beachte die [1] in der R-Konsolenausgabe zeigt lediglich an, dass du das erste Element der Ausgabe siehst]{style=“color: black;”}\n[VORSICHT! Der Wert eines Objekts kann überschrieben werden jederzeit überschrieben werden, indem ein Zuweisungsbefehl ausgeführt wird, um seinen Wert neu zu definieren. Daher kann der Reihenfolge der ausgeführten Befehle sehr wichtig.]{style=“color: orange;”}\nDer folgende Befehl definiert den Wert von current_week:\n\ncurrent_week &lt;- \"2018-W51\"   # assigns a NEW value to the object current_week\ncurrent_week                 # prints the current value of current_week in the console\n\n[1] \"2018-W51\"\n\n\nGleiche Zeichen =\nDu wirst auch Gleichheitszeichen im R-Code sehen:\n\nEin doppeltes Gleichheitszeichen == zwischen zwei Objekten oder Werten stellt eine logische Frage: “Ist dies gleich jenem?”.\\\nDu wirst auch Gleichheitszeichen innerhalb von Funktionen sehen, die verwendet werden, um Werte von Funktionsargumenten anzugeben (lies dazu die folgenden Abschnitte), zum Beispiel max(age, na.rm = TRUE).\\\nDu kannst ein einzelnes Gleichheitszeichen verwenden = anstelle von &lt;- um Objekte zu erstellen und zu definieren, aber davon wird abgeraten. Warum dies nicht empfehlenswert ist, kannst du nachlesen hier.\n\nDatensätze\nDatensätze sind ebenfalls Objekte (in der Regel “Datenrahmen”) und müssen beim Import mit Namen versehen werden. Im folgenden Code wird das Objekt linelist erstellt und mit dem Wert einer CSV-Datei versehen, die mit dem Befehl rio Paket importiert wurde und dessen import() Funktion.\n\n# linelist is created and assigned the value of the imported CSV file\nlinelist &lt;- import(\"my_linelist.csv\")\n\nMehr über das Importieren und Exportieren von Datensätzen erfährst du in dem Abschnitt über [Import und Export].\n[VORSICHT! Ein kurzer Hinweis zur Benennung von Objekten:]{style=“color: orange;”}\n\nObjektnamen dürfen keine Leerzeichen enthalten, aber du solltest einen Unterstrich (_) oder einen Punkt (.) anstelle eines Leerzeichens verwenden.\\\nBei Objektnamen wird zwischen Groß- und Kleinschreibung unterschieden (d.h. Dataset_A ist anders als dataset_A).\nObjektnamen müssen mit einem Buchstaben beginnen (sie dürfen nicht mit einer Zahl wie 1, 2 oder 3 beginnen).\n\nAusgänge\nAusgaben wie Tabellen und Diagramme sind ein Beispiel dafür, wie Ausgaben als Objekte gespeichert oder einfach ausgedruckt werden können, ohne gespeichert zu werden. Eine Kreuztabellierung von Geschlecht und Ergebnis unter Verwendung der Basis R-Funktion table() kann direkt auf der R-Konsole ausgegeben werden (ohne gespeichert werden).\n\n# printed to R console only\ntable(linelist$gender, linelist$outcome)\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\nDie gleiche Tabelle kann aber auch als benanntes Objekt gespeichert werden. Dann kann sie optional auch gedruckt werden.\n\n# save\ngen_out_table &lt;- table(linelist$gender, linelist$outcome)\n\n# print\ngen_out_table\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\nSpalten\nSpalten in einem Datensatz sind ebenfalls Objekte und können definiert, überschrieben und erstellt werden, wie unten im Abschnitt über Spalten beschrieben.\nDu kannst den Zuweisungsoperator von Basis R verwenden, um eine neue Spalte zu erstellen. Unten wird die neue Spalte bmi (Body Mass Index) erstellt, und für jede Zeile ist der neue Wert das Ergebnis einer mathematischen Operation auf den Zeilenwert in der Spalte wt_kg und ht_cm Spalten.\n\n# create new \"bmi\" column using base R syntax\nlinelist$bmi &lt;- linelist$wt_kg / (linelist$ht_cm/100)^2\n\nIn diesem Handbuch betonen wir jedoch einen anderen Ansatz zur Definition von Spalten, der die Funktion mutate() aus der dplyr Paket und Rohrleitungen mit dem Pipe-Operator (%&gt;%). Die Syntax ist einfacher zu lesen und es gibt weitere Vorteile, die auf der Seite über [Bereinigung von Daten und Kernfunktionen]. Du kannst mehr lesen überRohrleitungen in dem Abschnitt Rohrleitungen weiter unten.\n\n# create new \"bmi\" column using dplyr syntax\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\n\n\n\nObjektstruktur\nObjekte können ein einzelnes Datenelement sein (z. B. my_number &lt;- 24), oder sie können aus strukturierten Daten bestehen.\nDie folgende Grafik stammt aus diesem Online-R-Tutorial. Es zeigt einige gängige Datenstrukturen und ihre Namen. Nicht enthalten in diesem Bild sind räumliche Daten, die im Abschnitt [GIS-Grundlagen] Seite behandelt werden.\n\n\n\n\n\n\n\n\n\nIn der Epidemiologie (und insbesondere in der Feldepidemiologie) wirst du in der Regel Datenrahmen und Vektoren begegnen:\n+——————+————————————————————————————————–+————————————————————————————-+ | Gemeinsame Struktur | Erläuterung | Beispiel | +==================+==================================================================================================+=====================================================================================+ | Vektoren | Ein Container für eine Folge von einzelnen Objekten, die alle der gleichen Klasse angehören (z. B. Zahlen, Zeichen). | “Variablen” (Spalten) in Datenrahmen sind Vektoren (z. B. die Spalte age_years). | +——————+————————————————————————————————–+————————————————————————————-+ | Datenrahmen | Vektoren (z. B. Spalten), die miteinander verbunden sind und alle die gleiche Anzahl von Zeilen haben. | linelist ist ein Datenrahmen. | +——————+————————————————————————————————–+————————————————————————————-+\nUm einen Vektor zu erstellen, der für sich alleine steht (nicht Teil eines Datenrahmens ist), muss die Funktion c() verwendet wird, um die verschiedenen Elemente zu kombinieren. Wenn du zum Beispiel einen Vektor mit der Farbskala eines Plots erstellst: vector_of_colors &lt;- c(\"blue\", \"red2\", \"orange\", \"grey\")\n\n\n\nObjektklassen\nAlle in R gespeicherten Objekte haben eine Klasse die R sagt, wie das Objekt zu behandeln ist. Es gibt viele mögliche Klassen, aber die gängigsten sind:\n+————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | Klasse | Erläuterung | Beispiele | +============+=========================================================================================================================================================================================+=======================================================================================================+ | Zeichen | Dies sind Texte/Wörter/Sätze “innerhalb von Anführungszeichen”. Mathe kann mit diesen Objekten nicht durchgeführt werden. | “Zeichenobjekte stehen in Anführungszeichen” | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | Integer | Zahlen, die nur ganz (keine Dezimalzahlen) | -5, 14, oder 2000 | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | Numerisch | Dies sind Zahlen und können Nachkommastellen enthalten. Wenn sie in Anführungszeichen stehen, werden sie als Zeichenklasse betrachtet. | 23.1 oder 14 | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | Faktor | Dies sind Vektoren, die eine bestimmte Ordnung oder Hierarchie von Werten | Eine Variable des wirtschaftlichen Status mit geordneten Werten | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | Datum | Sobald R mitgeteilt wird, dass bestimmte Daten Dates sindsind, können diese Daten auf besondere Weise manipuliert und angezeigt werden. Siehe die Seite über [Arbeiten mit Daten] für weitere Informationen. | 2018-04-12 oder 15/3/1954 oder Mi 4 Jan 1980 | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | Logisch | Werte müssen einen der beiden speziellen Werte TRUE oder FALSE sein (beachte, dass diese nicht “TRUE” und “FALSE” in Anführungszeichen) | TRUE oder FALSE | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | data.frame | Ein Datenrahmen ist die Art und Weise, wie R eine typischen Datensatz. Er besteht aus miteinander verbundenen Datenvektoren (Spalten), die alle die gleiche Anzahl von Beobachtungen (Zeilen) haben. | Der AJS-Beispiel-Datensatz namens linelist_raw enthält 68 Variablen mit jeweils 300 Beobachtungen (Zeilen). | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | tibble | tibbles sind eine Variante des Datenrahmens, deren Hauptunterschied darin besteht, dass sie besser auf der Konsole ausgegeben werden (die ersten 10 Zeilen und nur die Spalten, die auf den Bildschirm passen) | Jeder Datenrahmen, jede Liste oder Matrix kann mit as_tibble() | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+ | Liste | Eine Liste ist wie ein Vektor, enthält aber andere Objekte, die auch andere Klassen sein können | Eine Liste kann eine einzelne Zahl, einen Datenrahmen, einen Vektor und sogar eine andere Liste enthalten! | +————+—————————————————————————————————————————————————————————————–+——————————————————————————————————-+\nDu kannst die Klasse eines Objekts testen, indem du seinen Namen an die Funktion class(). Hinweis: Du kannst auf eine bestimmte Spalte innerhalb eines Datensatzes verweisen, indem du die $ Notation verwenden, um den Namen des Datensatzes und den Namen der Spalte zu trennen.\n\nclass(linelist)         # class should be a data frame or tibble\n\n[1] \"data.frame\"\n\nclass(linelist$age)     # class should be numeric\n\n[1] \"numeric\"\n\nclass(linelist$gender)  # class should be character\n\n[1] \"character\"\n\n\nManchmal wird eine Spalte von R automatisch in eine andere Klasse umgewandelt. Achte hierauf! Wenn du zum Beispiel einen Vektor oder eine Spalte mit Zahlen hast, aber einen Zeichenwert einfügst, wird die gesamte Spalte in die Klasse Zeichen umgewandelt.\n\nnum_vector &lt;- c(1,2,3,4,5) # define vector as all numbers\nclass(num_vector)          # vector is numeric class\n\n[1] \"numeric\"\n\nnum_vector[3] &lt;- \"three\"   # convert the third element to a character\nclass(num_vector)          # vector is now character class\n\n[1] \"character\"\n\n\nEin häufiges Beispiel dafür ist die Bearbeitung eines Datenrahmens, um eine Tabelle zu drucken: Wenn du eine Summenzeile erstellst und versuchst, Prozentwerte in dieselbe Zelle wie Zahlen einzufügen/zu kleben (z. B. 23 (40%)), wird die gesamte numerische Spalte darüber in Zeichen umgewandelt und kann nicht mehr für mathematische Berechnungen verwendet werden.Manchmal musst du Objekte oder Spalten in eine andere Klasse umwandeln.\n+——————+—————————————————————————————+ | Funktion | Aktion | +==================+=======================================================================================+ | as.character() | Konvertiert in Zeichenklasse | +——————+—————————————————————————————+ | as.numeric() | Konvertiert in numerische Klasse | +——————+—————————————————————————————+ | as.integer() | Konvertiert in Integer-Klasse | +——————+—————————————————————————————+ | as.Date() | Konvertiert in die Date-Klasse - Hinweis: siehe Abschnitt über Daten für Details | +——————+—————————————————————————————+ | factor() | Hinweis: Das Umdefinieren der Reihenfolge der Wertstufen erfordert zusätzliche Argumente. +——————+—————————————————————————————+\nEbenso gibt es Basis R-Funktionen, um zu prüfen, ob ein Objekt einer bestimmten Klasse angehört, wie z. B. is.numeric(), is.character(), is.double(), is.factor(), is.integer()\nHier ist mehr Online-Material über Klassen und Datenstrukturen in R.\n\n\n\nSpalten/Variablen ($)\nEine Spalte in einem Datenrahmen ist technisch gesehen ein “Vektor” (siehe Tabelle oben) - eine Reihe von Werten, die alle dieselbe Klasse haben müssen (entweder Zeichen, Zahlen, logische Werte usw.).\nEin Vektor kann unabhängig von einem Datenrahmen existieren, z. B. ein Vektor von Spaltennamen, die du als erklärende Variablen in ein Modell aufnehmen willst. Um einen “eigenständigen” Vektor zu erstellen, verwendest du die c() Funktion wie unten beschrieben:\n\n# define the stand-alone vector of character values\nexplanatory_vars &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# print the values in this named vector\nexplanatory_vars\n\n[1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\" \n\n\nSpalten in einem Datenrahmen sind ebenfalls Vektoren und können mit der Funktion aufgerufen, referenziert, extrahiert oder erstellt $ Symbol. Die $ Symbol verbindet den Namen der Spalte mit dem Namen des zugehörigen Datenrahmens. In diesem Handbuch versuchen wir, das Wort “Spalte” anstelle von “Variable” zu verwenden.\n\n# Retrieve the length of the vector age_years\nlength(linelist$age) # (age is a column in the linelist data frame)\n\nIndem du den Namen des Datenrahmens eintippst, gefolgt von $ eingibst, siehst du auch ein Dropdown-Menü mit allen Spalten des Datenrahmens. Du kannst mit der Pfeiltaste durch die Spalten blättern, mit der Eingabetaste eine auswählen und so Rechtschreibfehler vermeiden!\n\n\n\n\n\n\n\n\n\n[ERWEITERTER TIPP: Einige komplexere Objekte (z. B. eine Liste oder ein epicontacts Objekt) können mehrere Ebenen haben, auf die durch mehrere Dollarzeichen zugegriffen werden kann. Zum Beispiel epicontacts$linelist$date_onset]{style=“color: darkgreen;”}\n\n\n\nZugang/Index mit Klammern ([ ])\nEs kann sein, dass du Teile von Objekten anzeigen musst, was auch als “Indizierung” bezeichnet wird und oft mit den eckigen Klammern [ ]. verwenden $ in einem Datenrahmen, um auf eine Spalte zuzugreifen, ist ebenfalls eine Art der Indizierung.\n\nmy_vector &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")  # define the vector\nmy_vector[5]                                  # print the 5th element\n\n[1] \"e\"\n\n\nEckige Klammern funktionieren auch, um bestimmte Teile einer zurückgegebenen Ausgabe zurückzugeben, wie zum Beispiel die Ausgabe einer summary() Funktion:\n\n# All of the summary\nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n# Just the second element of the summary, with name (using only single brackets)\nsummary(linelist$age)[2]\n\n1st Qu. \n      6 \n\n# Just the second element, without name (using double brackets)\nsummary(linelist$age)[[2]]\n\n[1] 6\n\n# Extract an element by name, without showing the name\nsummary(linelist$age)[[\"Median\"]]\n\n[1] 13\n\n\nKlammern funktionieren auch bei Datenrahmen, um bestimmte Zeilen und Spalten anzuzeigen. Du kannst dies mit der Syntax tun dataframe[rows, columns]:\n\n# View a specific row (2) from dataset, with all columns (don't forget the comma!)\nlinelist[2,]\n\n# View all rows, but just one column\nlinelist[, \"date_onset\"]\n\n# View values from row 2 and columns 5 through 10\nlinelist[2, 5:10] \n\n# View values from row 2 and columns 5 through 10 and 18\nlinelist[2, c(5:10, 18)] \n\n# View rows 2 through 20, and specific columns\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# View rows and columns based on criteria\n# *** Note the dataframe must still be named in the criteria!\nlinelist[linelist$age &gt; 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# Use View() to see the outputs in the RStudio Viewer pane (easier to read) \n# *** Note the capital \"V\" in View() function\nView(linelist[2:20, \"date_onset\"])\n\n# Save as a new object\nnew_table &lt;- linelist[2:20, c(\"date_onset\")] \n\nBeachten Sie, dass Sie die oben beschriebene Zeilen-/Spaltenindizierung für Datenrahmen und Tibbles auch mit folgenden Methoden erreichen können dplyr Syntax (Funktionen filter() für Zeilen, und select()für Spalten). Mehr über diese Kernfunktionen erfährst du im Abschnitt [Datenbereinigung und Kernfunktionen] Seite.\nUm nach der “Zeilennummer” zu filtern, kannst du die dplyr Funktion verwenden. row_number() mit offenen Klammern als Teil einer logischen Filteranweisung. Oft wirst du die %in% Operator und einen Zahlenbereich als Teil dieser logischen Anweisung, wie unten gezeigt. Um die erste N Zeilen zu sehen, kannst du auch die spezielle dplyr Funktion verwenden. head().\n\n# View first 100 rows\nlinelist %&gt;% head(100)\n\n# Show row 5 only\nlinelist %&gt;% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns (note no quotes necessary on column names)\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nBei der Indizierung eines Objekts der Klasse Liste geben einfache Klammern immer die Klasse list zurück, auch wenn nur ein einziges Objekt zurückgegeben wird. Doppelte Klammern hingegen können verwendet werden, um auf ein einzelnes Element zuzugreifen und eine andere Klasse als list zurückzugeben.\nKlammern können auch hintereinander geschrieben werden, wie unten gezeigt.\nDiese visuelle Erklärung der Listenindizierung, mit Pfefferstreuern ist humorvoll und hilfreich.\n\n# define demo list\nmy_list &lt;- list(\n  # First element in the list is a character vector\n  hospitals = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n  # second element in the list is a data frame of addresses\n  addresses   = data.frame(\n    street = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n    city   = c(\"Andover\", \"Hamilton\", \"El Paso\")\n    )\n  )\n\nHier siehst du, wie die Liste aussieht, wenn sie auf der Konsole ausgegeben wird. Du siehst, dass es zwei benannte Elemente gibt:\n\nhospitals, ein Zeichenvektor\\\naddresses, ein Datenrahmen mit Adressen\n\n\nmy_list\n\n$hospitals\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\n$addresses\n           street     city\n1 145 Medical Way  Andover\n2  1048 Brown Ave Hamilton\n3   999 El Camino  El Paso\n\n\nJetzt extrahieren wir mit verschiedenen Methoden:\n\nmy_list[1] # this returns the element in class \"list\" - the element name is still displayed\n\n$hospitals\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[1]] # this returns only the (unnamed) character vector\n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[\"hospitals\"]] # you can also index by name of the list element\n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[1]][3] # this returns the third element of the \"hospitals\" character vector\n\n[1] \"Santa Anna\"\n\nmy_list[[2]][1] # This returns the first column (\"street\") of the address data frame\n\n           street\n1 145 Medical Way\n2  1048 Brown Ave\n3   999 El Camino\n\n\n\n\n\nObjekte entfernen\nDu kannst einzelne Objekte aus deiner R-Umgebung entfernen, indem du den Namen in das Feld rm() Funktion einfügst (ohne Anführungszeichen):\n\nrm(object_name)\n\nDu kannst alle Objekte entfernen (deinen Arbeitsbereich leeren), indem du ausführst:\n\nrm(list = ls(all = TRUE))",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#rohrleitungen",
    "href": "new_pages/basics.de.html#rohrleitungen",
    "title": "3  R Grundlagen",
    "section": "3.11 Rohrleitungen (%>%)",
    "text": "3.11 Rohrleitungen (%&gt;%)\nEs gibt zwei allgemeine Ansätze für die Arbeit mit Objekten:\n\nPipes/Tidyverse - Pipes senden ein Objekt von Funktion zu Funktion - die Betonung liegt auf Aktion und nicht auf dem Objekt.\nDefiniere Zwischenobjekte - ein Objekt wird immer wieder neu definiert - die Betonung liegt auf “Objekt”.\n\n\n\nRohre\nEinfach erklärt, der Pipe-Operator (%&gt;%) eine Zwischenausgabe von einer Funktion zur nächsten weiter.\nDu kannst dir das so vorstellen, als würdest du “dann” sagen. Viele Funktionen können miteinander verknüpft werden mit %&gt;%.\n\nPiping betont eine Abfolge von Aktionen, nicht das Objekt, an dem die Aktionen ausgeführt\\\nPipes sind am besten geeignet, wenn eine Abfolge von Aktionen an einem Objekt ausgeführt werden muss\\\nPipes stammen aus dem Paket magrittr das automatisch in Paketen enthalten ist dplyr und enthalten ist. tidyverse\nPipes können den Code sauberer und leichter lesbar machen, intuitiver\n\nLies mehr über diesen Ansatz im tidyverse Styleguide\nHier ist ein fiktives Beispiel zum Vergleich, bei dem fiktive Funktionen verwendet werden, um “einen Kuchen zu backen”. Erstens, die Pipe-Methode:\n\n# A fake example of how to bake a cake using piping syntax\n\ncake &lt;- flour %&gt;%       # to define cake, start with flour, and then...\n  add(eggs) %&gt;%   # add eggs\n  add(oil) %&gt;%    # add oil\n  add(water) %&gt;%  # add water\n  mix_together(         # mix together\n    utensil = spoon,\n    minutes = 2) %&gt;%    \n  bake(degrees = 350,   # bake\n       system = \"fahrenheit\",\n       minutes = 35) %&gt;%  \n  let_cool()            # let it cool down\n\nHier ist eine weitere Link der den Nutzen von Rohren beschreibt.\nRohrleitungen sind keine Basis Funktion. Um Piping zu verwenden, muss die magrittr Paket installiert und geladen sein (dies geschieht in der Regel durch das Laden von tidyverse oder dplyr Paket, die es enthalten). Du kannst mehr über Piping in der magrittr-Dokumentation lesen.\nBeachte, dass Pipes genau wie andere R-Befehle verwendet werden können, um nur das Ergebnis anzuzeigen oder um ein Objekt zu speichern bzw. wieder zu speichern, je nachdem, ob der Zuweisungsoperator &lt;- beteiligt ist. Siehe beides unten:\n\n# Create or overwrite object, defining as aggregate counts by age category (not printed)\nlinelist_summary &lt;- linelist %&gt;% \n  count(age_cat)\n\n\n# Print the table of counts in the console, but don't save it\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\n%&lt;&gt;%\nDies ist eine “Zuweisungs-Pipe” von der magrittr Paket, das ein Objekt weiterleitet und auch das Objekt neu definiert. Es muss der erste Pipe-Operator in der Kette sein. Es ist eine Kurzschrift. Die beiden folgenden Befehle sind gleichwertig:\n\nlinelist &lt;- linelist %&gt;%\n  filter(age &gt; 50)\n\nlinelist %&lt;&gt;% filter(age &gt; 50)\n\n\n\n\nDefiniere Zwischenobjekte\nDieser Ansatz zum Ändern von Objekten/Datenrahmen kann besser sein, wenn:\n\nDu musst mehrere Objekte manipulieren.\nEs gibt Zwischenschritte, die sinnvoll sind und einen eigenen Objektnamen verdienen\n\nRisiken:\n\nFür jeden Schritt neue Objekte zu erstellen bedeutet, viele Objekte zu erstellen. Wenn du das falsche verwendest, merkst du das vielleicht nicht!\\\nDie Benennung aller Objekte kann verwirrend sein\\\nFehler sind möglicherweise nicht leicht zu erkennen\n\nEntweder benennst du jedes Zwischenobjekt, oder du überschreibst das Original, oder du kombinierst alle Funktionen miteinander. Alle sind mit ihren eigenen Risiken verbunden.\nUnten siehst du das gleiche Beispiel für einen gefälschten “Kuchen” wie oben, aber in diesem Stil:\n\n# a fake example of how to bake a cake using this method (defining intermediate objects)\nbatter_1 &lt;- left_join(flour, eggs)\nbatter_2 &lt;- left_join(batter_1, oil)\nbatter_3 &lt;- left_join(batter_2, water)\n\nbatter_4 &lt;- mix_together(object = batter_3, utensil = spoon, minutes = 2)\n\ncake &lt;- bake(batter_4, degrees = 350, system = \"fahrenheit\", minutes = 35)\n\ncake &lt;- let_cool(cake)\n\nKombiniere alle Funktionen miteinander - das ist schwer zu lesen:\n\n# an example of combining/nesting mutliple functions together - difficult to read\ncake &lt;- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = \"fahrenheit\", minutes = 35))",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#operators",
    "href": "new_pages/basics.de.html#operators",
    "title": "3  R Grundlagen",
    "section": "3.12 Wichtige Operatoren und Funktionen",
    "text": "3.12 Wichtige Operatoren und Funktionen\nDieser Abschnitt beschreibt die Operatoren in R, wie z. B.:\n\nDefinitorische Operatoren.\nRelationale Operatoren (kleiner als, gleich zu…)\\\nLogische Operatoren (und, oder…)\\\nUmgang mit fehlenden Werten\\\nMathematische Operatoren und Funktionen (+/-, &gt;, Summe(), Median(), …)\\\nDie %in% Operator\n\n\n\nZuweisungsoperatoren\n&lt;-\nDer grundlegende Zuweisungsoperator in R ist &lt;-. So, dass object_name &lt;- value.\nDieser Zuweisungsoperator kann auch geschrieben werden als =. Wir empfehlen die Verwendung von &lt;- für den allgemeinen Gebrauch von R.\nWir empfehlen außerdem, solche Operatoren mit Leerzeichen zu umgeben, um die Lesbarkeit zu verbessern.\n&lt;&lt;-\nWenn [Funktionen schreibst] oder R auf interaktive Weise mit Quellenskripten nutzt, musst du möglicherweise diesen Zuweisungsoperator verwenden&lt;&lt;- (von base R). Dieser Operator wird verwendet, um ein Objekt in einer höheren “übergeordneten” R-Umgebung zu definieren. Siehe dies Online-Referenz.\n%&lt;&gt;%\nDies ist eine “Zuweisungsleitung” aus dem magrittr Paket, die ein Objekt weiterleitet und auch das Objekt neu definiert. Es muss der erste Pipe-Operator in der Kette sein. Er ist eine Abkürzung, wie in den folgenden zwei Beispielen gezeigt wird:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_months = age_years * 12)\n\nDas oben Gesagte ist gleichbedeutend mit dem unten Gesagten:\n\nlinelist %&lt;&gt;% mutate(age_months = age_years * 12)\n\n%&lt;+%\nDies wird verwendet, um Daten zu phylogenetischen Bäumen hinzuzufügen mit der ggtreePaket. Siehe die Seite über [Phylogenetische Bäume] oder dieses OnlineRessourcenbuch.\n\n\n\nRelationale und logische Operatoren\nRelationale Operatoren vergleichen Werte und werden häufig verwendet, um neue Variablen und Teilmengen von Datensätzen zu definieren. Hier sind die gängigen relationalen Operatoren in R:\n+————————–+————+————–+——————————————————————————————————————————————————–+ | Bedeutung | Operator | Beispiel | Beispielergebnis | +==========================+============+==============+========================================================================================================================================================+ Gleich | Gleich | == | \"A\" == \"a\" | FALSE (weil bei R zwischen Groß- und Kleinschreibung unterschieden wird) Beachte, dass == (doppelte Gleichheit) sich von = (einfache Gleichheit) unterscheidet, das sich wie der Zuweisungsoperator verhält &lt;- | +————————–+————+————–+——————————————————————————————————————————————————–+ | Nicht gleich | != | 2 != 0 | TRUE | +————————–+————+————–+——————————————————————————————————————————————————–+ | Größer als | &gt; | 4 &gt; 2 | TRUE | +————————–+————+————–+——————————————————————————————————————————————————–+ | Weniger als | &lt; | 4 &lt; 2 | FALSE | +————————–+————+————–+——————————————————————————————————————————————————–+ | Größer als oder gleich | &gt;= | 6 &gt;= 4 | TRUE | +————————–+————+————–+——————————————————————————————————————————————————–+ | Kleiner als oder gleich | &lt;= | 6 &lt;= 4 | FALSE | +————————–+————+————–+——————————————————————————————————————————————————–+ | Wert fehlt | is.na() | is.na(7) | FALSE(siehe Seite über [Fehlende Daten]) | +————————–+————+————–+——————————————————————————————————————————————————–+ | Value is not missing | !is.na() | !is.na(7) | TRUE | +————————–+————+————–+——————————————————————————————————————————————————–+\nLogische Operatoren wie AND und OR werden oft verwendet, um relationale Operatoren zu verbinden und kompliziertere Kriterien zu erstellen. Komplexe Aussagen können Klammern ( ) für die Gruppierung und Reihenfolge der Anwendung erfordern.\n+———————+———————————————————————–+ | Bedeutung | Operator | +=====================+=======================================================================+ | AND | & | +———————+———————————————————————–+ | OR | | (vertikaler Balken) | +———————+———————————————————————–+ | Klammern | ( ) Wird verwendet, um Kriterien zusammenzufassen und die Reihenfolge der Operationen zu verdeutlichen. +———————+———————————————————————–+\nUnten haben wir zum Beispiel eine Liste mit zwei Variablen, die wir für unsere Falldefinition verwenden wollen, hep_e_rdt ein Testergebnis und other_cases_in_hh, die uns sagt, ob es noch andere Fälle im Haushalt gibt. Der folgende Befehl verwendet die Funktion case_when() um die neue Variable zu erstellen case_def so dass:\n\nlinelist_cleaned &lt;- linelist %&gt;%\n  mutate(case_def = case_when(\n    is.na(rdt_result) & is.na(other_case_in_home)            ~ NA_character_,\n    rdt_result == \"Positive\"                                 ~ \"Confirmed\",\n    rdt_result != \"Positive\" & other_cases_in_home == \"Yes\"  ~ \"Probable\",\n    TRUE                                                     ~ \"Suspected\"\n  ))\n\n+————————————————————————————————+——————————————–+ | Kriterien im obigen Beispiel | Resultierender Wert in neuer Variable “case_def” | +================================================================================================+============================================+ | Wenn der Wert für die Variablen rdt_result und other_cases_in_home fehlen | NA (fehlt) | +————————————————————————————————+——————————————–+ | Wenn der Wert in rdt_result “Positiv” | “Bestätigt” | “Bestätigt” ist +————————————————————————————————+——————————————–+ | Wenn der Wert in rdt_result NICHT “Positiv” ist UND der Wert in other_cases_in_home ist “Ja” | “Wahrscheinlich” | +————————————————————————————————+——————————————–+ | Wenn eines der oben genannten Kriterien nicht erfüllt ist | “Vermutlich” | +————————————————————————————————+——————————————–+\nBeachte, dass R zwischen Groß- und Kleinschreibung unterscheidet, also ist “positiv” etwas anderes als “positiv”…\n\n\n\nFehlende Werte\nIn R werden fehlende Werte durch einen speziellen Wert dargestellt NA (ein “reservierter” Wert) dargestellt (Großbuchstaben N und A - nicht in Anführungszeichen). Wenn du Daten importierst, die fehlende Daten auf eine andere Art und Weise erfassen (z. B. 99, “Missing” oder .), solltest du diese Werte umcodieren in NA. Wie du das machst, erfährst du im Abschnitt [Importieren und Exportieren] Seite.\nUm zu prüfen, ob ein Wert NA ist, verwenden Sie die spezielle Funktion is.na(), die Folgendes zurückgibt TRUE oder FALSE.\n\nrdt_result &lt;- c(\"Positive\", \"Suspected\", \"Positive\", NA)   # two positive cases, one suspected, and one unknown\nis.na(rdt_result)  # Tests whether the value of rdt_result is NA\n\n[1] FALSE FALSE FALSE  TRUE\n\n\nLies mehr über vermisst, unendlich, NULLund unmögliche Werte auf der Seite über [Fehlende Daten]. Wie du fehlende Werte beim Importieren von Daten konvertierst, erfährst du auf der Seite über [Importieren und Exportieren].\n\n\n\nMathematik und Statistik\nAlle Operatoren und Funktionen auf dieser Seite sind automatisch verfügbar mit Basis R.\n\nMathematische Operatoren\nDiese werden oft verwendet, um Additionen und Divisionen durchzuführen, neue Spalten zu erstellen usw. Im Folgenden findest du gängige mathematische Operatoren in R. Ob du Leerzeichen um die Operatoren setzt, ist nicht wichtig.\n\n\n\n\n\n\n\nZweck\nBeispiel in R\n\n\n\n\nAddition\n2 + 3\n\n\nSubtraktion\n2 - 3\n\n\nMultiplikation\n2 * 3\n\n\nDivision\n30 / 5\n\n\nExponent\n2^3\n\n\nReihenfolge der Operationen\n( )\n\n\n\n\n\nMathematische Funktionen\n\n\n\n\n\n\n\nZweck\nFunktion\n\n\n\n\nRundung\nround(x, Ziffern = n)\n\n\nRundung\njanitor::round_half_up(x, digits = n)\n\n\nObergrenze (aufrunden)\nObergrenze(x)\n\n\nfloor (abrunden)\nfloor(x)\n\n\nabsoluter Wert\nabs(x)\n\n\nQuadratwurzel\nsqrt(x)\n\n\nExponent\nexponent(x)\n\n\nnatürlicher Logarithmus\nlog(x)\n\n\nlog Basis 10\nlog10(x)\n\n\nlog Basis 2\nlog2(x)\n\n\n\nAnmerkung: für round() die digits = gibt die Anzahl der Nachkommastellen an. Verwende signif() um auf eine Anzahl signifikanter Stellen zu runden.\n\n\nWissenschaftliche Notation\nDie Wahrscheinlichkeit, dass die wissenschaftliche Notation verwendet wird, hängt vom Wert der scipen Option ab.\nAus der Dokumentation von ?options scipen ist ein Malus, der angewendet wird, wenn du entscheidest, ob numerische Werte in fester oder exponentieller Notation gedruckt werden sollen. Bei positiven Werten wird die feste Notation bevorzugt, bei negativen die wissenschaftliche Notation: Die feste Notation wird bevorzugt, es sei denn, sie ist um mehr als ‘scipen’ Stellen breiter.\nWenn der Wert auf eine niedrige Zahl (z.B. 0) gesetzt wird, ist sie immer “eingeschaltet”. Um die wissenschaftliche Notation in deiner R-Sitzung “auszuschalten”, setze sie z. B. auf eine sehr hohe Zahl:\n\n# turn off scientific notation\noptions(scipen=999)\n\n\n\nAbrunden\n[GEFAHR! round() Verwendet das “Banker’s Rounding”, das von einer 0,5 nur aufrundet, wenn die obere Zahl gerade ist. Verwende round_half_up() von Hausmeister um Halbe konsequent auf die nächste ganze Zahl aufzurunden. Siehe diese Erklärung ]{style=“color: red;”}\n\n# use the appropriate rounding function for your work\nround(c(2.5, 3.5))\n\n[1] 2 4\n\njanitor::round_half_up(c(2.5, 3.5))\n\n[1] 3 4\n\n\n\n\nStatistische Funktionen\n[VORSICHT! Die folgenden Funktionen berücksichtigen standardmäßig auch fehlende Werte in den Berechnungen. Fehlende Werte führen zu einer Ausgabe von NA es sei denn, das Argument na.rm = TRUE angegeben wird. Dies kann in Kurzform geschrieben werden als na.rm = T.]{style=“color: orange;”}\n\n\n\n\n\n\n\nZielsetzung\nFunktion\n\n\n\n\nMittelwert (Durchschnitt)\nmean(x, na.rm=T)\n\n\nMedian\nmedian(x, na.rm=T)\n\n\nStandardabweichung\nsd(x, na.rm=T)\n\n\nQuantile*\nQuantil(x, Probs)\n\n\nSumme\nsum(x, na.rm=T)\n\n\nMindestwert\nmin(x, na.rm=T)\n\n\nMaximalwert\nmax(x, na.rm=T)\n\n\nBereich der numerischen Werte\nbereich(x, na.rm=T)\n\n\nZusammenfassung**\nZusammenfassung(x)\n\n\n\nAnmerkungen:\n\n*quantile(): x ist der zu untersuchende numerische Vektor und probs = ist ein numerischer Vektor mit Wahrscheinlichkeiten zwischen 0 und 1,0, z. B. c(0.5, 0.8, 0.85)\n**summary() Zusammenfassung eines numerischen Vektors mit Mittelwert, Median und gemeinsamen Perzentilen\n\n[GEFAHR! Wenn du einen Zahlenvektor an eine der oben genannten Funktionen übergibst, musst du die Zahlen in eine c() .]{style=“color: red;”}\n\n# If supplying raw numbers to a function, wrap them in c()\nmean(1, 6, 12, 10, 5, 0)    # !!! INCORRECT !!!  \n\n[1] 1\n\nmean(c(1, 6, 12, 10, 5, 0)) # CORRECT\n\n[1] 5.666667\n\n\n\n\nAndere nützliche Funktionen\n+—————————-+——————-+————————————————-+ | Zielsetzung | Funktion | Beispiel | +============================+===================+=================================================+ | Eine Sequenz erstellen | seq(from, to, by) | seq(1, 10, 2) | +—————————-+——————-+————————————————-+ | x, n-mal wiederholen | rep(x, n-mal) | rep(1:3, 2) oder rep(c(\"a\", \"b\", \"c\"), 3) | +—————————-+——————-+————————————————-+ | einen numerischen Vektor unterteilen | cut(x, n) | cut(linelist$age, 5) | +—————————-+——————-+————————————————-+ | Eine Zufallsstichprobe nehmen | sample(x, size) | sample(linelist$id, size = 5, replace = TRUE) | +—————————-+——————-+————————————————-+\n\n\n\n\n%in%\nEin sehr nützlicher Operator, um Werte abzugleichen und um schnell festzustellen, ob ein Wert in einem Vektor oder Datenrahmen enthalten ist.\n\nmy_vector &lt;- c(\"a\", \"b\", \"c\", \"d\")\n\n\n\"a\" %in% my_vector\n\n[1] TRUE\n\n\"h\" %in% my_vector\n\n[1] FALSE\n\n\nUm zu fragen, ob ein Wert nicht %in% ein Vektor, setze ein Ausrufezeichen (!) vor vor die logische Aussage:\n\n# to negate, put an exclamation in front\n!\"a\" %in% my_vector\n\n[1] FALSE\n\n!\"h\" %in% my_vector\n\n[1] TRUE\n\n\n%in% ist sehr nützlich, wenn man die dplyr Funktion case_when(). Du kannst einen Vektor vorher definieren und ihn dann später referenzieren. Zum Beispiel:\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist &lt;- linelist %&gt;% \n  mutate(child_hospitaled = case_when(\n    hospitalized %in% affirmative & age &lt; 18 ~ \"Hospitalized Child\",\n    TRUE                                      ~ \"Not\"))\n\nHinweis: Wenn du eine Teilzeichenkette erkennen willst, vielleicht mit str_detect() von stringr nicht akzeptiert, sondern einen Zeichenvektor wie c(\"1\", \"Yes\", \"yes\", \"y\"). Stattdessen muss er eine regulärer Ausdruck - eine verdichtete Zeichenkette mit ODER-Balken, wie z.B. “1|Ja|Ja|J”. Zum Beispiel, str_detect(hospitalized, \"1|Yes|yes|y\"). Siehe die Seite über [Zeichen und Zeichenketten] für weitere Informationen.\nMit diesem Befehl kannst du einen Zeichenvektor in einen benannten regulären Ausdruck umwandeln:\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative\n\n[1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\" \n\n# condense to \naffirmative_str_search &lt;- paste0(affirmative, collapse = \"|\")  # option with base R\naffirmative_str_search &lt;- str_c(affirmative, collapse = \"|\")   # option with stringr package\n\naffirmative_str_search\n\n[1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\"",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.de.html#fehler-warnungen",
    "href": "new_pages/basics.de.html#fehler-warnungen",
    "title": "3  R Grundlagen",
    "section": "3.13 Fehler & Warnungen",
    "text": "3.13 Fehler & Warnungen\nDieser Abschnitt erklärt:\n\nDer Unterschied zwischen Fehlern und Warnungen\\\nAllgemeine Syntax-Tipps zum Schreiben von R-Code\\\nCode-Hilfen\n\nHäufige Fehler und Warnungen sowie Tipps zur Fehlerbehebung findest du auf der Seite [Fehler und Hilfe].\n\n\nFehler versus Warnung\nWenn ein Befehl ausgeführt wird, zeigt dir die R-Konsole möglicherweise Warn- oder Fehlermeldungen in rotem Text an.\n\nA Warnung bedeutet, dass R deinen Befehl ausgeführt hat, aber zusätzliche Schritte durchführen musste oder ungewöhnliche Ausgaben produziert hat, die du beachten solltest.\nEine Fehler bedeutet, dass R deinen Befehl nicht ausführen konnte.\n\nSuche nach Hinweisen:\n\nDie Fehler-/Warnmeldung enthält oft eine Zeilennummer für das Problem.\nWenn ein Objekt “unbekannt” oder “nicht gefunden” ist, hast du es vielleicht falsch geschrieben, vergessen, ein Paket mit library() aufzurufen, oder vergessen, dein Skript nach Änderungen erneut auszuführen.\n\nWenn alles andere fehlschlägt, kopiere die Fehlermeldung zusammen mit einigen Schlüsselbegriffen in Google - die Chancen stehen gut, dass jemand anderes das Problem bereits gelöst hat!\n\n\n\nAllgemeine Tipps zur Syntax\nEin paar Dinge, die du beim Schreiben von Befehlen in R beachten solltest, um Fehler und Warnungen zu vermeiden:\n\nSchließe immer Klammern - Tipp: Zähle die Anzahl der öffnenden “(” und schließenden Klammern “)” für jedes Code-Stück\nVermeide Leerzeichen in Spalten- und Objektnamen. Verwende stattdessen Unterstriche ( _ ) oder Punkte ( . )\nBehalte den Überblick und trenne die Argumente einer Funktion mit Kommas\nR unterscheidet zwischen Groß- und Kleinschreibung, das heißt Variable_A ist anders von variable_A\n\n\n\n\nCode Assistenten\nJedes Skript (RMarkdown oder ein anderes) gibt Hinweise, wenn du einen Fehler gemacht hast. Wenn du zum Beispiel vergessen hast, ein Komma zu setzen, wo es gebraucht wird, oder eine Klammer zu schließen, setzt RStudio in dieser Zeile auf der rechten Seite des Skripts eine Flagge, um dich zu warnen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.de.html",
    "href": "new_pages/transition_to_R.de.html",
    "title": "4  Übergang zu R",
    "section": "",
    "text": "4.1 Von Excel\nDer Umstieg von Excel direkt auf R ist ein sehr erreichbares Ziel. Es mag entmutigend erscheinen, aber du kannst es schaffen!\nEs stimmt, dass jemand mit guten Excel-Kenntnissen sehr fortgeschrittene Aktivitäten allein in Excel durchführen kann - sogar mit Skripting-Tools wie VBA. Excel wird auf der ganzen Welt verwendet und ist ein unverzichtbares Werkzeug für einen Epidemiologen. Wenn du es jedoch mit R ergänzt, kannst du deine Arbeitsabläufe drastisch verbessern und erweitern.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Übergang zu R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.de.html#von-excel",
    "href": "new_pages/transition_to_R.de.html#von-excel",
    "title": "4  Übergang zu R",
    "section": "",
    "text": "Vorteile\nDu wirst feststellen, dass die Verwendung von R immense Vorteile bietet: Zeitersparnis, konsistentere und genauere Analysen, Reproduzierbarkeit, Austauschbarkeit und schnellere Fehlerkorrekturen. Wie bei jeder neuen Software musst du eine gewisse Zeit investieren, um dich mit ihr vertraut zu machen. Das zahlt sich aus, denn mit R eröffnen sich dir unendlich viele neue Möglichkeiten.\nExcel ist eine bekannte Software, mit der auch Anfänger einfache Analysen und Visualisierungen mit “Zeigen und Klicken” erstellen können. Im Vergleich dazu kann es ein paar Wochen dauern, bis du dich mit den Funktionen und der Oberfläche von R vertraut gemacht hast. Allerdings hat sich R in den letzten Jahren weiterentwickelt und ist viel anfängerfreundlicher geworden.\nViele Excel-Arbeitsabläufe beruhen auf dem Gedächtnis und auf Wiederholungen - daher gibt es viele Möglichkeiten für Fehler. Außerdem sind die Datenbereinigung, die Analysemethode und die verwendeten Gleichungen in der Regel nicht einsehbar. Ein neuer Kollege oder eine neue Kollegin braucht viel Zeit, um zu lernen, was eine Excel-Arbeitsmappe macht und wie er oder sie Fehler beheben kann. In R sind alle Schritte explizit in einem Skript festgehalten und können leicht eingesehen, bearbeitet, korrigiert und auf andere Datensätze angewendet werden.\nUm von Excel auf R umzusteigen, musst du deine Denkweise in einigen wichtigen Punkten ändern:\n\n\nDaten aufräumen\nVerwende maschinenlesbare “aufgeräumte” Daten anstelle von unordentlichen “menschenlesbaren” Daten. Dies sind die drei wichtigsten Anforderungen an “ordentliche” Daten, wie in diesem Tutorial erklärt wird “aufgeräumte” Daten in R:\n\nJede Variable muss ihre eigene Spalte haben\nJede Beobachtung muss eine eigene Zeile haben\nJeder Wert muss seine eigene Zelle haben\n\nAn Excel-Benutzer - denken Sie an die Rolle, die Excel-“Tabellen” spielen, um Daten zu standardisieren und das Format berechenbarer zu machen.\nEin Beispiel für “aufgeräumte” Daten ist die Fallliste, die in diesem Handbuch verwendet wird - jede Variable ist in einer Spalte enthalten, jede Beobachtung (ein Fall) hat eine eigene Zeile und jeder Wert steht in nur einer Zelle. Unten siehst du die ersten 50 Zeilen der Strichliste:\n\n\n\n\n\n\nDer Hauptgrund, warum man auf unordentliche Daten stößt, ist, dass viele Excel-Tabellen so gestaltet sind, dass sie von Menschen leicht gelesen werden können und nicht von Maschinen/Software.\nUm dir den Unterschied zu verdeutlichen, findest du hier einige fiktive Beispiele für unordentlichen Daten die Prioritäten setzen menschliche-Lesbarkeit über Maschine-Lesbarkeit:\n\n\n\n\n\n\n\n\n\nProbleme: In der obigen Tabelle gibt es zusammengeführte Zellen die von R nicht leicht zu verstehen sind. Es ist nicht klar, welche Zeile als “Kopfzeile” gelten soll. Auf der rechten Seite befindet sich ein farbbasiertes Wörterbuch und die Zellwerte werden durch Farben dargestellt - auch das ist für R nicht leicht zu interpretieren (und für Menschen mit Farbenblindheit auch nicht!). Außerdem werden verschiedene Informationen in einer Zelle zusammengefasst (mehrere Partnerorganisationen, die in einem Gebiet arbeiten, oder der Status “TBC” in derselben Zelle wie “Partner D”).\n\n\n\n\n\n\n\n\n\nProbleme: In der obigen Tabelle gibt es zahlreiche zusätzliche leere Zeilen und Spalten im Datensatz - das bereitet in R Kopfzerbrechen. Außerdem sind die GPS-Koordinaten für ein bestimmtes Behandlungszentrum auf zwei Zeilen verteilt. Nebenbei bemerkt: Die GPS-Koordinaten sind in zwei verschiedenen Formaten!\n“Aufgeräumte” Datensätze sind für das menschliche Auge vielleicht nicht so gut lesbar, aber sie machen die Datenbereinigung und -analyse viel einfacher! Tidy-Daten können in verschiedenen Formaten gespeichert werden, zum Beispiel “lang” oder “breit” (siehe Seite über [Daten spiegeln]), aber die oben genannten Grundsätze werden trotzdem beachtet.\n\n\nFunktionen\nDas R-Wort “Funktion” mag neu sein, aber das Konzept existiert auch in Excel als Formeln. Auch Formeln in Excel erfordern eine präzise Syntax (z. B. die Platzierung von Semikolons und Klammern). Alles, was du tun musst, ist, ein paar neue Funktionen zu lernen und wie sie in R zusammenarbeiten.\n\n\nSkripte\nAnstatt auf Schaltflächen zu klicken und Zellen zu ziehen, schreibst du jede Schritt und Vorgang in ein “Skript”. Excel-Benutzer sind vielleicht mit den “VBA-Makros” vertraut, die ebenfalls einen Skript-Ansatz verwenden.\nDas R-Skript besteht aus Schritt-für-Schritt-Anweisungen.So kann jeder Kollege das Skript lesen und leicht erkennen, welche Schritte du gemacht hast. Das hilft auch dabei, Fehler oder ungenaue Berechnungen zu beseitigen. Siehe die [R-Grundlagen] Abschnitt über Skripte findest du Beispiele.\nHier ist ein Beispiel für ein R-Skript:\n\n\n\n\n\n\n\n\n\n\n\nExcel-zu-R-Ressourcen\nHier findest du einige Links zu Tutorials, die dir den Umstieg von Excel auf R erleichtern:\n\nR vs. Excel\nRStudio-Kurs in R für Excel-Benutzer\n\n\n\nR-Excel-Interaktion\nR hat robuste Möglichkeiten, Excel-Arbeitsmappen zu importieren, mit den Daten zu arbeiten, Excel-Dateien zu exportieren/speichern und mit den Feinheiten von Excel-Blättern zu arbeiten.\nEs stimmt, dass einige der ästhetischeren Excel-Formatierungen bei der Übersetzung verloren gehen können (z. B. Kursivschrift, seitlich stehender Text usw.). Wenn dein Arbeitsablauf erfordert, dass Dokumente zwischen R und Excel hin- und hergeschoben werden, ohne dass die ursprüngliche Excel-Formatierung verloren geht, solltest du Pakete wie openxlsx.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Übergang zu R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.de.html#von-stata",
    "href": "new_pages/transition_to_R.de.html#von-stata",
    "title": "4  Übergang zu R",
    "section": "4.2 Von Stata",
    "text": "4.2 Von Stata\n\nVon Stata zu R kommen\nViele Epidemiologen und Epidemiologinnen lernen zunächst, wie man Stata benutzt, und der Umstieg auf R kann entmutigend wirken. Wenn du jedoch mit Stata gut zurechtkommst, ist der Umstieg auf R sicherlich einfacher als du denkst. Es gibt zwar einige wichtige Unterschiede zwischen Stata und R, was die Erstellung und Änderung von Daten und die Implementierung von Analysefunktionen angeht - aber wenn du diese Unterschiede kennengelernt hast, wirst du in der Lage sein, deine Kenntnisse zu übertragen.\nIm Folgenden findest du einige wichtige Übersetzungen zwischen Stata und R, die dir bei der Lektüre dieses Leitfadens nützlich sein können.\nAllgemeine Hinweise\n\n\n\nSTATA\nR\n\n\n\n\nDu kannst immer nur einen Datensatz zur gleichen Zeit anzeigen und bearbeiten\nDu kannst mehrere Datensätze gleichzeitig anzeigen und bearbeiten, daher musst du deinen Datensatz häufig im Code angeben\n\n\nOnline-Community verfügbar über https://www.statalist.org/\nOnline-Community verfügbar über RStudio, StackOverFlow und R-Blogger\n\n\nPoint-and-Click-Funktionalität als Option\nMinimale Point-and-Click-Funktionalität\n\n\nHilfe für Befehle verfügbar durch help [command]\nHilfe verfügbar durch [function]? oder im Hilfefenster suchen\n\n\nCode mit * oder /// oder /* TEXT */ kommentieren\nCode mit # kommentieren\n\n\nFast alle Befehle sind in Stata eingebaut. Neue/benutzergeschriebene Funktionen können als ado Dateien mit ssc installieren[Paket]\nR installiert sich mit BasisFunktionen, aber typischerweise müssen andere Pakete von CRAN installiert werden (siehe Seite über [R-Grundlagen])\n\n\nDie Analyse wird normalerweise in einer tun Datei\nAnalyse, die in einem R-Skript im RStudio-Quelltextfenster geschrieben wurde. R Markdown-Skripte sind eine Alternative.\n\n\n\nArbeitsverzeichnis\n\n\n\n\n\n\n\nSTATA\nR\n\n\n\n\nBei Arbeitsverzeichnissen handelt es sich um absolute Dateipfade (z.B. “C:/username/documents/projects/data/”)\nArbeitsverzeichnisse können entweder absolut oder relativ zu einem Projektstammordner sein, indem du die hierPaket (siehe [Import und Export])\n\n\nSiehe aktuelles Arbeitsverzeichnis mit pwd\nverwenden getwd() oder here() (bei Verwendung der hier Paket), mit leeren Klammern\n\n\nArbeitsverzeichnis festlegen mit cd “Ordnerstandort”\nverwenden setwd(\"folder location\"), oder set_here(\"folder location) (bei Verwendung von hier Paket)\n\n\n\nDaten importieren und anzeigen\n\n\n\n\n\n\n\nSTATA\nR\n\n\n\n\nSpezifische Befehle pro Dateityp\nverwenden import() von rioPaket für fast alle Dateitypen. Es gibt spezielle Funktionen als Alternativen (siehe [Importieren und Exportieren])\n\n\nDas Einlesen von csv-Dateien erfolgt durch import delimited “filename.csv”\nverwenden import(\"filename.csv\")\n\n\nDas Einlesen von xslx-Dateien erfolgt durch excel importieren “filename.xlsx”\nverwenden import(\"filename.xlsx\")\n\n\nDurchsuche deine Daten in einem neuen Fenster mit dem Befehl durchsuchen\nBetrachte einen Datensatz im RStudio-Quellbereich mit View(dataset). Du musst den Namen deines Datensatzes für die Funktion in R angeben, da mehrere Datensätze gleichzeitig gehalten werden können. Beachte das große “V” in dieser Funktion\n\n\nVerschaffe dir einen umfassenden Überblick über deinen Datensatz mit zusammenfassen der die Variablennamen und grundlegende Informationen liefert\nVerschaffe dir einen umfassenden Überblick über deinen Datensatz mit summary(dataset)\n\n\n\nGrundlegende Datenmanipulation\n\n\n\n\n\n\n\nSTATA\nR\n\n\n\n\nDatensatzspalten werden oft als “Variablen” bezeichnet\nHäufiger als “Spalten” oder manchmal als “Vektoren” oder “Variablen” bezeichnet\n\n\nKeine Notwendigkeit, den Datensatz zu spezifizieren\nBei jedem der folgenden Befehle musst du das Dataset angeben - siehe die Seite über [Daten bereinigen und Kernfunktionen] für Beispiele\n\n\nNeue Variablen werden mit dem Befehl erstellt erzeugen varname =\nErstelle neue Variablen mit der Funktion mutate(varname = ). Siehe Seite über [Datenbereinigung und Kernfunktionen] für Details zu allen folgenden Punktendplyr Funktionen.\n\n\nVariablen werden umbenannt mit umbenennen alter_name neuer_name\nSpalten können umbenannt werden mit der Funktion rename(new_name = old_name)\n\n\nVariablen werden gelöscht mit drop varname\nSpalten können mit der Funktion entfernt werden select() mit dem Spaltennamen in der Klammer nach einem Minuszeichen\n\n\nFaktorvariablen können mit einer Reihe von Befehlen beschriftet werden, z. B. Etikett definieren\nDu kannst Werte beschriften, indem du die Spalte in eine Faktorklasse umwandelst und Stufen angibst. Siehe Seite über [Faktoren]. Spaltennamen werden in der Regel nicht beschriftet, wie es in Stata der Fall ist.\n\n\n\nDeskriptive Analyse\n\n\n\n\n\n\n\nSTATA\nR\n\n\n\n\nZählungen einer Variablen tabellarisch darstellen mit tab varname\nGeben Sie den Datensatz und den Spaltennamen an table() wie zum Beispiel table(dataset$colname). Alternativ kannst du auch count(varname) aus dem dplyrPaket, wie in [Daten gruppieren]\n\n\nDie Kreuztabelle von zwei Variablen in einer 2x2-Tabelle wird mit tab varname1 varname2\nverwenden table(dataset$varname1, dataset$varname2 oder count(varname1, varname2)\n\n\n\nDiese Liste gibt zwar einen Überblick über die Grundlagen der Übersetzung von Stata-Befehlen in R, ist aber nicht vollständig. Es gibt noch viele andere großartige Ressourcen für Stata-Nutzer, die auf R umsteigen, die von Interesse sein könnten:\n\nhttps://dss.princeton.edu/training/RStata.pdf\nhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.html\nhttp://r4stats.com/books/r4stata/",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Übergang zu R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.de.html#von-sas",
    "href": "new_pages/transition_to_R.de.html#von-sas",
    "title": "4  Übergang zu R",
    "section": "4.3 Von SAS",
    "text": "4.3 Von SAS\n\nVon SAS zu R kommend\nSAS wird häufig in Behörden des öffentlichen Gesundheitswesens und in der akademischen Forschung eingesetzt. Der Umstieg auf eine neue Sprache ist zwar selten einfach, aber wenn du die wichtigsten Unterschiede zwischen SAS und R verstehst, kann es dir helfen, dich mit deiner Muttersprache in der neuen Sprache zurechtzufinden. Im Folgenden werden die wichtigsten Unterschiede zwischen SAS und R bei der Datenverwaltung und der deskriptiven Analyse beschrieben.\nAllgemeine Hinweise\n\n\n\nSAS\nR\n\n\n\n\nOnline-Community verfügbar über SAS Kundenbetreuung\nOnline-Community verfügbar über RStudio, StackOverFlow und R-Blogger\n\n\nHilfe für Befehle verfügbar über help [command]\nHilfe verfügbar durch [Funktion]? oder Suche im Hilfefenster\n\n\nCode kommentieren mit * TEXT ; oder /* TEXT */\nCode mit # kommentieren\n\n\nFast alle Befehle sind eingebaut. Benutzer können neue Funktionen mit SAS-Makros, SAS/IML, SAS Component Language (SCL) und neuerdings auch mit Prozeduren schreiben Proc Fcmp und Proc Proto\nR installiert sich mit BasisFunktionen, aber typischerweise müssen andere Pakete von CRAN installiert werden (siehe Seite über [R-Grundlagen])\n\n\nDie Analyse wird normalerweise durch das Schreiben eines SAS-Programms im Editor-Fenster durchgeführt.\nDie Analyse wird in einem R-Skript im RStudio-Quelltextfenster geschrieben. R Markdown-Skripte sind eine Alternative.\n\n\n\nArbeitsverzeichnis\n\n\n\n\n\n\n\nSAS\nR\n\n\n\n\nArbeitsverzeichnisse können entweder absolut oder relativ zu einem Projektstammverzeichnis sein, indem das Stammverzeichnis mit %let rootdir=/root path; %include \"&rootdir/subfoldername/filename\"\nArbeitsverzeichnisse können entweder absolut oder relativ zu einem Projektstammordner angegeben werden, indem Sie die hierPaket (siehe [Import und Export])\n\n\nSiehe aktuelles Arbeitsverzeichnis mit %put %sysfunc(getoption(work));\nverwenden. getwd() oder here() (bei Verwendung der hier Paket), mit leeren Klammern\n\n\nArbeitsverzeichnis festlegen mit libname \"folder location\"\nverwenden setwd(\"folder location\"), oder set_here(\"folder location) wenn Sie hier Paket\n\n\n\nDaten importieren und anzeigen\n\n\n\nSAS\nR\n\n\n\n\nverwenden Proc Import Verfahren oder mit Data Step Infile Anweisung.\nverwenden import() von rioPaket für fast alle Dateitypen. Es gibt spezielle Funktionen als Alternativen (siehe [Importieren und Exportieren])\n\n\nDas Einlesen von csv-Dateien erfolgt mit Hilfe von Proc Import datafile=\"filename.csv\" out=work.filename dbms=CSV; run; ODER mit Datenschritt Infile-Anweisung\nverwenden import(\"filename.csv\")\n\n\nDas Einlesen von xslx-Dateien erfolgt mit der Proc Import datafile=\"filename.xlsx\" out=work.filename dbms=xlsx; run; ODER mit Datenschritt Infile-Anweisung\nVerwende import(“Dateiname.xlsx”)\n\n\nDurchsuche deine Daten in einem neuen Fenster, indem du das Explorer-Fenster öffnest und die gewünschte Bibliothek und den Datensatz auswählst\nZeige einen Datensatz im RStudio-Quellfenster mit View(dataset) an. Du musst den Namen deines Datensatzes in der Funktion in R angeben, da mehrere Datensätze gleichzeitig gehalten werden können. Beachte das große “V” in dieser Funktion\n\n\n\nGrundlegende Datenmanipulation\n\n\n\n\n\n\n\nSAS\nR\n\n\n\n\nDatensatzspalten werden oft als “Variablen” bezeichnet\nHäufiger als “Spalten” oder manchmal als “Vektoren” oder “Variablen” bezeichnet\n\n\nUm eine Variable zu erstellen, sind keine besonderen Verfahren erforderlich. Neue Variablen werden einfach durch die Eingabe des neuen Variablennamens, gefolgt von einem Gleichheitszeichen und einem Ausdruck für den Wert, erstellt\nErstelle neue Variablen mit der Funktion mutate(). Siehe Seite über [Datenbereinigung und Kernfunktionen] für Details zu allen folgenden Punktendplyr Funktionen.\n\n\nVariablen werden umbenannt mit rename *old_name=new_name*\nSpalten können umbenannt werden mit der Funktion rename(new_name = old_name)\n\n\nVariablen werden beibehalten mit **keep**=varname\nSpalten können mit der Funktion ausgewählt werden select() mit dem Spaltennamen in den Klammern\n\n\nVariablen werden mit der Funktion **drop**=varname\nSpalten können mit der Funktion entfernt werden select() mit dem Spaltennamen in der Klammer nach einem Minuszeichen\n\n\nFaktorvariablen können im Datenschritt mit den folgenden Funktionen gekennzeichnet werden Label Anweisung\nDu kannst Werte beschriften, indem du die Spalte in eine Faktorklasse umwandelst und Stufen angibst. Siehe Seite über [Faktoren]. Spaltennamen werden normalerweise nicht beschriftet.\n\n\nDatensätze werden ausgewählt mit Where oder If Anweisung im Datenschritt ausgewählt. Mehrere Auswahlbedingungen werden mit dem Befehl “und” getrennt.\nDie Auswahl der Datensätze erfolgt mit der Funktion filter() mit mehreren Auswahlbedingungen, die entweder durch einen UND-Operator (&) oder ein Komma getrennt sind\n\n\nDatensätze werden kombiniert mit Merge Anweisung im Datenschritt kombiniert. Die zusammenzuführenden Datensätze müssen zunächst sortiert werden. Proc Sort Verfahren.\ndplyrPaket bietet ein paar Funktionen zum Zusammenführen von Datensätzen. Siehe Seite [Daten zusammenführen] für Details.\n\n\n\nDeskriptive Analyse\n\n\n\n\n\n\n\nSAS\nR\n\n\n\n\nVerschaffe dir einen umfassenden Überblick über deinen Datensatz mit Proc Summary Prozedur, die die Variablennamen und beschreibenden Statistiken liefert\nVerschaffe dir einen umfassenden Überblick über deinen Datensatz mit summary(dataset) oder skim(dataset) aus dem skimr Paket\n\n\nZählungen einer Variable tabellarisch darstellen mit proc freq data=Dataset; Tables varname; Run;\nSiehe die Seite über [Beschreibende Tabellen]. Die Optionen umfassentable() von Basis R, und tabyl() von Hausmeister Paket, unter anderem. Beachte, dass du den Datensatz und den Spaltennamen angeben musst, da R mehrere Datensätze speichert.\n\n\nDie Kreuztabellierung von zwei Variablen in einer 2x2-Tabelle wird durchgeführt mit proc freq data=Dataset; Tables rowvar*colvar; Run;\nAuch hier kannst du verwenden table(), tabyl()oder andere Optionen verwenden, wie sie in den [Beschreibende Tabellen] Seite beschrieben sind.\n\n\n\nEinige nützliche Ressourcen:\nR für SAS- und SPSS-Benutzer (2011)\nSAS und R, Zweite Ausgabe (2014)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Übergang zu R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.de.html#daten-interoperabilität",
    "href": "new_pages/transition_to_R.de.html#daten-interoperabilität",
    "title": "4  Übergang zu R",
    "section": "4.4 Daten-Interoperabilität",
    "text": "4.4 Daten-Interoperabilität\n\nSiehe die [Importieren und Exportieren] Seite für Details darüber, wie das R-Paketrio Dateien wie STATA .dta Dateien, SAS .xpt und.sas7bdat Dateien, SPSS .por und.sav Dateien und viele andere importieren und exportieren kann.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Übergang zu R</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.de.html",
    "href": "new_pages/packages_suggested.de.html",
    "title": "5  Vorgeschlagene Pakete",
    "section": "",
    "text": "5.1 Pakete aus CRAN\n##########################################\n# List of useful epidemiology R packages #\n##########################################\n\n# This script uses the p_load() function from pacman R package, \n# which installs if package is absent, and loads for use if already installed\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n# Packages available from CRAN\n##############################\npacman::p_load(\n     \n     # learning R\n     ############\n     learnr,   # interactive tutorials in RStudio Tutorial pane\n     swirl,    # interactive tutorials in R console\n        \n     # project and file management\n     #############################\n     here,     # file paths relative to R project root folder\n     rio,      # import/export of many types of data\n     openxlsx, # import/export of multi-sheet Excel workbooks \n     \n     # package install and management\n     ################################\n     pacman,   # package install/load\n     renv,     # managing versions of packages when working in collaborative groups\n     remotes,  # install from github\n     \n     # General data management\n     #########################\n     tidyverse,    # includes many packages for tidy data wrangling and presentation\n          #dplyr,      # data management\n          #tidyr,      # data management\n          #ggplot2,    # data visualization\n          #stringr,    # work with strings and characters\n          #forcats,    # work with factors \n          #lubridate,  # work with dates\n          #purrr       # iteration and working with lists\n     linelist,     # cleaning linelists\n     naniar,       # assessing missing data\n     \n     # statistics  \n     ############\n     janitor,      # tables and data cleaning\n     gtsummary,    # making descriptive and statistical tables\n     rstatix,      # quickly run statistical tests and summaries\n     broom,        # tidy up results from regressions\n     lmtest,       # likelihood-ratio tests\n     easystats,\n          # parameters, # alternative to tidy up results from regressions\n          # see,        # alternative to visualise forest plots \n     \n     # epidemic modeling\n     ###################\n     epicontacts,  # Analysing transmission networks\n     EpiNow2,      # Rt estimation\n     EpiEstim,     # Rt estimation\n     projections,  # Incidence projections\n     incidence2,   # Make epicurves and handle incidence data\n     i2extras,     # Extra functions for the incidence2 package\n     epitrix,      # Useful epi functions\n     distcrete,    # Discrete delay distributions\n     \n     \n     # plots - general\n     #################\n     #ggplot2,         # included in tidyverse\n     cowplot,          # combining plots  \n     # patchwork,      # combining plots (alternative)     \n     RColorBrewer,     # color scales\n     ggnewscale,       # to add additional layers of color schemes\n\n     \n     # plots - specific types\n     ########################\n     DiagrammeR,       # diagrams using DOT language\n     incidence2,       # epidemic curves\n     gghighlight,      # highlight a subset\n     ggrepel,          # smart labels\n     plotly,           # interactive graphics\n     gganimate,        # animated graphics \n\n     \n     # gis\n     ######\n     sf,               # to manage spatial data using a Simple Feature format\n     tmap,             # to produce simple maps, works for both interactive and static maps\n     OpenStreetMap,    # to add OSM basemap in ggplot map\n     spdep,            # spatial statistics \n     \n     # routine reports\n     #################\n     rmarkdown,        # produce PDFs, Word Documents, Powerpoints, and HTML files\n     reportfactory,    # auto-organization of R Markdown outputs\n     officer,          # powerpoints\n     \n     # dashboards\n     ############\n     flexdashboard,    # convert an R Markdown script into a dashboard\n     shiny,            # interactive web apps\n     \n     # tables for presentation\n     #########################\n     knitr,            # R Markdown report generation and html tables\n     flextable,        # HTML tables\n     #DT,              # HTML tables (alternative)\n     #gt,              # HTML tables (alternative)\n     #huxtable,        # HTML tables (alternative) \n     \n     # phylogenetics\n     ###############\n     ggtree,           # visualization and annotation of trees\n     ape,              # analysis of phylogenetics and evolution\n     treeio            # to visualize phylogenetic files\n \n)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Vorgeschlagene Pakete</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.de.html#pakete-von-github",
    "href": "new_pages/packages_suggested.de.html#pakete-von-github",
    "title": "5  Vorgeschlagene Pakete",
    "section": "5.2 Pakete von Github",
    "text": "5.2 Pakete von Github\nNachfolgend findest du die Befehle, um zwei Pakete direkt aus den Github-Repositories zu installieren.\n\nDie Entwicklungsversion von epicontacts enthält die Möglichkeit, Übertragungsbäume mit einer zeitlichen x-Achse zu erstellen\nDie epirhandbook Paket enthält alle Beispieldaten für dieses Handbuch und kann verwendet werden, um die Offline-Version des Handbuchs herunterzuladen.\n\n\n# Packages to download from Github (not available on CRAN)\n##########################################################\n\n# Development version of epicontacts (for transmission chains with a time x-axis)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# The package for this handbook, which includes all the example data  \npacman::p_install_gh(\"appliedepi/epirhandbook\")",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Vorgeschlagene Pakete</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.de.html",
    "href": "new_pages/r_projects.de.html",
    "title": "6  R-Projekte",
    "section": "",
    "text": "6.1 Empfohlene Verwendung\nEine gängige, effiziente und problemlose Art, R zu nutzen, ist die Kombination dieser 3 Elemente. Ein einzelnes Arbeitsprojekt wird in einem R-Projekt gehostet. Jedes Element wird in den folgenden Abschnitten beschrieben.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R-Projekte</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.de.html#empfohlene-verwendung",
    "href": "new_pages/r_projects.de.html#empfohlene-verwendung",
    "title": "6  R-Projekte",
    "section": "",
    "text": "Eine R-Projekt\n\n\nEine in sich geschlossene Arbeitsumgebung mit Ordnern für Daten, Skripte, Ausgaben, etc.\n\n\nDie hier Paket für relative Dateipfade\n\n\nDateipfade werden relativ zum Stammordner des R-Projekts geschrieben - siehe [Importieren und Exportieren] für weitere Informationen\n\n\nDie rio Paket zum Importieren/Exportieren\n\n\nimport() und export() jeden Dateityp anhand seiner Endung behandeln (z.B. .csv, .xlsx, .png)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R-Projekte</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.de.html#ein-r-projekt-erstellen",
    "href": "new_pages/r_projects.de.html#ein-r-projekt-erstellen",
    "title": "6  R-Projekte",
    "section": "6.2 Ein R-Projekt erstellen",
    "text": "6.2 Ein R-Projekt erstellen\nUm ein R-Projekt zu erstellen, wähle “Neues Projekt” aus dem Menü “Datei”.\n\nWenn du einen neuen Ordner für das Projekt erstellen möchtest, wähle “Neues Verzeichnis” und gib an, wo er erstellt werden soll.\nWenn du das Projekt innerhalb eines bestehenden Ordners erstellen möchtest, klicke auf “Vorhandenes Verzeichnis” und gib den Ordner an.\nWenn du ein Github-Repository klonen willst, wähle die dritte Option “Versionskontrolle” und dann “Git”. Siehe die Seite über [Versionskontrolle und Zusammenarbeit mit Git und Github] für weitere Informationen.\n\n\n\n\n\n\n\n\n\n\nDas R-Projekt, das du erstellst, hat die Form eines Ordners, der eine .Rproj Datei. Diese Datei ist eine Verknüpfung und wahrscheinlich die erste Art, wie du dein Projekt öffnest. Du kannst ein Projekt auch öffnen, indem du “Projekt öffnen” aus dem Menü “Datei” wählst. Alternativ dazu siehst du ganz oben rechts in RStudio ein R-Projekt-Symbol und ein Dropdown-Menü mit den verfügbaren R-Projekten.\nUm ein R-Projekt zu verlassen, öffne entweder ein neues Projekt oder schließe das Projekt (Datei - Projekt schließen).\n\nProjekte wechseln\nUm zwischen den Projekten zu wechseln, klicke auf das R-Projekt-Symbol und das Dropdown-Menü ganz oben rechts in RStudio. Du siehst dann die Optionen Projekt schließen, Projekt öffnen und eine Liste der letzten Projekte.\n\n\n\n\n\n\n\n\n\n\n\nEinstellungen\nIm Allgemeinen wird empfohlen, RStudio jedes Mal mit einem “Neustart” zu beginnen, d.h. mit deinem Arbeitsbereich nicht aus der vorherigen Sitzung erhalten bleibt. Das bedeutet, dass deine Objekte und Ergebnisse nicht von Sitzung zu Sitzung erhalten bleiben (du musst sie beim Ausführen deiner Skripte neu erstellen). Das ist gut, denn es zwingt dich dazu, bessere Skripte zu schreiben und langfristig Fehler zu vermeiden.\nSo stellst du sicher, dass RStudio beim Start jedes Mal einen “Neustart” hat:\n\nWähle “Projektoptionen” aus dem Menü “Extras”.\nSetze RStudio auf der Registerkarte “Allgemein” auf nicht RData beim Start nicht im Arbeitsbereich wiederhergestellt wird, und nicht Arbeitsbereich beim Beenden in .RData zu speichern.\n\n\n\nOrganisation\nEs ist üblich, dass du Unterordner in deinem Projekt hast. Ziehe Ordner wie “Daten”, “Skripte”, “Zahlen” und “Präsentationen” in Betracht. Du kannst Ordner auf die gleiche Weise hinzufügen, wie du einen neuen Ordner auf deinem Computer anlegen würdest. Alternativ kannst du auch die Seite über [Verzeichnis-Interaktionen] um zu erfahren, wie du mit R-Befehlen neue Ordner erstellen kannst.\n\n\nVersionskontrolle\nZiehe ein Versionskontrollsystem in Betracht. Es könnte so einfach sein wie ein Datum im Namen der Skripte (z.B. “transmission_analysis_2020-10-03.R”) und ein “Archiv”-Ordner. Du könntest auch überlegen, ob du am Anfang jedes Skripts einen kommentierten Text mit einer Beschreibung, Tags, Autoren und einem Änderungsprotokoll einfügen willst.\nEine kompliziertere Methode wäre die Verwendung von Github oder einer ähnlichen Plattform für die Versionskontrolle. Siehe die Seite über [Versionskontrolle und Zusammenarbeit mit Git und Github].\nEin Tipp ist, dass du mit dem Werkzeug “In Dateien suchen” (Menü Bearbeiten) ein ganzes Projekt oder einen Ordner durchsuchen kannst. Damit kannst du in mehreren Dateien suchen und sogar Zeichenfolgen ersetzen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R-Projekte</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.de.html#beispiele",
    "href": "new_pages/r_projects.de.html#beispiele",
    "title": "6  R-Projekte",
    "section": "6.3 Beispiele",
    "text": "6.3 Beispiele\nNachfolgend sind einige Beispiele für den Import/Export/Speicherung mit here() innerhalb eines R-Projekts. Lies mehr über die Verwendung der hierPaket in der [Importieren und Exportieren] Seite.\nImportieren linelist_raw.xlsx aus dem Ordner “data” in deinem R-Projekt\n\nlinelist &lt;- import(here(\"data\", \"linelist_raw.xlsx\"))\n\nExportieren des R-Objekts linelist als “my_linelist.rds” in den Ordner “clean” innerhalb des Ordners “data” in deinem R-Projekt.\n\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\n\nSpeichere den zuletzt gedruckten Plot als “epicurve_2021-02-15.png” im Ordner “epicurves” im Ordner “outputs” in deinem R-Projekt.\n\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R-Projekte</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.de.html#ressourcen",
    "href": "new_pages/r_projects.de.html#ressourcen",
    "title": "6  R-Projekte",
    "section": "6.4 Ressourcen",
    "text": "6.4 Ressourcen\nRStudio-Webseite auf Verwendung von R-Projekten",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R-Projekte</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html",
    "href": "new_pages/importing.de.html",
    "title": "7  Import und Export",
    "section": "",
    "text": "7.1 Übersicht\nWenn du einen “Datensatz” in R importierst, erstellst du in der Regel einen neuen Datenrahmen Objekt in deiner R-Umgebung und definierst es als eine importierte Datei (z. B. Excel, CSV, TSV, RDS), die sich in deinen Ordnerverzeichnissen unter einem bestimmten Dateipfad/einer bestimmten Adresse befindet.\nDu kannst viele Arten von Dateien importieren/exportieren, auch solche, die von anderen Statistikprogrammen (SAS, STATA, SPSS) erstellt wurden. Du kannst auch eine Verbindung zu relationalen Datenbanken herstellen.\nR hat sogar seine eigenen Datenformate:",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#übersicht",
    "href": "new_pages/importing.de.html#übersicht",
    "title": "7  Import und Export",
    "section": "",
    "text": "Eine RDS-Datei (.rds) speichert ein einzelnes R-Objekt, z. B. einen Datenrahmen. Sie sind nützlich, um bereinigte Daten zu speichern, da sie R-Spaltenklassen enthalten. Lies mehr in diesem Abschnitt.\nEine RData-Datei (.Rdata) kann verwendet werden, um mehrere Objekte oder sogar einen kompletten R-Arbeitsbereich zu speichern. Lies mehr in diesem Abschnitt.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#die-rio-paket",
    "href": "new_pages/importing.de.html#die-rio-paket",
    "title": "7  Import und Export",
    "section": "7.2 Die rio Paket",
    "text": "7.2 Die rio Paket\nDas R-Paket, das wir empfehlen, ist: rio. Der Name “rio” ist eine Abkürzung für “R I/O” (input/output).\nSeine Funktionen import() und export() können mit vielen verschiedenen Dateitypen umgehen (z. B. .xlsx, .csv, .rds, .tsv). Wenn du einen Dateipfad für eine dieser Funktionen angibst (einschließlich der Dateierweiterung wie “.csv”), rio die Erweiterung und verwendet das richtige Tool, um die Datei zu importieren oder zu exportieren.\nDie Alternative zur Verwendung von rio zu verwenden, ist die Verwendung von Funktionen aus vielen anderen Paketen, von denen jedes für einen bestimmten Dateityp spezifisch ist. Zum Beispiel, read.csv() (base R), read.xlsx() (openxlsx Paket), und write_csv() (readr pacakge), etc. Diese Alternativen können schwer zu merken sein, während die Verwendung von import() und export() von rio ist einfach.\nrio’s Funktionen import() und export() das passende Paket und die passende Funktion für eine bestimmte Datei verwenden, basierend auf ihrer Dateierweiterung. Am Ende dieser Seite findest du eine vollständige Tabelle mit den Paketen/Funktionen rio im Hintergrund verwendet. Es kann auch dazu verwendet werden, STATA-, SAS- und SPSS-Dateien zu importieren, neben Dutzenden anderer Dateitypen.\nDer Import/Export von Shapefiles erfordert andere Pakete, wie auf der Seite über [GIS-Grundlagen].",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#here",
    "href": "new_pages/importing.de.html#here",
    "title": "7  Import und Export",
    "section": "7.3 Die hier Paket",
    "text": "7.3 Die hier Paket\nDas Paket hier und seine Funktion here() machen es einfach, R mitzuteilen, wo es deine Dateien finden und speichern soll - im Wesentlichen werden Dateipfade erstellt.\nWird in Verbindung mit einem R-Projekt verwendet, hier können Sie den Speicherort der Dateien in Ihrem R-Projekt in Bezug auf das R-Projekt selbst beschreiben. Stammverzeichnis (der oberste Ordner). Das ist nützlich, wenn das R-Projekt von mehreren Personen/Computern genutzt wird. Es verhindert Komplikationen aufgrund von eindeutigen Dateipfaden auf verschiedenen Computern (z. B. \"C:/Users/Laura/Documents...\" indem du den Dateipfad an einem Ort beginnst, der für alle Benutzer gleich ist (das Stammverzeichnis des R-Projekts).\nSo wird here() innerhalb eines R-Projekts funktioniert:\n\nWenn die hier Paket zum ersten Mal in das R-Projekt geladen wird, legt es eine kleine Datei namens “.here” im Stammverzeichnis deines R-Projekts als “Benchmark” oder “Anker” ab\nUm in deinen Skripten auf eine Datei in den Unterordnern des R-Projekts zu verweisen, verwendest du die Funktion here() um den Dateipfad zu erstellen in Bezug auf diesen Anker\nUm den Dateipfad zu erstellen, schreibst du die Namen der Ordner, die über das Stammverzeichnis hinausgehen, in Anführungszeichen, getrennt durch Kommas, und endest schließlich mit dem Dateinamen und der Dateierweiterung, wie unten gezeigt\nhere() Dateipfade können sowohl für den Import als auch für den Export verwendet werden\n\nIm Folgenden wird zum Beispiel die Funktion import() wird ein Dateipfad übergeben, der mit here().\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\nDer Befehl here(\"data\", \"linelists\", \"ebola_linelist.xlsx\") gibt eigentlich den vollständigen Dateipfad an, der der nur auf dem Computer des Benutzers:\n\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\"\nDas Schöne daran ist, dass der R-Befehl mit here() erfolgreich auf jedem Computer ausgeführt werden kann, der auf das R-Projekt zugreift.\nTIPP: Wenn du dir nicht sicher bist, wo die “.here”-Wurzel gesetzt ist, führe die Funktion here() mit leeren Klammern aus.\nLies mehr über die hier Paket unter diesem Link.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#dateipfade",
    "href": "new_pages/importing.de.html#dateipfade",
    "title": "7  Import und Export",
    "section": "7.4 Dateipfade",
    "text": "7.4 Dateipfade\nWenn du Daten importierst oder exportierst, musst du einen Dateipfad angeben. Du kannst dies auf drei Arten tun:\n\nEmpfohlen: Gib einen “relativen” Dateipfad mit der Option hier Paket\nGib den “vollständigen” / “absoluten” Dateipfad an\nManuelle Dateiauswahl\n\n\n“Relative” Dateipfade\nIn R bestehen “relative” Dateipfade aus dem Dateipfad relativ zu dem Stammverzeichnis eines R-Projekts. Sie ermöglichen einfachere Dateipfade, die auf verschiedenen Computern funktionieren können (z. B. wenn das R-Projekt auf einem gemeinsamen Laufwerk liegt oder per E-Mail verschickt wird). Wie beschrieben oben beschrieben, werden relative Dateipfade durch die Verwendung der hier Pakets.\nEin Beispiel für einen relativen Dateipfad, der mit here() konstruiert wurde, ist unten zu sehen. Wir gehen davon aus, dass sich die Arbeit in einem R-Projekt befindet, das einen Unterordner “data” und darin einen Unterordner “linelists” enthält, in dem sich die betreffende .xlsx-Datei befindet.\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\n\n\n“Absolute” Dateipfade\nAbsolute oder “vollständige” Dateipfade können an Funktionen übergeben werden wie import() zur Verfügung gestellt werden, aber sie sind “zerbrechlich”, da sie nur für den Computer des Nutzers gelten und daher nicht empfohlen.\nUnten siehst du ein Beispiel für einen absoluten Dateipfad: Auf Lauras Computer gibt es einen Ordner “analysis”, einen Unterordner “data” und darin einen Unterordner “linelists”, in dem sich die betreffende .xlsx-Datei befindet.\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")\n\nZu den absoluten Dateipfaden gibt es ein paar Dinge zu beachten:\n\nVermeide die Verwendung absoluter Dateipfade da sie nicht funktionieren, wenn das Skript auf einem anderen Computer ausgeführt wird\nVerwende vorwärts Schrägstriche (/), wie im obigen Beispiel (Hinweis: Dies ist NICHT der Standard für Windows-Dateipfade)\nDateipfade, die mit doppelten Schrägstrichen beginnen (z. B. “//…”), werden wahrscheinlich von R nicht erkannt werdennicht erkannt und führt zu einer Fehlermeldung. Erwäge, deine Arbeit auf ein “benanntes” oder “beschriftetes” Laufwerk zu verschieben, das mit einem Buchstaben beginnt (z. B. “J:” oder “C:”). Siehe die Seite über [Wechselwirkungen zwischen Verzeichnissen] für weitere Informationen zu diesem Thema.\n\nEin Szenario, in dem absolute Dateipfade sinnvoll sein können, ist, wenn du eine Datei von einem freigegebenen Laufwerk importieren willst, die für alle Benutzer denselben vollständigen Dateipfad hat.\nTIPP: So konvertieren Sie schnell alle \\ zu / zu konvertieren, markiere den gewünschten Code, benutze Strg+f (in Windows), aktiviere das Kontrollkästchen für “In Auswahl” und benutze dann die Ersetzen-Funktion, um sie zu konvertieren.\n\n\n\nDatei manuell auswählen\nDu kannst Daten mit einer der folgenden Methoden manuell importieren:\n\nUmgebung RStudio Pane, klicke auf “Datensatz importieren” und wähle die Art der Daten aus\nKlicke auf Datei / Datensatz importieren / (wähle die Art der Daten)\nUm eine manuelle Auswahl zu treffen, verwende die Basis-R Befehl file.choose() (die Klammern bleiben leer), um das Erscheinen eines Pop-up-Fensters das es dem Benutzer ermöglicht, die Datei manuell auf seinem Computer auszuwählen. Zum Beispiel:\n\n\n# Manual selection of a file. When this command is run, a POP-UP window will appear. \n# The file path selected will be supplied to the import() command.\n\nmy_data &lt;- import(file.choose())\n\nTIPP: Die Pop-up-Fenster kann HINTER deinem RStudio-Fenster erscheinen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#daten-importieren",
    "href": "new_pages/importing.de.html#daten-importieren",
    "title": "7  Import und Export",
    "section": "7.5 Daten importieren",
    "text": "7.5 Daten importieren\nZur Verwendung import() um einen Datensatz zu importieren, ist ganz einfach. Gib einfach den Pfad zur Datei (einschließlich des Dateinamens und der Dateierweiterung) in Anführungszeichen an. Wenn du here() um den Dateipfad zu erstellen, befolge die obigen Anweisungen. Nachfolgend ein paar Beispiele:\nImportieren einer csv-Datei, die sich in deinem “Arbeitsverzeichnis” oder im Stammverzeichnis des R-Projekts befindet:\n\nlinelist &lt;- import(\"linelist_cleaned.csv\")\n\nImportieren des ersten Blatts einer Excel-Arbeitsmappe, die sich in den Unterordnern “data” und “linelists” des R-Projekts befindet (der Dateipfad wurde mit here()):\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\n\nImportieren eines Datenrahmens (einer .rds-Datei) unter Verwendung eines absoluten Dateipfads:\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")\n\n\nSpezifische Excel-Tabellen\nWenn du eine Excel-Arbeitsmappe (.xlsx) an die Datenbank übergibst, wird diese standardmäßig import() angibst, wird das erste Blatt der Arbeitsmappe importiert. Wenn du ein bestimmtes Blatt importieren möchtest Blatt importieren möchtest, füge den Blattnamen in die which = Argument. Zum Beispiel:\n\nmy_data &lt;- import(\"my_excel_file.xlsx\", which = \"Sheetname\")\n\nWenn du das here() Methode verwenden, um einen relativen Pfad zu import() verwenden, können Sie trotzdem ein bestimmtes Blatt angeben, indem Sie die which = Argument nach der schließenden Klammer der Methode here() Funktion hinzufügst.\n\n# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\nlinelist_raw &lt;- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  \n\nAn exportieren einen Datenrahmen aus R in ein bestimmtes Excel-Blatt zu exportieren und den Rest der Excel-Arbeitsmappe unverändert zu lassen, musst du mit einem alternativen Paket importieren, bearbeiten und exportieren, das für diesen Zweck geeignet ist, wie z. B. openxlsx. Weitere Informationen finden Sie auf der Seite über [Verzeichnis-Interaktionen] oderauf dieser Github-Seite.\nWenn deine Excel-Arbeitsmappe das Format .xlsb hat (Excel-Arbeitsmappe im Binärformat), kannst du sie möglicherweise nicht importieren, indem du rio. Erwäge, sie erneut als .xlsx zu speichern, oder verwende ein Paket wie readxlsb das für folgende Zwecke entwickelt wurde diesem Zweck.\n\n\n\n7.5.1 Fehlende Werte {#import_missing .unnumbered}\nDu möchtest vielleicht festlegen, welche Werte in deinem Datensatz als fehlend gelten sollen. Wie auf der Seite über [Fehlende Daten] erläutert, ist der Wert in R für fehlende DatenNA aber vielleicht verwendet der Datensatz, den du importieren möchtest, stattdessen 99, “Missing” oder einfach nur ein leeres Zeichen ““.\nVerwenden Sie die na = Argument für import() und gib den/die Wert(e) in Anführungszeichen an (auch wenn es Zahlen sind). Du kannst mehrere Werte angeben, indem du sie in einen Vektor einschließt, indem du c() wie unten gezeigt.\nHier wird der Wert “99” im importierten Datensatz als fehlend betrachtet und in NA in R umgewandelt.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\n\nHier wird jeder der Werte “Missing”, “” (leere Zelle) oder ” ” (einzelnes Leerzeichen) im importierten Datensatz in NA in R umgewandelt.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))\n\n\n\n\nZeilen überspringen\nManchmal möchtest du vielleicht vermeiden, eine Datenzeile zu importieren. Das kannst du mit dem Argument skip = wenn du import() von rio auf eine .xlsx oder .csv Datei. Gib die Anzahl der Zeilen an, die übersprungen werden sollen.\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row\n\nLeider skip = nur einen ganzzahligen Wert akzeptiert, nicht einen Bereich (z. B. “2:10” funktioniert nicht). Um den Import bestimmter Zeilen, die nicht von oben nach unten aufeinander folgen, zu überspringen, kannst du den Import mehrfach durchführen und die bind_rows() von dplyr. Siehe das Beispiel unten, in dem nur Zeile 2 übersprungen wird.\n\n\nVerwalte eine zweite Kopfzeile\nManchmal kann es vorkommen, dass deine Daten eine zweite Zeile, zum Beispiel wenn es sich um eine “Data Dictionary”-Zeile handelt, wie unten gezeigt. Diese Situation kann problematisch sein, denn sie kann dazu führen, dass alle Spalten als Klasse “Zeichen” importiert werden.\nUnten siehst du ein Beispiel für einen solchen Datensatz (wobei die erste Zeile das Datenwörterbuch ist).\n\n\n\n\n\n\n\nEntferne die zweite Kopfzeile\nUm die zweite Kopfzeile zu entfernen, musst du die Daten wahrscheinlich zweimal importieren.\n\nImportiere die Daten, um die richtigen Spaltennamen zu speichern\nImportiere die Daten erneut und überspringe dabei den ersten zwei Zeilen (Kopfzeile und zweite Zeile)\nBinde die richtigen Namen an den reduzierten Datenrahmen\n\nDas genaue Argument, das zum Binden der korrekten Spaltennamen verwendet wird, hängt von der Art der Datendatei ab (.csv, .tsv, .xlsx, etc.). Das liegt daran, dass rio eine andere Funktion für die verschiedenen Dateitypen verwendet (siehe Tabelle oben).\nFür Excel-Dateien: (col_names =)\n\n# import first time; store the column names\nlinelist_raw_names &lt;- import(\"linelist_raw.xlsx\") %&gt;% names()  # save true column names\n\n# import second time; skip row 2, and assign column names to argument col_names =\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n\nFür CSV-Dateien: (col.names =)\n\n# import first time; sotre column names\nlinelist_raw_names &lt;- import(\"linelist_raw.csv\") %&gt;% names() # save true column names\n\n# note argument for csv files is 'col.names = '\nlinelist_raw &lt;- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n\nBackup-Option - Ändern von Spaltennamen als separater Befehl\n\n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) &lt;- linelist_raw_names\n\n\n\nEin Datenwörterbuch erstellen\nBonus! Wenn du eine zweite Zeile hast, die ein Datenwörterbuch ist, kannst du daraus ganz einfach ein richtiges Datenwörterbuch erstellen. Dieser Tipp ist von diesem Beitrag.\n\ndict &lt;- linelist_2headers %&gt;%             # begin: linelist with dictionary as first row\n  head(1) %&gt;%                             # keep only column names and first dictionary row                \n  pivot_longer(cols = everything(),       # pivot all columns to long format\n               names_to = \"Column\",       # assign new column names\n               values_to = \"Description\")\n\n\n\n\n\n\n\n\n\nKombiniere die beiden Kopfzeilen\nIn manchen Fällen, wenn dein Rohdatensatz zwei Kopfzeilen hat (oder genauer gesagt, die zweite Datenzeile ist eine sekundäre Kopfzeile), möchtest du sie vielleicht “kombinieren” oder die Werte der zweiten Kopfzeile zur ersten Kopfzeile hinzufügen.\nMit dem folgenden Befehl werden die Spaltennamen des Datenrahmens als Kombination (Zusammenfügen) der ersten (echten) Kopfzeile mit dem Wert direkt darunter (in der ersten Zeile) definiert.\n\nnames(my_data) &lt;- paste(names(my_data), my_data[1, ], sep = \"_\")\n\n\n\n\n\nGoogle Sheets\nDu kannst Daten aus einer Online-Google-Tabelle importieren, indem du die googlesheet4 Paket und durch Authentifizierung deines Zugriffs auf die Tabelle importieren.\n\npacman::p_load(\"googlesheets4\")\n\nNachfolgend wird ein Google-Demoblatt importiert und gespeichert. Dieser Befehl kann zur Bestätigung der Authentifizierung deines Google-Kontos auffordern. Folge den Aufforderungen und Pop-ups in deinem Internetbrowser, um den Tidyverse API-Paketen die Berechtigung zum Bearbeiten, Erstellen und Löschen deiner Tabellen in Google Drive zu erteilen.\nDas Blatt unten ist “für jeden mit dem Link einsehbar” und du kannst versuchen, es zu importieren.\n\nGsheets_demo &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\n\nDas Blatt kann auch nur mit der Blatt-ID, einem kürzeren Teil der URL, importiert werden:\n\nGsheets_demo &lt;- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")\n\nEin anderes Paket, googledrive bietet nützliche Funktionen zum Schreiben, Bearbeiten und Löschen von Google Sheets. Zum Beispiel kann man mit dem gs4_create() und sheet_write() Funktionen, die du in diesem Paket findest.\nHier sind einige andere hilfreiche Online-Tutorials:\nGrundlegende Anleitung zum Importieren von Google Sheets\nAusführlicheres Tutorial\nInteraktion zwischen googlesheets4 und tidyverse",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#mehrere-dateien---importieren-exportieren-teilen-kombinieren",
    "href": "new_pages/importing.de.html#mehrere-dateien---importieren-exportieren-teilen-kombinieren",
    "title": "7  Import und Export",
    "section": "7.6 Mehrere Dateien - importieren, exportieren, teilen, kombinieren",
    "text": "7.6 Mehrere Dateien - importieren, exportieren, teilen, kombinieren\nSiehe die Seite über [Iteration, Schleifen und Listen] findest du Beispiele dafür, wie du mehrere Dateien oder mehrere Excel-Arbeitsmappendateien importieren und kombinieren kannst. Auf dieser Seite findest du auch Beispiele dafür, wie du einen Datenrahmen in mehrere Teile aufteilst und diese einzeln oder als benannte Blätter in einer Excel-Arbeitsmappe exportierst.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#von-github-importieren-import_github",
    "href": "new_pages/importing.de.html#von-github-importieren-import_github",
    "title": "7  Import und Export",
    "section": "7.7 Von Github importieren {#import_github}",
    "text": "7.7 Von Github importieren {#import_github}\nDaten direkt von Github in R zu importieren, kann sehr einfach sein oder ein paar Schritte erfordern - je nach Dateityp. Im Folgenden findest du einige Ansätze:\n\nCSV-Dateien\nEs kann einfach sein, eine .csv-Datei direkt von Github mit einem R-Befehl in R zu importieren.\n\nGehe zum Github-Repositorium, suche die gewünschte Datei und klicke sie an\nKlicke auf die Schaltfläche “Raw” (du siehst dann die “rohen” csv-Daten, wie unten dargestellt)\nKopiere die URL (Webadresse)\nSetze die URL in Anführungszeichen innerhalb der import() R-Befehl\n\n\n\n\n\n\n\n\n\n\n\n\nXLSX-Dateien\nBei einigen Dateien (z. B. .xlsx, .rds, .nwk, .shp) kannst du die “Rohdaten” möglicherweise nicht anzeigen.\n\nGehe zum Github Repo, suche die gewünschte Datei und klicke sie an\nKlicke auf die Schaltfläche “Herunterladen”, wie unten gezeigt\nSpeichere die Datei auf deinem Computer und importiere sie in R\n\n\n\n\n\n\n\n\n\n\n\n\nShapefiles\nShapefiles haben viele Unterdateien, die jeweils eine andere Dateierweiterung haben. Eine Datei hat die Endung “.shp”, aber andere können “.dbf”, “.prj” usw. haben. Um ein Shapefile von Github herunterzuladen, musst du jede Unterkomponentendatei einzeln herunterladen und sie im Ordner gleichen Ordner auf deinem Computer speichern. Klicke in Github auf jede einzelne Datei und lade sie herunter, indem du auf die Schaltfläche “Herunterladen” klickst.\nSobald du sie auf deinem Computer gespeichert hast, kannst du das Shapefile importieren, wie im Abschnitt [GIS-Grundlagen] Seite gezeigt, mitst_read() aus dem sf Paket. Du musst nur den Dateipfad und den Namen der “.shp”-Datei angeben - vorausgesetzt, die anderen zugehörigen Dateien befinden sich im selben Ordner auf deinem Computer.\nUnten kannst du sehen, wie das Shapefile “sle_adm3” aus vielen Dateien besteht, die alle von Github heruntergeladen werden müssen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#manuelle-dateneingabe",
    "href": "new_pages/importing.de.html#manuelle-dateneingabe",
    "title": "7  Import und Export",
    "section": "7.8 Manuelle Dateneingabe",
    "text": "7.8 Manuelle Dateneingabe\n\nEingabe nach Zeilen\nVerwenden Sie die tribble Funktion aus dem tibble Paket aus dem tidyverse (Online-Referenz für tibble).\nBeachte, dass die Spaltenüberschriften mit einem Tilde (~). Beachte auch, dass jede Spalte nur eine Klasse von Daten enthalten darf (Zeichen, Zahlen usw.). Du kannst Tabulatoren, Abstände und neue Zeilen verwenden, um die Dateneingabe intuitiver und lesbarer zu machen. Leerzeichen zwischen den Werten spielen keine Rolle, aber jede Zeile wird durch eine neue Codezeile dargestellt. Ein Beispiel:\n\n# create the dataset manually by row\nmanual_entry_rows &lt;- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )\n\nUnd jetzt zeigen wir den neuen Datensatz an:\n\n\n\n\n\n\n\n\nEintrag nach Spalten\nDa ein Datenrahmen aus Vektoren (vertikalen Spalten) besteht, ist die Basis Ansatz zur manuellen Erstellung von Datenrahmen in R, dass du jede Spalte definierst und sie dann miteinander verbindest. Das kann in der Epidemiologie kontraintuitiv sein, da wir unsere Daten normalerweise in Zeilen denken (wie oben).\n\n# define each vector (vertical column) separately, each with its own name\nPatientID &lt;- c(235, 452, 778, 111)\nTreatment &lt;- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     &lt;- c(1, 0, 1, 0)\n\nVORSICHT! Alle Vektoren müssen die gleiche Länge haben (gleiche Anzahl von Werten).\nDie Vektoren können dann mit der Funktion zusammengebunden werden data.frame():\n\n# combine the columns into a data frame, by referencing the vector names\nmanual_entry_cols &lt;- data.frame(PatientID, Treatment, Death)\n\nUnd jetzt zeigen wir den neuen Datensatz an:\n\n\n\n\n\n\n\n\nEinfügen aus der Zwischenablage\nWenn du Daten von einem anderen Ort kopierst und sie in deiner Zwischenablage hast, kannst du eine der beiden folgenden Möglichkeiten ausprobieren:\nVon der clipr Paket kannst du Folgendes verwenden read_clip_tbl() als Datenrahmen importieren, oder einfach nur read_clip() um als Zeichenvektor zu importieren. In beiden Fällen lässt du die Klammern leer.\n\nlinelist &lt;- clipr::read_clip_tbl()  # imports current clipboard as data frame\nlinelist &lt;- clipr::read_clip()      # imports as character vector\n\nDu kannst auch einfach in die Zwischenablage deines Systems exportieren mit clipr. Siehe den Abschnitt unten über Export.\nAlternativ kannst du auch die Funktion read.table() Funktion von Basis R mit file = \"clipboard\") als Datenrahmen zu importieren:\n\ndf_from_clipboard &lt;- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#importiere-die-letzte-datei",
    "href": "new_pages/importing.de.html#importiere-die-letzte-datei",
    "title": "7  Import und Export",
    "section": "7.9 Importiere die letzte Datei",
    "text": "7.9 Importiere die letzte Datei\nOft erhältst du tägliche Aktualisierungen deiner Datensätze. In diesem Fall möchtest du einen Code schreiben, der die aktuellste Datei importiert. Im Folgenden stellen wir dir zwei Möglichkeiten vor, wie du vorgehen kannst:\n\nAuswahl der Datei anhand des Datums im Dateinamen\nAuswahl der Datei anhand der Datei-Metadaten (letzte Änderung)\n\n\nDatum im Dateinamen\nDieser Ansatz beruht auf drei Voraussetzungen:\n\nDu vertraust den Daten in den Dateinamen\nDie Datumsangaben sind numerisch und erscheinen in der Regel demselben Format (z.B. Jahr, Monat, Tag)\nEs gibt keine anderen Zahlen im Dateinamen\n\nWir erklären dir die einzelnen Schritte und zeigen sie dir am Ende kombiniert.\nVerwende zunächst dir() von BasisR, um nur die Dateinamen für jede Datei im gewünschten Ordner zu extrahieren. Siehe die Seite über [Verzeichnis-Interaktionen] für weitere Details überdir(). In diesem Beispiel ist der Ordner von Interesse der Ordner “linelists” innerhalb des Ordners “example” innerhalb von “data” im R-Projekt.\n\nlinelist_filenames &lt;- dir(here(\"data\", \"example\", \"linelists\")) # get file names from folder\nlinelist_filenames                                              # print\n\n[1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\" \n[3] \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \n[5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n[7] \"case_linelist20201006.csv\"    \n\n\nSobald du diesen Vektor von Namen hast, kannst du die Daten aus ihnen extrahieren, indem du str_extract() von stringr mithilfe dieses regulären Ausdrucks. Er extrahiert alle Zahlen im Dateinamen (einschließlich aller anderen Zeichen in der Mitte wie Bindestriche oder Schrägstriche). Du kannst mehr darüber lesen stringrim Abschnitt [Zeichenketten und Zeichen] Seite.\n\nlinelist_dates_raw &lt;- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print\n\n[1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"20201006\"  \n\n\nAngenommen, die Daten werden im Allgemeinen im gleichen Datumsformat geschrieben (z. B. Jahr, dann Monat, dann Tag) und die Jahre sind 4-stellig, dann kannst du Folgendes verwenden lubridate die flexiblen Konvertierungsfunktionen (ymd(), dmy(), oder mdy()), um sie in ein Datum umzuwandeln. Bei diesen Funktionen spielen die Bindestriche, Leerzeichen oder Schrägstriche keine Rolle, nur die Reihenfolge der Zahlen. Lies mehr im Abschnitt [Arbeiten mit Datumsangaben] Seite.\n\nlinelist_dates_clean &lt;- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean\n\n[1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"2020-10-06\"\n\n\nDie Basis R-Funktion which.max() kann dann verwendet werden, um die Indexposition (z. B. 1., 2., 3., …) des maximalen Datumswertes zurückzugeben. Die neueste Datei wird korrekt als die 6. Datei identifiziert - “case_linelist_2020-10-08.xlsx”.\n\nindex_latest_file &lt;- which.max(linelist_dates_clean)\nindex_latest_file\n\n[1] 6\n\n\nWenn wir alle diese Befehle zusammenfassen, könnte der vollständige Code wie folgt aussehen. Beachte, dass die . in der letzten Zeile ein Platzhalter für das gepipte Objekt an dieser Stelle der Pipe-Sequenz ist. An dieser Stelle ist der Wert einfach die Zahl 6. Diese wird in doppelte Klammern gesetzt, um das 6. Element des Vektors der Dateinamen zu extrahieren, der von dir().\n\n# load packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extract the file name of latest file\nlatest_file &lt;- dir(here(\"data\", \"example\", \"linelists\")) %&gt;%  # file names from \"linelists\" sub-folder          \n  str_extract(\"[0-9].*[0-9]\") %&gt;%                  # pull out dates (numbers)\n  ymd() %&gt;%                                        # convert numbers to dates (assuming year-month-day format)\n  which.max() %&gt;%                                  # get index of max date (latest file)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # return the filename of latest linelist\n\nlatest_file  # print name of latest file\n\n[1] \"case_linelist_2020-10-08.xlsx\"\n\n\nDu kannst diesen Namen nun verwenden, um den relativen Dateipfad zu vervollständigen, indem du here():\n\nhere(\"data\", \"example\", \"linelists\", latest_file) \n\nUnd schon kannst du die neueste Datei importieren:\n\n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # import \n\n\n\nVerwende die Dateiinfo\nWenn deine Dateien kein Datum im Namen haben (oder du diesen Daten nicht traust), kannst du versuchen, das Datum der letzten Änderung aus den Datei-Metadaten zu extrahieren. Verwende Funktionen aus dem Paket fs um die Metadaten jeder Datei zu untersuchen. Dazu gehören die Zeit der letzten Änderung und der Dateipfad.\nIm Folgenden stellen wir den Ordner von Interesse für fs’s dir_info(). In diesem Fall befindet sich der Ordner von Interesse im R-Projekt im Ordner “data”, dem Unterordner “example” und dessen Unterordner “linelists”. Das Ergebnis ist ein Datenrahmen mit einer Zeile pro Datei und Spalten für modification_time, path, usw. Ein visuelles Beispiel dafür findest du auf der Seite über [Verzeichnis-Interaktionen].\nWir können diesen Datenrahmen von Dateien nach der Spalte sortieren modification_time sortieren und dann nur die oberste/letzte Zeile (Datei) mit Basis R’s head(). Dann können wir den Dateipfad dieser letzten Datei nur mit dem dplyr Funktion pull() auf die Spalte path. Schließlich können wir diesen Dateipfad an import(). Die importierte Datei wird gespeichert als latest_file.\n\nlatest_file &lt;- dir_info(here(\"data\", \"example\", \"linelists\")) %&gt;%  # collect file info on all files in directory\n  arrange(desc(modification_time)) %&gt;%      # sort by modification time\n  head(1) %&gt;%                               # keep only the top (latest) file\n  pull(path) %&gt;%                            # extract only the file path\n  import()                                  # import the file",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#apis-import_api",
    "href": "new_pages/importing.de.html#apis-import_api",
    "title": "7  Import und Export",
    "section": "7.10 APIs {#import_api}",
    "text": "7.10 APIs {#import_api}\nEine “Automatisierte Programmierschnittstelle” (API) kann verwendet werden, um Daten direkt von einer Website abzufragen. APIs sind eine Reihe von Regeln, die es einer Softwareanwendung ermöglichen, mit einer anderen zu interagieren. Der Client (du) sendet eine “Anfrage” und erhält eine “Antwort” mit Inhalten. Die R-Pakete httr und jsonlite können diesen Prozess erleichtern.\nJede API-fähige Website hat ihre eigene Dokumentation und Besonderheiten, mit denen du dich vertraut machen musst. Einige Websites sind öffentlich zugänglich und können von jedermann genutzt werden. Andere, wie z. B. Plattformen mit Benutzer-IDs und Anmeldedaten, erfordern eine Authentifizierung, um auf ihre Daten zuzugreifen.\nNatürlich ist eine Internetverbindung erforderlich, um Daten über eine API zu importieren. Wir werden kurz Beispiele für die Nutzung von APIs für den Datenimport geben und dich mit weiteren Ressourcen verlinken.\nHinweis: Denke daran, dass die Daten veröffentlicht* auf einer Website ohne API veröffentlicht werden, die einfacher abzurufen ist. Auf eine CSV-Datei kann zum Beispiel einfach durch Angabe der URL der Website zugegriffen werden. import() wie in dem Abschnitt über Importieren aus Github.*\n\nHTTP-Anfrage\nDer API-Austausch erfolgt in der Regel über eine HTTP-Anfrage. HTTP steht für Hypertext Transfer Protocol und ist das grundlegende Format für eine Anfrage/Antwort zwischen einem Client und einem Server. Die genaue Eingabe und Ausgabe kann je nach Art der API variieren, aber der Prozess ist derselbe - eine “Anfrage” (oft HTTP Request) des Nutzers, die oft eine Abfrage enthält, gefolgt von einer “Antwort”, die Statusinformationen über die Anfrage und möglicherweise den angeforderten Inhalt enthält.\nHier sind ein paar Komponenten einer HTTP-Anfrage:\n\nDie URL des API-Endpunkts\nDie “Methode” (oder das “Verb”)\nÜberschriften\nKörper\n\nDie “Methode” der HTTP-Anfrage ist die Aktion, die du ausführen möchtest. Die beiden gängigsten HTTP-Methoden sind GET und POST aber andere können sein PUT, DELETE, PATCH, usw. Wenn du Daten in R importierst, ist es sehr wahrscheinlich, dass du GET.\nNach deiner Anfrage erhält dein Computer eine “Antwort” in einem ähnlichen Format wie das, was du gesendet hast, einschließlich URL, HTTP-Status (Status 200 ist das, was du willst!), Dateityp, Größe und dem gewünschten Inhalt. Diese Antwort musst du dann in deiner R-Umgebung parsen und in einen brauchbaren Datenrahmen verwandeln.\n\n\nPakete\nDie httr Paket eignet sich gut für die Bearbeitung von HTTP-Anfragen in R. Es erfordert kaum Vorkenntnisse über Web-APIs und kann auch von Personen verwendet werden, die mit der Terminologie der Softwareentwicklung weniger vertraut sind. Wenn die HTTP-Antwort im .json-Format vorliegt, kannst du außerdem mit jsonlite verwenden, um die Antwort zu parsen.\n\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)\n\n\n\nÖffentlich zugängliche Daten\nIm Folgenden findest du ein Beispiel für eine HTTP-Anfrage, das aus einem Tutorial von dem Trafford Data Lab. Auf dieser Seite findest du weitere Ressourcen zum Lernen und API-Übungen.\nSzenario: Wir wollen eine Liste von Fastfood-Lokalen in der Stadt Trafford, Großbritannien, importieren. Die Daten können über die API der Food Standards Agency abgerufen werden, die Daten zur Lebensmittelhygienebewertung für das Vereinigte Königreich bereitstellt.\nHier sind die Parameter für unsere Anfrage:\n\nHTTP-Verb: GET\nAPI-Endpunkt-URL: http://api.ratings.food.gov.uk/Establishments\nAusgewählte Parameter: Name, Adresse, Längengrad, Breitengrad, businessTypeId, ratingKey, localAuthorityId\nHeader: “x-api-version”, 2\nDatenformat(e): JSON, XML\nDokumentation: http://api.ratings.food.gov.uk/help\n\nDer R-Code würde wie folgt lauten:\n\n# prepare the request\npath &lt;- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest &lt;- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# check for any server error (\"200\" is good!)\nrequest$status_code\n\n# submit the request, parse the response, and convert to a data frame\nresponse &lt;- content(request, as = \"text\", encoding = \"UTF-8\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%\n  pluck(\"establishments\") %&gt;%\n  as_tibble()\n\nDu kannst jetzt den Code bereinigen und die response Datenrahmen, der eine Zeile pro Fastfood-Betrieb enthält, bereinigen und verwenden.\n\n\nAuthentifizierung erforderlich\nFür einige APIs ist eine Authentifizierung erforderlich - du musst nachweisen, wer du bist, damit du auf eingeschränkte Daten zugreifen kannst. Um diese Daten zu importieren, musst du eventuell zuerst eine POST-Methode verwenden, um einen Benutzernamen, ein Passwort oder einen Code anzugeben. Dadurch erhältst du ein Zugriffstoken, das du für nachfolgende GET-Anfragen zum Abrufen der gewünschten Daten verwenden kannst.\nIm Folgenden findest du ein Beispiel für die Abfrage von Daten aus Go.Daten das ein Werkzeug zur Untersuchung von Ausbrüchen ist. Go.Data verwendet eine API für alle Interaktionen zwischen dem Web-Frontend und den Smartphone-Anwendungen, die für die Datenerfassung verwendet werden. Go.Data wird auf der ganzen Welt verwendet. Weil Ausbruchsdaten sensibel sind und du nur auf Daten zugreifen können solltest, die deine Ausbruch zugreifen kannst, ist eine Authentifizierung erforderlich.\nIm Folgenden findest du ein Beispiel für R-Code mit httr und jsonlite für die Verbindung mit dem Go.Data API, um Daten zur Kontaktverfolgung aus deinem Ausbruch zu importieren.\n\n# set credentials for authorization\nurl &lt;- \"https://godatasampleURL.int/\"           # valid Go.Data instance url\nusername &lt;- \"username\"                          # valid Go.Data username \npassword &lt;- \"password\"                          # valid Go,Data password \noutbreak_id &lt;- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # valid Go.Data outbreak ID\n\n# get access token\nurl_request &lt;- paste0(url,\"api/oauth/token?access_token=123\") # define base URL request\n\n# prepare request\nresponse &lt;- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # use saved username/password from above to authorize                               \n    password = password),                                       \n    encode = \"json\")\n\n# execute request and parse response\ncontent &lt;-\n  content(response, as = \"text\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%          # flatten nested JSON\n  glimpse()\n\n# Save access token from response\naccess_token &lt;- content$access_token    # save access token to allow subsequent API calls below\n\n# import outbreak contacts\n# Use the access token \nresponse_contacts &lt;- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # GET request\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts &lt;- content(response_contacts, as = \"text\")         # convert to text JSON\n\ncontacts &lt;- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # flatten JSON to tibble\n\nVORSICHT! Wenn du große Datenmengen von einer API importierst, die eine Authentifizierung erfordert, kann es zu einer Zeitüberschreitung kommen. Um dies zu vermeiden, rufe das access_token vor jeder API-GET-Anfrage erneut ab und versuche, Filter oder Beschränkungen in der Abfrage zu verwenden. \nTIPP: Die fromJSON() Funktion in der jsonlite Paket entschachtelt beim ersten Mal nicht vollständig, so dass du wahrscheinlich immer noch Listenelemente in deinem Tibble haben wirst. Je nachdem, wie verschachtelt deine .json-Datei ist, musst du bestimmte Variablen weiter entschachteln. Weitere Informationen dazu findest du in der Dokumentation für die jsonlite Paket nach, zum Beispiel in der flatten() Funktion. \nFür weitere Details, siehe Dokumentation zu LoopBack Explorer, die [Kontaktverfolgung] Seite oder API-Tipps aufGo.Data Github Repository\nDu kannst mehr lesen über die httr Paket hier\nDieser Abschnitt wurde auch informiert von dieses Tutorium und dieses Tutorial.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#exportieren.",
    "href": "new_pages/importing.de.html#exportieren.",
    "title": "7  Import und Export",
    "section": "7.11 exportieren.",
    "text": "7.11 exportieren.\n\nMit rio Paket\nMit rio kannst du die export() Funktion auf ähnliche Weise verwenden wie import(). Gib zunächst den Namen des R-Objekts an, das du speichern möchtest (z. B. linelist) und gib dann in Anführungszeichen den Dateipfad an, in dem du die Datei speichern möchtest, einschließlich des gewünschten Dateinamens und der Dateierweiterung. Zum Beispiel:\nSo wird der Datenrahmen gespeichert linelist als Excel-Arbeitsmappe im Arbeitsverzeichnis/Projektstammordner:\n\nexport(linelist, \"my_linelist.xlsx\") # will save to working directory\n\nDu kannst denselben Datenrahmen auch als csv-Datei speichern, indem du die Erweiterung änderst. Wir speichern ihn zum Beispiel auch in einem Dateipfad, der mit here():\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))\n\n\n\nIn die Zwischenablage\nUm einen Datenrahmen in die “Zwischenablage” deines Computers zu exportieren (um ihn dann in eine andere Software wie Excel, Google Spreadsheets usw. einzufügen), kannst du Folgendes verwenden write_clip() aus der clipr Paket.\n\n# export the linelist data frame to your system's clipboard\nclipr::write_clip(linelist)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#rds-dateien-import_rds",
    "href": "new_pages/importing.de.html#rds-dateien-import_rds",
    "title": "7  Import und Export",
    "section": "7.12 RDS-Dateien {#import_rds}",
    "text": "7.12 RDS-Dateien {#import_rds}\nNeben .csv, .xlsx usw. kannst du auch R-Datenrahmen als .rds-Dateien exportieren/speichern. Das ist ein spezielles Dateiformat für R. Es ist sehr nützlich, wenn du weißt, dass du mit den exportierten Daten wieder in R arbeiten wirst.\nDie Spaltenklassen werden gespeichert, so dass du sie beim Import nicht noch einmal bereinigen musst (bei einer Excel- oder sogar CSV-Datei kann das Kopfzerbrechen bereiten). Außerdem ist die Datei kleiner, was für den Export und Import von Vorteil ist, wenn dein Datensatz groß ist.\nWenn du zum Beispiel in einem Epidemiologie-Team arbeitest und Dateien an ein GIS-Team schicken musst, das ebenfalls R verwendet, schick ihnen einfach die .rds-Datei! Dann bleiben alle Spaltenklassen erhalten und sie haben weniger Arbeit.\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#rdata-dateien-und-listen-import_rdata",
    "href": "new_pages/importing.de.html#rdata-dateien-und-listen-import_rdata",
    "title": "7  Import und Export",
    "section": "7.13 Rdata Dateien und Listen {#import_rdata}",
    "text": "7.13 Rdata Dateien und Listen {#import_rdata}\n.Rdata Dateien können mehrere R-Objekte speichern - zum Beispiel mehrere Datenrahmen, Modellergebnisse, Listen usw. Das kann sehr nützlich sein, um viele deiner Daten für ein bestimmtes Projekt zu konsolidieren oder zu teilen.\nIn dem folgenden Beispiel werden mehrere R-Objekte in der exportierten Datei “my_objects.Rdata” gespeichert:\n\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\n\nHinweis: Wenn du versuchst importieren eine Liste zu importieren, verwende import_list() von rio zu importieren, und zwar mit der vollständigen ursprünglichen Struktur und dem Inhalt.\n\nrio::import_list(\"my_list.Rdata\")",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#speichern-von-plots",
    "href": "new_pages/importing.de.html#speichern-von-plots",
    "title": "7  Import und Export",
    "section": "7.14 Speichern von Plots",
    "text": "7.14 Speichern von Plots\nAnweisungen zum Speichern von Plots, wie sie beispielsweise von ggplot()erstellt werden, werden ausführlich in den [ggplot Grundlagen] Seite.\nKurz gesagt, führe ggsave(\"my_plot_filepath_and_name.png\") nachdem du deinen Plot gedruckt hast. Du kannst entweder ein gespeichertes Plot-Objekt an die plot = Argument übergeben oder nur den Pfad der Zieldatei (mit Dateierweiterung) angeben, um den zuletzt angezeigten Plot zu speichern. Du kannst auch die width =, height =, units =, und dpi =.\nWie du einen Netzwerkgraphen, z. B. einen Übertragungsbaum, speicherst, erfährst du auf der Seite über [Übertragungsketten].",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.de.html#ressourcen",
    "href": "new_pages/importing.de.html#ressourcen",
    "title": "7  Import und Export",
    "section": "7.15 Ressourcen",
    "text": "7.15 Ressourcen\nDie R Daten Import/Export Handbuch\nR 4 Data Science Kapitel zum Datenimport\nggsave()-Dokumentation\nNachfolgend eine Tabelle, die aus der rio online Vignette. Für jeden Dateityp wird angezeigt: die erwartete Dateierweiterung, das Paket rio verwendet, um die Daten zu importieren oder zu exportieren, und ob diese Funktionalität in der standardmäßig installierten Version von rio.\n\n\n\n\n\n\n\n\n\n\nFormat\nTypische Erweiterung\nPaket importieren\nPaket exportieren\nStandardmäßig installiert\n\n\n\n\nKomma-getrennte Daten\n.csv\ndaten.tabelle fread()\ndaten.tabelle\nJa\n\n\nPipe-getrennte Daten\n.psv\ndata.table fread()\ndaten.tabelle\nJa\n\n\nTab-getrennte Daten\n.tsv\ndata.table fread()\ndaten.tabelle\nJa\n\n\nSAS\n.sas7bdat\nhaven\nhaven\nJa\n\n\nSPSS\n.sav\nhaven\nhaven\nJa\n\n\nStata\n.dta\nhaven\nhaven\nJa\n\n\nSAS\nXPORT\n.xpt\nhaven\nhaven\n\n\nSPSS Portable\n.por\nHafen\n\nJa\n\n\nExcel\n.xls\nreadxl\n\nJa\n\n\nExcel\n.xlsx\nreadxl\nopenxlsx\nJa\n\n\nR-Syntax\n.R\nBasis\nBasis\nJa\n\n\nGespeicherte R-Objekte\n.RData, .rda\nBasis\nBasis\nJa\n\n\nSerialisierte R-Objekte\n.rds\nBasis\nBasis\nJa\n\n\nEpiinfo\n.rec\nfremd\n\nJa\n\n\nMinitab\n.mtp\nausländische\n\nJa\n\n\nSystat\n.syd\nausländische\n\nJa\n\n\n“XBASE”\nDatenbank-Dateien\n.dbf\nfremd\nausländisch\n\n\nWeka Attribut-Relation Dateiformat\n.arff\nfremd\nausländisch\nJa\n\n\nFormat des Datenaustauschs\n.dif\nutils\n\nJa\n\n\nFortran-Daten\nkeine anerkannte Erweiterung\nutils\n\nJa\n\n\nDaten im Festbreitenformat\n.fwf\nutilities\nutils\nJa\n\n\ngzip Komma-getrennte Daten\n.csv.gz\nutilities\nutils\nJa\n\n\nCSVY (CSV + YAML-Metadaten-Header)\n.csvy\ncsvy\ncsvy\nNein\n\n\nEViews\n.wf1\nhexView\n\nNein\n\n\nFeather R/Python-Austauschformat\n.feather\nfeder\nfeder\nNein\n\n\nSchneller Speicher\n.fst\nfst\nfst\nNein\n\n\nJSON\n.json\njsonlite\njsonlite\nNein\n\n\nMatlab\n.mat\nrmatio\nrmatio\nNein\n\n\nOpenDocument Tabellenkalkulation\n.ods\nreadODS\nreadODS\nNein\n\n\nHTML-Tabellen\n.html\nxml2\nxml2\nNein\n\n\nShallow XML Dokumente\n.xml\nxml2\nxml2\nNein\n\n\nYAML\n.yml\nyaml\nyaml\nKeine\n\n\nZwischenablage Standard ist tsv\n\nclipr\nclipr\nNein",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Import und Export</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html",
    "href": "new_pages/cleaning.de.html",
    "title": "8  Cleaning data and core functions",
    "section": "",
    "text": "Core functions\nThis handbook emphasizes use of the functions from the tidyverse family of R packages. The essential R functions demonstrated in this page are listed below.\nMany of these functions belong to the dplyr R package, which provides “verb” functions to solve data manipulation challenges (the name is a reference to a “data frame-plier. dplyr is part of the tidyverse family of R packages (which also includes ggplot2, tidyr, stringr, tibble, purrr, magrittr, and forcats among others).\nIf you want to see how these functions compare to Stata or SAS commands, see the page on [Transition to R].\nYou may encounter an alternative data management framework from the data.table R package with operators like := and frequent use of brackets [ ]. This approach and syntax is briefly explained in the [Data Table] page.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#cleaning-pipeline",
    "href": "new_pages/cleaning.de.html#cleaning-pipeline",
    "title": "8  Cleaning data and core functions",
    "section": "8.1 Cleaning pipeline",
    "text": "8.1 Cleaning pipeline\nThis page proceeds through typical cleaning steps, adding them sequentially to a cleaning pipe chain.\nIn epidemiological analysis and data processing, cleaning steps are often performed sequentially, linked together. In R, this often manifests as a cleaning “pipeline”, where the raw dataset is passed or “piped” from one cleaning step to another.\nSuch chains utilize dplyr “verb” functions and the magrittr pipe operator %&gt;%. This pipe begins with the “raw” data (“linelist_raw.xlsx”) and ends with a “clean” R data frame (linelist) that can be used, saved, exported, etc.\nIn a cleaning pipeline the order of the steps is important. Cleaning steps might include:\n\nImporting of data\n\nColumn names cleaned or changed\n\nDe-duplication\n\nColumn creation and transformation (e.g. re-coding or standardising values)\n\nRows filtered or added",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#load-packages",
    "href": "new_pages/cleaning.de.html#load-packages",
    "title": "8  Cleaning data and core functions",
    "section": "8.2 Load packages",
    "text": "8.2 Load packages\nThis code chunk shows the loading of packages required for the analyses. In this handbook we emphasize p_load() from pacman, which installs the package if necessary and loads it for use. You can also load installed packages with library() from base R. See the page on [R basics] for more information on R packages.\n\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  matchmaker, # dictionary-based cleaning\n  epikit,     # age_categories() function\n  tidyverse   # data management and visualization\n)",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#import-data",
    "href": "new_pages/cleaning.de.html#import-data",
    "title": "8  Cleaning data and core functions",
    "section": "8.3 Import data",
    "text": "8.3 Import data\n\nImport\nHere we import the “raw” case linelist Excel file using the import() function from the package rio. The rio package flexibly handles many types of files (e.g. .xlsx, .csv, .tsv, .rds. See the page on [Import and export] for more information and tips on unusual situations (e.g. skipping rows, setting missing values, importing Google sheets, etc).\nIf you want to follow along, click to download the “raw” linelist (as .xlsx file).\nIf your dataset is large and takes a long time to import, it can be useful to have the import command be separate from the pipe chain and the “raw” saved as a distinct file. This also allows easy comparison between the original and cleaned versions.\nBelow we import the raw Excel file and save it as the data frame linelist_raw. We assume the file is located in your working directory or R project root, and so no sub-folders are specified in the file path.\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\")\n\nYou can view the first 50 rows of the the data frame below. Note: the base R function head(n) allow you to view just the first n rows in the R console.\n\n\n\n\n\n\n\n\nReview\nYou can use the function skim() from the package skimr to get an overview of the entire dataframe (see page on [Descriptive tables] for more info). Columns are summarised by class/type such as character, numeric. Note: “POSIXct” is a type of raw date class (see [Working with dates].\n\nskimr::skim(linelist_raw)\n\n\n\n\nData summary\n\n\nName\nlinelist_raw\n\n\nNumber of rows\n6611\n\n\nNumber of columns\n28\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n17\n\n\nnumeric\n8\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n137\n0.98\n6\n6\n0\n5888\n0\n\n\ndate onset\n293\n0.96\n10\n10\n0\n580\n0\n\n\noutcome\n1500\n0.77\n5\n7\n0\n2\n0\n\n\ngender\n324\n0.95\n1\n1\n0\n2\n0\n\n\nhospital\n1512\n0.77\n5\n36\n0\n13\n0\n\n\ninfector\n2323\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2323\n0.65\n5\n7\n0\n2\n0\n\n\nage\n107\n0.98\n1\n2\n0\n75\n0\n\n\nage_unit\n7\n1.00\n5\n6\n0\n2\n0\n\n\nfever\n258\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n258\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n258\n0.96\n2\n3\n0\n2\n0\n\n\naches\n258\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n258\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n844\n0.87\n5\n5\n0\n1091\n0\n\n\nmerged_header\n0\n1.00\n1\n1\n0\n1\n0\n\n\n…28\n0\n1.00\n1\n1\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n7\n1.00\n16.60\n5.71\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nlon\n7\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n7\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nrow_num\n0\n1.00\n3240.91\n1857.83\n1.00\n1647.50\n3241.00\n4836.50\n6481.00\n\n\nwt_kg\n7\n1.00\n52.69\n18.59\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n7\n1.00\n125.25\n49.57\n4.00\n91.00\n130.00\n159.00\n295.00\n\n\nct_blood\n7\n1.00\n21.26\n1.67\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n158\n0.98\n38.60\n0.95\n35.20\n38.30\n38.80\n39.20\n40.80\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ninfection date\n2322\n0.65\n2012-04-09\n2015-04-27\n2014-10-04\n538\n\n\nhosp date\n7\n1.00\n2012-04-20\n2015-04-30\n2014-10-15\n570\n\n\ndate_of_outcome\n1068\n0.84\n2012-05-14\n2015-06-04\n2014-10-26\n575",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#column-names",
    "href": "new_pages/cleaning.de.html#column-names",
    "title": "8  Cleaning data and core functions",
    "section": "8.4 Column names",
    "text": "8.4 Column names\nIn R, column names are the “header” or “top” value of a column. They are used to refer to columns in the code, and serve as a default label in figures.\nOther statistical software such as SAS and STATA use “labels” that co-exist as longer printed versions of the shorter column names. While R does offer the possibility of adding column labels to the data, this is not emphasized in most practice. To make column names “printer-friendly” for figures, one typically adjusts their display within the plotting commands that create the outputs (e.g. axis or legend titles of a plot, or column headers in a printed table - see the scales section of the ggplot tips page and [Tables for presentation] pages). If you want to assign column labels in the data, read more online here and here.\nAs R column names are used very often, so they must have “clean” syntax. We suggest the following:\n\nShort names\nNo spaces (replace with underscores _ )\nNo unusual characters (&, #, &lt;, &gt;, …)\n\nSimilar style nomenclature (e.g. all date columns named like date_onset, date_report, date_death…)\n\nThe columns names of linelist_raw are printed below using names() from base R. We can see that initially:\n\nSome names contain spaces (e.g. infection date)\n\nDifferent naming patterns are used for dates (date onset vs. infection date)\n\nThere must have been a merged header across the two last columns in the .xlsx. We know this because the name of two merged columns (“merged_header”) was assigned by R to the first column, and the second column was assigned a placeholder name “…28” (as it was then empty and is the 28th column).\n\n\nnames(linelist_raw)\n\n [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"     \n [5] \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\"          \n\n\nNOTE: To reference a column name that includes spaces, surround the name with back-ticks, for example: linelist$` '\\x60infection date\\x60'`. note that on your keyboard, the back-tick (`) is different from the single quotation mark (’).\n\nAutomatic cleaning\nThe function clean_names() from the package janitor standardizes column names and makes them unique by doing the following:\n\nConverts all names to consist of only underscores, numbers, and letters\n\nAccented characters are transliterated to ASCII (e.g. german o with umlaut becomes “o”, spanish “enye” becomes “n”)\n\nCapitalization preference for the new column names can be specified using the case = argument (“snake” is default, alternatives include “sentence”, “title”, “small_camel”…)\n\nYou can specify specific name replacements by providing a vector to the replace = argument (e.g. replace = c(onset = \"date_of_onset\"))\n\nHere is an online vignette\n\nBelow, the cleaning pipeline begins by using clean_names() on the raw linelist.\n\n# pipe the raw dataset through the function clean_names(), assign result as \"linelist\"  \nlinelist &lt;- linelist_raw %&gt;% \n  janitor::clean_names()\n\n# see the new column names\nnames(linelist)\n\n [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"     \n [5] \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\"            \n\n\nNOTE: The last column name “…28” was changed to “x28”.\n\n\nManual name cleaning\nRe-naming columns manually is often necessary, even after the standardization step above. Below, re-naming is performed using the rename() function from the dplyr package, as part of a pipe chain. rename() uses the style NEW = OLD - the new column name is given before the old column name.\nBelow, a re-naming command is added to the cleaning pipeline. Spaces have been added strategically to align code for easier reading.\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)\n\nNow you can see that the columns names have been changed:\n\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nRename by column position\nYou can also rename by column position, instead of column name, for example:\n\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)\n\n\n\nRename via select() and summarise()\nAs a shortcut, you can also rename columns within the dplyr select() and summarise() functions. select() is used to keep only certain columns (and is covered later in this page). summarise() is covered in the [Grouping data] and [Descriptive tables] pages. These functions also uses the format new_name = old_name. Here is an example:\n\nlinelist_raw %&gt;% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)\n\n\n\n\nOther challenges\n\nEmpty Excel column names\nR cannot have dataset columns that do not have column names (headers). So, if you import an Excel dataset with data but no column headers, R will fill-in the headers with names like “…1” or “…2”. The number represents the column number (e.g. if the 4th column in the dataset has no header, then R will name it “…4”).\nYou can clean these names manually by referencing their position number (see example above), or their assigned name (linelist_raw$...1).\n\n\nMerged Excel column names and cells\nMerged cells in an Excel file are a common occurrence when receiving data. As explained in [Transition to R], merged cells can be nice for human reading of data, but are not “tidy data” and cause many problems for machine reading of data. R cannot accommodate merged cells.\nRemind people doing data entry that human-readable data is not the same as machine-readable data. Strive to train users about the principles of tidy data. If at all possible, try to change procedures so that data arrive in a tidy format without merged cells.\n\nEach variable must have its own column.\n\nEach observation must have its own row.\n\nEach value must have its own cell.\n\nWhen using rio’s import() function, the value in a merged cell will be assigned to the first cell and subsequent cells will be empty.\nOne solution to deal with merged cells is to import the data with the function readWorkbook() from the package openxlsx. Set the argument fillMergedCells = TRUE. This gives the value in a merged cell to all cells within the merge range.\n\nlinelist_raw &lt;- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)\n\nDANGER: If column names are merged with readWorkbook(), you will end up with duplicate column names, which you will need to fix manually - R does not work well with duplicate column names! You can re-name them by referencing their position (e.g. column 5), as explained in the section on manual column name cleaning.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#select-or-re-order-columns",
    "href": "new_pages/cleaning.de.html#select-or-re-order-columns",
    "title": "8  Cleaning data and core functions",
    "section": "8.5 Select or re-order columns",
    "text": "8.5 Select or re-order columns\nUse select() from dplyr to select the columns you want to retain, and to specify their order in the data frame.\nCAUTION: In the examples below, the linelist data frame is modified with select() and displayed, but not saved. This is for demonstration purposes. The modified column names are printed by piping the data frame to names().\nHere are ALL the column names in the linelist at this point in the cleaning pipe chain:\n\nnames(linelist)\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nKeep columns\nSelect only the columns you want to remain\nPut their names in the select() command, with no quotation marks. They will appear in the data frame in the order you provide. Note that if you include a column that does not exist, R will return an error (see use of any_of() below if you want no error in this situation).\n\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %&gt;% \n  select(case_id, date_onset, date_hospitalisation, fever) %&gt;% \n  names()  # display the column names\n\n[1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\"\n[4] \"fever\"               \n\n\n\n\n“tidyselect” helper functions\nThese helper functions exist to make it easy to specify columns to keep, discard, or transform. They are from the package tidyselect, which is included in tidyverse and underlies how columns are selected in dplyr functions.\nFor example, if you want to re-order the columns, everything() is a useful function to signify “all other columns not yet mentioned”. The command below moves columns date_onset and date_hospitalisation to the beginning (left) of the dataset, but keeps all the other columns afterward. Note that everything() is written with empty parentheses:\n\n# move date_onset and date_hospitalisation to beginning\nlinelist %&gt;% \n  select(date_onset, date_hospitalisation, everything()) %&gt;% \n  names()\n\n [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"             \n [4] \"generation\"           \"date_infection\"       \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\nHere are other “tidyselect” helper functions that also work within dplyr functions like select(), across(), and summarise():\n\neverything() - all other columns not mentioned\n\nlast_col() - the last column\n\nwhere() - applies a function to all columns and selects those which are TRUE\n\ncontains() - columns containing a character string\n\nexample: select(contains(\"time\"))\n\n\nstarts_with() - matches to a specified prefix\n\nexample: select(starts_with(\"date_\"))\n\n\nends_with() - matches to a specified suffix\n\nexample: select(ends_with(\"_post\"))\n\n\nmatches() - to apply a regular expression (regex)\n\nexample: select(matches(\"[pt]al\"))\n\n\nnum_range() - a numerical range like x01, x02, x03\n\nany_of() - matches IF column exists but returns no error if it is not found\n\nexample: select(any_of(date_onset, date_death, cardiac_arrest))\n\n\nIn addition, use normal operators such as c() to list several columns, : for consecutive columns, ! for opposite, & for AND, and | for OR.\nUse where() to specify logical criteria for columns. If providing a function inside where(), do not include the function’s empty parentheses. The command below selects columns that are class Numeric.\n\n# select columns that are class Numeric\nlinelist %&gt;% \n  select(where(is.numeric)) %&gt;% \n  names()\n\n[1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"     \n[6] \"ht_cm\"      \"ct_blood\"   \"temp\"      \n\n\nUse contains() to select only columns in which the column name contains a specified character string. ends_with() and starts_with() provide more nuance.\n\n# select columns containing certain characters\nlinelist %&gt;% \n  select(contains(\"date\")) %&gt;% \n  names()\n\n[1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n[4] \"date_outcome\"        \n\n\nThe function matches() works similarly to contains() but can be provided a regular expression (see page on [Characters and strings]), such as multiple strings separated by OR bars within the parentheses:\n\n# searched for multiple character matches\nlinelist %&gt;% \n  select(matches(\"onset|hosp|fev\")) %&gt;%   # note the OR symbol \"|\"\n  names()\n\n[1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"            \n[4] \"fever\"               \n\n\nCAUTION: If a column name that you specifically provide does not exist in the data, it can return an error and stop your code. Consider using any_of() to cite columns that may or may not exist, especially useful in negative (remove) selections.\nOnly one of these columns exists, but no error is produced and the code continues without stopping your cleaning chain.\n\nlinelist %&gt;% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %&gt;% \n  names()\n\n[1] \"date_onset\"\n\n\n\n\nRemove columns\nIndicate which columns to remove by placing a minus symbol “-” in front of the column name (e.g. select(-outcome)), or a vector of column names (as below). All other columns will be retained.\n\nlinelist %&gt;% \n  select(-c(date_onset, fever:vomit)) %&gt;% # remove date_onset and all columns from fever to vomit\n  names()\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n [7] \"gender\"               \"hospital\"             \"lon\"                 \n[10] \"lat\"                  \"infector\"             \"source\"              \n[13] \"age\"                  \"age_unit\"             \"row_num\"             \n[16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n[19] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[22] \"x28\"                 \n\n\nYou can also remove a column using base R syntax, by defining it as NULL. For example:\n\nlinelist$date_onset &lt;- NULL   # deletes column with base R syntax \n\n\n\nStandalone\nselect() can also be used as an independent command (not in a pipe chain). In this case, the first argument is the original dataframe to be operated upon.\n\n# Create a new linelist with id and age-related columns\nlinelist_age &lt;- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)\n\n[1] \"case_id\"  \"age\"      \"age_unit\"\n\n\n\nAdd to the pipe chain\nIn the linelist_raw, there are a few columns we do not need: row_num, merged_header, and x28. We remove them with a select() command in the cleaning pipe chain:\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#deduplication",
    "href": "new_pages/cleaning.de.html#deduplication",
    "title": "8  Cleaning data and core functions",
    "section": "8.6 Deduplication",
    "text": "8.6 Deduplication\nSee the handbook page on [De-duplication] for extensive options on how to de-duplicate data. Only a very simple row de-duplication example is presented here.\nThe package dplyr offers the distinct() function. This function examines every row and reduce the data frame to only the unique rows. That is, it removes rows that are 100% duplicates.\nWhen evaluating duplicate rows, it takes into account a range of columns - by default it considers all columns. As shown in the de-duplication page, you can adjust this column range so that the uniqueness of rows is only evaluated in regards to certain columns.\nIn this simple example, we just add the empty command distinct() to the pipe chain. This ensures there are no rows that are 100% duplicates of other rows (evaluated across all columns).\nWe begin with nrow(linelist) rows in linelist.\n\nlinelist &lt;- linelist %&gt;% \n  distinct()\n\nAfter de-duplication there are nrow(linelist) rows. Any removed rows would have been 100% duplicates of other rows.\nBelow, the distinct() command is added to the cleaning pipe chain:\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#column-creation-and-transformation",
    "href": "new_pages/cleaning.de.html#column-creation-and-transformation",
    "title": "8  Cleaning data and core functions",
    "section": "8.7 Column creation and transformation",
    "text": "8.7 Column creation and transformation\nWe recommend using the dplyr function mutate() to add a new column, or to modify an existing one.\nBelow is an example of creating a new column with mutate(). The syntax is: mutate(new_column_name = value or transformation)\nIn Stata, this is similar to the command generate, but R’s mutate() can also be used to modify an existing column.\n\nNew columns\nThe most basic mutate() command to create a new column might look like this. It creates a new column new_col where the value in every row is 10.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(new_col = 10)\n\nYou can also reference values in other columns, to perform calculations. Below, a new column bmi is created to hold the Body Mass Index (BMI) for each case - as calculated using the formula BMI = kg/m^2, using column ht_cm and column wt_kg.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\nIf creating multiple new columns, separate each with a comma and new line. Below are examples of new columns, including ones that consist of values from other columns combined using str_glue() from the stringr package (see page on [Characters and strings].\n\nnew_col_demo &lt;- linelist %&gt;%                       \n  mutate(\n    new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n    new_var_static = 7,                   # new column = all values the same\n    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n    ) %&gt;% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        # show only new columns, for demonstration purposes\n\nReview the new columns. For demonstration purposes, only the new columns and the columns used to create them are shown:\n\n\n\n\n\n\nTIP: A variation on mutate() is the function transmute(). This function adds a new column just like mutate(), but also drops/removes all other columns that you do not mention within its parentheses.\n\n# HIDDEN FROM READER\n# removes new demo columns created above\n# linelist &lt;- linelist %&gt;% \n#   select(-contains(\"new_var\"))\n\n\n\nConvert column class\nColumns containing values that are dates, numbers, or logical values (TRUE/FALSE) will only behave as expected if they are correctly classified. There is a difference between “2” of class character and 2 of class numeric!\nThere are ways to set column class during the import commands, but this is often cumbersome. See the [R Basics] section on object classes to learn more about converting the class of objects and columns.\nFirst, let’s run some checks on important columns to see if they are the correct class. We also saw this in the beginning when we ran skim().\nCurrently, the class of the age column is character. To perform quantitative analyses, we need these numbers to be recognized as numeric!\n\nclass(linelist$age)\n\n[1] \"character\"\n\n\nThe class of the date_onset column is also character! To perform analyses, these dates must be recognized as dates!\n\nclass(linelist$date_onset)\n\n[1] \"character\"\n\n\nTo resolve this, use the ability of mutate() to re-define a column with a transformation. We define the column as itself, but converted to a different class. Here is a basic example, converting or ensuring that the column age is class Numeric:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age = as.numeric(age))\n\nIn a similar way, you can use as.character() and as.logical(). To convert to class Factor, you can use factor() from base R or as_factor() from forcats. Read more about this in the [Factors] page.\nYou must be careful when converting to class Date. Several methods are explained on the page [Working with dates]. Typically, the raw date values must all be in the same format for conversion to work correctly (e.g “MM/DD/YYYY”, or “DD MM YYYY”). After converting to class Date, check your data to confirm that each value was converted correctly.\n\n\nGrouped data\nIf your data frame is already grouped (see page on [Grouping data]), mutate() may behave differently than if the data frame is not grouped. Any summarizing functions, like mean(), median(), max(), etc. will calculate by group, not by all the rows.\n\n# age normalized to mean of ALL rows\nlinelist %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\nRead more about using mutate () on grouped dataframes in this tidyverse mutate documentation.\n\n\nTransform multiple columns\nOften to write concise code you want to apply the same transformation to multiple columns at once. A transformation can be applied to multiple columns at once using the across() function from the package dplyr (also contained within tidyverse package). across() can be used with any dplyr function, but is commonly used within select(), mutate(), filter(), or summarise(). See how it is applied to summarise() in the page on [Descriptive tables].\nSpecify the columns to the argument .cols = and the function(s) to apply to .fns =. Any additional arguments to provide to the .fns function can be included after a comma, still within across().\n\nacross() column selection\nSpecify the columns to the argument .cols =. You can name them individually, or use “tidyselect” helper functions. Specify the function to .fns =. Note that using the function mode demonstrated below, the function is written without its parentheses ( ).\nHere the transformation as.character() is applied to specific columns named within across().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n\nThe “tidyselect” helper functions are available to assist you in specifying columns. They are detailed above in the section on Selecting and re-ordering columns, and they include: everything(), last_col(), where(), starts_with(), ends_with(), contains(), matches(), num_range() and any_of().\nHere is an example of how one would change all columns to character class:\n\n#to change all columns to character class\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = everything(), .fns = as.character))\n\nConvert to character all columns where the name contains the string “date” (note the placement of commas and parentheses):\n\n#to change all columns to character class\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\n\nBelow, an example of mutating the columns that are currently class POSIXct (a raw datetime class that shows timestamps) - in other words, where the function is.POSIXct() evaluates to TRUE. Then we want to apply the function as.Date() to these columns to convert them to a normal class Date.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))\n\n\nNote that within across() we also use the function where() as is.POSIXct is evaluating to either TRUE or FALSE.\n\nNote that is.POSIXct() is from the package lubridate. Other similar “is” functions like is.character(), is.numeric(), and is.logical() are from base R\n\n\n\nacross() functions\nYou can read the documentation with ?across for details on how to provide functions to across(). A few summary points: there are several ways to specify the function(s) to perform on a column and you can even define your own functions:\n\nYou can provide the function name alone (e.g. mean or as.character)\n\nYou can provide the function in purrr-style (e.g. ~ mean(.x, na.rm = TRUE)) (see [this page][Iteration, loops, and lists])\n\nYou can specify multiple functions by providing a list (e.g. list(mean = mean, n_miss = ~ sum(is.na(.x))).\n\nIf you provide multiple functions, multiple transformed columns will be returned per input column, with unique names in the format col_fn. You can adjust how the new columns are named with the .names = argument using glue syntax (see page on [Characters and strings]) where {.col} and {.fn} are shorthand for the input column and function.\n\n\nHere are a few online resources on using across(): creator Hadley Wickham’s thoughts/rationale\n\n\n\ncoalesce()\nThis dplyr function finds the first non-missing value at each position. It “fills-in” missing values with the first available value in an order you specify.\nHere is an example outside the context of a data frame: Let us say you have two vectors, one containing the patient’s village of detection and another containing the patient’s village of residence. You can use coalesce to pick the first non-missing value for each index:\n\nvillage_detection &lt;- c(\"a\", \"b\", NA,  NA)\nvillage_residence &lt;- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage &lt;- coalesce(village_detection, village_residence)\nvillage    # print\n\n[1] \"a\" \"b\" \"a\" \"d\"\n\n\nThis works the same if you provide data frame columns: for each row, the function will assign the new column value with the first non-missing value in the columns you provided (in order provided).\n\nlinelist &lt;- linelist %&gt;% \n  mutate(village = coalesce(village_detection, village_residence))\n\nThis is an example of a “row-wise” operation. For more complicated row-wise calculations, see the section below on Row-wise calculations.\n\n\nCumulative math\nIf you want a column to reflect the cumulative sum/mean/min/max etc as assessed down the rows of a dataframe to that point, use the following functions:\ncumsum() returns the cumulative sum, as shown below:\n\nsum(c(2,4,15,10))     # returns only one number\n\n[1] 31\n\ncumsum(c(2,4,15,10))  # returns the cumulative sum at each step\n\n[1]  2  6 21 31\n\n\nThis can be used in a dataframe when making a new column. For example, to calculate the cumulative number of cases per day in an outbreak, consider code like this:\n\ncumulative_case_counts &lt;- linelist %&gt;%  # begin with case linelist\n  count(date_onset) %&gt;%                 # count of rows per day, as column 'n'   \n  mutate(cumulative_cases = cumsum(n))  # new column, of the cumulative sum at each row\n\nBelow are the first 10 rows:\n\nhead(cumulative_case_counts, 10)\n\n   date_onset n cumulative_cases\n1  2012-04-15 1                1\n2  2012-05-05 1                2\n3  2012-05-08 1                3\n4  2012-05-31 1                4\n5  2012-06-02 1                5\n6  2012-06-07 1                6\n7  2012-06-14 1                7\n8  2012-06-21 1                8\n9  2012-06-24 1                9\n10 2012-06-25 1               10\n\n\nSee the page on [Epidemic curves] for how to plot cumulative incidence with the epicurve.\nSee also:\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall()\n\n\nUsing base R\nTo define a new column (or re-define a column) using base R, write the name of data frame, connected with $, to the new column (or the column to be modified). Use the assignment operator &lt;- to define the new value(s). Remember that when using base R you must specify the data frame name before the column name every time (e.g. dataframe$column). Here is an example of creating the bmi column using base R:\n\nlinelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)\n\n\n\nAdd to pipe chain\nBelow, a new column is added to the pipe chain and some classes are converted.\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;% \n  \n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#re-code-values",
    "href": "new_pages/cleaning.de.html#re-code-values",
    "title": "8  Cleaning data and core functions",
    "section": "8.8 Re-code values",
    "text": "8.8 Re-code values\nHere are a few scenarios where you need to re-code (change) values:\n\nto edit one specific value (e.g. one date with an incorrect year or format)\n\nto reconcile values not spelled the same\nto create a new column of categorical values\n\nto create a new column of numeric categories (e.g. age categories)\n\n\nSpecific values\nTo change values manually you can use the recode() function within the mutate() function.\nImagine there is a nonsensical date in the data (e.g. “2014-14-15”): you could fix the date manually in the raw source data, or, you could write the change into the cleaning pipeline via mutate() and recode(). The latter is more transparent and reproducible to anyone else seeking to understand or repeat your analysis.\n\n# fix incorrect values                   # old value       # new value\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\n\nThe mutate() line above can be read as: “mutate the column date_onset to equal the column date_onset re-coded so that OLD VALUE is changed to NEW VALUE”. Note that this pattern (OLD = NEW) for recode() is the opposite of most R patterns (new = old). The R development community is working on revising this.\nHere is another example re-coding multiple values within one column.\nIn linelist the values in the column “hospital” must be cleaned. There are several different spellings and many missing values.\n\ntable(linelist$hospital, useNA = \"always\")  # print table of all unique values, including missing  \n\n\n                     Central Hopital                     Central Hospital \n                                  11                                  457 \n                          Hospital A                           Hospital B \n                                 290                                  289 \n                    Military Hopital                    Military Hospital \n                                  32                                  798 \n                    Mitylira Hopital                    Mitylira Hospital \n                                   1                                   79 \n                               Other                         Port Hopital \n                                 907                                   48 \n                       Port Hospital St. Mark's Maternity Hospital (SMMH) \n                                1756                                  417 \n  St. Marks Maternity Hopital (SMMH)                                 &lt;NA&gt; \n                                  11                                 1512 \n\n\nThe recode() command below re-defines the column “hospital” as the current column “hospital”, but with the specified recode changes. Don’t forget commas after each!\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital,\n                     # for reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\n\nNow we see the spellings in the hospital column have been corrected and consolidated:\n\ntable(linelist$hospital, useNA = \"always\")\n\n\n                    Central Hospital                           Hospital A \n                                 468                                  290 \n                          Hospital B                    Military Hospital \n                                 289                                  910 \n                               Other                        Port Hospital \n                                 907                                 1804 \nSt. Mark's Maternity Hospital (SMMH)                                 &lt;NA&gt; \n                                 428                                 1512 \n\n\nTIP: The number of spaces before and after an equals sign does not matter. Make your code easier to read by aligning the = for all or most rows. Also, consider adding a hashed comment row to clarify for future readers which side is OLD and which side is NEW. \nTIP: Sometimes a blank character value exists in a dataset (not recognized as R’s value for missing - NA). You can reference this value with two quotation marks with no space inbetween (““).\n\n\nBy logic\nBelow we demonstrate how to re-code values in a column using logic and conditions:\n\nUsing replace(), ifelse() and if_else() for simple logic\nUsing case_when() for more complex logic\n\n\n\nSimple logic\n\nreplace()\nTo re-code with simple logical criteria, you can use replace() within mutate(). replace() is a function from base R. Use a logic condition to specify the rows to change . The general syntax is:\nmutate(col_to_change = replace(col_to_change, criteria for rows, new value)).\nOne common situation to use replace() is changing just one value in one row, using an unique row identifier. Below, the gender is changed to “Female” in the row where the column case_id is “2195”.\n\n# Example: change gender of one specific observation to \"Female\" \nlinelist &lt;- linelist %&gt;% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\n\nThe equivalent command using base R syntax and indexing brackets [ ] is below. It reads as “Change the value of the dataframe linelist‘s column gender (for the rows where linelist’s column case_id has the value ’2195’) to ‘Female’”.\n\nlinelist$gender[linelist$case_id == \"2195\"] &lt;- \"Female\"\n\n\n\nifelse() and if_else()\nAnother tool for simple logic is ifelse() and its partner if_else(). However, in most cases for re-coding it is more clear to use case_when() (detailed below). These “if else” commands are simplified versions of an if and else programming statement. The general syntax is:\nifelse(condition, value to return if condition evaluates to TRUE, value to return if condition evaluates to FALSE)\nBelow, the column source_known is defined. Its value in a given row is set to “known” if the row’s value in column source is not missing. If the value in source is missing, then the value in source_known is set to “unknown”.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n\nif_else() is a special version from dplyr that handles dates. Note that if the ‘true’ value is a date, the ‘false’ value must also qualify a date, hence using the special value NA_real_ instead of just NA.\n\n# Create a date of death column, which is NA if patient has not died.\nlinelist &lt;- linelist %&gt;% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))\n\nAvoid stringing together many ifelse commands… use case_when() instead! case_when() is much easier to read and you’ll make fewer errors.\n\n\n\n\n\n\n\n\n\nOutside of the context of a data frame, if you want to have an object used in your code switch its value, consider using switch() from base R.\n\n\n\nComplex logic\nUse dplyr’s case_when() if you are re-coding into many new groups, or if you need to use complex logic statements to re-code values. This function evaluates every row in the data frame, assess whether the rows meets specified criteria, and assigns the correct new value.\ncase_when() commands consist of statements that have a Right-Hand Side (RHS) and a Left-Hand Side (LHS) separated by a “tilde” ~. The logic criteria are in the left side and the pursuant values are in the right side of each statement. Statements are separated by commas.\nFor example, here we utilize the columns age and age_unit to create a column age_years:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_years = case_when(\n       age_unit == \"years\"  ~ age,       # if age unit is years\n       age_unit == \"months\" ~ age/12,    # if age unit is months, divide age by 12\n       is.na(age_unit)      ~ age))      # if age unit is missing, assume years\n                                         # any other circumstance, assign NA (missing)\n\nAs each row in the data is evaluated, the criteria are applied/evaluated in the order the case_when() statements are written - from top-to-bottom. If the top criteria evaluates to TRUE for a given row, the RHS value is assigned, and the remaining criteria are not even tested for that row in the data. Thus, it is best to write the most specific criteria first, and the most general last. A data row that does not meet any of the RHS criteria will be assigned NA.\nSometimes, you may with to write a final statement that assigns a value for all other scenarios not described by one of the previous lines. To do this, place TRUE on the left-side, which will capture any row that did not meet any of the previous criteria. The right-side of this statement could be assigned a value like “check me!” or missing.\nBelow is another example of case_when() used to create a new column with the patient classification, according to a case definition for confirmed and suspect cases:\n\nlinelist &lt;- linelist %&gt;% \n     mutate(case_status = case_when(\n          \n          # if patient had lab test and it is positive,\n          # then they are marked as a confirmed case \n          ct_blood &lt; 20                   ~ \"Confirmed\",\n          \n          # given that a patient does not have a positive lab result,\n          # if patient has a \"source\" (epidemiological link) AND has fever, \n          # then they are marked as a suspect case\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n          \n          # any other patient not addressed above \n          # is marked for follow up\n          TRUE                            ~ \"To investigate\"))\n\nDANGER: Values on the right-side must all be the same class - either numeric, character, date, logical, etc. To assign missing (NA), you may need to use special variations of NA such as NA_character_, NA_real_ (for numeric or POSIX), and as.Date(NA). Read more in [Working with dates].\n\n\nMissing values\nBelow are special functions for handling missing values in the context of data cleaning.\nSee the page on [Missing data] for more detailed tips on identifying and handling missing values. For example, the is.na() function which logically tests for missingness.\nreplace_na()\nTo change missing values (NA) to a specific value, such as “Missing”, use the dplyr function replace_na() within mutate(). Note that this is used in the same manner as recode above - the name of the variable must be repeated within replace_na().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\n\nfct_explicit_na()\nThis is a function from the forcats package. The forcats package handles columns of class Factor. Factors are R’s way to handle ordered values such as c(\"First\", \"Second\", \"Third\") or to set the order that values (e.g. hospitals) appear in tables and plots. See the page on [Factors].\nIf your data are class Factor and you try to convert NA to “Missing” by using replace_na(), you will get this error: invalid factor level, NA generated. You have tried to add “Missing” as a value, when it was not defined as a possible level of the factor, and it was rejected.\nThe easiest way to solve this is to use the forcats function fct_explicit_na() which converts a column to class factor, and converts NA values to the character “(Missing)”.\n\nlinelist %&gt;% \n  mutate(hospital = fct_explicit_na(hospital))\n\nA slower alternative would be to add the factor level using fct_expand() and then convert the missing values.\nna_if()\nTo convert a specific value to NA, use dplyr’s na_if(). The command below performs the opposite operation of replace_na(). In the example below, any values of “Missing” in the column hospital are converted to NA.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n\nNote: na_if() cannot be used for logic criteria (e.g. “all values &gt; 99”) - use replace() or case_when() for this:\n\n# Convert temperatures above 40 to NA \nlinelist &lt;- linelist %&gt;% \n  mutate(temp = replace(temp, temp &gt; 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = replace(date_onset, date_onset &gt; as.Date(\"2000-01-01\"), NA))\n\n\n\nCleaning dictionary\nUse the R package matchmaker and its function match_df() to clean a data frame with a cleaning dictionary.\n\nCreate a cleaning dictionary with 3 columns:\n\nA “from” column (the incorrect value)\n\nA “to” column (the correct value)\n\nA column specifying the column for the changes to be applied (or “.global” to apply to all columns)\n\n\nNote: .global dictionary entries will be overridden by column-specific dictionary entries.\n\n\n\n\n\n\n\n\n\n\nImport the dictionary file into R. This example can be downloaded via instructions on the [Download handbook and data] page.\n\n\ncleaning_dict &lt;- import(\"cleaning_dict.csv\")\n\n\nPipe the raw linelist to match_df(), specifying to dictionary = the cleaning dictionary data frame. The from = argument should be the name of the dictionary column which contains the “old” values, the by = argument should be dictionary column which contains the corresponding “new” values, and the third column lists the column in which to make the change. Use .global in the by = column to apply a change across all columns. A fourth dictionary column order can be used to specify factor order of new values.\n\nRead more details in the package documentation by running ?match_df. Note this function can take a long time to run for a large dataset.\n\nlinelist &lt;- linelist %&gt;%     # provide or pipe your dataset\n     matchmaker::match_df(\n          dictionary = cleaning_dict,  # name of your dictionary\n          from = \"from\",               # column with values to be replaced (default is col 1)\n          to = \"to\",                   # column with final values (default is col 2)\n          by = \"col\"                   # column with column names (default is col 3)\n  )\n\nNow scroll to the right to see how values have changed - particularly gender (lowercase to uppercase), and all the symptoms columns have been transformed from yes/no to 1/0.\n\n\n\n\n\n\nNote that your column names in the cleaning dictionary must correspond to the names at this point in your cleaning script. See this online reference for the linelist package for more details.\n\nAdd to pipe chain\nBelow, some new columns and column transformations are added to the pipe chain.\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n  \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n   # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n   ###################################################\n\n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#num_cats",
    "href": "new_pages/cleaning.de.html#num_cats",
    "title": "8  Cleaning data and core functions",
    "section": "8.9 Numeric categories",
    "text": "8.9 Numeric categories\nHere we describe some special approaches for creating categories from numerical columns. Common examples include age categories, groups of lab values, etc. Here we will discuss:\n\nage_categories(), from the epikit package\n\ncut(), from base R\n\ncase_when()\n\nquantile breaks with quantile() and ntile()\n\n\nReview distribution\nFor this example we will create an age_cat column using the age_years column.\n\n#check the class of the linelist variable age\nclass(linelist$age_years)\n\n[1] \"numeric\"\n\n\nFirst, examine the distribution of your data, to make appropriate cut-points. See the page on [ggplot basics].\n\n# examine the distribution\nhist(linelist$age_years)\n\n\n\n\n\n\n\n\n\nsummary(linelist$age_years, na.rm=T)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.04   23.00   84.00     107 \n\n\nCAUTION: Sometimes, numeric variables will import as class “character”. This occurs if there are non-numeric characters in some of the values, for example an entry of “2 months” for age, or (depending on your R locale settings) if a comma is used in the decimals place (e.g. “4,5” to mean four and one half years)..\n\n\n\nage_categories()\nWith the epikit package, you can use the age_categories() function to easily categorize and label numeric columns (note: this function can be applied to non-age numeric variables too). As a bonum, the output column is automatically an ordered factor.\nHere are the required inputs:\n\nA numeric vector (column)\n\nThe breakers = argument - provide a numeric vector of break points for the new groups\n\nFirst, the simplest example:\n\n# Simple example\n################\npacman::p_load(epikit)                    # load package\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(             # create new column\n      age_years,                            # numeric column to make groups from\n      breakers = c(0, 5, 10, 15, 20,        # break points\n                   30, 40, 50, 60, 70)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    27     7   107 \n\n\nThe break values you specify are by default the lower bounds - that is, they are included in the “higher” group / the groups are “open” on the lower/left side. As shown below, you can add 1 to each break value to achieve groups that are open at the top/right.\n\n# Include upper ends for the same categories\n############################################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  &lt;NA&gt; \n 1469  1195  1040   770  1149   547   231    70    24     6   107 \n\n\nYou can adjust how the labels are displayed with separator =. The default is “-”\nYou can adjust how the top numbers are handled, with the ceiling = arguemnt. To set an upper cut-off set ceiling = TRUE. In this use, the highest break value provided is a “ceiling” and a category “XX+” is not created. Any values above highest break value (or to upper =, if defined) are categorized as NA. Below is an example with ceiling = TRUE, so that there is no category of XX+ and values above 70 (the highest break value) are assigned as NA.\n\n# With ceiling set to TRUE\n##########################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    28   113 \n\n\nAlternatively, instead of breakers =, you can provide all of lower =, upper =, and by =:\n\nlower = The lowest number you want considered - default is 0\n\nupper = The highest number you want considered\n\nby = The number of years between groups\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  &lt;NA&gt; \n 2450  1875  1216   597   251    78    27     6     1     0     0   107 \n\n\nSee the function’s Help page for more details (enter ?age_categories in the R console).\n\n\n\ncut()\ncut() is a base R alternative to age_categories(), but I think you will see why age_categories() was developed to simplify this process. Some notable differences from age_categories() are:\n\nYou do not need to install/load another package\n\nYou can specify whether groups are open/closed on the right/left\n\nYou must provide accurate labels yourself\n\nIf you want 0 included in the lowest group you must specify this\n\nThe basic syntax within cut() is to first provide the numeric column to be cut (age_years), and then the breaks argument, which is a numeric vector c() of break points. Using cut(), the resulting column is an ordered factor.\nBy default, the categorization occurs so that the right/upper side is “open” and inclusive (and the left/lower side is “closed” or exclusive). This is the opposite behavior from the age_categories() function. The default labels use the notation “(A, B]”, which means A is not included but B is. Reverse this behavior by providing the right = TRUE argument.\nThus, by default, “0” values are excluded from the lowest group, and categorized as NA! “0” values could be infants coded as age 0 so be careful! To change this, add the argument include.lowest = TRUE so that any “0” values will be included in the lowest group. The automatically-generated label for the lowest category will then be “[A],B]”. Note that if you include the include.lowest = TRUE argument and right = TRUE, the extreme inclusion will now apply to the highest break point value and category, not the lowest.\nYou can provide a vector of customized labels using the labels = argument. As these are manually written, be very careful to ensure they are accurate! Check your work using cross-tabulation, as described below.\nAn example of cut() applied to age_years to make the new variable age_cat is below:\n\n# Create new variable, by cutting the numeric age variable\n# lower break is excluded but upper break is included in each category\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")\n\n\n   [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100] \n    1469     1195     1040      770     1149      778       94        6 \n    &lt;NA&gt; \n     107 \n\n\nCheck your work!!! Verify that each age value was assigned to the correct category by cross-tabulating the numeric and category columns. Examine assignment of boundary values (e.g. 15, if neighboring categories are 10-15 and 16-20).\n\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values\n\n                    Categories\nNumeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70]\n  0                    136      0       0       0       0       0       0\n  0.0833333333333333     1      0       0       0       0       0       0\n  0.25                   2      0       0       0       0       0       0\n  0.333333333333333      6      0       0       0       0       0       0\n  0.416666666666667      1      0       0       0       0       0       0\n  0.5                    6      0       0       0       0       0       0\n  0.583333333333333      3      0       0       0       0       0       0\n  0.666666666666667      3      0       0       0       0       0       0\n  0.75                   3      0       0       0       0       0       0\n  0.833333333333333      1      0       0       0       0       0       0\n  0.916666666666667      1      0       0       0       0       0       0\n  1                    275      0       0       0       0       0       0\n  1.5                    2      0       0       0       0       0       0\n  2                    308      0       0       0       0       0       0\n  3                    246      0       0       0       0       0       0\n  4                    233      0       0       0       0       0       0\n  5                    242      0       0       0       0       0       0\n  6                      0    241       0       0       0       0       0\n  7                      0    256       0       0       0       0       0\n  8                      0    239       0       0       0       0       0\n  9                      0    245       0       0       0       0       0\n  10                     0    214       0       0       0       0       0\n  11                     0      0     220       0       0       0       0\n  12                     0      0     224       0       0       0       0\n  13                     0      0     191       0       0       0       0\n  14                     0      0     199       0       0       0       0\n  15                     0      0     206       0       0       0       0\n  16                     0      0       0     186       0       0       0\n  17                     0      0       0     164       0       0       0\n  18                     0      0       0     141       0       0       0\n  19                     0      0       0     130       0       0       0\n  20                     0      0       0     149       0       0       0\n  21                     0      0       0       0     158       0       0\n  22                     0      0       0       0     149       0       0\n  23                     0      0       0       0     125       0       0\n  24                     0      0       0       0     144       0       0\n  25                     0      0       0       0     107       0       0\n  26                     0      0       0       0     100       0       0\n  27                     0      0       0       0     117       0       0\n  28                     0      0       0       0      85       0       0\n  29                     0      0       0       0      82       0       0\n  30                     0      0       0       0      82       0       0\n  31                     0      0       0       0       0      68       0\n  32                     0      0       0       0       0      84       0\n  33                     0      0       0       0       0      78       0\n  34                     0      0       0       0       0      58       0\n  35                     0      0       0       0       0      58       0\n  36                     0      0       0       0       0      33       0\n  37                     0      0       0       0       0      46       0\n  38                     0      0       0       0       0      45       0\n  39                     0      0       0       0       0      45       0\n  40                     0      0       0       0       0      32       0\n  41                     0      0       0       0       0      34       0\n  42                     0      0       0       0       0      26       0\n  43                     0      0       0       0       0      31       0\n  44                     0      0       0       0       0      24       0\n  45                     0      0       0       0       0      27       0\n  46                     0      0       0       0       0      25       0\n  47                     0      0       0       0       0      16       0\n  48                     0      0       0       0       0      21       0\n  49                     0      0       0       0       0      15       0\n  50                     0      0       0       0       0      12       0\n  51                     0      0       0       0       0       0      13\n  52                     0      0       0       0       0       0       7\n  53                     0      0       0       0       0       0       4\n  54                     0      0       0       0       0       0       6\n  55                     0      0       0       0       0       0       9\n  56                     0      0       0       0       0       0       7\n  57                     0      0       0       0       0       0       9\n  58                     0      0       0       0       0       0       6\n  59                     0      0       0       0       0       0       5\n  60                     0      0       0       0       0       0       4\n  61                     0      0       0       0       0       0       2\n  62                     0      0       0       0       0       0       1\n  63                     0      0       0       0       0       0       5\n  64                     0      0       0       0       0       0       1\n  65                     0      0       0       0       0       0       5\n  66                     0      0       0       0       0       0       3\n  67                     0      0       0       0       0       0       2\n  68                     0      0       0       0       0       0       1\n  69                     0      0       0       0       0       0       3\n  70                     0      0       0       0       0       0       1\n  72                     0      0       0       0       0       0       0\n  73                     0      0       0       0       0       0       0\n  76                     0      0       0       0       0       0       0\n  84                     0      0       0       0       0       0       0\n  &lt;NA&gt;                   0      0       0       0       0       0       0\n                    Categories\nNumeric Values       (70,100] &lt;NA&gt;\n  0                         0    0\n  0.0833333333333333        0    0\n  0.25                      0    0\n  0.333333333333333         0    0\n  0.416666666666667         0    0\n  0.5                       0    0\n  0.583333333333333         0    0\n  0.666666666666667         0    0\n  0.75                      0    0\n  0.833333333333333         0    0\n  0.916666666666667         0    0\n  1                         0    0\n  1.5                       0    0\n  2                         0    0\n  3                         0    0\n  4                         0    0\n  5                         0    0\n  6                         0    0\n  7                         0    0\n  8                         0    0\n  9                         0    0\n  10                        0    0\n  11                        0    0\n  12                        0    0\n  13                        0    0\n  14                        0    0\n  15                        0    0\n  16                        0    0\n  17                        0    0\n  18                        0    0\n  19                        0    0\n  20                        0    0\n  21                        0    0\n  22                        0    0\n  23                        0    0\n  24                        0    0\n  25                        0    0\n  26                        0    0\n  27                        0    0\n  28                        0    0\n  29                        0    0\n  30                        0    0\n  31                        0    0\n  32                        0    0\n  33                        0    0\n  34                        0    0\n  35                        0    0\n  36                        0    0\n  37                        0    0\n  38                        0    0\n  39                        0    0\n  40                        0    0\n  41                        0    0\n  42                        0    0\n  43                        0    0\n  44                        0    0\n  45                        0    0\n  46                        0    0\n  47                        0    0\n  48                        0    0\n  49                        0    0\n  50                        0    0\n  51                        0    0\n  52                        0    0\n  53                        0    0\n  54                        0    0\n  55                        0    0\n  56                        0    0\n  57                        0    0\n  58                        0    0\n  59                        0    0\n  60                        0    0\n  61                        0    0\n  62                        0    0\n  63                        0    0\n  64                        0    0\n  65                        0    0\n  66                        0    0\n  67                        0    0\n  68                        0    0\n  69                        0    0\n  70                        0    0\n  72                        1    0\n  73                        3    0\n  76                        1    0\n  84                        1    0\n  &lt;NA&gt;                      0  107\n\n\nRe-labeling NA values\nYou may want to assign NA values a label such as “Missing”. Because the new column is class Factor (restricted values), you cannot simply mutate it with replace_na(), as this value will be rejected. Instead, use fct_explicit_na() from forcats as explained in the [Factors] page.\n\nlinelist &lt;- linelist %&gt;% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # make missing values explicit\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n  )    \n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat = fct_explicit_na(age_cat, na_level = \"Missing age\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n# table to view counts\ntable(linelist$age_cat, useNA = \"always\")\n\n\n        0-4         5-9       10-14       15-19       20-29       30-49 \n       1227        1223        1048         827        1216         848 \n      50-69      70-100 Missing age        &lt;NA&gt; \n        105           7         107           0 \n\n\nQuickly make breaks and labels\nFor a fast way to make breaks and label vectors, use something like below. See the [R basics] page for references on seq() and rep().\n\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)\n\nRead more about cut() in its Help page by entering ?cut in the R console.\n\n\nQuantile breaks\nIn common understanding, “quantiles” or “percentiles” typically refer to a value below which a proportion of values fall. For example, the 95th percentile of ages in linelist would be the age below which 95% of the age fall.\nHowever in common speech, “quartiles” and “deciles” can also refer to the groups of data as equally divided into 4, or 10 groups (note there will be one more break point than group).\nTo get quantile break points, you can use quantile() from the stats package from base R. You provide a numeric vector (e.g. a column in a dataset) and vector of numeric probability values ranging from 0 to 1.0. The break points are returned as a numeric vector. Explore the details of the statistical methodologies by entering ?quantile.\n\nIf your input numeric vector has any missing values it is best to set na.rm = TRUE\n\nSet names = FALSE to get an un-named numeric vector\n\n\nquantile(linelist$age_years,               # specify numeric vector to work on\n  probs = c(0, .25, .50, .75, .90, .95),   # specify the percentiles you want\n  na.rm = TRUE)                            # ignore missing values \n\n 0% 25% 50% 75% 90% 95% \n  0   6  13  23  33  41 \n\n\nYou can use the results of quantile() as break points in age_categories() or cut(). Below we create a new column deciles using cut() where the breaks are defined using quantiles() on age_years. Below, we display the results using tabyl() from janitor so you can see the percentages (see the [Descriptive tables] page). Note how they are not exactly 10% in each group.\n\nlinelist %&gt;%                                # begin with linelist\n  mutate(deciles = cut(age_years,           # create new column decile as cut() on column age_years\n    breaks = quantile(                      # define cut breaks using quantile()\n      age_years,                               # operate on age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 to 1.0 by 0.1\n      na.rm = TRUE),                           # ignore missing values\n    include.lowest = TRUE)) %&gt;%             # for cut() include age 0\n  janitor::tabyl(deciles)                   # pipe to table to display\n\n deciles   n    percent valid_percent\n   [0,2] 748 0.11319613    0.11505922\n   (2,5] 721 0.10911017    0.11090601\n   (5,7] 497 0.07521186    0.07644978\n  (7,10] 698 0.10562954    0.10736810\n (10,13] 635 0.09609564    0.09767728\n (13,17] 755 0.11425545    0.11613598\n (17,21] 578 0.08746973    0.08890940\n (21,26] 625 0.09458232    0.09613906\n (26,33] 596 0.09019370    0.09167820\n (33,84] 648 0.09806295    0.09967697\n    &lt;NA&gt; 107 0.01619249            NA\n\n\n\n\nEvenly-sized groups\nAnother tool to make numeric groups is the the dplyr function ntile(), which attempts to break your data into n evenly-sized groups - but be aware that unlike with quantile() the same value could appear in more than one group. Provide the numeric vector and then the number of groups. The values in the new column created is just group “numbers” (e.g. 1 to 10), not the range of values themselves as when using cut().\n\n# make groups with ntile()\nntile_data &lt;- linelist %&gt;% \n  mutate(even_groups = ntile(age_years, 10))\n\n# make table of counts and proportions by group\nntile_table &lt;- ntile_data %&gt;% \n  janitor::tabyl(even_groups)\n  \n# attach min/max values to demonstrate ranges\nntile_ranges &lt;- ntile_data %&gt;% \n  group_by(even_groups) %&gt;% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `min = min(age_years, na.rm = T)`.\nℹ In group 11: `even_groups = NA`.\nCaused by warning in `min()`:\n! no non-missing arguments to min; returning Inf\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n# combine and print - note that values are present in multiple groups\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")\n\n even_groups   n    percent valid_percent min  max\n           1 651 0.09851695    0.10013844   0    2\n           2 650 0.09836562    0.09998462   2    5\n           3 650 0.09836562    0.09998462   5    7\n           4 650 0.09836562    0.09998462   7   10\n           5 650 0.09836562    0.09998462  10   13\n           6 650 0.09836562    0.09998462  13   17\n           7 650 0.09836562    0.09998462  17   21\n           8 650 0.09836562    0.09998462  21   26\n           9 650 0.09836562    0.09998462  26   33\n          10 650 0.09836562    0.09998462  33   84\n          NA 107 0.01619249            NA Inf -Inf\n\n\n\n\n\ncase_when()\nIt is possible to use the dplyr function case_when() to create categories from a numeric column, but it is easier to use age_categories() from epikit or cut() because these will create an ordered factor automatically.\nIf using case_when(), please review the proper use as described earlier in the Re-code values section of this page. Also be aware that all right-hand side values must be of the same class. Thus, if you want NA on the right-side you should either write “Missing” or use the special NA value NA_character_.\n\n\nAdd to pipe chain\nBelow, code to create two categorical age columns is added to the cleaning pipe chain:\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#add-rows",
    "href": "new_pages/cleaning.de.html#add-rows",
    "title": "8  Cleaning data and core functions",
    "section": "8.10 Add rows",
    "text": "8.10 Add rows\n\nOne-by-one\nAdding rows one-by-one manually is tedious but can be done with add_row() from dplyr. Remember that each column must contain values of only one class (either character, numeric, logical, etc.). So adding a row requires nuance to maintain this.\n\nlinelist &lt;- linelist %&gt;% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)\n\nUse .before and .after. to specify the placement of the row you want to add. .before = 3 will put the new row before the current 3rd row. The default behavior is to add the row to the end. Columns not specified will be left empty (NA).\nThe new row number may look strange (“…23”) but the row numbers in the pre-existing rows have changed. So if using the command twice, examine/test the insertion carefully.\nIf a class you provide is off you will see an error like this:\nError: Can't combine ..1$infection date &lt;date&gt; and ..2$infection date &lt;character&gt;.\n(when inserting a row with a date value, remember to wrap the date in the function as.Date() like as.Date(\"2020-10-10\")).\n\n\nBind rows\nTo combine datasets together by binding the rows of one dataframe to the bottom of another data frame, you can use bind_rows() from dplyr. This is explained in more detail in the page [Joining data].",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#filter-rows",
    "href": "new_pages/cleaning.de.html#filter-rows",
    "title": "8  Cleaning data and core functions",
    "section": "8.11 Filter rows",
    "text": "8.11 Filter rows\nA typical cleaning step after you have cleaned the columns and re-coded values is to filter the data frame for specific rows using the dplyr verb filter().\nWithin filter(), specify the logic that must be TRUE for a row in the dataset to be kept. Below we show how to filter rows based on simple and complex logical conditions.\n\n\nSimple filter\nThis simple example re-defines the dataframe linelist as itself, having filtered the rows to meet a logical condition. Only the rows where the logical statement within the parentheses evaluates to TRUE are kept.\nIn this example, the logical statement is gender == \"f\", which is asking whether the value in the column gender is equal to “f” (case sensitive).\nBefore the filter is applied, the number of rows in linelist is nrow(linelist).\n\nlinelist &lt;- linelist %&gt;% \n  filter(gender == \"f\")   # keep only rows where gender is equal to \"f\"\n\nAfter the filter is applied, the number of rows in linelist is linelist %&gt;% filter(gender == \"f\") %&gt;% nrow().\n\n\nFilter out missing values\nIt is fairly common to want to filter out rows that have missing values. Resist the urge to write filter(!is.na(column) & !is.na(column)) and instead use the tidyr function that is custom-built for this purpose: drop_na(). If run with empty parentheses, it removes rows with any missing values. Alternatively, you can provide names of specific columns to be evaluated for missingness, or use the “tidyselect” helper functions described above.\n\nlinelist %&gt;% \n  drop_na(case_id, age_years)  # drop rows with missing values for case_id or age_years\n\nSee the page on [Missing data] for many techniques to analyse and manage missingness in your data.\n\n\nFilter by row number\nIn a data frame or tibble, each row will usually have a “row number” that (when seen in R Viewer) appears to the left of the first column. It is not itself a true column in the data, but it can be used in a filter() statement.\nTo filter based on “row number”, you can use the dplyr function row_number() with open parentheses as part of a logical filtering statement. Often you will use the %in% operator and a range of numbers as part of that logical statement, as shown below. To see the first N rows, you can also use the special dplyr function head().\n\n# View first 100 rows\nlinelist %&gt;% head(100)     # or use tail() to see the n last rows\n\n# Show row 5 only\nlinelist %&gt;% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nYou can also convert the row numbers to a true column by piping your data frame to the tibble function rownames_to_column() (do not put anything in the parentheses).\n\n\n\nComplex filter\nMore complex logical statements can be constructed using parentheses ( ), OR |, negate !, %in%, and AND & operators. An example is below:\nNote: You can use the ! operator in front of a logical criteria to negate it. For example, !is.na(column) evaluates to true if the column value is not missing. Likewise !column %in% c(\"a\", \"b\", \"c\") evaluates to true if the column value is not in the vector.\n\nExamine the data\nBelow is a simple one-line command to create a histogram of onset dates. See that a second smaller outbreak from 2012-2013 is also included in this raw dataset. For our analyses, we want to remove entries from this earlier outbreak.\n\nhist(linelist$date_onset, breaks = 50)\n\n\n\n\n\n\n\n\n\n\nHow filters handle missing numeric and date values\nCan we just filter by date_onset to rows after June 2013? Caution! Applying the code filter(date_onset &gt; as.Date(\"2013-06-01\"))) would remove any rows in the later epidemic with a missing date of onset!\nDANGER: Filtering to greater than (&gt;) or less than (&lt;) a date or number can remove any rows with missing values (NA)! This is because NA is treated as infinitely large and small.\n(See the page on [Working with dates] for more information on working with dates and the package lubridate)\n\n\nDesign the filter\nExamine a cross-tabulation to make sure we exclude only the correct rows:\n\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values\n\n                                      YearOnset\nHospital                               2012 2013 2014 2015 &lt;NA&gt;\n  Central Hospital                        0    0  351   99   18\n  Hospital A                            229   46    0    0   15\n  Hospital B                            227   47    0    0   15\n  Military Hospital                       0    0  676  200   34\n  Missing                                 0    0 1117  318   77\n  Other                                   0    0  684  177   46\n  Port Hospital                           9    1 1372  347   75\n  St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n  &lt;NA&gt;                                    0    0    0    0    0\n\n\nWhat other criteria can we filter on to remove the first outbreak (in 2012 & 2013) from the dataset? We see that:\n\nThe first epidemic in 2012 & 2013 occurred at Hospital A, Hospital B, and that there were also 10 cases at Port Hospital.\n\nHospitals A & B did not have cases in the second epidemic, but Port Hospital did.\n\nWe want to exclude:\n\nThe nrow(linelist %&gt;% filter(hospital %in% c(\"Hospital A\", \"Hospital B\") | date_onset &lt; as.Date(\"2013-06-01\"))) rows with onset in 2012 and 2013 at either hospital A, B, or Port:\n\nExclude nrow(linelist %&gt;% filter(date_onset &lt; as.Date(\"2013-06-01\"))) rows with onset in 2012 and 2013\nExclude nrow(linelist %&gt;% filter(hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) rows from Hospitals A & B with missing onset dates\n\nDo not exclude nrow(linelist %&gt;% filter(!hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) other rows with missing onset dates.\n\n\nWe start with a linelist of nrow(linelist)`. Here is our filter statement:\n\nlinelist &lt;- linelist %&gt;% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)\n\n[1] 6019\n\n\nWhen we re-make the cross-tabulation, we see that Hospitals A & B are removed completely, and the 10 Port Hospital cases from 2012 & 2013 are removed, and all other values are the same - just as we wanted.\n\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values\n\n                                      YearOnset\nHospital                               2014 2015 &lt;NA&gt;\n  Central Hospital                      351   99   18\n  Military Hospital                     676  200   34\n  Missing                              1117  318   77\n  Other                                 684  177   46\n  Port Hospital                        1372  347   75\n  St. Mark's Maternity Hospital (SMMH)  322   93   13\n  &lt;NA&gt;                                    0    0    0\n\n\nMultiple statements can be included within one filter command (separated by commas), or you can always pipe to a separate filter() command for clarity.\nNote: some readers may notice that it would be easier to just filter by date_hospitalisation because it is 100% complete with no missing values. This is true. But date_onset is used for purposes of demonstrating a complex filter.\n\n\n\nStandalone\nFiltering can also be done as a stand-alone command (not part of a pipe chain). Like other dplyr verbs, in this case the first argument must be the dataset itself.\n\n# dataframe &lt;- filter(dataframe, condition(s) for rows to keep)\n\nlinelist &lt;- filter(linelist, !is.na(case_id))\n\nYou can also use base R to subset using square brackets which reflect the [rows, columns] that you want to retain.\n\n# dataframe &lt;- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist &lt;- linelist[!is.na(case_id), ]\n\n\n\nQuickly review records\nOften you want to quickly review a few records, for only a few columns. The base R function View() will print a data frame for viewing in your RStudio.\nView the linelist in RStudio:\n\nView(linelist)\n\nHere are two examples of viewing specific cells (specific rows, and specific columns):\nWith dplyr functions filter() and select():\nWithin View(), pipe the dataset to filter() to keep certain rows, and then to select() to keep certain columns. For example, to review onset and hospitalization dates of 3 specific cases:\n\nView(linelist %&gt;%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %&gt;%\n       select(date_onset, date_hospitalisation))\n\nYou can achieve the same with base R syntax, using brackets [ ] to subset you want to see.\n\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\n\n\nAdd to pipe chain\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %&gt;% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#row-wise-calculations",
    "href": "new_pages/cleaning.de.html#row-wise-calculations",
    "title": "8  Cleaning data and core functions",
    "section": "8.12 Row-wise calculations",
    "text": "8.12 Row-wise calculations\nIf you want to perform a calculation within a row, you can use rowwise() from dplyr. See this online vignette on row-wise calculations.\nFor example, this code applies rowwise() and then creates a new column that sums the number of the specified symptom columns that have value “yes”, for each row in the linelist. The columns are specified within sum() by name within a vector c(). rowwise() is essentially a special kind of group_by(), so it is best to use ungroup() when you are done (page on [Grouping data]).\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %&gt;% \n  ungroup() %&gt;% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # for display\n\n# A tibble: 5,888 × 6\n   fever chills cough aches vomit num_symptoms\n   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;\n 1 no    no     yes   no    yes              2\n 2 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 3 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 4 no    no     no    no    no               0\n 5 no    no     yes   no    yes              2\n 6 no    no     yes   no    yes              2\n 7 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 8 no    no     yes   no    yes              2\n 9 no    no     yes   no    yes              2\n10 no    no     yes   no    no               1\n# ℹ 5,878 more rows\n\n\nAs you specify the column to evaluate, you may want to use the “tidyselect” helper functions described in the select() section of this page. You just have to make one adjustment (because you are not using them within a dplyr function like select() or summarise()).\nPut the column-specification criteria within the dplyr function c_across(). This is because c_across (documentation) is designed to work with rowwise() specifically. For example, the following code:\n\nApplies rowwise() so the following operation (sum()) is applied within each row (not summing entire columns)\n\nCreates new column num_NA_dates, defined for each row as the number of columns (with name containing “date”) for which is.na() evaluated to TRUE (they are missing data).\n\nungroup() to remove the effects of rowwise() for subsequent steps\n\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %&gt;% \n  ungroup() %&gt;% \n  select(num_NA_dates, contains(\"date\")) # for display\n\n# A tibble: 5,888 × 5\n   num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n          &lt;int&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n 2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n 3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n 4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n 5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n\n\nYou could also provide other functions, such as max() to get the latest or most recent date for each row:\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %&gt;% \n  ungroup() %&gt;% \n  select(latest_date, contains(\"date\"))  # for display\n\n# A tibble: 5,888 × 5\n   latest_date date_infection date_onset date_hospitalisation date_outcome\n   &lt;date&gt;      &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n 2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n 3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n 4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n 5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.de.html#arrange-and-sort",
    "href": "new_pages/cleaning.de.html#arrange-and-sort",
    "title": "8  Cleaning data and core functions",
    "section": "8.13 Arrange and sort",
    "text": "8.13 Arrange and sort\nUse the dplyr function arrange() to sort or order the rows by column values.\nSimple list the columns in the order they should be sorted on. Specify .by_group = TRUE if you want the sorting to to first occur by any groupings applied to the data (see page on [Grouping data]).\nBy default, column will be sorted in “ascending” order (which applies to numeric and also to character columns). You can sort a variable in “descending” order by wrapping it with desc().\nSorting data with arrange() is particularly useful when making [Tables for presentation], using slice() to take the “top” rows per group, or setting factor level order by order of appearance.\nFor example, to sort the our linelist rows by hospital, then by date_onset in descending order, we would use:\n\nlinelist %&gt;% \n   arrange(hospital, desc(date_onset))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html",
    "href": "new_pages/dates.de.html",
    "title": "9  Mit Daten arbeiten",
    "section": "",
    "text": "9.1 Vorbereitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#vorbereitung",
    "href": "new_pages/dates.de.html#vorbereitung",
    "title": "9  Mit Daten arbeiten",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden der Pakete, die für diese Seite benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\n# Checks if package is installed, installs if necessary, and loads package for current session\n\npacman::p_load(\n  lubridate,  # general package for handling and converting dates  \n  parsedate,  # has function to \"guess\" messy dates\n  aweek,      # another option for converting dates to weeks, and weeks to dates\n  zoo,        # additional date/time functions\n  here,       # file management\n  rio,        # data import/export\n  tidyverse)  # data management and visualization  \n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du die Daten herunterladen möchtest, um Schritt für Schritt mitzumachen, sieh dir die Anleitung im [Handbuch und Daten herunterladen] Seite. Wir gehen davon aus, dass sich die Datei im Arbeitsverzeichnis befindet, also werden in diesem Dateipfad keine Unterordner angegeben.\n\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#aktuelles-datum",
    "href": "new_pages/dates.de.html#aktuelles-datum",
    "title": "9  Mit Daten arbeiten",
    "section": "9.2 Aktuelles Datum",
    "text": "9.2 Aktuelles Datum\nDu kannst das aktuelle “System”-Datum oder die System-Datumszeit deines Computers ermitteln, indem du Folgendes tust mit Basis R.\n\n# get the system date - this is a DATE class\nSys.Date()\n\n[1] \"2024-02-21\"\n\n# get the system time - this is a DATETIME class\nSys.time()\n\n[1] \"2024-02-21 13:57:57 CET\"\n\n\nMit der lubridate Paket können diese auch zurückgegeben werden mit today() und now() zurückgegeben werden. date() gibt das aktuelle Datum und die Uhrzeit mit Wochentags- und Monatsnamen zurück.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#in-datum-umwandeln",
    "href": "new_pages/dates.de.html#in-datum-umwandeln",
    "title": "9  Mit Daten arbeiten",
    "section": "9.3 In Datum umwandeln",
    "text": "9.3 In Datum umwandeln\nNach dem Import eines Datensatzes in R können die Werte der Datumsspalten wie “1989/12/30”, “05/06/2014” oder “13 Jan 2020” aussehen. In diesen Fällen behandelt R diese Werte wahrscheinlich immer noch als Zeichenwerte. R muss mitgeteilt dass es sich bei diesen Werten um Datumswerte handelt… und welches Format das Datum hat (welcher Teil ist der Tag, welcher der Monat, welcher das Jahr, usw.).\nSobald dies bekannt ist, wandelt R diese Werte in die Klasse Datum um. Im Hintergrund speichert R die Daten als Zahlen (die Anzahl der Tage seit dem “Ursprungsdatum” 1. Januar 1970). Du wirst nicht oft mit den Datumszahlen in Berührung kommen, aber so kann R Datumswerte als kontinuierliche Variablen behandeln und spezielle Operationen wie die Berechnung des Abstands zwischen Datumswerten ermöglichen.\nStandardmäßig werden Werte der Klasse Datum in R als JJJJ-MM-TT angezeigt. Später in diesem Abschnitt werden wir besprechen, wie du die Anzeige von Datumswerten ändern kannst.\nIm Folgenden stellen wir zwei Methoden vor, um eine Spalte von Zeichenwerten in die Klasse Datum zu konvertieren.\nTIPP: Du kannst die aktuelle Klasse einer Spalte mit base R-Funktion class(), wie class(linelist$date_onset).\n\nBasis R\nas.Date() ist der Standard, Basis R-Funktion, um ein Objekt oder eine Spalte in die Klasse Datum zu konvertieren (beachte die Großschreibung von “D”).\nDie Verwendung von as.Date() erfordert, dass:\n\nDu specify the bestehende Format des Rohzeichendatums oder des Ursprungsdatums, wenn das Datum als Zahl angegeben wird (siehe Abschnitt über Excel-Datumsangaben)\nBei der Verwendung in einer Zeichenspalte müssen alle Datumswerte genau dasselbe Format haben (ist dies nicht der Fall, versuche parse_date() aus der parsedate Paket)\n\nErste überprüfe die Klasse deiner Spalte mit class() von Basis R. Wenn du unsicher oder verwirrt über die Klasse deiner Daten bist (z. B. siehst du “POSIXct” usw.), kann es am einfachsten sein, die Spalte zunächst in die Klasse Character umzuwandeln mit as.character() zu konvertieren und sie dann in die Klasse Datum umzuwandeln.\nZweite innerhalb der as.Date() Funktion, die format = Argument, um R die aktuelle Format der Datumskomponenten mitteilt - welche Zeichen sich auf den Monat, den Tag und das Jahr beziehen und wie sie getrennt werden. Wenn deine Werte bereits in einem der Standard-Datumsformate von R vorliegen (“JJJJ-MM-TT” oder “JJJJ/MM/TT”), wird das format = Argument nicht notwendig.\nAn format = gibst du eine Zeichenkette (in Anführungszeichen) an, die den aktuelle Datumsformat unter Verwendung der speziellen “strptime” Abkürzungen unten. Wenn deine Datumsangaben zum Beispiel das Format “TT/MM/JJJJ” haben, z. B. “24/04/1968”, würdest du Folgendes verwenden format = \"%d/%m/%Y\" verwenden, um die Werte in Datumsangaben umzuwandeln. Das Format muss in Anführungszeichen gesetzt werden. Und vergiss keine Schrägstriche oder Bindestriche!\n\n# Convert to class date\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))\n\nDie meisten strptime-Abkürzungen sind unten aufgeführt. Die vollständige Liste kannst du sehen, indem du ?strptime.\n%d = Tagesnummer des Monats (5, 17, 28, etc.)\n%j = Tagesnummer des Jahres (Julianischer Tag 001-366)\n%a = Abgekürzter Wochentag (Mo, Di, Mi, etc.)\n%A = Voller Wochentag (Montag, Dienstag, etc.) %w = Wochentagsnummer (0-6, Sonntag ist 0)\n%u = Wochentagsnummer (1-7, Montag ist 1)\n%W = Wochennummer (00-53, Montag ist der Wochenanfang)\n%U = Wochennummer (01-53, Sonntag ist der Wochenbeginn)\n%m = Monatsnummer (z. B. 01, 02, 03, 04)\n%b = abgekürzter Monat (Jan, Feb, etc.)\n%B = Ganzer Monat (Januar, Februar, etc.)\n%y = 2-stelliges Jahr (z. B. 89)\n%Y = 4-stellige Jahreszahl (z. B. 1989)\n%h = Stunden (24-Stunden-Uhr)\n%m = Minuten\n%s = Sekunden %z = Abweichung von der GMT\n%Z = Zeitzone (Zeichen)\nTIPP: Die format = Argument der as.Date() ist nicht R mitzuteilen, welches Format die Daten haben sollen, sondern wie die Datumsbestandteile zu identifizieren sind vor du den Befehl ausführst.\nTIPP: Achte darauf, dass in der format = Argument die Datumsteil-Trennzeichen (z.B. /, - oder Leerzeichen), das in deinen Daten vorhanden ist.\nSobald die Werte in der Klasse Datum sind, zeigt R sie standardmäßig im Standardformat an, also JJJJ-MM-TT.\n\n\nlubridate\nDie Umwandlung von Zeichenobjekten in Datumsangaben kann durch die Verwendung der lubridate Paket. Dies ist ein tidyverse Paket, das die Arbeit mit Daten und Zeiten einfacher und konsistenter als in base R. Aus diesen Gründen, lubridate oft als das Standardpaket für Datum und Zeit angesehen und wird empfohlen, wenn du mit ihnen arbeitest.\nDie lubridate Paket stellt verschiedene Hilfsfunktionen zur Verfügung, mit denen Zeichenobjekte auf intuitive Weise in Datumsangaben umgewandelt werden können, was einfacher ist als die Angabe des Formats in as.Date(). Diese Funktionen sind spezifisch für das grobe Datumsformat, erlauben aber eine Vielzahl von Trennzeichen und Synonymen für Datumsangaben (z.B. 01 vs Jan vs Januar) - sie sind nach Abkürzungen von Datumsformaten benannt.\n\n# install/load lubridate \npacman::p_load(lubridate)\n\nDie ymd() Funktion konvertiert flexibel Datumswerte, die als Jahr, dann Monat, dann Tag.\n\n# read date in year-month-day format\nymd(\"2020-10-11\")\n\n[1] \"2020-10-11\"\n\nymd(\"20201011\")\n\n[1] \"2020-10-11\"\n\n\nDie mdy() Funktion konvertiert flexibel Datumswerte, die als Monat, dann Tag, dann Jahr.\n\n# read date in month-day-year format\nmdy(\"10/11/2020\")\n\n[1] \"2020-10-11\"\n\nmdy(\"Oct 11 20\")\n\n[1] \"2020-10-11\"\n\n\nDie dmy() Funktion konvertiert flexibel Datumswerte, die als Tag, dann Monat, dann Jahr.\n\n# read date in day-month-year format\ndmy(\"11 10 2020\")\n\n[1] \"2020-10-11\"\n\ndmy(\"11 October 2020\")\n\n[1] \"2020-10-11\"\n\n\n\n\n\n\nWenn du Piping verwendest, kann die Umwandlung einer Zeichenspalte in ein Datum mit lubridate könnte so aussehen:\n\nlinelist &lt;- linelist %&gt;%\n  mutate(date_onset = lubridate::dmy(date_onset))\n\nWenn du fertig bist, kannst du Folgendes ausführen class() ausführen, um die Klasse der Spalte zu überprüfen\n\n# Check the class of the column\nclass(linelist$date_onset)  \n\nWenn die Werte in der Klasse Datum sind, zeigt R sie standardmäßig im Standardformat an, also JJJJ-MM-TT.\nBeachte, dass die oben genannten Funktionen am besten mit 4-stelligen Jahreszahlen funktionieren. Zweistellige Jahreszahlen können zu unerwarteten Ergebnissen führen, da lubridate versucht, das Jahrhundert zu erraten.\nUm eine zweistellige Jahreszahl in eine vierstellige Jahreszahl umzuwandeln (alle im selben Jahrhundert), kannst du in Klassenzeichen umwandeln und dann die vorhandenen Ziffern mit einem Präfix kombinieren, indem du str_glue() aus der stringrPaket (siehe [Zeichen und Zeichenketten]). Dann konvertiere in ein Datum.\n\ntwo_digit_years &lt;- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")\n\n2015\n2015\n2016\n2017\n\n\n\n\nSpalten kombinieren\nDu kannst die lubridate Funktionen make_date() und make_datetime() um mehrere numerische Spalten zu einer Datumsspalte zu kombinieren. Wenn du zum Beispiel numerische Spalten hast onset_day, onset_month, und onset_year in dem Datenrahmen linelist:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#excel-daten",
    "href": "new_pages/dates.de.html#excel-daten",
    "title": "9  Mit Daten arbeiten",
    "section": "9.4 Excel-Daten",
    "text": "9.4 Excel-Daten\nIm Hintergrund speichern die meisten Programme Datumsangaben als Zahlen. R speichert Datumsangaben ab dem 1. Januar 1970. Wenn du also as.numeric(as.Date(\"1970-01-01)) aufrufst, erhältst du 0.\nMicrosoft Excel speichert Datumsangaben, deren Ursprung entweder der 30. Dezember 1899 (Windows) oder der 1. Januar 1904 (Mac) ist, abhängig von deinem Betriebssystem. Siehe dies Microsoft-Anleitung für weitere Informationen.\nExcel-Datumsangaben werden oft als numerische Werte in R importiert und nicht als Zeichen. Wenn der Datensatz, den du aus Excel importiert hast, Datumsangaben in Form von Zahlen oder Zeichen wie “41369”… enthält, verwende as.Date() (oder lubridate’s as_date() Funktion) zu konvertieren, aber anstatt ein “Format” wie oben anzugeben, gib das Excel-Ursprungsdatum an an das Argument origin =.\nDas funktioniert nicht, wenn das Excel-Datum in R als Zeichentyp gespeichert ist. Achte also darauf, dass die Zahl der Klasse Numerisch angehört!\nHINWEIS: Du solltest das Ursprungsdatum im Standard-Datumsformat von R (“JJJJ-MM-TT”) angeben.\n\n# An example of providing the Excel 'origin date' when converting Excel number dates\ndata_cleaned &lt;- data %&gt;% \n  mutate(date_onset = as.numeric(date_onset)) %&gt;%   # ensure class is numeric\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # convert to date using Excel origin",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#unordentliche-termine",
    "href": "new_pages/dates.de.html#unordentliche-termine",
    "title": "9  Mit Daten arbeiten",
    "section": "9.5 Unordentliche Termine",
    "text": "9.5 Unordentliche Termine\nDie Funktion parse_date() aus dem parsedate Paket versucht, eine “chaotische” Datumsspalte zu lesen, die Datumsangaben in vielen verschiedenen Formaten enthält, und die Daten in ein Standardformat zu konvertieren. Du kannst mehr online lesen über parse_date().\nZum Beispiel parse_date() einen Vektor der folgenden Zeichendaten “03 Jan 2018”, “07/03/1982” und “08/20/85” und konvertiert sie in die Klasse Datum als: 2018-01-03, 1982-03-07, und 1985-08-20.\n\nparsedate::parse_date(c(\"03 January 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))\n\n[1] \"2018-01-03 UTC\" \"1982-07-03 UTC\" \"1985-08-20 UTC\"\n\n\n\n# An example using parse_date() on the column date_onset\nlinelist &lt;- linelist %&gt;%      \n  mutate(date_onset = parse_date(date_onset))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#arbeiten-mit-der-datum-zeit-klasse",
    "href": "new_pages/dates.de.html#arbeiten-mit-der-datum-zeit-klasse",
    "title": "9  Mit Daten arbeiten",
    "section": "9.6 Arbeiten mit der Datum-Zeit-Klasse",
    "text": "9.6 Arbeiten mit der Datum-Zeit-Klasse\nWie bereits erwähnt, unterstützt R auch eine datetime Klasse - eine Spalte, die das Datum enthält und Zeitinformationen enthält. Wie bei der Date Klasse, müssen diese oft von character Objekten in datetime Objekte umgewandelt werden.\n\nDaten mit Zeiten umrechnen\nA Standard datetime Objekt wird zuerst mit dem Datum formatiert, gefolgt von einer Zeitkomponente - zum Beispiel 01 Jan 2020, 16:30. Wie bei den Datumsangaben gibt es viele Möglichkeiten, diese zu formatieren, und es gibt zahlreiche Genauigkeitsstufen (Stunden, Minuten, Sekunden), die angegeben werden können.\nZum Glück, lubridate auch Hilfsfunktionen, die dabei helfen, diese Zeichenketten in datetime Objekte umzuwandeln. Diese Funktionen sind Erweiterungen der date-Hilfsfunktionen, mit _h (nur Stunden angegeben), _hm (mit Stunden und Minuten), oder _hms (mit Stunden, Minuten und Sekunden) am Ende angehängt (z. B. dmy_hms()). Diese können wie gezeigt verwendet werden:\ndatetime mit nur Stunden in datetime-Objekt konvertieren\n\nymd_h(\"2020-01-01 16hrs\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\nymd_h(\"2020-01-01 4PM\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\n\ndatetime mit Stunden und Minuten in ein datetime-Objekt konvertieren\n\ndmy_hm(\"01 January 2020 16:20\")\n\n[1] \"2020-01-01 16:20:00 UTC\"\n\n\ndatetime mit Stunden, Minuten und Sekunden in ein datetime-Objekt konvertieren\n\nmdy_hms(\"01 January 2020, 16:20:40\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nDu kannst die Zeitzone angeben, aber sie wird ignoriert. Siehe den Abschnitt über Zeitzonen weiter unten auf dieser Seite.\n\nmdy_hms(\"01 January 2020, 16:20:40 PST\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nWenn du mit einem Datenrahmen arbeitest, können Zeit- und Datumsspalten kombiniert werden, um eine Datetime-Spalte zu erstellen. str_glue() von stringr Paket und eine entsprechende lubridateFunktion. Siehe die Seite über [Zeichen und Zeichenketten] für Details zustringr.\nIn diesem Beispiel wird die linelist Datenrahmen eine Spalte im Format “Stunden:Minuten”. Um diese in eine Datumszeit zu konvertieren, folgen wir ein paar Schritten:\n\nErstelle eine “saubere” Aufnahmezeitspalte, in der fehlende Werte mit dem Spaltenmedian aufgefüllt werden. Wir tun dies, weil lubridate nicht mit fehlenden Werten arbeiten kann. Kombiniere sie mit der Spalte date_hospitalisation und verwende dann die Funktion ymd_hm() umzuwandeln.\n\n\n# packages\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission is a column in hours:minutes\nlinelist &lt;- linelist %&gt;%\n  \n  # when time of admission is not given, assign the median admission time\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # if time is missing\n      median(time_admission),        # assign the median\n      time_admission                 # if not missing keep as is\n  ) %&gt;%\n  \n    # use str_glue() to combine date and time columns to create one character column\n    # and then use ymd_hm() to convert it to datetime\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %&gt;% \n      ymd_hm()\n  )\n\n\n\nZeiten allein umrechnen\nWenn deine Daten nur eine Zeichenzeit (Stunden und Minuten) enthalten, kannst du sie als Zeiten konvertieren und manipulieren, indem du strptime() von Basis R. Um zum Beispiel die Differenz zwischen zwei dieser Zeiten zu ermitteln:\n\n# raw character times\ntime1 &lt;- \"13:45\" \ntime2 &lt;- \"15:20\"\n\n# Times converted to a datetime class\ntime1_clean &lt;- strptime(time1, format = \"%H:%M\")\ntime2_clean &lt;- strptime(time2, format = \"%H:%M\")\n\n# Difference is of class \"difftime\" by default, here converted to numeric hours \nas.numeric(time2_clean - time1_clean)   # difference in hours\n\n[1] 1.583333\n\n\nBeachte jedoch, dass ohne Angabe eines Datumswertes davon ausgegangen wird, dass das Datum heute ist. Um ein String-Datum und eine String-Zeit miteinander zu kombinieren, siehe stringr im Abschnitt weiter oben. Lies mehr über strptime() hier.\nUm einstellige Zahlen in zweistellige umzuwandeln (z.B. um Stunden oder Minuten mit führenden Nullen “aufzufüllen”, um 2 Stellen zu erhalten), siehe dies Abschnitt “Auffülllänge” auf der Seite Zeichen und Zeichenketten.\n\n\nZeit extrahieren\nDu kannst Elemente einer Zeit extrahieren mit hour(), minute(), oder second() von lubridate.\nHier ist ein Beispiel für die Extraktion der Stunde und die anschließende Klassifizierung nach Tageszeiten. Wir beginnen mit der Spalte time_admission die die Klasse Zeichen im Format “HH:MM” enthält. Zuerst wird die strptime() wie oben beschrieben verwendet, um die Zeichen in die Datetime-Klasse umzuwandeln. Dann wird die Stunde extrahiert mit hour() extrahiert, was eine Zahl von 0-24 ergibt. Schließlich wird eine Spalte time_period erstellt, indem die Logik mit case_when() erstellt, um die Zeilen anhand der Uhrzeit ihrer Aufnahme in Vormittag/Nachmittag/Abend/Nacht einzuteilen.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %&gt;%\n  mutate(time_period = case_when(\n    hour_admit &gt; 06 & hour_admit &lt; 12 ~ \"Morning\",\n    hour_admit &gt;= 12 & hour_admit &lt; 17 ~ \"Afternoon\",\n    hour_admit &gt;= 17 & hour_admit &lt; 21 ~ \"Evening\",\n    hour_admit &gt;=21 | hour_admit &lt;= 6 ~ \"Night\"))\n\nUm mehr zu erfahren über case_when()siehe die Seite über [Datenbereinigung und Kernfunktionen].",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#arbeiten-mit-daten",
    "href": "new_pages/dates.de.html#arbeiten-mit-daten",
    "title": "9  Mit Daten arbeiten",
    "section": "9.7 Arbeiten mit Daten",
    "text": "9.7 Arbeiten mit Daten\nlubridate kann auch für eine Vielzahl anderer Funktionen verwendet werden, wie zum Beispiel Aspekte eines Datums/einer Uhrzeit extrahieren, Durchführen von Datumsarithmetik oder Berechnung von Datumsintervallen\nHier legen wir ein Datum fest, das wir für die Beispiele verwenden:\n\n# create object of class Date\nexample_date &lt;- ymd(\"2020-03-01\")\n\n\nDatumskomponenten extrahieren\nDu kannst allgemeine Aspekte wie Monat, Tag und Wochentag extrahieren:\n\nmonth(example_date)  # month number\n\n[1] 3\n\nday(example_date)    # day (number) of the month\n\n[1] 1\n\nwday(example_date)   # day number of the week (1-7)\n\n[1] 1\n\n\nDu kannst auch Zeitkomponenten aus einer datetime Objekt oder einer Spalte extrahieren. Das kann nützlich sein, wenn du dir die Verteilung der Aufnahmezeiten ansehen willst.\n\nexample_datetime &lt;- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime)     # extract hour\nminute(example_datetime)   # extract minute\nsecond(example_datetime)   # extract second\n\nEs gibt mehrere Optionen, um Wochen abzurufen. Siehe den Abschnitt über epidemiologische Wochen weiter unten.\nBeachte, dass du, wenn du anzeigen Wenn du ein Datum auf eine bestimmte Art und Weise anzeigen lassen willst (z. B. “Januar 2020” oder “Donnerstag, 20. März” oder “Woche 20, 1977”), kannst du dies flexibler tun, wie im Abschnitt über die Datumsanzeige beschrieben.\n\n\nDatumsmathematik\nDu kannst eine bestimmte Anzahl von Tagen oder Wochen hinzufügen, indem du die entsprechende Funktion aus lubridate.\n\n# add 3 days to this date\nexample_date + days(3)\n\n[1] \"2020-03-04\"\n\n# add 7 weeks and subtract two days from this date\nexample_date + weeks(7) - days(2)\n\n[1] \"2020-04-17\"\n\n\n\n\nDatumsintervalle\nDie Differenz zwischen den Daten kann berechnet werden durch:\n\nSicherstellen, dass beide Daten ein Klassendatum sind\nVerwende die Subtraktion, um die “difftime”-Differenz zwischen den beiden Daten zu ermitteln\nFalls nötig, konvertiere das Ergebnis in eine numerische Klasse, um weitere mathematische Berechnungen durchzuführen\n\nUnten wird das Intervall zwischen zwei Daten berechnet und angezeigt. Du kannst Intervalle ermitteln, indem du das Subtraktionssymbol “Minus” für Werte der Klasse Datum verwendest. Beachte jedoch, dass die Klasse des zurückgegebenen Wertes “difftime” ist, wie unten dargestellt, und in numerisch umgewandelt werden muss.\n\n# find the interval between this date and Feb 20 2020 \noutput &lt;- example_date - ymd(\"2020-02-20\")\noutput    # print\n\nTime difference of 10 days\n\nclass(output)\n\n[1] \"difftime\"\n\n\nUm weitere Operationen mit einer “difftime” durchzuführen, musst du sie in numerisch umwandeln mit as.numeric().\nDas alles kann zusammengeführt werden, um mit Daten zu arbeiten - zum Beispiel:\n\npacman::p_load(lubridate, tidyverse)   # load packages\n\nlinelist &lt;- linelist %&gt;%\n  \n  # convert date of onset from character to date objects by specifying dmy format\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %&gt;%\n  \n  # filter out all cases without onset in march\n  filter(month(date_onset) == 3) %&gt;%\n    \n  # find the difference in days between onset and hospitalisation\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n\nWenn in einem Datenrahmen eines der oben genannten Daten fehlt, schlägt der Vorgang für diese Zeile fehl. Das Ergebnis ist eine NA statt eines numerischen Wertes. Wenn du diese Spalte für Berechnungen verwendest, musst du die Option na.rm = Argument auf TRUE. Zum Beispiel:\n\n# calculate the median number of days to hospitalisation for all cases where data are available\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#datumsanzeige",
    "href": "new_pages/dates.de.html#datumsanzeige",
    "title": "9  Mit Daten arbeiten",
    "section": "9.8 Datumsanzeige",
    "text": "9.8 Datumsanzeige\nWenn das Datum die richtige Klasse hat, möchtest du es oft anders anzeigen lassen, zum Beispiel als “Montag, 05. Januar” statt als “2018-01-05”. Vielleicht möchtest du die Anzeige auch anpassen, um die Zeilen nach den angezeigten Datumselementen zu gruppieren - zum Beispiel nach Monat und Jahr.\n\nformat()\nStelle die Datumsanzeige mit der Taste Basis R-Funktion format(). Diese Funktion akzeptiert eine Zeichenkette (in Anführungszeichen), die den gewünschten Ausgabeformat in den “%”-Strptime-Abkürzungen angibt (die gleiche Syntax wie in as.Date()). Nachfolgend sind die meisten gängigen Abkürzungen aufgeführt.\nHinweis: Die Verwendung format() werden die Werte in Klassenzeichen umgewandelt, daher wird dies in der Regel gegen Ende einer Analyse oder nur zu Anzeigezwecken verwendet! Du kannst die vollständige Liste sehen, indem du ?strptime.\n%d = Tagesnummer des Monats (5, 17, 28, etc.)\n%j = Tagesnummer des Jahres (Julianischer Tag 001-366)\n%a = Abgekürzter Wochentag (Mo, Di, Mi, etc.)\n%A = Voller Wochentag (Montag, Dienstag, etc.)\n%w = Wochentagsnummer (0-6, Sonntag ist 0)\n%u = Wochentagsnummer (1-7, Montag ist 1)\n%W = Wochennummer (00-53, Montag ist der Wochenanfang)\n%U = Wochennummer (01-53, Sonntag ist der Wochenbeginn)\n%m = Monatsnummer (z. B. 01, 02, 03, 04)\n%b = abgekürzter Monat (Jan, Feb, etc.)\n%B = Ganzer Monat (Januar, Februar, etc.)\n%y = 2-stelliges Jahr (z. B. 89)\n%Y = 4-stellige Jahreszahl (z. B. 1989)\n%h = Stunden (24-Stunden-Uhr)\n%m = Minuten\n%s = Sekunden\n%z = Abweichung von der GMT\n%Z = Zeitzone (Zeichen)\nEin Beispiel für die Formatierung des heutigen Datums:\n\n# today's date, with formatting\nformat(Sys.Date(), format = \"%d %B %Y\")\n\n[1] \"21 February 2024\"\n\n# easy way to get full date and time (default formatting)\ndate()\n\n[1] \"Wed Feb 21 13:57:58 2024\"\n\n# formatted combined date, time, and time zone using str_glue() function\nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z  %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")\n\nWednesday, February 21 2024, +0000  UTC, 13:57:58\n\n# Using format to display weeks\nformat(Sys.Date(), \"%Y Week %W\")\n\n[1] \"2024 Week 08\"\n\n\nBeachten Sie, dass bei der Verwendung von str_glue() verwenden, solltest du beachten, dass du innerhalb der erwarteten doppelten Anführungszeichen ” nur einfache Anführungszeichen verwenden solltest (wie oben).\n\n\nMonat-Jahr\nUm eine Datumsspalte in das Format Monat-Jahr umzuwandeln, empfehlen wir dir die Funktion as.yearmon() aus der zoo Paket. Dadurch wird das Datum in die Klasse “yearmon” umgewandelt und die richtige Reihenfolge beibehalten. Im Gegensatz dazu wird bei der Verwendung von format(column, \"%Y %B\") wird dagegen in die Klasse “Character” umgewandelt und die Werte werden (fälschlicherweise) alphabetisch geordnet.\nUnten, eine neue Spalte yearmonth erstellt aus der Spalte date_onset erstellt, indem die as.yearmon() Funktion. Die standardmäßige (korrekte) Reihenfolge der resultierenden Werte wird in der Tabelle angezeigt.\n\n# create new column \ntest_zoo &lt;- linelist %&gt;% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# print table\ntable(test_zoo$yearmon)\n\n\nApr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 \n       7       64      100      226      528     1070     1112      763 \nDec 2014 Jan 2015 Feb 2015 Mar 2015 Apr 2015 \n     562      431      306      277      186 \n\n\nIm Gegensatz dazu kannst du sehen, wie nur mit format() zwar das gewünschte Anzeigeformat, aber nicht die richtige Reihenfolge erreicht.\n\n# create new column\ntest_format &lt;- linelist %&gt;% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# print table\ntable(test_format$yearmon)\n\n\nApr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 \n       7      186      528      562      306      431      226      100 \nMar 2015 May 2014 Nov 2014 Oct 2014 Sep 2014 \n     277       64      763     1112     1070 \n\n\nHinweis: Wenn du innerhalb einer ggplot() und anpassen möchtest, wie die Daten angezeigt anpassen möchten, kann es ausreichen, ein strptime-Format für die date_labels = Argument in scale_x_date() - kannst du verwenden \"%b %Y\" oder \"%Y %b\". Siehe die [ggplot-Tipps] Seite.\nzoo bietet auch die Funktion as.yearqtr() an, und du kannst die Funktion scale_x_yearmon() wenn du ggplot().",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#epidemiologische-wochen-dates_epi_wks",
    "href": "new_pages/dates.de.html#epidemiologische-wochen-dates_epi_wks",
    "title": "9  Mit Daten arbeiten",
    "section": "9.9 Epidemiologische Wochen {#dates_epi_wks}",
    "text": "9.9 Epidemiologische Wochen {#dates_epi_wks}\n\nlubridate\nSiehe die Seite über [Daten gruppieren] für ausführlichere Beispiele zur Gruppierung von Daten nach Datum. Im Folgenden beschreiben wir kurz die Gruppierung von Daten nach Wochen.\nWir empfehlen generell die Verwendung der floor_date() Funktion von lubridate mit dem Argument unit = \"week\". Dies rundet das Datum auf den “Anfang” der Woche ab, wie er durch das Argument week_start =. Der Standard-Wochenanfang ist 1 (für Montag), aber du kannst jeden beliebigen Wochentag als Anfang angeben (z. B. 7 für Sonntag). floor_date() ist vielseitig und kann zum Abrunden auf andere Zeiteinheiten verwendet werden, indem du unit = auf “Sekunde”, “Minute”, “Stunde”, “Tag”, “Monat” oder “Jahr”.\nDer zurückgegebene Wert ist das Startdatum der Woche in der Date-Klasse. Die Date-Klasse ist beim Plotten der Daten nützlich, da sie leicht erkannt und korrekt geordnet werden kann. ggplot().\nWenn du nur an der Anpassung von Daten an anzeigen nach Woche in einem Diagramm anzeigen möchtest, lies den Abschnitt über die Datumsanzeige auf dieser Seite. Wenn du zum Beispiel eine Epikurve zeichnest, kannst du die Datumsanzeige formatieren, indem du die gewünschte Strptime-“%”-Nomenklatur angibst. Verwende z. B. “%Y-%W” oder “%Y-%U”, um das Jahr und die Wochennummer (bei Wochenbeginn am Montag bzw. Sonntag) anzuzeigen.\n\n\nWöchentliche Zählungen\nSiehe die Seite über [Daten gruppieren] für eine ausführliche Erklärung der Gruppierung von Daten mitcount(), group_by(), und summarise(). Im Folgenden findest du ein kurzes Beispiel.\n\nErstelle eine neue Spalte “Woche” mit mutate(), mit floor_date() mit unit = \"week\"\nZählung der Zeilen (Fälle) pro Woche mit count() Filtert alle Fälle mit fehlendem Datum heraus\nBeende mit complete() von tidyr um sicherzustellen, dass alle Wochen in den Daten auftauchen - auch die, die keine Zeilen/Fälle enthalten. Standardmäßig sind die Zählwerte für alle “neuen” Zeilen NA, aber du kannst sie mit der Option fill = Argument, das eine benannte Liste erwartet (siehe unten, n ist der Name der Zählspalte).\n\n\n# Make aggregated dataset of weekly case counts\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%             # remove cases missing onset date\n  mutate(weekly_cases = floor_date(   # make new column, week of onset\n    date_onset,\n    unit = \"week\")) %&gt;%            \n  count(weekly_cases) %&gt;%           # group data by week and count rows per group (creates column 'n')\n  tidyr::complete(                  # ensure all weeks are present, even those with no cases reported\n    weekly_cases = seq.Date(          # re-define the \"weekly_cases\" column as a complete sequence,\n      from = min(weekly_cases),       # from the minimum date\n      to = max(weekly_cases),         # to the maxiumum date\n      by = \"week\"),                   # by weeks\n    fill = list(n = 0))             # fill-in NAs in the n counts column with 0\n\nHier sind die ersten Zeilen des resultierenden Datenrahmens:\n\n\n\n\n\n\n\n\nEpiweek Alternativen\nBeachte, dass lubridate auch Funktionen hat week(), epiweek(), und isoweek(), die jeweils leicht unterschiedliche Startdaten und andere Feinheiten haben. Generell gilt jedoch, floor_date() alles sein, was du brauchst. Lies die Details zu diesen Funktionen, indem du ?week in die Konsole eingibst oder die Dokumentation liest hier.\nDu könntest auch das Paket aweek um epidemiologische Wochen zu setzen. Du kannst mehr darüber lesen auf der RECON-Website. Es hat die Funktionen date2week() und week2date() in denen du den Wochenstarttag einstellen kannst mit week_start = \"Monday\". Dieses Paket ist am einfachsten, wenn du Ausgaben im “Wochen”-Stil möchtest (z.B. “2020-W12”). Ein weiterer Vorteil von aweek ist, dass wenn date2week() auf eine Datumsspalte angewendet wird, ist die zurückgegebene Spalte (Wochenformat) automatisch von der Klasse Factor und enthält die Werte für alle Wochen in der Zeitspanne (dies vermeidet den zusätzlichen Schritt der complete() wie oben beschrieben). Allerdings, aweek verfügt jedoch nicht über die Möglichkeit, Daten auf andere Zeiteinheiten wie Monate, Jahre usw. zu runden.\nEine andere Alternative für Zeitreihen, die auch gut funktioniert, um ein “Wochen”-Format (“2020 W12”) anzuzeigen, ist yearweek() aus dem Paket tsibble, wie auf der Seite über [Zeitreihen und Ausbruchserkennung].",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#umrechnung-von-datenzeitzonen",
    "href": "new_pages/dates.de.html#umrechnung-von-datenzeitzonen",
    "title": "9  Mit Daten arbeiten",
    "section": "9.10 Umrechnung von Daten/Zeitzonen",
    "text": "9.10 Umrechnung von Daten/Zeitzonen\nWenn Daten in verschiedenen Zeitzonen vorliegen, kann es oft wichtig sein, diese Daten in einer einheitlichen Zeitzone zu standardisieren. Dies kann eine weitere Herausforderung darstellen, da die Zeitzonen-Komponente der Daten in den meisten Fällen manuell kodiert werden muss.\nIn R wird jede datetime Objekt eine Zeitzonen-Komponente. Standardmäßig tragen alle datetime-Objekte die lokale Zeitzone des verwendeten Computers - dies ist in der Regel spezifisch für eine Standort als eine benannte Zeitzone, da sich die Zeitzonen aufgrund der Sommerzeit an verschiedenen Orten oft ändern. Es ist nicht möglich, Zeitzonen ohne eine Zeitkomponente eines Datums genau auszugleichen, da das Ereignis, das eine Datumsspalte darstellt, keiner bestimmten Zeit zugeordnet werden kann und daher Zeitverschiebungen, die in Stunden gemessen werden, nicht sinnvoll berücksichtigt werden können.\nUm mit Zeitzonen umzugehen, gibt es in lubridate eine Reihe von Hilfsfunktionen, mit denen die Zeitzone eines datetime-Objekts von der lokalen Zeitzone in eine andere Zeitzone geändert werden kann. Zeitzonen werden festgelegt, indem dem datetime-Objekt eine gültige Zeitzone der tz-Datenbank zugewiesen wird. Eine Liste davon findest du hier - wenn der Ort, dessen Daten du verwendest, nicht auf dieser Liste steht, sind nahegelegene Großstädte in der Zeitzone verfügbar und erfüllen denselben Zweck.\nhttps://en.wikipedia.org/wiki/List_of_tz_database_time_zones\n\n# assign the current time to a column\ntime_now &lt;- Sys.time()\ntime_now\n\n[1] \"2024-02-21 13:57:58 CET\"\n\n# use with_tz() to assign a new timezone to the column, while CHANGING the clock time\ntime_london_real &lt;- with_tz(time_now, \"Europe/London\")\n\n# use force_tz() to assign a new timezone to the column, while KEEPING the clock time\ntime_london_local &lt;- force_tz(time_now, \"Europe/London\")\n\n\n# note that as long as the computer that was used to run this code is NOT set to London time,\n# there will be a difference in the times \n# (the number of hours difference from the computers time zone to london)\ntime_london_real - time_london_local\n\nTime difference of -1 hours\n\n\nDies mag sehr abstrakt erscheinen und wird oft nicht benötigt, wenn der/die Nutzer/in nicht über Zeitzonen hinweg arbeitet.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#nachlaufende-und-vorlaufende-berechnungen",
    "href": "new_pages/dates.de.html#nachlaufende-und-vorlaufende-berechnungen",
    "title": "9  Mit Daten arbeiten",
    "section": "9.11 Nachlaufende und vorlaufende Berechnungen",
    "text": "9.11 Nachlaufende und vorlaufende Berechnungen\nlead() und lag() sind Funktionen aus der dplyr Paket, die helfen, frühere (verzögerte) oder nachfolgende (führende) Werte in einem Vektor zu finden - typischerweise ein numerischer oder Datumsvektor. Dies ist nützlich bei Berechnungen von Veränderungen/Differenzen zwischen Zeiteinheiten.\nNehmen wir an, du möchtest die Differenz der Fälle zwischen der aktuellen Woche und der vorherigen Woche berechnen. Die Daten werden zunächst in wöchentlichen Zählungen bereitgestellt, wie unten gezeigt.\n\n\n\n\n\n\nBei der Verwendung von lag() oder lead() ist die Reihenfolge der Zeilen im Datenrahmen sehr wichtig! - achte darauf, ob deine Daten/Zahlen aufsteigend oder absteigend sind\nErstelle zunächst eine neue Spalte, die den Wert der vorherigen (verzögerten) Woche enthält.\n\nKontrolliere die Anzahl der Einheiten zurück/vorwärts mit n = (muss eine nicht-negative ganze Zahl sein)\nverwenden default = um den Wert festzulegen, der in nicht existierende Zeilen gesetzt wird (z. B. die erste Zeile, für die es keinen verzögerten Wert gibt). Standardmäßig ist dies NA.\nverwenden order_by = TRUE wenn deine Zeilen nicht nach deiner Referenzspalte geordnet sind\n\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\n\n\n\n\n\n\n\nAls nächstes erstellst du eine neue Spalte, die die Differenz zwischen den beiden Fallspalten darstellt:\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)\n\n\n\n\n\n\n\nDu kannst mehr darüber lesen lead() und lag() in der Dokumentation hier oder durch Eingabe von ?lag in deine Konsole eingibst.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.de.html#ressourcen",
    "href": "new_pages/dates.de.html#ressourcen",
    "title": "9  Mit Daten arbeiten",
    "section": "9.12 Ressourcen",
    "text": "9.12 Ressourcen\nlubridate aufgeräumte Seite\nlubridate RStudio Spickzettel\nR für Data Science Seite auf Daten und Zeiten\nOnline-Tutorial Datumsformate",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mit Daten arbeiten</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html",
    "href": "new_pages/characters_strings.de.html",
    "title": "10  Characters and strings",
    "section": "",
    "text": "10.1 Preparation",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#preparation",
    "href": "new_pages/characters_strings.de.html#preparation",
    "title": "10  Characters and strings",
    "section": "",
    "text": "Load packages\nInstall or load the stringr and other tidyverse packages.\n\n# install/load packages\npacman::p_load(\n  stringr,    # many functions for handling strings\n  tidyverse,  # for optional data manipulation\n  tools)      # alternative for converting to title case\n\n\n\nImport data\nIn this page we will occassionally reference the cleaned linelist of cases from a simulated Ebola epidemic. If you want to follow along, click to download the “clean” linelist (as .rds file). Import data with the import() function from the rio package (it handles many file types like .xlsx, .csv, .rds - see the [Import and export] page for details).\n\n# import case linelist \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nThe first 50 rows of the linelist are displayed below.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#unite-split-and-arrange",
    "href": "new_pages/characters_strings.de.html#unite-split-and-arrange",
    "title": "10  Characters and strings",
    "section": "10.2 Unite, split, and arrange",
    "text": "10.2 Unite, split, and arrange\nThis section covers:\n\nUsing str_c(), str_glue(), and unite() to combine strings\n\nUsing str_order() to arrange strings\n\nUsing str_split() and separate() to split strings\n\n\n\nCombine strings\nTo combine or concatenate multiple strings into one string, we suggest using str_c from stringr. If you have distinct character values to combine, simply provide them as unique arguments, separated by commas.\n\nstr_c(\"String1\", \"String2\", \"String3\")\n\n[1] \"String1String2String3\"\n\n\nThe argument sep = inserts a character value between each of the arguments you provided (e.g. inserting a comma, space, or newline \"\\n\")\n\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")\n\n[1] \"String1, String2, String3\"\n\n\nThe argument collapse = is relevant if you are inputting multiple vectors as arguments to str_c(). It is used to separate the elements of what would be an output vector, such that the output vector only has one long character element.\nThe example below shows the combination of two vectors into one (first names and last names). Another similar example might be jurisdictions and their case counts. In this example:\n\nThe sep = value appears between each first and last name\n\nThe collapse = value appears between each person\n\n\nfirst_names &lt;- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  &lt;- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep displays between the respective input strings, while collapse displays between the elements produced\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")\n\n[1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n\n\nNote: Depending on your desired display context, when printing such a combined string with newlines, you may need to wrap the whole phrase in cat() for the newlines to print properly:\n\n# For newlines to print correctly, the phrase may need to be wrapped in cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))\n\nabdul hussein;\nfahruk akinleye;\njanice okeke\n\n\n\n\n\nDynamic strings\nUse str_glue() to insert dynamic R code into a string. This is a very useful function for creating dynamic plot captions, as demonstrated below.\n\nAll content goes between double quotation marks str_glue(\"\")\n\nAny dynamic code or references to pre-defined values are placed within curly brackets {} within the double quotation marks. There can be many curly brackets in the same str_glue() command.\n\nTo display character quotes ’’, use single quotes within the surrounding double quotes (e.g. when providing date format - see example below)\n\nTip: You can use \\n to force a new line\n\nTip: You use format() to adjust date display, and use Sys.Date() to display the current date\n\nA simple example, of a dynamic plot caption:\n\nstr_glue(\"Data include {nrow(linelist)} cases and are current to {format(Sys.Date(), '%d %b %Y')}.\")\n\nData include 5888 cases and are current to 21 Feb 2024.\n\n\nAn alternative format is to use placeholders within the brackets and define the code in separate arguments at the end of the str_glue() function, as below. This can improve code readability if the text is long.\n\nstr_glue(\"Linelist as of {current_date}.\\nLast case hospitalized on {last_hospital}.\\n{n_missing_onset} cases are missing date of onset and not shown\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %&gt;% filter(is.na(date_onset)))\n         )\n\nLinelist as of 21 Feb 2024.\nLast case hospitalized on 30 Apr 2015.\n256 cases are missing date of onset and not shown\n\n\nPulling from a data frame\nSometimes, it is useful to pull data from a data frame and have it pasted together in sequence. Below is an example data frame. We will use it to to make a summary statement about the jurisdictions and the new and total case counts.\n\n# make case data frame\ncase_table &lt;- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\n\n\n\n\n\n\n\nUse str_glue_data(), which is specially made for taking data from data frame rows:\n\ncase_table %&gt;% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")\n\nZone 1: 3 (40 total cases)\nZone 2: 0 (4 total cases)\nZone 3: 7 (25 total cases)\nZone 4: 0 (10 total cases)\nZone 5: 15 (103 total cases)\n\n\nCombine strings across rows\nIf you are trying to “roll-up” values in a data frame column, e.g. combine values from multiple rows into just one row by pasting them together with a separator, see the section of the [De-duplication] page on “rolling-up” values.\nData frame to one line\nYou can make the statement appear in one line using str_c() (specifying the data frame and column names), and providing sep = and collapse = arguments.\n\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")\n\n[1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\nYou could add the pre-fix text “New Cases:” to the beginning of the statement by wrapping with a separate str_c() (if “New Cases:” was within the original str_c() it would appear multiple times).\n\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))\n\n[1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\n\n\nUnite columns\nWithin a data frame, bringing together character values from multiple columns can be achieved with unite() from tidyr. This is the opposite of separate().\nProvide the name of the new united column. Then provide the names of the columns you wish to unite.\n\nBy default, the separator used in the united column is underscore _, but this can be changed with the sep = argument.\n\nremove = removes the input columns from the data frame (TRUE by default)\n\nna.rm = removes missing values while uniting (FALSE by default)\n\nBelow, we define a mini-data frame to demonstrate with:\n\ndf &lt;- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # patient 1\n                \"chills, aches, pains\",        # patient 2 \n                \"fever\",                       # patient 3\n                \"vomiting, diarrhoea\",         # patient 4\n                \"bleeding from gums, fever\",   # patient 5\n                \"rapid pulse, headache\"),      # patient 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\n\n\ndf_split &lt;- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")\n\nWarning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\n\n\nHere is the example data frame:\n\n\n\n\n\n\nBelow, we unite the three symptom columns:\n\ndf_split %&gt;% \n  unite(\n    col = \"all_symptoms\",         # name of the new united column\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # columns to unite\n    sep = \", \",                   # separator to use in united column\n    remove = TRUE,                # if TRUE, removes input cols from the data frame\n    na.rm = TRUE                  # if TRUE, missing values are removed before uniting\n  )\n\n  case_ID                all_symptoms outcome\n1       1     jaundice, fever, chills Recover\n2       2        chills, aches, pains   Death\n3       3                       fever   Death\n4       4         vomiting, diarrhoea Recover\n5       5 bleeding, from, gums, fever Recover\n6       6      rapid, pulse, headache Recover\n\n\n\n\n\nSplit\nTo split a string based on a pattern, use str_split(). It evaluates the string(s) and returns a list of character vectors consisting of the newly-split values.\nThe simple example below evaluates one string and splits it into three. By default it returns an object of class list with one element (a character vector) for each string initially provided. If simplify = TRUE it returns a character matrix.\nIn this example, one string is provided, and the function returns a list with one element - a character vector with three values.\n\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n\nIf the output is saved, you can then access the nth split value with bracket syntax. To access a specific value you can use syntax like this: the_returned_object[[1]][2], which would access the second value from the first evaluated string (“fever”). See the [R basics] page for more detail on accessing elements.\n\npt1_symptoms &lt;- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extracts 2nd value from 1st (and only) element of the list\n\n[1] \" fever\"\n\n\nIf multiple strings are provided by str_split(), there will be more than one element in the returned list.\n\nsymptoms &lt;- c(\"jaundice, fever, chills\",     # patient 1\n              \"chills, aches, pains\",        # patient 2 \n              \"fever\",                       # patient 3\n              \"vomiting, diarrhoea\",         # patient 4\n              \"bleeding from gums, fever\",   # patient 5\n              \"rapid pulse, headache\")       # patient 6\n\nstr_split(symptoms, \",\")                     # split each patient's symptoms\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n[[2]]\n[1] \"chills\" \" aches\" \" pains\"\n\n[[3]]\n[1] \"fever\"\n\n[[4]]\n[1] \"vomiting\"   \" diarrhoea\"\n\n[[5]]\n[1] \"bleeding from gums\" \" fever\"            \n\n[[6]]\n[1] \"rapid pulse\" \" headache\"  \n\n\nTo return a “character matrix” instead, which may be useful if creating data frame columns, set the argument simplify = TRUE as shown below:\n\nstr_split(symptoms, \",\", simplify = TRUE)\n\n     [,1]                 [,2]         [,3]     \n[1,] \"jaundice\"           \" fever\"     \" chills\"\n[2,] \"chills\"             \" aches\"     \" pains\" \n[3,] \"fever\"              \"\"           \"\"       \n[4,] \"vomiting\"           \" diarrhoea\" \"\"       \n[5,] \"bleeding from gums\" \" fever\"     \"\"       \n[6,] \"rapid pulse\"        \" headache\"  \"\"       \n\n\nYou can also adjust the number of splits to create with the n = argument. For example, this restricts the number of splits to 2. Any further commas remain within the second values.\n\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)\n\n     [,1]                 [,2]            \n[1,] \"jaundice\"           \" fever, chills\"\n[2,] \"chills\"             \" aches, pains\" \n[3,] \"fever\"              \"\"              \n[4,] \"vomiting\"           \" diarrhoea\"    \n[5,] \"bleeding from gums\" \" fever\"        \n[6,] \"rapid pulse\"        \" headache\"     \n\n\nNote - the same outputs can be achieved with str_split_fixed(), in which you do not give the simplify argument, but must instead designate the number of columns (n).\n\nstr_split_fixed(symptoms, \",\", n = 2)\n\n\n\nSplit columns\nIf you are trying to split data frame column, it is best to use the separate() function from dplyr. It is used to split one character column into other columns.\nLet’s say we have a simple data frame df (defined and united in the unite section) containing a case_ID column, one character column with many symptoms, and one outcome column. Our goal is to separate the symptoms column into many columns - each one containing one symptom.\n\n\n\n\n\n\nAssuming the data are piped into separate(), first provide the column to be separated. Then provide into = as a vector c( ) containing the new columns names, as shown below.\n\nsep = the separator, can be a character, or a number (interpreted as the character position to split at)\nremove = FALSE by default, removes the input column\n\nconvert = FALSE by default, will cause string “NA”s to become NA\n\nextra = this controls what happens if there are more values created by the separation than new columns named.\n\nextra = \"warn\" means you will see a warning but it will drop excess values (the default)\n\nextra = \"drop\" means the excess values will be dropped with no warning\n\nextra = \"merge\" will only split to the number of new columns listed in into - this setting will preserve all your data\n\n\nAn example with extra = \"merge\" is below - no data is lost. Two new columns are defined but any third symptoms are left in the second new column:\n\n# third symptoms combined into second new column\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1          sym_2 outcome\n1       1           jaundice  fever, chills Recover\n2       2             chills   aches, pains   Death\n3       3              fever           &lt;NA&gt;   Death\n4       4           vomiting      diarrhoea Recover\n5       5 bleeding from gums          fever Recover\n6       6        rapid pulse       headache Recover\n\n\nWhen the default extra = \"drop\" is used below, a warning is given but the third symptoms are lost:\n\n# third symptoms are lost\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")\n\nWarning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].\n\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1      sym_2 outcome\n1       1           jaundice      fever Recover\n2       2             chills      aches   Death\n3       3              fever       &lt;NA&gt;   Death\n4       4           vomiting  diarrhoea Recover\n5       5 bleeding from gums      fever Recover\n6       6        rapid pulse   headache Recover\n\n\nCAUTION: If you do not provide enough into values for the new columns, your data may be truncated.\n\n\n\nArrange alphabetically\nSeveral strings can be sorted by alphabetical order. str_order() returns the order, while str_sort() returns the strings in that order.\n\n# strings\nhealth_zones &lt;- c(\"Alba\", \"Takota\", \"Delta\")\n\n# return the alphabetical order\nstr_order(health_zones)\n\n[1] 1 3 2\n\n# return the strings in alphabetical order\nstr_sort(health_zones)\n\n[1] \"Alba\"   \"Delta\"  \"Takota\"\n\n\nTo use a different alphabet, add the argument locale =. See the full list of locales by entering stringi::stri_locale_list() in the R console.\n\n\n\nbase R functions\nIt is common to see base R functions paste() and paste0(), which concatenate vectors after converting all parts to character. They act similarly to str_c() but the syntax is arguably more complicated - in the parentheses each part is separated by a comma. The parts are either character text (in quotes) or pre-defined code objects (no quotes). For example:\n\nn_beds &lt;- 10\nn_masks &lt;- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")\n\n[1] \"Regional hospital needs 10 beds and 20 masks.\"\n\n\nsep = and collapse = arguments can be specified. paste() is simply paste0() with a default sep = \" \" (one space).",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#clean-and-standardise",
    "href": "new_pages/characters_strings.de.html#clean-and-standardise",
    "title": "10  Characters and strings",
    "section": "10.3 Clean and standardise",
    "text": "10.3 Clean and standardise\n\n\nChange case\nOften one must alter the case/capitalization of a string value, for example names of jursidictions. Use str_to_upper(), str_to_lower(), and str_to_title(), from stringr, as shown below:\n\nstr_to_upper(\"California\")\n\n[1] \"CALIFORNIA\"\n\nstr_to_lower(\"California\")\n\n[1] \"california\"\n\n\nUsing *base** R, the above can also be achieved with toupper(), tolower().\nTitle case\nTransforming the string so each word is capitalized can be achieved with str_to_title():\n\nstr_to_title(\"go to the US state of california \")\n\n[1] \"Go To The Us State Of California \"\n\n\nUse toTitleCase() from the tools package to achieve more nuanced capitalization (words like “to”, “the”, and “of” are not capitalized).\n\ntools::toTitleCase(\"This is the US state of california\")\n\n[1] \"This is the US State of California\"\n\n\nYou can also use str_to_sentence(), which capitalizes only the first letter of the string.\n\nstr_to_sentence(\"the patient must be transported\")\n\n[1] \"The patient must be transported\"\n\n\n\n\nPad length\nUse str_pad() to add characters to a string, to a minimum length. By default spaces are added, but you can also pad with other characters using the pad = argument.\n\n# ICD codes of differing length\nICD_codes &lt;- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# ICD codes padded to 7 characters on the right side\nstr_pad(ICD_codes, 7, \"right\")\n\n[1] \"R10.13 \" \"R10.819\" \"R17    \"\n\n# Pad with periods instead of spaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")\n\n[1] \"R10.13.\" \"R10.819\" \"R17....\"\n\n\nFor example, to pad numbers with leading zeros (such as for hours or minutes), you can pad the number to minimum length of 2 with pad = \"0\".\n\n# Add leading zeros to two digits (e.g. for times minutes/hours)\nstr_pad(\"4\", 2, pad = \"0\") \n\n[1] \"04\"\n\n# example using a numeric column named \"hours\"\n# hours &lt;- str_pad(hours, 2, pad = \"0\")\n\n\n\nTruncate\nstr_trunc() sets a maximum length for each string. If a string exceeds this length, it is truncated (shortened) and an ellipsis (…) is included to indicate that the string was previously longer. Note that the ellipsis is counted in the length. The ellipsis characters can be changed with the argument ellipsis =. The optional side = argument specifies which where the ellipsis will appear within the truncated string (“left”, “right”, or “center”).\n\noriginal &lt;- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")\n\n[1] \"Symp...ing\"\n\n\n\n\nStandardize length\nUse str_trunc() to set a maximum length, and then use str_pad() to expand the very short strings to that truncated length. In the example below, 6 is set as the maximum length (one value is truncated), and then one very short value is padded to achieve length of 6.\n\n# ICD codes of differing length\nICD_codes   &lt;- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# truncate to maximum length of 6\nICD_codes_2 &lt;- str_trunc(ICD_codes, 6)\nICD_codes_2\n\n[1] \"R10.13\" \"R10...\" \"R17\"   \n\n# expand to minimum length of 6\nICD_codes_3 &lt;- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3\n\n[1] \"R10.13\" \"R10...\" \"R17   \"\n\n\n\n\nRemove leading/trailing whitespace\nUse str_trim() to remove spaces, newlines (\\n) or tabs (\\t) on sides of a string input. Add \"right\" \"left\", or \"both\" to the command to specify which side to trim (e.g. str_trim(x, \"right\").\n\n# ID numbers with excess spaces on right\nIDs &lt;- c(\"provA_1852  \", # two excess spaces\n         \"provA_2345\",   # zero excess spaces\n         \"provA_9460 \")  # one excess space\n\n# IDs trimmed to remove excess spaces on right side only\nstr_trim(IDs)\n\n[1] \"provA_1852\" \"provA_2345\" \"provA_9460\"\n\n\n\n\nRemove repeated whitespace within\nUse str_squish() to remove repeated spaces that appear inside a string. For example, to convert double spaces into single spaces. It also removes spaces, newlines, or tabs on the outside of the string like str_trim().\n\n# original contains excess spaces within string\nstr_squish(\"  Pt requires   IV saline\\n\") \n\n[1] \"Pt requires IV saline\"\n\n\nEnter ?str_trim, ?str_pad in your R console to see further details.\n\n\nWrap into paragraphs\nUse str_wrap() to wrap a long unstructured text into a structured paragraph with fixed line length. Provide the ideal character length for each line, and it applies an algorithm to insert newlines (\\n) within the paragraph, as seen in the example below.\n\npt_course &lt;- \"Symptom onset 1/4/2020 vomiting chills fever. Pt saw traditional healer in home village on 2/4/2020. On 5/4/2020 pt symptoms worsened and was admitted to Lumta clinic. Sample was taken and pt was transported to regional hospital on 6/4/2020. Pt died at regional hospital on 7/4/2020.\"\n\nstr_wrap(pt_course, 40)\n\n[1] \"Symptom onset 1/4/2020 vomiting chills\\nfever. Pt saw traditional healer in\\nhome village on 2/4/2020. On 5/4/2020\\npt symptoms worsened and was admitted\\nto Lumta clinic. Sample was taken and pt\\nwas transported to regional hospital on\\n6/4/2020. Pt died at regional hospital\\non 7/4/2020.\"\n\n\nThe base function cat() can be wrapped around the above command in order to print the output, displaying the new lines added.\n\ncat(str_wrap(pt_course, 40))\n\nSymptom onset 1/4/2020 vomiting chills\nfever. Pt saw traditional healer in\nhome village on 2/4/2020. On 5/4/2020\npt symptoms worsened and was admitted\nto Lumta clinic. Sample was taken and pt\nwas transported to regional hospital on\n6/4/2020. Pt died at regional hospital\non 7/4/2020.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#handle-by-position",
    "href": "new_pages/characters_strings.de.html#handle-by-position",
    "title": "10  Characters and strings",
    "section": "10.4 Handle by position",
    "text": "10.4 Handle by position\n\nExtract by character position\nUse str_sub() to return only a part of a string. The function takes three main arguments:\n\nthe character vector(s)\n\nstart position\n\nend position\n\nA few notes on position numbers:\n\nIf a position number is positive, the position is counted starting from the left end of the string.\n\nIf a position number is negative, it is counted starting from the right end of the string.\n\nPosition numbers are inclusive.\n\nPositions extending beyond the string will be truncated (removed).\n\nBelow are some examples applied to the string “pneumonia”:\n\n# start and end third from left (3rd letter from left)\nstr_sub(\"pneumonia\", 3, 3)\n\n[1] \"e\"\n\n# 0 is not present\nstr_sub(\"pneumonia\", 0, 0)\n\n[1] \"\"\n\n# 6th from left, to the 1st from right\nstr_sub(\"pneumonia\", 6, -1)\n\n[1] \"onia\"\n\n# 5th from right, to the 2nd from right\nstr_sub(\"pneumonia\", -5, -2)\n\n[1] \"moni\"\n\n# 4th from left to a position outside the string\nstr_sub(\"pneumonia\", 4, 15)\n\n[1] \"umonia\"\n\n\n\n\nExtract by word position\nTo extract the nth ‘word’, use word(), also from stringr. Provide the string(s), then the first word position to extract, and the last word position to extract.\nBy default, the separator between ‘words’ is assumed to be a space, unless otherwise indicated with sep = (e.g. sep = \"_\" when words are separated by underscores.\n\n# strings to evaluate\nchief_complaints &lt;- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extract 1st to 3rd words of each string\nword(chief_complaints, start = 1, end = 3, sep = \" \")\n\n[1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\" \n\n\n\n\nReplace by character position\nstr_sub() paired with the assignment operator (&lt;-) can be used to modify a part of a string:\n\nword &lt;- \"pneumonia\"\n\n# convert the third and fourth characters to X \nstr_sub(word, 3, 4) &lt;- \"XX\"\n\n# print\nword\n\n[1] \"pnXXmonia\"\n\n\nAn example applied to multiple strings (e.g. a column). Note the expansion in length of “HIV”.\n\nwords &lt;- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convert the third and fourth characters to X \nstr_sub(words, 3, 4) &lt;- \"XX\"\n\nwords\n\n[1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\"        \n\n\n\n\nEvaluate length\n\nstr_length(\"abc\")\n\n[1] 3\n\n\nAlternatively, use nchar() from base R",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#patterns",
    "href": "new_pages/characters_strings.de.html#patterns",
    "title": "10  Characters and strings",
    "section": "10.5 Patterns",
    "text": "10.5 Patterns\nMany stringr functions work to detect, locate, extract, match, replace, and split based on a specified pattern.\n\n\nDetect a pattern\nUse str_detect() as below to detect presence/absence of a pattern within a string. First provide the string or vector to search in (string =), and then the pattern to look for (pattern =). Note that by default the search is case sensitive!\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")\n\n[1] TRUE\n\n\nThe argument negate = can be included and set to TRUE if you want to know if the pattern is NOT present.\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)\n\n[1] FALSE\n\n\nTo ignore case/capitalization, wrap the pattern within regex(), and within regex() add the argument ignore_case = TRUE (or T as shorthand).\n\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))\n\n[1] TRUE\n\n\nWhen str_detect() is applied to a character vector or a data frame column, it will return TRUE or FALSE for each of the values.\n\n# a vector/column of occupations \noccupations &lt;- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# Detect presence of pattern \"teach\" in each string - output is vector of TRUE/FALSE\nstr_detect(occupations, \"teach\")\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nIf you need to count the TRUEs, simply sum() the output. This counts the number TRUE.\n\nsum(str_detect(occupations, \"teach\"))\n\n[1] 1\n\n\nTo search inclusive of multiple terms, include them separated by OR bars (|) within the pattern = argument, as shown below:\n\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))\n\n[1] 3\n\n\nIf you need to build a long list of search terms, you can combine them using str_c() and sep = |, then define this is a character object, and then reference the vector later more succinctly. The example below includes possible occupation search terms for front-line medical providers.\n\n# search terms\noccupation_med_frontline &lt;- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline\n\n[1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\n\n\nThis command returns the number of occupations which contain any one of the search terms for front-line medical providers (occupation_med_frontline):\n\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))\n\n[1] 2\n\n\nBase R string search functions\nThe base function grepl() works similarly to str_detect(), in that it searches for matches to a pattern and returns a logical vector. The basic syntax is grepl(pattern, strings_to_search, ignore.case = FALSE, ...). One advantage is that the ignore.case argument is easier to write (there is no need to involve the regex() function).\nLikewise, the base functions sub() and gsub() act similarly to str_replace(). Their basic syntax is: gsub(pattern, replacement, strings_to_search, ignore.case = FALSE). sub() will replace the first instance of the pattern, whereas gsub() will replace all instances of the pattern.\n\nConvert commas to periods\nHere is an example of using gsub() to convert commas to periods in a vector of numbers. This could be useful if your data come from parts of the world other than the United States or Great Britain.\nThe inner gsub() which acts first on lengths is converting any periods to no space ““. The period character”.” has to be “escaped” with two slashes to actually signify a period, because “.” in regex means “any character”. Then, the result (with only commas) is passed to the outer gsub() in which commas are replaced by periods.\n\nlengths &lt;- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # find commas     \n                replacement = \".\",            # replace with periods\n                x = gsub(\"\\\\.\", \"\", lengths)  # vector with other periods removed (periods escaped)\n                )\n           )                                  # convert outcome to numeric\n\n\n\n\nReplace all\nUse str_replace_all() as a “find and replace” tool. First, provide the strings to be evaluated to string =, then the pattern to be replaced to pattern =, and then the replacement value to replacement =. The example below replaces all instances of “dead” with “deceased”. Note, this IS case sensitive.\n\noutcome &lt;- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")\n\n[1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\"\n\n\nNotes:\n\nTo replace a pattern with NA, use str_replace_na().\n\nThe function str_replace() replaces only the first instance of the pattern within each evaluated string.\n\n\n\n\nDetect within logic\nWithin case_when()\nstr_detect() is often used within case_when() (from dplyr). Let’s say occupations is a column in the linelist. The mutate() below creates a new column called is_educator by using conditional logic via case_when(). See the page on data cleaning to learn more about case_when().\n\ndf &lt;- df %&gt;% \n  mutate(is_educator = case_when(\n    # term search within occupation, not case sensitive\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # all others\n    TRUE                                               ~ \"Not an educator\"))\n\nAs a reminder, it may be important to add exclusion criteria to the conditional logic (negate = F):\n\ndf &lt;- df %&gt;% \n  # value in new column is_educator is based on conditional logic\n  mutate(is_educator = case_when(\n    \n    # occupation column must meet 2 criteria to be assigned \"Educator\":\n    # it must have a search term AND NOT any exclusion term\n    \n    # Must have a search term\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \n    \n    # AND must NOT have an exclusion term\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # All rows not meeting above criteria\n    TRUE                                            ~ \"Not an educator\"))\n\n\n\n\nLocate pattern position\nTo locate the first position of a pattern, use str_locate(). It outputs a start and end position.\n\nstr_locate(\"I wish\", \"sh\")\n\n     start end\n[1,]     5   6\n\n\nLike other str functions, there is an “_all” version (str_locate_all()) which will return the positions of all instances of the pattern within each string. This outputs as a list.\n\nphrases &lt;- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" )     # position of *first* instance of the pattern\n\n     start end\n[1,]     6   6\n[2,]     3   3\n[3,]     1   1\n[4,]     4   4\n\nstr_locate_all(phrases, \"h\" ) # position of *every* instance of the pattern\n\n[[1]]\n     start end\n[1,]     6   6\n\n[[2]]\n     start end\n[1,]     3   3\n\n[[3]]\n     start end\n[1,]     1   1\n[2,]     4   4\n\n[[4]]\n     start end\n[1,]     4   4\n\n\n\n\n\nExtract a match\nstr_extract_all() returns the matching patterns themselves, which is most useful when you have offered several patterns via “OR” conditions. For example, looking in the string vector of occupations (see previous tab) for either “teach”, “prof”, or “tutor”.\nstr_extract_all() returns a list which contains all matches for each evaluated string. See below how occupation 3 has two pattern matches within it.\n\nstr_extract_all(occupations, \"teach|prof|tutor\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\n[1] \"prof\"\n\n[[3]]\n[1] \"teach\" \"tutor\"\n\n[[4]]\n[1] \"tutor\"\n\n[[5]]\ncharacter(0)\n\n[[6]]\ncharacter(0)\n\n[[7]]\ncharacter(0)\n\n[[8]]\ncharacter(0)\n\n[[9]]\ncharacter(0)\n\n[[10]]\ncharacter(0)\n\n\nstr_extract() extracts only the first match in each evaluated string, producing a character vector with one element for each evaluated string. It returns NA where there was no match. The NAs can be removed by wrapping the returned vector with na.exclude(). Note how the second of occupation 3’s matches is not shown.\n\nstr_extract(occupations, \"teach|prof|tutor\")\n\n [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA     \n[10] NA     \n\n\n\n\n\nSubset and count\nAligned functions include str_subset() and str_count().\nstr_subset() returns the actual values which contained the pattern:\n\nstr_subset(occupations, \"teach|prof|tutor\")\n\n[1] \"university professor\"           \"primary school teacher & tutor\"\n[3] \"tutor\"                         \n\n\nstr_count() returns a vector of numbers: the number of times a search term appears in each evaluated value.\n\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))\n\n [1] 0 1 2 1 0 0 0 0 0 0\n\n\n\n\n\nRegex groups\nUNDER CONSTRUCTION",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#special-characters",
    "href": "new_pages/characters_strings.de.html#special-characters",
    "title": "10  Characters and strings",
    "section": "10.6 Special characters",
    "text": "10.6 Special characters\nBackslash \\ as escape\nThe backslash \\ is used to “escape” the meaning of the next character. This way, a backslash can be used to have a quote mark display within other quote marks (\\\") - the middle quote mark will not “break” the surrounding quote marks.\nNote - thus, if you want to display a backslash, you must escape it’s meaning with another backslash. So you must write two backslashes \\\\ to display one.\nSpecial characters\n\n\n\n\n\n\n\nSpecial character\nRepresents\n\n\n\n\n\"\\\\\"\nbackslash\n\n\n\"\\n\"\na new line (newline)\n\n\n\"\\\"\"\ndouble-quote within double quotes\n\n\n'\\''\nsingle-quote within single quotes\n\n\n\"\\“| grave accent”| carriage return“| tab”| vertical tab“`\nbackspace\n\n\n\nRun ?\"'\" in the R Console to display a complete list of these special characters (it will appear in the RStudio Help pane).",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#regular-expressions-regex",
    "href": "new_pages/characters_strings.de.html#regular-expressions-regex",
    "title": "10  Characters and strings",
    "section": "10.7 Regular expressions (regex)",
    "text": "10.7 Regular expressions (regex)",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#regex-and-special-characters",
    "href": "new_pages/characters_strings.de.html#regex-and-special-characters",
    "title": "10  Characters and strings",
    "section": "10.8 Regex and special characters",
    "text": "10.8 Regex and special characters\nRegular expressions, or “regex”, is a concise language for describing patterns in strings. If you are not familiar with it, a regular expression can look like an alien language. Here we try to de-mystify this language a little bit.\nMuch of this section is adapted from this tutorial and this cheatsheet. We selectively adapt here knowing that this handbook might be viewed by people without internet access to view the other tutorials.\nA regular expression is often applied to extract specific patterns from “unstructured” text - for example medical notes, chief complaints, patient history, or other free text columns in a data frame\nThere are four basic tools one can use to create a basic regular expression:\n\nCharacter sets\n\nMeta characters\n\nQuantifiers\n\nGroups\n\nCharacter sets\nCharacter sets, are a way of expressing listing options for a character match, within brackets. So any a match will be triggered if any of the characters within the brackets are found in the string. For example, to look for vowels one could use this character set: “[aeiou]”. Some other common character sets are:\n\n\n\n\n\n\n\nCharacter set\nMatches for\n\n\n\n\n\"[A-Z]\"\nany single capital letter\n\n\n\"[a-z]\"\nany single lowercase letter\n\n\n\"[0-9]\"\nany digit\n\n\n[:alnum:]\nany alphanumeric character\n\n\n[:digit:]\nany numeric digit\n\n\n[:alpha:]\nany letter (upper or lowercase)\n\n\n[:upper:]\nany uppercase letter\n\n\n[:lower:]\nany lowercase letter\n\n\n\nCharacter sets can be combined within one bracket (no spaces!), such as \"[A-Za-z]\" (any upper or lowercase letter), or another example \"[t-z0-5]\" (lowercase t through z OR number 0 through 5).\nMeta characters\nMeta characters are shorthand for character sets. Some of the important ones are listed below:\n\n\n\n\n\n\n\nMeta character\nRepresents\n\n\n\n\n\"\\\\s\"\na single space\n\n\n\"\\\\w\"\nany single alphanumeric character (A-Z, a-z, or 0-9)\n\n\n\"\\\\d\"\nany single numeric digit (0-9)\n\n\n\nQuantifiers\nTypically you do not want to search for a match on only one character. Quantifiers allow you to designate the length of letters/numbers to allow for the match.\nQuantifiers are numbers written within curly brackets `` after the character they are quantifying, for example,\n\n\"A{2}\" will return instances of two capital A letters.\n\n\"A{2,4}\" will return instances of between two and four capital A letters (do not put spaces!).\n\n\"A{2,}\" will return instances of two or more capital A letters.\n\n\"A+\" will return instances of one or more capital A letters (group extended until a different character is encountered).\n\nPrecede with an * asterisk to return zero or more matches (useful if you are not sure the pattern is present)\n\nUsing the + plus symbol as a quantifier, the match will occur until a different character is encountered. For example, this expression will return all words (alpha characters: \"[A-Za-z]+\"\n\n# test string for quantifiers\ntest &lt;- \"A-AA-AAA-AAAA\"\n\nWhen a quantifier of {2} is used, only pairs of consecutive A’s are returned. Two pairs are identified within AAAA.\n\nstr_extract_all(test, \"A{2}\")\n\n[[1]]\n[1] \"AA\" \"AA\" \"AA\" \"AA\"\n\n\nWhen a quantifier of {2,4} is used, groups of consecutive A’s that are two to four in length are returned.\n\nstr_extract_all(test, \"A{2,4}\")\n\n[[1]]\n[1] \"AA\"   \"AAA\"  \"AAAA\"\n\n\nWith the quantifier +, groups of one or more are returned:\n\nstr_extract_all(test, \"A+\")\n\n[[1]]\n[1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\n\n\nRelative position\nThese express requirements for what precedes or follows a pattern. For example, to extract sentences, “two numbers that are followed by a period” (\"\"). (?&lt;=\\.)\\s(?=[A-Z])\n\nstr_extract_all(test, \"\")\n\n[[1]]\n [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\n\n\n\n\n\n\n\n\n\nPosition statement\nMatches to\n\n\n\n\n\"(?&lt;=b)a\"\n“a” that is preceded by a “b”\n\n\n\"(?&lt;!b)a\"\n“a” that is NOT preceded by a “b”\n\n\n\"a(?=b)\"\n“a” that is followed by a “b”\n\n\n\"a(?!b)\"\n“a” that is NOT followed by a “b”\n\n\n\nGroups\nCapturing groups in your regular expression is a way to have a more organized output upon extraction.\nRegex examples\nBelow is a free text for the examples. We will try to extract useful information from it using a regular expression search term.\n\npt_note &lt;- \"Patient arrived at Broward Hospital emergency ward at 18:00 on 6/12/2005. Patient presented with radiating abdominal pain from LR quadrant. Patient skin was pale, cool, and clammy. Patient temperature was 99.8 degrees farinheit. Patient pulse rate was 100 bpm and thready. Respiratory rate was 29 per minute.\"\n\nThis expression matches to all words (any character until hitting non-character such as a space):\n\nstr_extract_all(pt_note, \"[A-Za-z]+\")\n\n[[1]]\n [1] \"Patient\"     \"arrived\"     \"at\"          \"Broward\"     \"Hospital\"   \n [6] \"emergency\"   \"ward\"        \"at\"          \"on\"          \"Patient\"    \n[11] \"presented\"   \"with\"        \"radiating\"   \"abdominal\"   \"pain\"       \n[16] \"from\"        \"LR\"          \"quadrant\"    \"Patient\"     \"skin\"       \n[21] \"was\"         \"pale\"        \"cool\"        \"and\"         \"clammy\"     \n[26] \"Patient\"     \"temperature\" \"was\"         \"degrees\"     \"farinheit\"  \n[31] \"Patient\"     \"pulse\"       \"rate\"        \"was\"         \"bpm\"        \n[36] \"and\"         \"thready\"     \"Respiratory\" \"rate\"        \"was\"        \n[41] \"per\"         \"minute\"     \n\n\nThe expression \"[0-9]{1,2}\" matches to consecutive numbers that are 1 or 2 digits in length. It could also be written \"\\\\d{1,2}\", or \"[:digit:]{1,2}\".\n\nstr_extract_all(pt_note, \"[0-9]{1,2}\")\n\n[[1]]\n [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\"\n\n\n\n\n\n\nYou can view a useful list of regex expressions and tips on page 2 of this cheatsheet\nAlso see this tutorial.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.de.html#resources",
    "href": "new_pages/characters_strings.de.html#resources",
    "title": "10  Characters and strings",
    "section": "10.9 Resources",
    "text": "10.9 Resources\nA reference sheet for stringr functions can be found here\nA vignette on stringr can be found here",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Characters and strings</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html",
    "href": "new_pages/factors.de.html",
    "title": "11  Faktoren",
    "section": "",
    "text": "11.1 Vorbereitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#vorbereitung",
    "href": "new_pages/factors.de.html#vorbereitung",
    "title": "11  Faktoren",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,           # import/export\n  here,          # filepaths\n  lubridate,     # working with dates\n  forcats,       # factors\n  aweek,         # create epiweeks with automatic factor levels\n  janitor,       # tables\n  tidyverse      # data mgmt and viz\n  )\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\n\n# import your dataset\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\n\n\n11.1.1 Neue kategoriale Variable {#fct_newcat .unnumbered}\nZur Veranschaulichung verwenden wir auf dieser Seite ein gängiges Szenario - die Erstellung einer neuen kategorialen Variablen.\nWenn du eine numerische Spalte in einen Klassenfaktor umwandelst, kannst du keine numerischen Statistiken berechnen.\n\nSpalte erstellen\nWir verwenden die vorhandene Spalte days_onset_hosp (Tage vom Auftreten der Symptome bis zur Krankenhausaufnahme) und erstellen eine neue Spalte delay_cat indem wir jede Zeile in eine von mehreren Kategorien einordnen. Wir tun dies mit der dplyr Funktion case_when() die nacheinander logische Kriterien (rechte Seite) auf jede Zeile anwendet und den entsprechenden Wert der linken Seite für die neue Spalte zurückgibt delay_cat. Lies mehr über case_when()in [Datenbereinigung und Kernfunktionen].\n\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = case_when(\n    # criteria                                   # new value if TRUE\n    days_onset_hosp &lt; 2                        ~ \"&lt;2 days\",\n    days_onset_hosp &gt;= 2 & days_onset_hosp &lt; 5 ~ \"2-5 days\",\n    days_onset_hosp &gt;= 5                       ~ \"&gt;5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  \n\n\n\nStandardwert Reihenfolge\nWie erstellt mit case_when() erstellt wurde, ist die neue Spalte delay_cat ist eine kategoriale Spalte der Klasse Charakter - nicht noch ein Faktor. In einer Häufigkeitstabelle sehen wir also, dass die eindeutigen Werte in einer standardmäßigen alphanumerischen Reihenfolge erscheinen - eine Reihenfolge, die intuitiv nicht viel Sinn macht:\n\ntable(linelist$delay_cat, useNA = \"always\")\n\n\n &lt;2 days  &gt;5 days 2-5 days     &lt;NA&gt; \n    2990      602     2040      256 \n\n\nWenn wir ein Balkendiagramm erstellen, erscheinen die Werte ebenfalls in dieser Reihenfolge auf der x-Achse (siehe die [ggplot Grundlagen] Seite für mehr überggplot2 - dem am weitesten verbreiteten Visualisierungspaket in R).\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#in-faktor-umwandeln",
    "href": "new_pages/factors.de.html#in-faktor-umwandeln",
    "title": "11  Faktoren",
    "section": "11.2 In Faktor umwandeln",
    "text": "11.2 In Faktor umwandeln\nUm eine Zeichen- oder Zahlenspalte in eine Klasse umzuwandeln Faktor umzuwandeln, kannst du jede Funktion aus der forcats Paket verwenden (viele sind detailliert unter). Sie konvertieren in den Klassenfaktor und führen dann auch eine bestimmte Ordnung der Ebenen durch oder erlauben diese - zum Beispiel mit fct_relevel() kannst du die Reihenfolge der Stufen manuell festlegen. Die Funktion as_factor() wandelt die Klasse einfach um, ohne weitere Fähigkeiten.\nDie Basis R-Funktion factor() wandelt eine Spalte in einen Faktor um und ermöglicht es dir, die Reihenfolge der Ebenen manuell festzulegen, und zwar als Zeichenvektor zu seinem levels = Argument.\nIm Folgenden verwenden wir mutate() und fct_relevel() um die Spalte zu konvertieren delay_cat von Klassenzeichen in Klassenfaktor umzuwandeln. Die Spalte delay_cat wird erstellt in der Vorbereitung Abschnitt oben beschrieben.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat))\n\nDie einzelnen “Werte” in dieser Spalte werden nun als “Stufen” des Faktors betrachtet. Die Stufen haben einen Ordnung die mit dem Befehl Basis R-Funktion levels() oder alternativ in einer Zähltabelle über table() von Basis R oder tabyl() von Hausmeister. Die Reihenfolge der Ebenen ist standardmäßig alphanumerisch, wie bisher. Beachte, dass NA keine Faktorstufe ist.\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"&gt;5 days\"  \"2-5 days\"\n\n\nDie Funktion fct_relevel() hat den zusätzlichen Nutzen, dass du die Reihenfolge der Ebenen manuell festlegen kannst. Schreibe einfach die Werte der Ebenen in Anführungszeichen, getrennt durch Kommas, wie unten gezeigt. Beachte, dass die Schreibweise genau mit den Werten übereinstimmen muss. Wenn du Ebenen erstellen willst, die in den Daten nicht vorhanden sind, verwende fct_expand() stattdessen).\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))\n\nJetzt können wir sehen, dass die Ebenen in einer sinnvollen Reihenfolge angeordnet sind, wie im vorherigen Befehl angegeben.\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\nJetzt macht auch die Reihenfolge der Darstellung intuitiv mehr Sinn.\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#ebenen-hinzufügen-oder-entfernen",
    "href": "new_pages/factors.de.html#ebenen-hinzufügen-oder-entfernen",
    "title": "11  Faktoren",
    "section": "11.3 Ebenen hinzufügen oder entfernen",
    "text": "11.3 Ebenen hinzufügen oder entfernen\n\n11.3.1 hinzufügen {#fct_add .unnumbered}\nWenn du einem Faktor Stufen hinzufügen musst, kannst du dies mit fct_expand(). Schreibe einfach den Spaltennamen gefolgt von den neuen Stufen (durch Kommas getrennt). Wenn du die Werte tabellierst, kannst du die neuen Stufen und die Nullen sehen. Du kannst verwenden table() von Basis R, oder tabyl() von Hausmeister:\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %&gt;% \n  tabyl(delay_cat)   # print table\n\n                      delay_cat    n    percent valid_percent\n                        &lt;2 days 2990 0.50781250     0.5308949\n                       2-5 days 2040 0.34646739     0.3622159\n                        &gt;5 days  602 0.10224185     0.1068892\n       Not admitted to hospital    0 0.00000000     0.0000000\n Transfer to other jurisdiction    0 0.00000000     0.0000000\n                           &lt;NA&gt;  256 0.04347826            NA\n\n\nHinweis: Es gibt eine besondere forcats Funktion, um fehlende Werte einfach hinzuzufügen (NA) als Ebene. Siehe den Abschnitt über Fehlende Werte unten.\n\n\nDrop\nWenn du fct_drop() verwendest, werden die “ungenutzten” Ebenen mit Nullwerten aus der Menge der Ebenen entfernt. Die Ebenen, die wir oben hinzugefügt haben (“Nicht in ein Krankenhaus eingewiesen”), gibt es zwar als Ebene, aber keine Zeile hat diese Werte. Daher werden sie durch die Anwendung von fct_drop() auf unsere Faktorspalte:\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_drop(delay_cat)) %&gt;% \n  tabyl(delay_cat)\n\n delay_cat    n    percent valid_percent\n   &lt;2 days 2990 0.50781250     0.5308949\n  2-5 days 2040 0.34646739     0.3622159\n   &gt;5 days  602 0.10224185     0.1068892\n      &lt;NA&gt;  256 0.04347826            NA",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#reihenfolge-der-ebenen-anpassen-fct_adjust",
    "href": "new_pages/factors.de.html#reihenfolge-der-ebenen-anpassen-fct_adjust",
    "title": "11  Faktoren",
    "section": "11.4 Reihenfolge der Ebenen anpassen {#fct_adjust}",
    "text": "11.4 Reihenfolge der Ebenen anpassen {#fct_adjust}\nDas Paket forcats bietet nützliche Funktionen, mit denen du die Reihenfolge der Stufen eines Faktors leicht anpassen kannst (nachdem eine Spalte als Klassenfaktor definiert wurde):\nDiese Funktionen können in zwei Kontexten auf eine Faktorspalte angewendet werden:\n\nzur Spalte im Datenrahmen, wie üblich, damit die Transformation für jede spätere Verwendung der Daten verfügbar ist\nInnerhalb eines Diagramms damit die Änderung nur innerhalb des Plots angewendet wird\n\n\nManuell\nMit dieser Funktion kannst du die Faktorstufen manuell anordnen. Wenn sie auf eine Spalte ohne Faktor angewendet wird, wird die Spalte zunächst in einen Klassenfaktor umgewandelt.\nIn den Klammern gibst du zuerst den Namen der Faktorspalte an und dann entweder:\n\nAlle Ebenen in der gewünschten Reihenfolge (als Zeichenvektor) c()), oder\nEine Ebene und ihre korrigierte Platzierung mit dem after = Argument\n\nHier ist ein Beispiel für die Neudefinition der Spalte delay_cat (die bereits die Klasse Factor ist) und die Angabe der gewünschten Reihenfolge der Ebenen.\n\n# re-define level order\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\")))\n\nWenn du nur eine Ebene verschieben willst, kannst du sie auf fct_relevel() allein und gibst eine Nummer für die after = Argument eine Zahl, um anzugeben, wo in der Reihenfolge sie stehen soll. Der folgende Befehl verschiebt zum Beispiel “&lt;2 Tage” an die zweite Position:\n\n# re-define level order\nlinelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", after = 1)) %&gt;% \n  tabyl(delay_cat)\n\n\n\nInnerhalb eines Plots\nDie forcats Befehle können verwendet werden, um die Reihenfolge der Ebenen im Datenrahmen oder nur innerhalb eines Plots festzulegen. Indem du den Befehl zum “Umschließen” des Spaltennamens verwendest innerhalb von der ggplot() Plot-Befehl kannst du die Transformation rückgängig machen, neu ausrichten usw. Die Transformation gilt dann nur innerhalb dieses Plots.\nUnten werden zwei Plots erstellt mit ggplot()erstellt (siehe die [ggplot Grundlagen] Seite). In der ersten wird diedelay_cat Spalte auf die x-Achse des Plots abgebildet, wobei die Standardreihenfolge der Ebenen wie in den Daten linelist. Im zweiten Beispiel wird die Spalte in die fct_relevel() und die Reihenfolge wird im Diagramm geändert.\n\n# Alpha-numeric default order - no adjustment within ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# Factor level order adjusted within ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeachte, dass der Standardtitel der x-Achse jetzt ziemlich kompliziert ist - du kannst diesen Titel mit dem ggplot2 labs() Argument.\n\n\nUmkehren\nEs kommt häufig vor, dass du die Reihenfolge der Ebenen umkehren möchtest. Schließe den Faktor einfach mit fct_rev().\nBeachte, dass du, wenn du den Faktor umkehren willst nur eine Plotlegende umkehren willst, nicht aber die tatsächlichen Faktorstufen, kannst du das mit guides()(siehe [ggplot-Tipps]).\n\n\nNach Häufigkeit\nUm nach der Häufigkeit zu sortieren, mit der der Wert in den Daten erscheint, verwende fct_infreq(). Alle fehlenden Werte (NA) werden automatisch am Ende eingefügt, es sei denn, sie werden in eine explizite Ebene umgewandelt (siehe diesen Abschnitt). Du kannst die Reihenfolge umkehren, indem du einen weiteren Wrapper mit fct_rev().\nDiese Funktion kann innerhalb einer ggplot() verwenden, wie unten gezeigt.\n\n# ordered by frequency\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# reversed frequency\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNach Aussehen\nVerwende fct_inorder() kannst du die Reihenfolge der Ebenen so einstellen, dass sie mit der Reihenfolge des Auftretens in den Daten übereinstimmt, beginnend mit der ersten Zeile. Das kann nützlich sein, wenn du zuerst sorgfältig arrange() die Daten in den Datenrahmen einträgst und dann damit die Reihenfolge der Faktoren festlegst.\n\n\nNach der zusammenfassenden Statistik einer anderen Spalte\nDu kannst verwenden fct_reorder() um die Ebenen einer Spalte zu ordnen nach einer statistischen Zusammenfassung einer anderen Spalte. Dies kann zu optisch ansprechenden Diagrammen führen, bei denen die Balken/Punkte gleichmäßig auf- oder absteigen.\nIn den folgenden Beispielen ist die x-Achse delay_cat und die y-Achse ist eine numerische Spalte ct_blood (Zyklus-Schwellenwert). Boxplots zeigen die Verteilung der CT-Werte nach delay_cat Gruppe. Wir wollen die Boxplots in aufsteigender Reihenfolge nach dem mittleren CT-Wert der Gruppe ordnen.\nIm ersten Beispiel unten wird die Standardreihenfolge der alphanumerischen Ebenen verwendet. Du kannst sehen, dass die Höhen der Boxplots durcheinander und nicht in einer bestimmten Reihenfolge sind. Im zweiten Beispiel wird die delay_cat Spalte (die der x-Achse zugeordnet ist) in fct_reorder(), die Spalte ct_blood als zweites Argument und “Median” als drittes Argument angegeben (du könntest auch “max”, “mean”, “min”, etc. verwenden). So wird die Reihenfolge der Ebenen von delay_cat die aufsteigenden Median-CT-Werte der einzelnen delay_cat des mittleren CT-Werts jeder Gruppe. Das spiegelt sich in der zweiten Grafik wider - die Box-Plots wurden aufsteigend angeordnet. Beachte, wie NA (fehlend) am Ende erscheint, wenn es nicht in eine explizite Ebene umgewandelt wird.\n\n# boxplots ordered by original factor levels\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by original alpha-numeric levels\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# boxplots ordered by median CT value\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by median CT value in group\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeachte, dass in diesem Beispiel keine Schritte erforderlich sind, bevor die ggplot() Aufruf keine Schritte erforderlich sind - die Gruppierung und die Berechnungen werden alle intern im ggplot-Befehl durchgeführt.\n\n\nNach “End”-Wert\nverwenden fct_reorder2() für gruppierte Liniendiagramme. Sie ordnet die Ebenen (und damit die Legende) so, dass sie mit der vertikalen Anordnung der Linien am “Ende” des Diagramms übereinstimmen. Technisch ausgedrückt: Sie ordnet nach den y-Werten, die mit den größten x-Werten verbunden sind.\nWenn du zum Beispiel Linien hast, die die Fallzahlen nach Krankenhaus im Laufe der Zeit darstellen, kannst du Folgendes anwenden fct_reorder2() auf die color = Argument innerhalb aes(), so dass die vertikale Reihenfolge der Krankenhäuser in der Legende mit der Reihenfolge der Linien am Ende des Plots übereinstimmt. Lies mehr in der Online-Dokumentation.\n\nepidemic_data &lt;- linelist %&gt;%         # begin with the linelist   \n    filter(date_onset &lt; as.Date(\"2014-09-21\")) %&gt;%    # cut-off date, for visual clarity\n    count(                                            # get case counts per week and by hospital\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # start plot\n  geom_line(                                        # make lines\n    aes(\n      x = epiweek,                                  # x-axis epiweek\n      y = n,                                        # height is number of cases per week\n      color = fct_reorder2(hospital, epiweek, n)))+ # data grouped and colored by hospital, with factor order by height at end of plot\n  labs(title = \"Factor levels (and legend display) by line height at end of plot\",\n       color = \"Hospital\")                          # change legend title",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#fehlende-werte-fct_missing",
    "href": "new_pages/factors.de.html#fehlende-werte-fct_missing",
    "title": "11  Faktoren",
    "section": "11.5 Fehlende Werte {#fct_missing}",
    "text": "11.5 Fehlende Werte {#fct_missing}\nWenn du NA Werte in deiner Faktorspalte hast, kannst du sie ganz einfach in eine benannte Ebene wie “Missing” umwandeln mit fct_explicit_na(). Die NA Werte werden am Ende der Ebenenreihenfolge standardmäßig in “(Missing)” umgewandelt. Du kannst den Namen der Ebene mit dem Argument na_level =.\nIm Folgenden wird diese Operation für die Spalte delay_cat durchgeführt und es wird eine Tabelle mit tabyl() mit NA in “Fehlende Verzögerung” umgewandelt.\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %&gt;% \n  tabyl(delay_cat)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing\n  delay\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\n     delay_cat    n    percent\n      2-5 days 2040 0.34646739\n       &lt;2 days 2990 0.50781250\n       &gt;5 days  602 0.10224185\n Missing delay  256 0.04347826",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#ebenen-kombinieren",
    "href": "new_pages/factors.de.html#ebenen-kombinieren",
    "title": "11  Faktoren",
    "section": "11.6 Ebenen kombinieren",
    "text": "11.6 Ebenen kombinieren\n\nManuell\nDu kannst die Pegelanzeigen manuell einstellen mit fct_recode(). Dies ist wie die dplyr Funktion recode()(siehe [Datenbereinigung und Kernfunktionen]), aber sie ermöglicht die Erstellung neuer Faktorstufen. Wenn du die einfacherecode() auf einen Faktor anwendest, werden neue, neu kodierte Werte abgelehnt, es sei denn, sie wurden bereits als zulässige Ebenen festgelegt.\nMit diesem Tool kannst du auch Ebenen “kombinieren”, indem du mehreren Ebenen denselben neu kodierten Wert zuweist. Achte nur darauf, dass keine Informationen verloren gehen! Achte darauf, dass du diese Kombinationsschritte in einer neuen Spalte durchführst (und nicht die bestehende Spalte überschreibst).\nfct_recode() hat eine andere Syntax als recode(). recode() verwendet OLD = NEW, während fct_recode() verwendet NEW = OLD.\nDie aktuellen Werte der delay_cat sind:\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\nDie neuen Ebenen werden mit der Syntax erstellt fct_recode(column, \"new\" = \"old\", \"new\" = \"old\", \"new\" = \"old\") erstellt und gedruckt:\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"&lt;2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 2 days 2990 0.50781250     0.5308949\n      2 to 5 days 2040 0.34646739     0.3622159\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\nHier werden sie manuell kombiniert mit fct_recode(). Beachte, dass bei der Erstellung einer neuen Ebene “Weniger als 5 Tage” kein Fehler auftritt.\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"&lt;2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 5 days 5030 0.85427989     0.8931108\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\n\n\nReduzieren auf “Sonstiges”\nDu kannst verwenden fct_other() kannst du die Faktorebenen manuell einer Ebene “Andere” zuordnen. Unten werden alle Ebenen in der Spalte hospital mit Ausnahme von “Hafenkrankenhaus” und “Zentralkrankenhaus” zu “Sonstige” zusammengefasst. Du kannst einen Vektor angeben, um entweder keep =, oder drop =. Du kannst die Anzeige der Ebene “Andere” mit other_level =.\n\nlinelist %&gt;%    \n  mutate(hospital = fct_other(                      # adjust levels\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # keep these separate\n    other_level = \"Other Hospital\")) %&gt;%            # All others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table\n\n         hospital    n    percent\n Central Hospital  454 0.07710598\n    Port Hospital 1762 0.29925272\n   Other Hospital 3672 0.62364130\n\n\n\n\nVerringern nach Frequenz\nDu kannst die am wenigsten häufigen Faktorstufen automatisch kombinieren, indem du fct_lump().\nUm viele niedrigfrequente Ebenen in einer Gruppe “Andere” zusammenzufassen, kannst du einen der folgenden Schritte ausführen:\n\nSetze n = als die Anzahl der Gruppen ein, die du behalten willst. Die n am häufigsten vorkommenden Stufen werden beibehalten, alle anderen werden zu “Andere” zusammengefasst.\neinstellen prop = als Schwellenwert für den Frequenzanteil der Pegel, die du behalten möchtest. Alle anderen Werte werden zu “Sonstige” zusammengefasst.\n\nDu kannst die Anzeige der Stufe “Sonstige” mit other_level =. Unten werden alle Krankenhäuser bis auf die beiden häufigsten zu “Anderes Krankenhaus” zusammengefasst.\n\nlinelist %&gt;%    \n  mutate(hospital = fct_lump(                      # adjust levels\n    hospital,\n    n = 2,                                          # keep top 2 levels\n    other_level = \"Other Hospital\")) %&gt;%            # all others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table\n\n       hospital    n   percent\n        Missing 1469 0.2494905\n  Port Hospital 1762 0.2992527\n Other Hospital 2657 0.4512568",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#alle-levels-anzeigen",
    "href": "new_pages/factors.de.html#alle-levels-anzeigen",
    "title": "11  Faktoren",
    "section": "11.7 Alle Levels anzeigen",
    "text": "11.7 Alle Levels anzeigen\nEin Vorteil der Verwendung von Faktoren ist die Vereinheitlichung des Aussehens von Legenden und Tabellen, unabhängig davon, welche Werte in einem Datensatz tatsächlich vorhanden sind.\nWenn du viele Zahlen vorbereitest (z. B. für mehrere Gerichtsbarkeiten), möchtest du, dass die Legenden und Tabellen auch bei unterschiedlichem Grad der Datenvervollständigung oder Datenzusammensetzung identisch aussehen.\n\nIn Diagrammen\nIn einem ggplot() Figur fügst du einfach das Argument drop = FALSE in der entsprechenden scale_xxxx() Funktion ein. Es werden alle Faktorstufen angezeigt, unabhängig davon, ob sie in den Daten vorhanden sind. Wenn deine Faktorspaltenebenen angezeigt werden, indem du fill = angezeigt werden, dann fügst du in scale_fill_discrete() drop = FALSE ein, wie unten gezeigt. Wenn deine Ebenen mit x = (auf der x-Achse) color = oder size = du würdest dies zur Verfügung stellen scale_color_discrete() oder scale_size_discrete() entsprechend.\nDieses Beispiel ist ein gestapeltes Balkendiagramm der Alterskategorie, aufgeschlüsselt nach Krankenhaus. Hinzufügen von scale_fill_discrete(drop = FALSE) sorgt dafür, dass alle Altersgruppen in der Legende erscheinen, auch wenn sie nicht in den Daten enthalten sind.\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+                        # show all age groups in the legend, even those not present\n  labs(\n    title = \"All age groups will appear in legend, even if not present in data\")\n\n\n\n\n\n\n\n\n\n\nIn Tabellen\nSowohl die Basis R table() und tabyl() von Hausmeister zeigt alle Faktorebenen an (auch unbenutzte Ebenen).\nWenn du count() oder summarise() von dplyr um eine Tabelle zu erstellen, füge das Argument .drop = FALSE hinzu, um die Zählungen für alle Faktorebenen einzuschließen, auch für die nicht verwendeten.\nLesen Sie mehr in den [Beschreibende Tabellen] Seite, oder auf derscale_discrete Dokumentation oder die count()-Dokumentation. Ein weiteres Beispiel findest du in der [Kontaktverfolgung] Seite.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#epiweeks",
    "href": "new_pages/factors.de.html#epiweeks",
    "title": "11  Faktoren",
    "section": "11.8 Epiweeks",
    "text": "11.8 Epiweeks\nBitte beachten Sie die ausführliche Diskussion über die Erstellung von epidemiologischen Wochen im Abschnitt [Daten gruppieren] Seite.\nBitte beachte auch die Seite [Arbeiten mit Daten] Seite für Tipps zum Erstellen und Formatieren von epidemiologischen Wochen.\n\nEpiweeks in einer Grafik\nWenn du Epiweeks erstellen willst, um sie in einem Plot anzuzeigen, kannst du das ganz einfach tun mit lubridate’s floor_date(), wie im Abschnitt [Daten gruppieren] Seite erklärt. Die zurückgegebenen Werte sind von der Klasse Datum mit dem Format JJJJ-MM-TT. Wenn du diese Spalte in einem Diagramm verwendest, werden die Daten natürlich richtig angeordnet, und du musst dich nicht um Ebenen oder die Umwandlung in die Klasse Faktor kümmern. Siehe dieggplot() Histogramm der Eintrittsdaten unten.\nBei diesem Ansatz kannst du die Anzeige der Daten auf einer Achse mit scale_x_date(). Siehe die Seite über [Epidemie-Kurven] für weitere Informationen. Du kannst ein “strptime”-Anzeigeformat für diedate_labels = Argument von scale_x_date(). Diese Formate verwenden “%”-Platzhalter und werden im Abschnitt [Arbeiten mit Datumsangaben] Seite behandelt. Verwende “%Y”, um ein vierstelliges Jahr darzustellen, und entweder “%W” oder “%U”, um die Wochennummer (Montag bzw. Sonntag) anzugeben.\n\nlinelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %&gt;%  # create week column\n  ggplot()+                                                  # begin ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histogram of date of onset\n  scale_x_date(date_labels = \"%Y-W%W\")                       # adjust disply of dates to be YYYY-WWw\n\n\n\n\n\n\n\n\n\n\nEpiweeks in den Daten\nWenn dein Ziel beim Factoring jedoch ist nicht zu plotten, kannst du dies auf zwei Arten angehen:\n\nFür eine feine Kontrolle über die Anzeige konvertieren Sie die lubridate epiweek-Spalte (JJJJ-MM-TT) in das gewünschte Anzeigeformat (JJJJ-WWW) innerhalb des Datenrahmens selbst und konvertiere sie dann in die Klasse Faktor.\n\nErstens, benutze format() von BasisR, um die Datumsanzeige von JJJJ-MM-TT in JJJJ-WW-Anzeige umzuwandeln (siehe den Abschnitt [Arbeiten mit Datumsangaben] Seite). Bei diesem Vorgang wird die Klasse in Zeichen umgewandelt. Konvertiere dann von Character zu Class Factor mitfactor().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # create epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convert to display (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convert to factor\n\n# Display levels\nlevels(linelist$epiweek_formatted)\n\n [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\"\n [7] \"2014-W19\" \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\" \"2014-W24\"\n[13] \"2014-W25\" \"2014-W26\" \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\"\n[19] \"2014-W31\" \"2014-W32\" \"2014-W33\" \"2014-W34\" \"2014-W35\" \"2014-W36\"\n[25] \"2014-W37\" \"2014-W38\" \"2014-W39\" \"2014-W40\" \"2014-W41\" \"2014-W42\"\n[31] \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\" \"2014-W48\"\n[37] \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\"\n[43] \"2015-W03\" \"2015-W04\" \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\"\n[49] \"2015-W09\" \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\"\n[55] \"2015-W15\" \"2015-W16\"\n\n\nGEFAHR! Wenn du die Wochen vor den Jahren (“Www-YYYY”) platzierst (“%W-%Y”), ist die standardmäßige alphanumerische Reihenfolge der Ebenen falsch (z.B. 01-2015 liegt vor 35-2014). Du könntest die Reihenfolge manuell anpassen müssen, was ein langwieriger Prozess wäre.\n\nFür eine schnelle Standardanzeige verwenden Sie die aweek Paket und seine Funktion date2week(). Du kannst die week_start = Tag, und wenn du den factor = TRUE einstellst, ist die Ausgabespalte ein geordneter Faktor. Als Bonus enthält der Faktor Stufen für alle möglichen Wochen in der Spanne - auch wenn es in dieser Woche keine Fälle gibt.\n\n\ndf &lt;- linelist %&gt;% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)\n\nSiehe die [Arbeiten mit Daten] Seite für weitere Informationen übereine Woche. Es bietet auch die umgekehrte Funktion week2date().",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.de.html#ressourcen",
    "href": "new_pages/factors.de.html#ressourcen",
    "title": "11  Faktoren",
    "section": "11.9 Ressourcen",
    "text": "11.9 Ressourcen\nR für Data Science Seite auf Faktoren\naweek Paket Vignette",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.de.html",
    "href": "new_pages/pivoting.de.html",
    "title": "12  Daten pivotieren",
    "section": "",
    "text": "12.1 Vorbereitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Daten pivotieren</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.de.html#vorbereitung",
    "href": "new_pages/pivoting.de.html#vorbereitung",
    "title": "12  Daten pivotieren",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  kableExtra,   # Build and manipulate complex tables\n  tidyverse)    # data management + ggplot2 graphics\n\n\n\nDaten importieren\n\n\nMalaria Zähldaten\nAuf dieser Seite verwenden wir einen fiktiven Datensatz mit täglichen Malariafällen, aufgeschlüsselt nach Einrichtungen und Altersgruppen. Wenn du mitmachen willst, klicke hier zum Herunterladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus dem rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# Import data\ncount_data &lt;- import(\"malaria_facility_count_data.rds\")\n\nDie ersten 50 Zeilen werden unten angezeigt.\n\n\n\n\n\n\n\n\nLinelist Falldaten\nIm späteren Teil dieser Seite werden wir auch den Datensatz der Fälle einer simulierten Ebola-Epidemie verwenden. Wenn du mitmachen willst, klicke hier, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\n\n# import your dataset\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Daten pivotieren</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.de.html#weit-zu-lang",
    "href": "new_pages/pivoting.de.html#weit-zu-lang",
    "title": "12  Daten pivotieren",
    "section": "12.2 Weit-zu-lang",
    "text": "12.2 Weit-zu-lang\n\n\n\n\n\n\n\n\n\n\n\nFormat “Breit”\nDaten werden oft in einem “breiten” Format eingegeben und gespeichert, d. h. die Merkmale oder Antworten einer Person werden in einer einzigen Zeile gespeichert. Das kann zwar für die Präsentation nützlich sein, ist aber für einige Arten von Analysen nicht ideal.\nNehmen wir die count_data Datensatz, der im Abschnitt Vorbereitung importiert wurde, als Beispiel. Du kannst sehen, dass jede Zeile einen “Einrichtungstag” darstellt. Die tatsächlichen Fallzahlen (die Spalten ganz rechts) werden in einem “breiten” Format gespeichert, so dass die Informationen für jede Altersgruppe an einem bestimmten Einrichtungstag in einer einzigen Zeile gespeichert sind.\n\n\n\n\n\n\nJede Beobachtung in diesem Datensatz bezieht sich auf die Malaria-Zahlen in einer von 65 Einrichtungen an einem bestimmten Tag, und zwar von count_data$data_date %&gt;% min() bis count_data$data_date %&gt;% max(). Diese Einrichtungen befinden sich in einem Province (Norden) und vier Districts (Spring, Bolo, Dingo und Barnard). Der Datensatz enthält die Gesamtzahlen der Malariafälle sowie die altersspezifischen Zahlen für jede der drei Altersgruppen - &lt;4 Jahre, 5-14 Jahre und 15 Jahre und älter.\n“Breite” Daten wie diese entsprechen nicht den Standards für “aufgeräumte Daten”, denn die Spaltenüberschriften stellen eigentlich keine “Variablen” dar - sie stehen für Werte einer hypothetischen Variable “Altersgruppe”.\nDieses Format kann für die Darstellung der Informationen in einer Tabelle oder für die Eingabe von Daten (z. B. in Excel) aus Fallberichtsformularen nützlich sein. In der Analysephase sollten diese Daten jedoch normalerweise in ein “längeres” Format umgewandelt werden, das den Standards für “aufgeräumte Daten” entspricht. Das R-Paket Plotting ggplot2 funktioniert am besten, wenn die Daten in einem “langen” Format vorliegen.\nDie Visualisierung der gesamten Die Visualisierung der Malaria-Gesamtzahlen im Zeitverlauf ist mit den Daten in ihrem derzeitigen Format kein Problem:\n\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)\n\n\n\n\n\n\n\n\nWas aber, wenn wir den relativen Anteil der einzelnen Altersgruppen an dieser Gesamtzahl anzeigen wollen? In diesem Fall müssen wir sicherstellen, dass die Variable, die uns interessiert (die Altersgruppe), im Datensatz in einer einzigen Spalte erscheint, die wir an {ggplot2} Die “Mapping-Ästhetik” aes() Argument übergeben werden kann.\n\n\n\npivot_longer()\nDie tidyr Funktion pivot_longer() macht Daten “länger”. tidyr ist Teil der tidyverse von R-Paketen.\nEs akzeptiert einen Bereich von Spalten, die transformiert werden sollen (angegeben in cols =). Daher kann sie nur einen Teil eines Datensatzes bearbeiten. Das ist nützlich für die Malaria-Daten, da wir nur die Spalten mit den Fallzahlen drehen wollen.\nBei diesem Vorgang erhältst du zwei “neue” Spalten - eine mit den Kategorien (die früheren Spaltennamen) und eine mit den entsprechenden Werten (z. B. Fallzahlen). Du kannst die voreingestellten Namen für diese neuen Spalten akzeptieren oder deine eigenen Namen angeben, um names_to = und values_to = festlegen.\nSchauen wir mal pivot_longer() in Aktion…\n\n\nStandard-Schwenken\nWir wollen verwenden tidyr’s pivot_longer() Funktion, um die “breiten” Daten in ein “langes” Format umzuwandeln. Konkret geht es darum, die vier numerischen Spalten mit den Daten zu den Malariazahlen in zwei neue Spalten umzuwandeln: eine, die die Altersgruppen und eine, die die entsprechenden Werte.\n\ndf_long &lt;- count_data %&gt;% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n\nBeachten Sie, dass der neu erstellte Datenrahmen (df_long) mehr Zeilen hat (12.152 gegenüber 3.038); er wurde länger. Tatsächlich ist sie genau viermal so lang, weil jede Zeile im ursprünglichen Datensatz jetzt vier Zeilen in df_long darstellt, eine für jede der Malaria-Beobachtungen (&lt;4y, 5-14y, 15y+ und total).\nDer neue Datensatz ist nicht nur länger, sondern hat auch weniger Spalten (8 gegenüber 10), da die Daten zuvor in vier Spalten gespeichert wurden (die mit dem Präfix malaria_) jetzt in zwei Spalten gespeichert werden.\nDa die Namen dieser vier Spalten alle mit dem Präfix malaria_ beginnen, hätten wir auch die praktische Funktion “tidyselect” verwenden können starts_with()verwenden können, um das gleiche Ergebnis zu erzielen (siehe die Seite [Daten bereinigen und Kernfunktionen] für mehr über diese Hilfsfunktionen).\n\n# provide column with a tidyselect helper function\ncount_data %&gt;% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid name    value\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    11\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    12\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    23\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    46\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    11\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    10\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…     5\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    26\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     8\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     5\n# ℹ 12,142 more rows\n\n\noder nach Position:\n\n# provide columns by position\ncount_data %&gt;% \n  pivot_longer(\n    cols = 6:9\n  )\n\noder nach benanntem Bereich:\n\n# provide range of consecutive columns\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\n\nDiese beiden neuen Spalten erhalten die Standardnamen name und value aber wir können diese Standardnamen überschreiben, um aussagekräftigere Namen zu vergeben, die uns helfen, uns an den Inhalt zu erinnern, indem wir die names_to und values_to Argumente. Verwenden wir die Namen age_group und counts:\n\ndf_long &lt;- \n  count_data %&gt;% \n  pivot_longer(\n    cols = starts_with(\"malaria_\"),\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid age_group    \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;        \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot  \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot  \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n# ℹ 12,142 more rows\n# ℹ 1 more variable: counts &lt;int&gt;\n\n\nWir können diesen neuen Datensatz nun an {ggplot2} übergeben und die neue Spalte count auf die y-Achse und die neue Spalte age_group auf die fill = Argument (die interne Farbe der Spalte). Dadurch werden die Malariazahlen in einem gestapelten Balkendiagramm nach Altersgruppen angezeigt:\n\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nSieh dir dieses neue Diagramm an und vergleiche es mit dem Diagramm, das wir zuvor erstellt haben - Was ist falsch gelaufen?\nWir sind auf ein häufiges Problem beim Umgang mit Überwachungsdaten gestoßen - wir haben auch die Gesamtzahlen aus den malaria_tot Spalte einbezogen, so dass die Größe jedes Balkens in der Grafik doppelt so hoch ist, wie sie sein sollte.\nEs gibt mehrere Möglichkeiten, damit umzugehen. Wir könnten diese Summen einfach aus dem Datensatz filtern, bevor wir ihn an ggplot():\n\ndf_long %&gt;% \n  filter(age_group != \"malaria_tot\") %&gt;% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nAlternativ hätten wir diese Variable auch ausschließen können, als wir die pivot_longer() ausschließen und sie so als separate Variable im Datensatz behalten. Sieh dir an, wie sich ihre Werte “ausdehnen”, um die neuen Zeilen zu füllen.\n\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # does not include the totals column\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\n# A tibble: 9,114 × 9\n   location_name data_date  submitted_date Province District malaria_tot newid\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt; &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4\n# ℹ 9,104 more rows\n# ℹ 2 more variables: age_group &lt;chr&gt;, counts &lt;int&gt;\n\n\n\n\nPivotierung von Daten mit mehreren Klassen\nDas obige Beispiel funktioniert gut in Situationen, in denen alle Spalten, die du “länger schwenken” willst, derselben Klasse angehören (Zeichen, Zahlen, logisch …).\nEs wird jedoch viele Fälle geben, in denen du als Epidemiologe vor Ort mit Daten arbeitest, die von Nichtfachleuten aufbereitet wurden und die ihrer eigenen, nicht standardisierten Logik folgen - wie Hadley Wickham (mit Verweis auf Tolstoi) in seinem bahnbrechenden Artikel auf Aufgeräumte Daten Prinzipien: “Wie Familien sind aufgeräumte Datensätze alle gleich, aber jeder unordentliche Datensatz ist auf seine eigene Art unordentlich.”\nEin besonders häufiges Problem, auf das du stoßen wirst, ist die Notwendigkeit, Spalten, die verschiedene Datenklassen enthalten, zu pivotieren. Dieser Pivot führt dazu, dass diese verschiedenen Datentypen in einer einzigen Spalte gespeichert werden, was keine gute Situation ist. Es gibt verschiedene Ansätze, um das dadurch entstehende Chaos zu beseitigen, aber es gibt einen wichtigen Schritt, den du mit pivot_longer() um zu vermeiden, dass du selbst in eine solche Situation gerätst.\nNimm eine Situation an, in der es eine Reihe von Beobachtungen in verschiedenen Zeitschritten für jedes der drei Elemente A, B und C gibt. Beispiele für solche Elemente könnten Einzelpersonen sein (z. B. Kontaktpersonen eines Ebola-Falls, die 21 Tage lang jeden Tag verfolgt werden) oder abgelegene Dorfgesundheitsposten, die einmal im Jahr überwacht werden, um sicherzustellen, dass sie noch funktionsfähig sind. Nehmen wir das Beispiel der Kontaktverfolgung. Stell dir vor, dass die Daten wie folgt gespeichert werden:\n\n\n\n\n\n\nWie du siehst, sind die Daten ein bisschen kompliziert. Jede Zeile speichert Informationen über ein Element, wobei die Zeitreihe mit fortschreitender Zeit immer weiter nach rechts verläuft. Außerdem wechseln sich die Spaltenklassen zwischen Datums- und Zeichenwerten ab.\nEin besonders schlimmes Beispiel, auf das dieser Autor gestoßen ist, waren die Daten zur Choleraüberwachung, bei denen 8 neue Spalten mit Beobachtungen hinzugefügt wurden jeden Tag im Laufe von 4 Jahre. Allein das Öffnen der Excel-Datei, in der diese Daten gespeichert waren, hat auf meinem Laptop mehr als 10 Minuten gedauert!\nUm mit diesen Daten arbeiten zu können, müssen wir den Datenrahmen in ein langes Format umwandeln, aber die Trennung zwischen einem date Spalte und einer character (Status-)Spalte für jede Beobachtung für jedes Element beibehalten. Andernfalls könnte es passieren, dass wir in einer einzigen Spalte eine Mischung aus verschiedenen Variablentypen haben (ein großes “No-No”, wenn es um Datenmanagement und ordentliche Daten geht):\n\ndf %&gt;% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\")\n  )\n\n# A tibble: 18 × 3\n   id    observation value     \n   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;     \n 1 A     obs1_date   2021-04-23\n 2 A     obs1_status Healthy   \n 3 A     obs2_date   2021-04-24\n 4 A     obs2_status Healthy   \n 5 A     obs3_date   2021-04-25\n 6 A     obs3_status Unwell    \n 7 B     obs1_date   2021-04-23\n 8 B     obs1_status Healthy   \n 9 B     obs2_date   2021-04-24\n10 B     obs2_status Healthy   \n11 B     obs3_date   2021-04-25\n12 B     obs3_status Healthy   \n13 C     obs1_date   2021-04-23\n14 C     obs1_status Missing   \n15 C     obs2_date   2021-04-24\n16 C     obs2_status Healthy   \n17 C     obs3_date   2021-04-25\n18 C     obs3_status Healthy   \n\n\nOben hat unser Pivot Folgendes zusammengeführt Daten und Zeichen in eine einzige value Spalte. R reagiert darauf, indem es die gesamte Spalte in Klassenzeichen umwandelt, und der Nutzen der Daten geht verloren.\nUm dies zu verhindern, können wir uns die Syntaxstruktur der ursprünglichen Spaltennamen zunutze machen. Es gibt eine gemeinsame Namensstruktur mit der Beobachtungsnummer, einem Unterstrich und dann entweder “Status” oder “Datum”. Wir können diese Syntax nutzen, um diese beiden Datentypen nach dem Pivot in getrennten Spalten zu halten.\nWir tun dies, indem wir:\n\nBereitstellung eines Zeichenvektors für die names_to = Argument, wobei das zweite Element (\".value\" ). Dieser spezielle Begriff zeigt an, dass die gepivoteten Spalten anhand eines Zeichens in ihrem Namen aufgeteilt werden…\nDu musst auch das “Splitting”-Zeichen in der names_sep = Argument angeben. In diesem Fall ist es der Unterstrich “_”.\n\nDie Benennung und Aufteilung neuer Spalten basiert also auf dem Unterstrich in den bestehenden Variablennamen.\n\ndf_long &lt;- \n  df %&gt;% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  \n1 A     obs1        2021-04-23 Healthy\n2 A     obs2        2021-04-24 Healthy\n3 A     obs3        2021-04-25 Unwell \n4 B     obs1        2021-04-23 Healthy\n5 B     obs2        2021-04-24 Healthy\n6 B     obs3        2021-04-25 Healthy\n7 C     obs1        2021-04-23 Missing\n8 C     obs2        2021-04-24 Healthy\n9 C     obs3        2021-04-25 Healthy\n\n\nDer letzte Schliff:\nBeachte, dass die date Spalte derzeit in Zeichen Klasse - wir können sie leicht in die richtige Datumsklasse umwandeln, indem wir die mutate() und as_date()Funktionen, die im Abschnitt [Arbeiten mit Daten] Seite beschrieben sind.\nVielleicht möchten wir auch die observation Spalte in eine numeric Format konvertieren, indem wir das Präfix “obs” weglassen und in ein numerisches Format konvertieren. Wir können dies tun mit str_remove_all() aus der stringrPaket (siehe die [Zeichen und Zeichenketten] Seite).\n\ndf_long &lt;- \n  df_long %&gt;% \n  mutate(\n    date = date %&gt;% lubridate::as_date(),\n    observation = \n      observation %&gt;% \n      str_remove_all(\"obs\") %&gt;% \n      as.numeric()\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;  \n1 A               1 2021-04-23 Healthy\n2 A               2 2021-04-24 Healthy\n3 A               3 2021-04-25 Unwell \n4 B               1 2021-04-23 Healthy\n5 B               2 2021-04-24 Healthy\n6 B               3 2021-04-25 Healthy\n7 C               1 2021-04-23 Missing\n8 C               2 2021-04-24 Healthy\n9 C               3 2021-04-25 Healthy\n\n\nJetzt können wir mit den Daten in diesem Format arbeiten, z.B. indem wir eine beschreibende Wärmekachel aufzeichnen:\n\nggplot(data = df_long, mapping = aes(x = date, y = id, fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\" = \"red\", \n        \"Missing\" = \"orange\")\n  )",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Daten pivotieren</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.de.html#lang-zu-breit",
    "href": "new_pages/pivoting.de.html#lang-zu-breit",
    "title": "12  Daten pivotieren",
    "section": "12.3 Lang-zu-breit",
    "text": "12.3 Lang-zu-breit\n\n\n\n\n\n\n\n\n\nIn manchen Fällen möchten wir einen Datensatz in ein breiteres Format konvertieren. Hierfür können wir die pivot_wider() Funktion.\nEin typischer Anwendungsfall ist, wenn wir die Ergebnisse einer Analyse in ein Format umwandeln wollen, das für den Leser besser verdaulich ist (z. B. eine [Tabelle für die Präsentation][Tabellen für die Präsentation]). Normalerweise geht es darum, einen Datensatz, in dem die Informationen zu einem Thema über mehrere Zeilen verteilt sind, in ein Format umzuwandeln, in dem diese Informationen in einer einzigen Zeile gespeichert sind.\n\nDaten\nFür diesen Abschnitt der Seite verwenden wir die Fall-Lineliste (siehe die Vorbereitung Abschnitt), die eine Zeile pro Fall enthält.\nHier sind die ersten 50 Zeilen:\n\n\n\n\n\n\nAngenommen, wir wollen die Anzahl der Personen in den verschiedenen Altersgruppen nach Geschlecht wissen:\n\ndf_wide &lt;- \n  linelist %&gt;% \n  count(age_cat, gender)\n\ndf_wide\n\n   age_cat gender   n\n1      0-4      f 640\n2      0-4      m 416\n3      0-4   &lt;NA&gt;  39\n4      5-9      f 641\n5      5-9      m 412\n6      5-9   &lt;NA&gt;  42\n7    10-14      f 518\n8    10-14      m 383\n9    10-14   &lt;NA&gt;  40\n10   15-19      f 359\n11   15-19      m 364\n12   15-19   &lt;NA&gt;  20\n13   20-29      f 468\n14   20-29      m 575\n15   20-29   &lt;NA&gt;  30\n16   30-49      f 179\n17   30-49      m 557\n18   30-49   &lt;NA&gt;  18\n19   50-69      f   2\n20   50-69      m  91\n21   50-69   &lt;NA&gt;   2\n22     70+      m   5\n23     70+   &lt;NA&gt;   1\n24    &lt;NA&gt;   &lt;NA&gt;  86\n\n\nSo erhalten wir einen langen Datensatz, der sich hervorragend für die Erstellung von Visualisierungen in ggplot2 eignet, aber nicht ideal für die Darstellung in einer Tabelle:\n\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))\n\n\n\n\n\n\n\n\n\n\nDrehpunkt breiter\nDaher können wir verwenden pivot_wider() verwenden, um die Daten in ein besseres Format umzuwandeln, damit sie als Tabellen in unsere Berichte aufgenommen werden können.\nDas Argument names_from gibt die Spalte an von aus der die neue Spalte erzeugt werden soll Namen, während das Argument values_from die Spalte angibt von die Spalte, aus der die Werte um die Zellen zu füllen. Das Argument id_cols = ist optional, kann aber als Vektor von Spaltennamen angegeben werden, die nicht gepivotet werden sollen und somit jede Zeile identifizieren.\n\ntable_wide &lt;- \n  df_wide %&gt;% \n  pivot_wider(\n    id_cols = age_cat,\n    names_from = gender,\n    values_from = n\n  )\n\ntable_wide\n\n# A tibble: 9 × 4\n  age_cat     f     m  `NA`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 0-4       640   416    39\n2 5-9       641   412    42\n3 10-14     518   383    40\n4 15-19     359   364    20\n5 20-29     468   575    30\n6 30-49     179   557    18\n7 50-69       2    91     2\n8 70+        NA     5     1\n9 &lt;NA&gt;       NA    NA    86\n\n\nDiese Tabelle ist viel leserfreundlicher und eignet sich daher besser für die Aufnahme in unsere Berichte. Du kannst sie mit verschiedenen Paketen in eine hübsche Tabelle umwandeln. flextable und knitr. Dieser Prozess wird auf der Seite [Tabellen für die Präsentation].\n\ntable_wide %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% # adds row and column totals\n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 10, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nage_cat\nf\nm\nNA\nTotal\n\n\n\n\n0-4\n640\n416\n39\n1095\n\n\n5-9\n641\n412\n42\n1095\n\n\n10-14\n518\n383\n40\n941\n\n\n15-19\n359\n364\n20\n743\n\n\n20-29\n468\n575\n30\n1073\n\n\n30-49\n179\n557\n18\n754\n\n\n50-69\n2\n91\n2\n95\n\n\n70+\nNA\n5\n1\n6\n\n\nNA\nNA\nNA\n86\n86\n\n\nTotal\n2807\n2803\n278\n5888",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Daten pivotieren</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.de.html#fülle",
    "href": "new_pages/pivoting.de.html#fülle",
    "title": "12  Daten pivotieren",
    "section": "12.4 Fülle",
    "text": "12.4 Fülle\nIn manchen Situationen nach einer pivot, und häufiger nach einem bind bleiben in einigen Zellen Lücken, die wir gerne füllen würden.\n\n\nDaten\nNehmen wir zum Beispiel zwei Datensätze, die jeweils Beobachtungen für die Messnummer, den Namen der Einrichtung und die Fallzahl zu diesem Zeitpunkt enthalten. Der zweite Datensatz enthält jedoch auch eine Variable Year.\n\ndf1 &lt;- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 \n\n# A tibble: 9 × 3\n  Measurement Facility Cases\n        &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1           1 Hosp 1      66\n2           2 Hosp 1      26\n3           3 Hosp 1       8\n4           1 Hosp 2      71\n5           2 Hosp 2      62\n6           3 Hosp 2      70\n7           1 Hosp 3      47\n8           2 Hosp 3      70\n9           3 Hosp 3      38\n\ndf2 &lt;- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2\n\n# A tibble: 3 × 4\n   Year Measurement Facility Cases\n  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1  2000           1 Hosp 4      82\n2  2001           2 Hosp 4      87\n3  2002           3 Hosp 4      46\n\n\nWenn wir eine bind_rows() um die beiden Datensätze zusammenzuführen, wird die Year Variable gefüllt mit NA für die Zeilen, für die es keine vorherigen Informationen gab (d. h. für den ersten Datensatz):\n\ndf_combined &lt;- \n  bind_rows(df1, df2) %&gt;% \n  arrange(Measurement, Facility)\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66    NA\n 2           1 Hosp 2      71    NA\n 3           1 Hosp 3      47    NA\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26    NA\n 6           2 Hosp 2      62    NA\n 7           2 Hosp 3      70    NA\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8    NA\n10           3 Hosp 2      70    NA\n11           3 Hosp 3      38    NA\n12           3 Hosp 4      46  2002\n\n\n\n\n\nfill()\nIn diesem Fall, Year eine nützliche Variable, vor allem wenn wir Trends im Zeitverlauf untersuchen wollen. Daher verwenden wir fill() zu füllen diese leeren Zellen zu füllen, indem du die zu füllende Spalte und die Richtung angibst (in diesem Fall oben):\n\ndf_combined %&gt;% \n  fill(Year, .direction = \"up\")\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66  2000\n 2           1 Hosp 2      71  2000\n 3           1 Hosp 3      47  2000\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26  2001\n 6           2 Hosp 2      62  2001\n 7           2 Hosp 3      70  2001\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8  2002\n10           3 Hosp 2      70  2002\n11           3 Hosp 3      38  2002\n12           3 Hosp 4      46  2002\n\n\nAlternativ können wir die Daten auch so anordnen, dass wir sie nach unten hin ausfüllen müssen:\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  arrange(Measurement, desc(Facility))\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47    NA\n 3           1 Hosp 2      71    NA\n 4           1 Hosp 1      66    NA\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70    NA\n 7           2 Hosp 2      62    NA\n 8           2 Hosp 1      26    NA\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38    NA\n11           3 Hosp 2      70    NA\n12           3 Hosp 1       8    NA\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  fill(Year, .direction = \"down\")\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47  2000\n 3           1 Hosp 2      71  2000\n 4           1 Hosp 1      66  2000\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70  2001\n 7           2 Hosp 2      62  2001\n 8           2 Hosp 1      26  2001\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38  2002\n11           3 Hosp 2      70  2002\n12           3 Hosp 1       8  2002\n\n\nJetzt haben wir einen brauchbaren Datensatz zum Plotten:\n\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\n\n\n\n\n\n\n\n\nFür die Darstellung in einer Tabelle ist er jedoch weniger geeignet. Deshalb wollen wir uns darin üben, diesen langen, unordentlichen Datenrahmen in einen breiteren, ordentlichen Datenrahmen umzuwandeln:\n\ndf_combined %&gt;% \n  pivot_wider(\n    id_cols = c(Measurement, Facility),\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  arrange(Facility) %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% \n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 5, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\nTotal\n\n\n\n\n1\nHosp 1\n66\nNA\nNA\n66\n\n\n2\nHosp 1\nNA\n26\nNA\n26\n\n\n3\nHosp 1\nNA\nNA\n8\n8\n\n\n1\nHosp 2\n71\nNA\nNA\n71\n\n\n2\nHosp 2\nNA\n62\nNA\n62\n\n\n3\nHosp 2\nNA\nNA\n70\n70\n\n\n1\nHosp 3\n47\nNA\nNA\n47\n\n\n2\nHosp 3\nNA\n70\nNA\n70\n\n\n3\nHosp 3\nNA\nNA\n38\n38\n\n\n1\nHosp 4\n82\nNA\nNA\n82\n\n\n2\nHosp 4\nNA\n87\nNA\n87\n\n\n3\nHosp 4\nNA\nNA\n46\n46\n\n\nTotal\n-\n266\n245\n162\n673\n\n\n\n\n\n\n\n\nN.B. In diesem Fall mussten wir festlegen, dass nur die drei Variablen enthalten sind Facility, Year, und Cases als die zusätzliche Variable Measurement bei der Erstellung der Tabelle stören würde:\n\ndf_combined %&gt;% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  knitr::kable()\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\n\n\n\n\n1\nHosp 4\n82\nNA\nNA\n\n\n1\nHosp 3\n47\nNA\nNA\n\n\n1\nHosp 2\n71\nNA\nNA\n\n\n1\nHosp 1\n66\nNA\nNA\n\n\n2\nHosp 4\nNA\n87\nNA\n\n\n2\nHosp 3\nNA\n70\nNA\n\n\n2\nHosp 2\nNA\n62\nNA\n\n\n2\nHosp 1\nNA\n26\nNA\n\n\n3\nHosp 4\nNA\nNA\n46\n\n\n3\nHosp 3\nNA\nNA\n38\n\n\n3\nHosp 2\nNA\nNA\n70\n\n\n3\nHosp 1\nNA\nNA\n8",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Daten pivotieren</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.de.html#ressourcen",
    "href": "new_pages/pivoting.de.html#ressourcen",
    "title": "12  Daten pivotieren",
    "section": "12.5 Ressourcen",
    "text": "12.5 Ressourcen\nHier ist eine hilfreiche Anleitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Daten pivotieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html",
    "href": "new_pages/grouping.de.html",
    "title": "13  Daten gruppieren",
    "section": "",
    "text": "13.1 Vorbereitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#vorbereitung",
    "href": "new_pages/grouping.de.html#vorbereitung",
    "title": "13  Daten gruppieren",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,       # to import data\n  here,      # to locate files\n  tidyverse, # to clean, handle, and plot the data (includes dplyr)\n  janitor)   # adding total rows and columns\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Der Datensatz wird importiert mit dem import() Funktion aus der rioPaket. Siehe die Seite über [Import und Export] für verschiedene Möglichkeiten, Daten zu importieren.\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen von linelist:",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#gruppierung",
    "href": "new_pages/grouping.de.html#gruppierung",
    "title": "13  Daten gruppieren",
    "section": "13.2 Gruppierung",
    "text": "13.2 Gruppierung\nDie Funktion group_by() von dplyr gruppiert die Zeilen nach den eindeutigen Werten in der angegebenen Spalte. Wenn mehrere Spalten angegeben sind, werden die Zeilen nach den eindeutigen Wertekombinationen der Spalten gruppiert. Jeder eindeutige Wert (oder jede Kombination von Werten) bildet eine Gruppe. Spätere Änderungen am Datensatz oder Berechnungen können dann im Kontext der einzelnen Gruppen durchgeführt werden.\nDer folgende Befehl nimmt zum Beispiel die linelist und gruppiert die Zeilen nach eindeutigen Werten in der Spalte outcome und speichert die Ausgabe als neuen Datenrahmen ll_by_outcome. Die Gruppierungsspalte(n) werden innerhalb der Klammern der Funktion platziert group_by().\n\nll_by_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\nBeachten Sie, dass sich der Datensatz nicht merklich verändert nach der Ausführung group_by(), bis eine andere dplyr Verb wie zum Beispiel mutate(), summarise(), oder arrange() wird auf den “gruppierten” Datenrahmen angewendet.\nDu kannst die Gruppierungen jedoch “sehen”, wenn du den Datenrahmen druckst. Wenn du einen gruppierten Datenrahmen ausdruckst, wirst du sehen, dass er in ein Feld umgewandelt wurde. tibble Klassenobjekt umgewandelt, das beim Drucken anzeigt, welche Gruppierungen angewendet wurden und wie viele Gruppen es gibt - direkt über der Kopfzeile.\n\n# print to see which groups are active\nll_by_outcome\n\n# A tibble: 5,888 × 30\n# Groups:   outcome [3]\n   case_id generation date_infection date_onset date_hospitalisation\n   &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;              \n 1 5fe599           4 2014-05-08     2014-05-13 2014-05-15          \n 2 8689b7           4 NA             2014-05-13 2014-05-14          \n 3 11f8ea           2 NA             2014-05-16 2014-05-18          \n 4 b8812a           3 2014-05-04     2014-05-18 2014-05-20          \n 5 893f25           3 2014-05-18     2014-05-21 2014-05-22          \n 6 be99c8           3 2014-05-03     2014-05-22 2014-05-23          \n 7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29          \n 8 369449           4 2014-05-28     2014-06-02 2014-06-03          \n 9 f393b4           4 NA             2014-06-05 2014-06-06          \n10 1389ca           4 NA             2014-06-05 2014-06-07          \n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_outcome &lt;date&gt;, outcome &lt;chr&gt;, gender &lt;chr&gt;,\n#   age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;,\n#   hospital &lt;chr&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;,\n#   wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;,\n#   cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;,\n#   bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\nEindeutige Gruppen\nDie erstellten Gruppen spiegeln jede einzigartige Kombination von Werten in den Gruppierungsspalten wider.\nUm die Gruppen zu sehen und die Anzahl der Zeilen in jeder Gruppe übergibst du die gruppierten Daten an tally(). Um nur die eindeutigen Gruppen ohne Zählung zu sehen, kannst du die Daten an group_keys().\nSiehe unten, dass es drei eindeutige Werte in der Gruppierungsspalte outcome: “Tod”, “Genesung”, und NA. Sie sehen, dass es nrow(linelist %&gt;% filter(outcome == \"Death\")) Todesfälle, nrow(linelist %&gt;% filter(outcome == \"Recover\")) Genesungen, und nrow(linelist %&gt;% filter(is.na(outcome))) ohne Ergebnis aufgezeichnet.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally()\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\nDu kannst nach mehr als einer Spalte gruppieren. Unten ist der Datenrahmen gruppiert nach outcome und gender gruppiert und dann summiert. Beachte, wie jede einzelne Kombination von outcome und gender als eigene Gruppe registriert wird - einschließlich fehlender Werte für beide Spalten.\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally()\n\n# A tibble: 9 × 3\n# Groups:   outcome [3]\n  outcome gender     n\n  &lt;chr&gt;   &lt;chr&gt;  &lt;int&gt;\n1 Death   f       1227\n2 Death   m       1228\n3 Death   &lt;NA&gt;     127\n4 Recover f        953\n5 Recover m        950\n6 Recover &lt;NA&gt;      80\n7 &lt;NA&gt;    f        627\n8 &lt;NA&gt;    m        625\n9 &lt;NA&gt;    &lt;NA&gt;      71\n\n\n\n\nNeue Spalten\nDu kannst auch eine neue Gruppierungsspalte erstellen innerhalb von der group_by() Anweisung. Dies ist gleichbedeutend mit dem Aufruf mutate() vor der group_by(). Für eine schnelle Tabellierung kann dieser Stil praktisch sein, aber für mehr Klarheit in deinem Code solltest du diese Spalte in einer eigenen Spalte erstellen mutate() Schritt zu erstellen und dann per Piping an group_by().\n\n# group dat based on a binary column created *within* the group_by() command\nlinelist %&gt;% \n  group_by(\n    age_class = ifelse(age &gt;= 18, \"adult\", \"child\")) %&gt;% \n  tally(sort = T)\n\n# A tibble: 3 × 2\n  age_class     n\n  &lt;chr&gt;     &lt;int&gt;\n1 child      3618\n2 adult      2184\n3 &lt;NA&gt;         86\n\n\n\n\nGruppierungsspalten hinzufügen/verwerfen\nWenn du standardmäßig group_by() auf Daten anwendest, die bereits gruppiert sind, werden die alten Gruppen entfernt und die neue(n) Gruppe(n) wird/werden angewendet. Wenn du neue Gruppen zu den bestehenden Gruppen hinzufügen möchtest, füge das Argument .add = TRUE.\n\n# Grouped by outcome\nby_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\n# Add grouping by gender in addition\nby_outcome_gender &lt;- by_outcome %&gt;% \n  group_by(gender, .add = TRUE)\n\n** Alle Gruppen beibehalten**\nWenn du nach einer Spalte eines Klassenfaktors gruppierst, kann es sein, dass es Ebenen des Faktors gibt, die derzeit nicht in den Daten vorhanden sind. Wenn du nach dieser Spalte gruppierst, werden diese nicht vorhandenen Stufen standardmäßig ausgelassen und nicht als Gruppen berücksichtigt. Um dies zu ändern, damit alle Ebenen als Gruppen erscheinen (auch wenn sie nicht in den Daten vorhanden sind), setze .drop = FALSE in deiner group_by() Befehl ein.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#un-group",
    "href": "new_pages/grouping.de.html#un-group",
    "title": "13  Daten gruppieren",
    "section": "13.3 Un-group",
    "text": "13.3 Un-group\nDaten, die gruppiert wurden, bleiben gruppiert, bis die Gruppierung über ungroup(). Wenn du vergisst, die Gruppierung aufzuheben, kann das zu falschen Berechnungen führen! Im Folgenden siehst du ein Beispiel für das Aufheben aller Gruppierungen:\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup()\n\nDu kannst die Gruppierung auch nur für bestimmte Spalten aufheben, indem du den Spaltennamen in ungroup().\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup(gender) # remove the grouping by gender, leave grouping by outcome\n\nHINWEIS: Das Verb count() hebt die Gruppierung der Daten nach dem Zählen automatisch auf.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#zusammenfassen-group_summarise",
    "href": "new_pages/grouping.de.html#zusammenfassen-group_summarise",
    "title": "13  Daten gruppieren",
    "section": "13.4 Zusammenfassen {#group_summarise}",
    "text": "13.4 Zusammenfassen {#group_summarise}\nSiehe die dplyrAbschnitt der [Beschreibende Tabellen] Seite für eine ausführliche Beschreibung, wie man zusammenfassende Tabellen mitsummarise(). Hier gehen wir kurz darauf ein, wie sich das Verhalten bei der Anwendung auf gruppierte Daten ändert.\nDie dplyr Funktion summarise() (oder summarize()) nimmt einen Datenrahmen und wandelt ihn in eine neuen Datenrahmen um, dessen Spalten die von dir definierten Zusammenfassungsstatistiken enthalten. Bei einem nicht gruppierten Datenrahmen wird die zusammenfassende Statistik aus allen Zeilen berechnet. Anwenden von summarise() auf gruppierte Daten werden diese Zusammenfassungsstatistiken für jede Gruppe.\nDie Syntax von summarise() ist so aufgebaut, dass du den/die Namen der neuen Zusammenfassungsspalte(n), ein Gleichheitszeichen und eine statistische Funktion angibst, die auf die Daten angewendet werden soll, wie unten gezeigt. Zum Beispiel, min(), max(), median(), oder sd(). In der statistischen Funktion gibst du die zu bearbeitende Spalte und alle relevanten Argumente an (z. B. na.rm = TRUE). Du kannst verwenden sum() kannst du die Anzahl der Zeilen zählen, die ein logisches Kriterium erfüllen (mit doppelten Gleichheitszeichen ==).\nUnten ist ein Beispiel für summarise() angewandt ohne gruppierte Daten. Die zurückgegebenen Statistiken werden aus dem gesamten Datensatz erstellt.\n\n# summary statistics on ungrouped linelist\nlinelist %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males  = sum(gender == \"m\", na.rm=T))\n\n  n_cases mean_age max_age min_age n_males\n1    5888 16.01831      84       0    2803\n\n\nIm Gegensatz dazu ist unten die gleiche summarise() Anweisung auf gruppierte Daten angewendet. Die Statistiken werden für jede outcome Gruppe berechnet. Beachte, wie die gruppierten Spalten in den neuen Datenrahmen übertragen werden.\n\n# summary statistics on grouped linelist\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males    = sum(gender == \"m\", na.rm=T))\n\n# A tibble: 3 × 6\n  outcome n_cases mean_age max_age min_age n_males\n  &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;\n1 Death      2582     15.9      76       0    1228\n2 Recover    1983     16.1      84       0     950\n3 &lt;NA&gt;       1323     16.2      69       0     625\n\n\nTIPP: Die Funktion “Zusammenfassen” funktioniert sowohl mit britischer als auch mit US-amerikanischer Rechtschreibung - summarise() und summarize() die gleiche Funktion aufrufen.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#zählungen-und-übersichten",
    "href": "new_pages/grouping.de.html#zählungen-und-übersichten",
    "title": "13  Daten gruppieren",
    "section": "13.5 Zählungen und Übersichten",
    "text": "13.5 Zählungen und Übersichten\ncount() und tally() bieten ähnliche Funktionen, sind aber unterschiedlich. Lies mehr über den Unterschied zwischen tally() und count() hier\n\ntally()\ntally() ist die Kurzform für summarise(n = n()), und tut nicht Daten gruppieren. Um gruppierte Summen zu erhalten, muss es also eine group_by() Befehl folgen. Du kannst hinzufügen sort = TRUE um die größten Gruppen zuerst zu sehen.\n\nlinelist %&gt;% \n  tally()\n\n     n\n1 5888\n\n\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally(sort = TRUE)\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\n\n\ncount()\nIm Gegensatz dazu, count() das Folgende:\n\nwendet an. group_by() auf die angegebene(n) Spalte(n)\ngilt summarise() und gibt die Spalte n mit der Anzahl der Zeilen pro Gruppe\nwendet an ungroup()\n\n\nlinelist %&gt;% \n  count(outcome)\n\n  outcome    n\n1   Death 2582\n2 Recover 1983\n3    &lt;NA&gt; 1323\n\n\nGenau wie bei group_by() kannst du eine neue Spalte innerhalb der count() Befehl erstellen:\n\nlinelist %&gt;% \n  count(age_class = ifelse(age &gt;= 18, \"adult\", \"child\"), sort = T)\n\n  age_class    n\n1     child 3618\n2     adult 2184\n3      &lt;NA&gt;   86\n\n\ncount() kann mehrfach aufgerufen werden, wobei die Funktionalität “aufgerollt” wird. Um zum Beispiel die Anzahl der Krankenhäuser für jedes Geschlecht zusammenzufassen, führe den folgenden Befehl aus. Beachte, dass der Name der letzten Spalte aus Gründen der Übersichtlichkeit vom Standardwert “n” geändert wurde (mit name  =).\n\nlinelist %&gt;% \n  # produce counts by unique outcome-gender groups\n  count(gender, hospital) %&gt;% \n  # gather rows by gender (3) and count number of hospitals per gender (6)\n  count(gender, name = \"hospitals per gender\" ) \n\n  gender hospitals per gender\n1      f                    6\n2      m                    6\n3   &lt;NA&gt;                    6\n\n\n\n\nZählungen hinzufügen\nIm Gegensatz zu count() und summarise() kannst du verwenden add_count() zu hinzufügen eine neue Spalte n mit der Anzahl der Zeilen pro Gruppe während alle anderen Spalten des Datenrahmens beibehalten werden.\nDas bedeutet, dass die Zählnummer einer Gruppe in der neuen Spalte n in jeder Zeile der Gruppe gedruckt wird. Zur Veranschaulichung fügen wir diese Spalte hinzu und ordnen die Spalten dann zur besseren Übersicht neu an. Siehe den Abschnitt unten über Filter auf Gruppengröße für ein weiteres Beispiel.\n\nlinelist %&gt;% \n  as_tibble() %&gt;%                   # convert to tibble for nicer printing \n  add_count(hospital) %&gt;%           # add column n with counts by hospital\n  select(hospital, n, everything()) # re-arrange for demo purposes\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\nSummen hinzufügen\nSo addieren Sie ganz einfach die Summe Summe Zeilen oder Spalten nach der Verwendung von tally() oder count() verwenden, siehe die Hausmeister Abschnitt der Beschreibende Tabellen Seite. Dieses Paket bietet Funktionen wie adorn_totals() und adorn_percentages() um Summen zu addieren und zu konvertieren, um Prozentsätze anzuzeigen. Im Folgenden findest du ein kurzes Beispiel:\n\nlinelist %&gt;%                                  # case linelist\n  tabyl(age_cat, gender) %&gt;%                  # cross-tabulate counts of two columns\n  adorn_totals(where = \"row\") %&gt;%             # add a total row\n  adorn_percentages(denominator = \"col\") %&gt;%  # convert to proportions with column denominator\n  adorn_pct_formatting() %&gt;%                  # convert proportions to percents\n  adorn_ns(position = \"front\") %&gt;%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")\n\n                      Gender                            \n Age Category              f              m          NA_\n          0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n          5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n        10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n        15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n        20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n        30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n        50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n          70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n         &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n        Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\nUm komplexere Summenzeilen hinzuzufügen, die andere zusammenfassende Statistiken enthalten als Summen siehe diesen Abschnitt der Seite Beschreibende Tabellen.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#gruppierung-nach-datum",
    "href": "new_pages/grouping.de.html#gruppierung-nach-datum",
    "title": "13  Daten gruppieren",
    "section": "13.6 Gruppierung nach Datum",
    "text": "13.6 Gruppierung nach Datum\nWenn du Daten nach Datum gruppierst, musst du eine Spalte für die gewünschte Datumseinheit haben (oder erstellen) - zum Beispiel “Tag”, “Epiwoche”, “Monat” usw. Du kannst diese Spalte erstellen mit floor_date() von lubridate, wie in der Abschnitt Epidemiologische Wochender [Arbeiten mit Daten] Seite. Sobald du diese Spalte hast, kannst ducount() von dplyr um die Zeilen nach diesen eindeutigen Datumswerten zu gruppieren und die Zählungen zu aggregieren.\nEin zusätzlicher Schritt, der bei Datumsangaben üblich ist, besteht darin, alle Datumsangaben in der Sequenz auszufüllen, die nicht in den Daten enthalten sind. Verwende complete() von tidyr so dass die aggregierte Datumsreihe lautet vollständig einschließlich alle möglichen Datumseinheiten innerhalb des Bereichs. Ohne diesen Schritt würde eine Woche, in der keine Fälle gemeldet wurden, möglicherweise nicht in deinen Daten erscheinen!\nUnter complete() du definiereneu deine Datumsspalte als Folge von Daten seq.Date() vom Minimum zum Maximum - die Daten werden also erweitert. Standardmäßig werden die Fallzahlenwerte in allen neuen “erweiterten” Zeilen wie folgt lauten NA. Du kannst sie auf 0 setzen, indem du die fill = Argument von complete() verwenden, das eine benannte Liste erwartet (wenn deine Zählspalte den Namen n ist, geben Sie fill = list(n = 0). Siehe ?complete für Details und die Arbeiten mit Daten Seite für ein Beispiel.\n\nFälle in Tagen auflisten\nHier ist ein Beispiel für die Gruppierung von Fällen nach Tagen ohne mit complete(). Beachte, dass die ersten Zeilen die Daten ohne Fälle überspringen.\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%        # remove that were missing date_onset\n  count(date_onset)              # count number of rows per unique date\n\n\n\n\n\n\n\nDarunter fügen wir die complete() Befehl hinzu, um sicherzustellen, dass jeder Tag im Bereich vertreten ist.\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%                 # remove case missing date_onset\n  count(date_onset) %&gt;%                   # count number of rows per unique date\n  complete(                               # ensure all days appear even if no cases\n    date_onset = seq.Date(                # re-define date colume as daily sequence of dates\n      from = min(date_onset, na.rm=T), \n      to = max(date_onset, na.rm=T),\n      by = \"day\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) \n\n\n\n\n\n\n\n\n\nFälle in Wochen auflisten\nDas gleiche Prinzip kann für Wochen angewendet werden. Erstelle zunächst eine neue Spalte, die die Woche des Falles enthält, indem du floor_date() mit unit = \"week\". Verwenden Sie dann count() wie oben, um wöchentliche Fallzahlen zu erhalten. Beende mit complete() um sicherzustellen, dass alle Wochen vertreten sind, auch wenn sie keine Fälle enthalten.\n\n# Make dataset of weekly case counts\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%                 # remove cases missing date_onset\n  mutate(week = lubridate::floor_date(date_onset, unit = \"week\")) %&gt;%  # new column of week of onset\n  count(week) %&gt;%                         # group data by week and count rows per group\n  complete(                               # ensure all days appear even if no cases\n    week = seq.Date(                      # re-define date colume as daily sequence of dates\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) \n\nHier sind die ersten 50 Zeilen des resultierenden Datenrahmens:\n\n\n\n\n\n\n\n\nLinelist Fälle nach Monaten\nUm Fälle nach Monaten zu aggregieren, verwende wieder floor_date() aus dem lubridate Paket, aber mit dem Argument unit = \"months\". Dadurch wird jedes Datum auf den 1. des Monats abgerundet. Die Ausgabe ist dann die Klasse Date. Beachte, dass in der complete() Schritt verwenden wir auch by = \"months\".\n\n# Make dataset of monthly case counts\nmonthly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;% \n  mutate(month = lubridate::floor_date(date_onset, unit = \"months\")) %&gt;%  # new column, 1st of month of onset\n  count(month) %&gt;%                          # count cases by month\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # include all months with no cases reported\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))\n\n\n\n\n\n\n\n\n\nTägliche Zählungen in Wochen\nUm tägliche Zählungen zu wöchentlichen Zählungen zu aggregieren, verwende floor_date() wie oben. Verwende jedoch group_by() und summarize() anstelle von count() denn du musst sum() tägliche Fallzahlen, anstatt nur die Anzahl der Zeilen pro Woche zu zählen.\n\nTägliche Zählungen in Monaten\nUm tägliche Zählungen zu Monatszählungen zu aggregieren, verwende floor_date() mit unit = \"month\" wie oben. Verwende jedoch group_by() und summarize() anstelle von count() denn du musst sum() tägliche Fallzahlen, anstatt nur die Anzahl der Zeilen pro Monat zu zählen.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#gruppierte-daten-anordnen",
    "href": "new_pages/grouping.de.html#gruppierte-daten-anordnen",
    "title": "13  Daten gruppieren",
    "section": "13.7 Gruppierte Daten anordnen",
    "text": "13.7 Gruppierte Daten anordnen\nVerwenden der dplyr Verb arrange() um die Zeilen in einem Datenrahmen zu ordnen, verhält sich gleich, wenn die Daten gruppiert sind, es sei denn, du setzt das Argument .by_group =TRUE. In diesem Fall werden die Zeilen zuerst nach den Gruppierungsspalten und dann nach allen anderen Spalten geordnet, die du mit arrange().",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#auf-gruppierte-daten-filtern",
    "href": "new_pages/grouping.de.html#auf-gruppierte-daten-filtern",
    "title": "13  Daten gruppieren",
    "section": "13.8 Auf gruppierte Daten filtern",
    "text": "13.8 Auf gruppierte Daten filtern\n\nfilter()\nBei der Anwendung in Verbindung mit Funktionen, die den Datenrahmen auswerten (wie max(), min(), mean()), werden diese Funktionen jetzt auf die Gruppen angewendet. Wenn du zum Beispiel Zeilen filtern und behalten möchtest, in denen das Durchschnittsalter der Patienten über dem Median liegt, wird dies nun pro Gruppe angewendet - die Filterung, um Zeilen über dem der Gruppe Medianalter der Gruppe.\n\n\nScheibenreihen pro Gruppe\nDie dplyr Funktion slice(), die Zeilen anhand ihrer Position filtert in den Daten filtert, kann auch pro Gruppe angewendet werden. Vergiss nicht, die Daten innerhalb jeder Gruppe zu sortieren, um den gewünschten “Slice” zu erhalten.\nWenn du zum Beispiel nur die letzten 5 Einweisungen aus jedem Krankenhaus abrufen möchtest:\n\nGruppiere die Zeilenliste nach Spalte hospital\nOrdne die Datensätze vom jüngsten zum frühesten an date_hospitalisation innerhalb jeder Krankenhausgruppe\nSchneide, um die ersten 5 Zeilen von jedem Krankenhaus abzurufen\n\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  arrange(hospital, date_hospitalisation) %&gt;%\n  slice_head(n = 5) %&gt;% \n  arrange(hospital) %&gt;%                            # for display\n  select(case_id, hospital, date_hospitalisation)  # for display\n\n# A tibble: 30 × 3\n# Groups:   hospital [6]\n   case_id hospital          date_hospitalisation\n   &lt;chr&gt;   &lt;chr&gt;             &lt;date&gt;              \n 1 20b688  Central Hospital  2014-05-06          \n 2 d58402  Central Hospital  2014-05-10          \n 3 b8f2fd  Central Hospital  2014-05-13          \n 4 acf422  Central Hospital  2014-05-28          \n 5 275cc7  Central Hospital  2014-05-28          \n 6 d1fafd  Military Hospital 2014-04-17          \n 7 974bc1  Military Hospital 2014-05-13          \n 8 6a9004  Military Hospital 2014-05-13          \n 9 09e386  Military Hospital 2014-05-14          \n10 865581  Military Hospital 2014-05-15          \n# ℹ 20 more rows\n\n\nslice_head() - wählt n Zeilen von oben aus\nslice_tail() - wählt n Zeilen vom Ende her aus\nslice_sample() - wählt zufällig n Zeilen aus\nslice_min() - wählt n Zeilen mit den höchsten Werten in order_by = Spalte, verwendet with_ties = TRUE um Gleichstände zu erhalten\nslice_max() - wählt n Zeilen mit den niedrigsten Werten in order_by = Spalte, verwende with_ties = TRUE um Gleichstände zu erhalten\nSiehe die [De-Duplizierung] Seite für weitere Beispiele und Details zuslice().\n\n\n13.8.1 Filter nach Gruppengröße {#group_filter_grp_size .unnumbered}\nDie Funktion add_count() fügt eine Spalte hinzu n zu den Originaldaten hinzu, die die Anzahl der Zeilen in der Gruppe dieser Zeile angibt.\nUnten abgebildet, add_count() wird auf die Spalte hospital angewendet, so dass die Werte in der neuen Spalte n die Anzahl der Zeilen in der Krankenhausgruppe dieser Zeile widerspiegeln. Beachte, wie die Werte in der Spalte n wiederholt werden. Im folgenden Beispiel wird der Spaltenname n geändert werden mit name = innerhalb von add_count(). Zu Demonstrationszwecken ordnen wir die Spalten neu an mit select().\n\nlinelist %&gt;% \n  as_tibble() %&gt;% \n  add_count(hospital) %&gt;%          # add \"number of rows admitted to same hospital as this row\" \n  select(hospital, n, everything())\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\nDann ist es einfach, nach Fallzeilen zu filtern, die in einem “kleinen” Krankenhaus aufgenommen wurden, z. B. in einem Krankenhaus, das weniger als 500 Patienten aufnimmt:\n\nlinelist %&gt;% \n  add_count(hospital) %&gt;% \n  filter(n &lt; 500)",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#auf-gruppierten-daten-mutieren",
    "href": "new_pages/grouping.de.html#auf-gruppierten-daten-mutieren",
    "title": "13  Daten gruppieren",
    "section": "13.9 Auf gruppierten Daten mutieren",
    "text": "13.9 Auf gruppierten Daten mutieren\nUm alle Spalten und Zeilen beizubehalten (nicht zusammenzufassen) und eine neue Spalte mit Gruppenstatistiken hinzufügen verwenden mutate() nach group_by() anstelle von summarise().\nDies ist nützlich, wenn du Gruppenstatistiken im Originaldatensatz haben möchtest und alle anderen Spalten vorhanden sind - z.B. für Berechnungen, die eine Zeile mit ihrer Gruppe vergleichen.\nDer folgende Code berechnet zum Beispiel die Differenz zwischen der Wartezeit bis zur Einweisung einer Zeile und dem Medianwert für das jeweilige Krankenhaus. Die Schritte sind:\n\nGruppiere die Daten nach Krankenhaus\nVerwenden Sie die Spalte days_onset_hosp (Verzögerung bis zum Krankenhausaufenthalt), um eine neue Spalte zu erstellen, die die durchschnittliche Verzögerung im Krankenhaus von dieser Zeile\nBerechne die Differenz zwischen den beiden Spalten\n\nWir select() zu Demonstrationszwecken nur bestimmte Spalten anzeigen.\n\nlinelist %&gt;% \n  # group data by hospital (no change to linelist yet)\n  group_by(hospital) %&gt;% \n  \n  # new columns\n  mutate(\n    # mean days to admission per hospital (rounded to 1 decimal)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),\n    \n    # difference between row's delay and mean delay at their hospital (rounded to 1 decimal)\n    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %&gt;%\n  \n  # select certain rows only - for demonstration/viewing purposes\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)\n\n# A tibble: 5,888 × 5\n# Groups:   hospital [6]\n   case_id hospital              days_onset_hosp group_delay_admit diff_to_group\n   &lt;chr&gt;   &lt;chr&gt;                           &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 5fe599  Other                               2               2             0  \n 2 8689b7  Missing                             1               2.1          -1.1\n 3 11f8ea  St. Mark's Maternity…               2               2.1          -0.1\n 4 b8812a  Port Hospital                       2               2.1          -0.1\n 5 893f25  Military Hospital                   1               2.1          -1.1\n 6 be99c8  Port Hospital                       1               2.1          -1.1\n 7 07e3e8  Missing                             2               2.1          -0.1\n 8 369449  Missing                             1               2.1          -1.1\n 9 f393b4  Missing                             1               2.1          -1.1\n10 1389ca  Missing                             2               2.1          -0.1\n# ℹ 5,878 more rows",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#auf-gruppierte-daten-auswählen",
    "href": "new_pages/grouping.de.html#auf-gruppierte-daten-auswählen",
    "title": "13  Daten gruppieren",
    "section": "13.10 Auf gruppierte Daten auswählen",
    "text": "13.10 Auf gruppierte Daten auswählen\nDas Verb select() funktioniert bei gruppierten Daten, aber die Gruppierungsspalten sind immer enthalten (auch wenn sie nicht in select()). Wenn du diese Gruppierungsspalten nicht möchtest, verwende ungroup() zuerst.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.de.html#ressourcen",
    "href": "new_pages/grouping.de.html#ressourcen",
    "title": "13  Daten gruppieren",
    "section": "13.11 Ressourcen",
    "text": "13.11 Ressourcen\nHier sind einige nützliche Quellen für weitere Informationen:\nDu kannst jede Zusammenfassungsfunktion auf gruppierte Daten anwenden; siehe die RStudio Spickzettel zur Datentransformation\nDie Data Carpentry Seite auf dplyr\nDie tidyverse Referenzseiten auf group_by() und gruppieren\nDiese Seite auf Datenmanipulation\nZusammenfassen mit Bedingungen in dplyr",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Daten gruppieren</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.de.html",
    "href": "new_pages/joining_matching.de.html",
    "title": "14  Daten verknüpfen",
    "section": "",
    "text": "14.1 Vorbereitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Daten verknüpfen</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.de.html#vorbereitung",
    "href": "new_pages/joining_matching.de.html#vorbereitung",
    "title": "14  Daten verknüpfen",
    "section": "",
    "text": "Pakete laden\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,            # import and export\n  here,           # locate files \n  tidyverse,      # data management and visualisation\n  RecordLinkage,  # probabilistic matches\n  fastLink        # probabilistic matches\n)\n\n\n\nDaten importieren\nZunächst importieren wir die bereinigte Liste der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import case linelist \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.\n\n\n\n\n\n\n\n\n\nBeispiel-Datensätze\nIm folgenden Abschnitt über das Verbinden werden wir die folgenden Datensätze verwenden:\n\nEine “Miniatur”-Version des Falls linelist, die nur die Spalten case_id, date_onset, und hospital, und nur die ersten 10 Zeilen\nEin separater Datenrahmen namens hosp_info, der mehr Details über jedes Krankenhaus enthält\n\nIm Abschnitt über das probabilistische Matching werden wir zwei verschiedene kleine Datensätze verwenden. Den Code zur Erstellung dieser Datensätze findest du in diesem Abschnitt.\n\n14.1.0.1 “Miniatur”-Fall-Lineliste {#joins_llmini .unnumbered}\nHier ist die Miniatur-Fallliste, die nur 10 Zeilen und nur Spalten enthält case_id, date_onset, und hospital.\n\nlinelist_mini &lt;- linelist %&gt;%                 # start with original linelist\n  select(case_id, date_onset, hospital) %&gt;%   # select columns\n  head(10)                                    # only take the first 10 rows\n\n\n\n\n\n\n\n\n\n14.1.0.2 Datenrahmen für Krankenhausinformationen {#joins_hosp_info .unnumbered}\nIm Folgenden findest du den Code zur Erstellung eines separaten Datenrahmens mit zusätzlichen Informationen über sieben Krankenhäuser (Einzugsgebiet und Versorgungsstufe). Beachte, dass der Name “Militärkrankenhaus” zu zwei verschiedenen Krankenhäusern gehört - das eine ist ein Krankenhaus der Primärebene mit 10000 Einwohnern und das andere ein Krankenhaus der Sekundärebene mit 50280 Einwohnern.\n\n# Make the hospital information data frame\nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\", \"Secondary\", \"Primary\", \"Primary\")\n)\n\nHier ist dieser Datenrahmen:\n\n\n\n\n\n\n\n\n\n\nVor-Reinigung\nHerkömmliche (nicht-probabilistische) Verknüpfungen unterscheiden Groß- und Kleinschreibung und erfordern exakte Zeichenübereinstimmungen zwischen den Werten in den beiden Datenrahmen. Um einige der Bereinigungsschritte zu veranschaulichen, die du vor einem Join durchführen musst, bereinigen und richten wir die linelist_mini und hosp_info Datensätze bereinigen und abgleichen.\nUnterschiede erkennen\nWir brauchen die Werte der hosp_name Spalte in der hosp_info Datenrahmens mit den Werten der hospital Spalte in der linelist_mini Datenrahmens anzupassen.\nHier sind die Werte in der linelist_mini Datenrahmen, gedruckt mit dem Basis R-Funktion unique():\n\nunique(linelist_mini$hospital)\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n\n\nund hier sind die Werte in der hosp_info Datenrahmen:\n\nunique(hosp_info$hosp_name)\n\n[1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"      \n[5] \"ignace\"           \"sisters\"         \n\n\nDu kannst sehen, dass einige der Krankenhäuser zwar in beiden Datenrahmen vorhanden sind, es aber viele Unterschiede in der Schreibweise gibt.\nWerte abgleichen\nWir beginnen mit dem Bereinigen der Werte in der hosp_infoDatenrahmen. Wie im Abschnitt [Datenbereinigung und Kernfunktionen] erklärt, können wir Werte mit logischen Kriterien neu kodieren, indem wirdplyr’s case_when() Funktion. Für die vier Krankenhäuser, die in beiden Datenrahmen vorhanden sind, ändern wir die Werte, um sie an die Werte in linelist_mini. Für die anderen Krankenhäuser belassen wir die Werte so, wie sie sind (TRUE ~ hosp_name).\nVORSICHT! Normalerweise sollte man beim Reinigen eine neue Spalte erstellen (z.B. hosp_name_clean), aber zur Veranschaulichung zeigen wir die Änderung der alten Spalte\n\nhosp_info &lt;- hosp_info %&gt;% \n  mutate(\n    hosp_name = case_when(\n      # criteria                         # new value\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\n\nDie Namen der Krankenhäuser, die in beiden Datenrahmen vorkommen, werden angeglichen. Es gibt zwei Krankenhäuser in hosp_info die nicht in den linelist_mini - Wir werden uns mit diesen später in der Verknüpfung befassen.\n\nunique(hosp_info$hosp_name)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Port Hospital\"                       \n[4] \"St. Mark's Maternity Hospital (SMMH)\"\n[5] \"ignace\"                              \n[6] \"sisters\"                             \n\n\nVor einer Verknüpfung ist es oft am einfachsten, eine Spalte ganz in Klein- oder Großbuchstaben umzuwandeln. Wenn du alle Werte in einer Spalte in Groß- oder Kleinbuchstaben umwandeln musst, verwende mutate() und verpacke die Spalte mit einer der folgenden Funktionen aus stringrein, wie es auf der Seite über [Zeichen und Zeichenketten].\nstr_to_upper()\nstr_to_upper()\nstr_to_title()",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Daten verknüpfen</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.de.html#dplyr-verbindet",
    "href": "new_pages/joining_matching.de.html#dplyr-verbindet",
    "title": "14  Daten verknüpfen",
    "section": "14.2 dplyr verbindet",
    "text": "14.2 dplyr verbindet\nDie dplyr Paket bietet mehrere verschiedene Join-Funktionen. dplyr ist enthalten in der tidyverse Paket enthalten. Diese Verknüpfungsfunktionen werden im Folgenden mit einfachen Anwendungsfällen beschrieben.\nVielen Dank an https://github.com/gadenbuie für die informativen Gifs!\n\n\nAllgemeine Syntax\nDie Join-Befehle können als eigenständige Befehle ausgeführt werden, um zwei Datenrahmen zu einem neuen Objekt zu verbinden, oder sie können innerhalb einer Pipe-Kette verwendet werden (%&gt;%) verwendet werden, um einen Datenrahmen mit einem anderen zusammenzuführen, während dieser bereinigt oder anderweitig verändert wird.\nIn dem folgenden Beispiel wird die Funktion left_join() als eigenständiger Befehl verwendet, um einen neuen joined_data Datenrahmen zu erstellen. Die Eingaben sind die Datenrahmen 1 und 2 (df1 und df2). Der erste aufgelistete Datenrahmen ist der Basisdatenrahmen, und der zweite ist mit dem zu verbunden.\nDas dritte Argument by = gibst du die Spalten in jedem Datenrahmen an, die zum Ausrichten der Zeilen in den beiden Datenrahmen verwendet werden sollen. Wenn die Namen dieser Spalten unterschiedlich sind, gibst du sie in einer c() Vektor an, wie unten gezeigt, wobei die Zeilen auf der Grundlage gemeinsamer Werte zwischen den Spalten abgeglichen werden ID in df1 und der Spalte identifier in df2.\n\n# Join based on common values between column \"ID\" (first data frame) and column \"identifier\" (second data frame)\njoined_data &lt;- left_join(df1, df2, by = c(\"ID\" = \"identifier\"))\n\nWenn die by Spalten in beiden Datenrahmen genau denselben Namen haben, kannst du nur diesen einen Namen in Anführungszeichen angeben.\n\n# Joint based on common values in column \"ID\" in both data frames\njoined_data &lt;- left_join(df1, df2, by = \"ID\")\n\nWenn du die Datenrahmen auf der Grundlage gemeinsamer Werte in mehreren Feldern verbindest, führe diese Felder in der Spalte c() Vektor auf. In diesem Beispiel werden Zeilen verbunden, wenn die Werte in drei Spalten in jedem Datensatz genau übereinstimmen.\n\n# join based on same first name, last name, and age\njoined_data &lt;- left_join(df1, df2, by = c(\"name\" = \"firstname\", \"surname\" = \"lastname\", \"Age\" = \"age\"))\n\nDie Join-Befehle können auch innerhalb einer Pipe-Kette ausgeführt werden. Dadurch wird der Datenrahmen, der über die Pipeline übertragen wird, geändert.\nIm folgenden Beispiel, df1 wird durch die Pipes geleitet, df2 wird mit ihr verbunden, und df wird so verändert und neu definiert.\n\ndf1 &lt;- df1 %&gt;%\n  filter(date_onset &lt; as.Date(\"2020-03-05\")) %&gt;% # miscellaneous cleaning \n  left_join(df2, by = c(\"ID\" = \"identifier\"))    # join df2 to df1\n\nVORSICHT! Bei der Verknüpfung wird zwischen Groß- und Kleinschreibung unterschieden! Deshalb ist es sinnvoll, alle Werte vor der Verknüpfung in Klein- oder Großbuchstaben umzuwandeln. Siehe die Seite über Zeichen/Strings.\n\n\n\nLinke und rechte Fugen\nEine linke oder rechte Verknüpfung wird üblicherweise verwendet, um einem Datenrahmen Informationen hinzuzufügen - Die neuen Informationen werden nur den Zeilen hinzugefügt, die bereits im Basisdatensatz vorhanden sind. Diese Verknüpfungen sind in der Epidemiologie üblich, da sie dazu verwendet werden, Informationen aus einem Datensatz in einen anderen einzufügen.\nBei der Verwendung dieser Verknüpfungen ist die Reihenfolge, in der die Datenrahmen im Befehl geschrieben werden, wichtig*.\n\nIn einer linken Verknüpfung ist die erste geschriebene Datenrahmen ist die Basislinie\nIn einem rechten Verknüpfung ist die zweite geschriebene Datenrahmen ist die Basislinie\n\nAlle Zeilen des Basisdatenrahmens werden beibehalten. Die Informationen in dem anderen (sekundären) Datenrahmen werden mit dem Basisdatenrahmen verbunden nur dann verbunden, wenn es eine Übereinstimmung über die Identifikatorspalte(n. Darüber hinaus:\n\nZeilen im sekundären Datenrahmen, die nicht übereinstimmen, werden gelöscht.\nWenn es viele Basislinienzeilen gibt, die mit einer Zeile im sekundären Datenrahmen übereinstimmen (viele-zu-eins), werden die sekundären Informationen zu jeder übereinstimmenden Grundlinienzeile.\nWenn eine Baseline-Zeile mit mehreren Zeilen im sekundären Datenrahmen übereinstimmt (one-to-many), werden alle Kombinationen angegeben, das heißt neue Zeilen können zu deinem zurückgegebenen Datenrahmen hinzugefügt werden!\n\nAnimierte Beispiele für linke und rechte Joins (Bildquelle)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeispiel\nNachfolgend ist die Ausgabe einer left_join() von hosp_info (sekundärer Datenrahmen, hier ansehen) in linelist_mini (Basisdatenrahmen, hier ansehen). Das Original linelist_mini hat nrow(linelist_mini) Zeilen. Das geänderte linelist_mini wird angezeigt. Beachte das Folgende:\n\nZwei neue Spalten, catchment_pop und level wurden auf der linken Seite von linelist_mini\nAlle ursprünglichen Zeilen des Basisdatenrahmens linelist_mini werden beibehalten\nAlle Originalzeilen des linelist_mini für “Militärkrankenhaus” werden dupliziert, weil sie mit zwei Zeilen im sekundären Datenrahmen übereinstimmen, sodass beide Kombinationen zurückgegeben werden\nDie Join-Identifier-Spalte des sekundären Datensatzes (hosp_name) ist verschwunden, weil sie mit der Bezeichnerspalte im primären Datensatz (hospital)\nWenn eine Basiszeile mit keiner Sekundärzeile übereinstimmte (z. B. wenn hospital “Sonstige” oder “Fehlend” ist), NA (leer) füllt die Spalten aus dem sekundären Datenrahmen aus\nZeilen im sekundären Datenrahmen, die nicht mit dem Basisdatenrahmen übereinstimmen (“Schwestern” und “Ignace”-Krankenhäuser), wurden gelöscht\n\n\nlinelist_mini %&gt;% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in left_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n“Soll ich eine rechte oder eine linke Verknüpfung verwenden?”\nUm die obige Frage zu beantworten, frage dich: “Welcher Datenrahmen sollte alle seine Zeilen behalten?” - nimm diesen als Grundlage. A linke Verknüpfung behält alle Zeilen des ersten Datenrahmens bei, die im Befehl geschrieben wurden, während eine rechte Verknüpfung alle Zeilen des zweiten Datenrahmens beibehält.\nDie beiden folgenden Befehle erzielen das gleiche Ergebnis - 10 Zeilen von hosp_info verbundenen in a linelist_mini Basislinie, aber sie verwenden unterschiedliche Joins. Das Ergebnis ist, dass die Reihenfolge der Spalten unterschiedlich ist, je nachdem, ob hosp_info von rechts (im linken Join) oder von links (im rechten Join) eintrifft. Auch die Reihenfolge der Zeilen kann sich entsprechend verschieben. Diese beiden Folgen können jedoch nachträglich behoben werden, indem du select() um Spalten neu zu ordnen oder arrange() um Zeilen zu sortieren.\n\n# The two commands below achieve the same data, but with differently ordered rows and columns\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\nHier ist das Ergebnis von hosp_info in linelist_mini über einen Left Join (neue Spalten kommen von rechts)\n\n\nWarning in left_join(linelist_mini, hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nHier ist das Ergebnis von hosp_info in linelist_mini über einen Right Join (neue Spalten von links kommend)\n\n\nWarning in right_join(hosp_info, linelist_mini, by = c(hosp_name = \"hospital\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 4 of `x` matches multiple rows in `y`.\nℹ Row 5 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nÜberlege auch, ob dein Anwendungsfall innerhalb einer Rohrkette liegt (%&gt;%). Wenn der Datensatz in den Pipes die Baseline ist, wirst du wahrscheinlich einen Left Join verwenden, um Daten hinzuzufügen.\n\n\n\n\nVollständiger Join\nEin Vollanschluss ist die inklusive der Verknüpfungen - gibt er alle Zeilen aus beiden Datenrahmen zurück.\nWenn es in einem Datenrahmen Zeilen gibt, die im anderen nicht vorhanden sind (weil keine Übereinstimmung gefunden wurde), werden diese in den Datenrahmen aufgenommen und verlängern sich. NA Fehlende Werte werden verwendet, um entstandene Lücken aufzufüllen. Achte beim Zusammenführen genau auf die Anzahl der Spalten und Zeilen, um die Groß- und Kleinschreibung zu beachten und exakte Zeichenübereinstimmungen zu vermeiden.\nDer “Basis”-Datenrahmen ist derjenige, der zuerst in den Befehl geschrieben wird. Wenn du dies änderst, hat das keinen Einfluss darauf, welche Datensätze aus der Verknüpfung zurückgegeben werden, aber es kann sich auf die Reihenfolge der Spalten und Zeilen auswirken und darauf, welche Bezeichnungsspalten beibehalten werden.\n\n\n\n\n\n\n\n\n\nAnimiertes Beispiel für einen vollständigen Join (Bildquelle)\nBeispiel\nNachfolgend ist die Ausgabe einer full_join() von hosp_info (ursprünglich nrow(hosp_info), hier ansehen) in linelist_mini (ursprünglich nrow(linelist_mini), hier ansehen). Beachte das Folgende:\n\nAlle Zeilen der Grundlinie werden beibehalten (linelist_mini)\nZeilen in der Sekundärdatei, die nicht mit der Basislinie übereinstimmen, werden beibehalten (“ignace” und “sisters”), mit Werten in den entsprechenden Spalten der Basislinie case_id und onset mit fehlenden Werten aufgefüllt\nEbenso werden die Zeilen im Basisdatenrahmen, die nicht mit den sekundären Daten übereinstimmen (“Andere” und “Fehlende”), beibehalten und mit sekundären Spalten catchment_pop und level mit fehlenden Werten aufgefüllt\nIm Falle von Eins-zu-Viel- oder Viele-zu-Eins-Übereinstimmungen (z. B. Zeilen für “Militärkrankenhaus”) werden alle möglichen Kombinationen zurückgegeben (was den endgültigen Datenrahmen verlängert)\nNur die Identifizierungsspalte aus der Grundlinie wird beibehalten (hospital)\n\n\nlinelist_mini %&gt;% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in full_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\nInnere Verknüpfung\nEin innerer Join ist die am meisten restriktivste der Verknüpfungen - er gibt nur Zeilen mit Übereinstimmungen in beiden Datenrahmen zurück.\nDas bedeutet, dass die Anzahl der Zeilen im Basisdatenrahmen tatsächlich verringern. Die Anpassung des “Basisdatenrahmens” (der in der Funktion an erster Stelle steht) hat keinen Einfluss darauf, welche Zeilen zurückgegeben werden, aber sie wirkt sich auf die Reihenfolge der Spalten und Zeilen aus und darauf, welche Kennzeichnungsspalten beibehalten werden.\n\n\n\n\n\n\n\n\n\nAnimiertes Beispiel für eine innere Verknüpfung (Bildquelle)\nBeispiel\nNachfolgend ist die Ausgabe einer inner_join() von linelist_mini (Baseline) mit hosp_info (sekundär). Beachte das Folgende:\n\nBasiszeilen, die nicht mit den Sekundärdaten übereinstimmen, werden entfernt (Zeilen, in denen hospital “Fehlt” oder “Andere” ist)\nEbenso werden Zeilen aus dem sekundären Datenrahmen entfernt, die keine Übereinstimmung mit der Baseline haben (Zeilen, bei denen hosp_name “Schwestern” oder “nicht vorhanden” ist)\nNur die Identifikatorspalte aus der Baseline wird beibehalten (hospital)\n\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\nSemi join\nEin Semi-Join ist ein “filternder Join”, der einen anderen Datensatz verwendet nicht um Zeilen oder Spalten hinzuzufügen, sondern um eine Filterung durchzuführen.\nA Semi-Join behält alle Beobachtungen im Basisdaten-Frame, die eine Übereinstimmung im sekundären Daten-Frame haben (es werden jedoch weder neue Spalten hinzugefügt noch Zeilen für Mehrfachübereinstimmungen dupliziert). Lies mehr über diese “filternden” Joins hier.\n\n\n\n\n\n\n\n\n\nAnimiertes Beispiel für einen Semi Join (Bildquelle)\nDer folgende Code gibt zum Beispiel Zeilen aus der hosp_info Datenrahmen zurück, die Übereinstimmungen haben in linelist_mini basierend auf dem Namen des Krankenhauses.\n\nhosp_info %&gt;% \n  semi_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n                             hosp_name catchment_pop     level\n1                    Military Hospital         40500 Secondary\n2                    Military Hospital         10000   Primary\n3                        Port Hospital         50280 Secondary\n4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary\n\n\n\n\n\nAnti join\nDer Anti-Join ist ein weiterer “filternder Join”, der Zeilen im Basisdatenrahmen zurückgibt, die nicht die keine Übereinstimmung im sekundären Datenrahmen haben.\nLies mehr über das Filtern von Joins hier.\nHäufige Szenarien für einen Anti-Join sind die Identifizierung von Datensätzen, die in einem anderen Datenrahmen nicht vorhanden sind, die Behebung von Rechtschreibfehlern in einem Join (Überprüfung von Datensätzen, die haben sollten übereinstimmen sollten), und die Überprüfung von Datensätzen, die nach einem anderen Join ausgeschlossen wurden.\nWie bei right_join() und left_join() ist die Basislinie Datenrahmen (an erster Stelle) ist wichtig. Die zurückgegebenen Zeilen stammen nur aus dem Basisdatenrahmen. In der Grafik unten siehst du, dass die Zeile im sekundären Datenrahmen (lila Zeile 4) nicht zurückgegeben wird, obwohl sie nicht mit der Basislinie übereinstimmt.\n\n\n\n\n\n\n\n\n\nAnimiertes Beispiel für einen Anti-Join (Bildquelle)\n\nEinfach anti_join() Beispiel\nEin einfaches Beispiel: Wir finden die hosp_info Krankenhäuser, die keine Fälle haben, die in linelist_mini. Wir listen auf hosp_info als erstes auf, als Basisdatenrahmen. Die Krankenhäuser, die nicht in der linelist_mini sind, werden zurückgegeben.\n\nhosp_info %&gt;% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n\n\n\n\n\n\n\n\nKomplexe anti_join() Beispiel\nEin weiteres Beispiel: Nehmen wir an, wir haben eine inner_join() zwischen linelist_mini und hosp_info. Dies liefert nur eine Teilmenge der ursprünglichen linelist_mini Datensätze zurück, da einige nicht in hosp_info.\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nZur Überprüfung der linelist_mini Datensätze zu überprüfen, die beim Inner Join ausgeschlossen wurden, können wir einen Anti-Join mit denselben Einstellungen durchführen (linelist_mini wie in der Baseline).\n\nlinelist_mini %&gt;% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\n\n\n\n\nUm die hosp_info Datensätze zu sehen, die im Inner Join ausgeschlossen wurden, können wir auch einen Anti-Join mit hosp_info als Basisdatenrahmen durchführen.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Daten verknüpfen</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.de.html#probabalistischer-abgleich",
    "href": "new_pages/joining_matching.de.html#probabalistischer-abgleich",
    "title": "14  Daten verknüpfen",
    "section": "14.3 Probabalistischer Abgleich",
    "text": "14.3 Probabalistischer Abgleich\nWenn du keinen eindeutigen Identifikator hast, der allen Datensätzen gemeinsam ist, kannst du einen probabilistischen Abgleichsalgorithmus verwenden. Dieser findet Übereinstimmungen zwischen Datensätzen auf der Grundlage von Ähnlichkeiten (z. B. Jaro-Winkler String-Distanz oder numerische Distanz). Nachfolgend ein einfaches Beispiel, das das Paket fastLink .\nPakete laden\n\npacman::p_load(\n  tidyverse,      # data manipulation and visualization\n  fastLink        # record matching\n  )\n\nHier sind zwei kleine Beispieldatensätze, anhand derer wir das probabilistische Matching demonstrieren wollen (cases und test_results):\nHier ist der Code, mit dem die Datensätze erstellt wurden:\n\n# make datasets\n\ncases &lt;- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults &lt;- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )\n\nDie cases Datensatz hat 9 Datensätze von Patienten, die auf Testergebnisse warten.\n\n\n\n\n\n\nDie test_results Datensatz hat 14 Datensätze und enthält die Spalte result die wir zu den Datensätzen in cases basierend auf dem probabilistischen Abgleich der Datensätze.\n\n\n\n\n\n\n\nProbabilistischer Abgleich\nDie fastLink() Funktion aus dem fastLink Paket kann verwendet werden, um einen Matching-Algorithmus anzuwenden. Hier sind die grundlegenden Informationen. Du kannst mehr Details lesen, indem du ?fastLink in deiner Konsole eingibst.\n\nDefiniere die beiden Datenrahmen für den Vergleich mit Argumenten dfA = und dfB =\nIn varnames = gib alle Spaltennamen an, die für den Abgleich verwendet werden sollen. Sie müssen alle in beiden dfA und dfB.\nUnter stringdist.match = geben Sie Spalten aus denen in varnames auf den String “Abstand” ausgewertet werden.\nIn numeric.match = werden die Spalten von denen in varnames auf numerischen Abstand ausgewertet werden.\nFehlende Werte werden ignoriert\nStandardmäßig wird jede Zeile in einem der beiden Datenrahmen mit höchstens einer Zeile im anderen Datenrahmen abgeglichen. Wenn du alle ausgewerteten Übereinstimmungen sehen willst, setze dedupe.matches = FALSE. Die Deduplizierung wird mit der linearen Zuordnungslösung von Winkler durchgeführt.\n\nTipp: Teile eine Datumsspalte in drei separate numerische Spalten auf, indem du day(), month(), und year() von lubridate Paket\nDer Standardschwellenwert für Übereinstimmungen ist 0,94 (threshold.match =), aber du kannst ihn höher oder niedriger einstellen. Wenn du den Schwellenwert festlegst, solltest du bedenken, dass ein höherer Schwellenwert zu mehr falsch-negativen Übereinstimmungen führen kann (Zeilen, die nicht übereinstimmen, obwohl sie eigentlich übereinstimmen sollten) und dass ein niedrigerer Schwellenwert zu mehr falsch-positiven Übereinstimmungen führen kann.\nIm Folgenden werden die Daten anhand der String-Distanz für die Spalten Name und Bezirk und anhand der numerischen Distanz für Jahr, Monat und Tag der Geburt abgeglichen. Als Schwellenwert für die Übereinstimmung wurde eine Wahrscheinlichkeit von 95 % festgelegt.\n\nfl_output &lt;- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nDeduping the estimated matches.\nGetting the match patterns for each estimated match.\n\n\nÜberprüfung Spiele\nWir haben das Objekt definiert, das von fastLink() als fl_output. Es ist von der Klasse list und enthält mehrere Datenrahmen, in denen die Ergebnisse des Abgleichs festgehalten werden. Einer dieser Datenrahmen ist matches Er enthält die wahrscheinlichsten Übereinstimmungen aus cases und results. Du kannst auf diesen “Matches”-Datenrahmen zugreifen mit fl_output$matches. Unten wird er gespeichert als my_matches gespeichert, damit du später leichter darauf zugreifen kannst.\nWenn my_matches gedruckt wird, siehst du zwei Spaltenvektoren: die Paare von Zeilennummern/Indizes (auch “rownames” genannt) in cases (“inds.a”) und in results (“inds.b”), die die besten Übereinstimmungen darstellen. Wenn eine Zeilennummer aus einem Datenrahmen fehlt, wurde in dem anderen Datenrahmen keine Übereinstimmung mit der angegebenen Übereinstimmungsschwelle gefunden.\n\n# print matches\nmy_matches &lt;- fl_output$matches\nmy_matches\n\n  inds.a inds.b\n1      1      1\n2      2      2\n3      3      3\n4      4      4\n5      8      8\n6      7      9\n7      6     10\n8      5     12\n\n\nDinge, die du beachten solltest:\n\nEs gab Übereinstimmungen trotz leichter Unterschiede in der Schreibweise der Namen und der Geburtsdaten:\n\n“Tony B. Smith” wurde mit “Anthony B. Smith” abgeglichen.\n“Maria Rodriguez” mit “Marialisa Rodrigues” abgeglichen\n“Betty Chase” mit “Elizabeth Chase” abgeglichen\n“Olivier Laurent De Bordeaux” mit “Oliver Laurent De Bordow” abgeglichen (fehlendes Geburtsdatum ignoriert)\n\nEine Zeile von cases (für “Blessing Adebayo”, Zeile 9) hatte keine gute Übereinstimmung in results und ist daher nicht vorhanden in my_matches.\n\nJoin basierend auf den probabilistischen Übereinstimmungen\nUm diese Übereinstimmungen für den Join zu verwenden results zu cases zu verbinden, ist eine Strategie:\n\nNutze left_join() zum Verbinden my_matches zu cases (passende rownames in cases zu “inds.a” in my_matches)\nVerwenden Sie dann eine andere left_join() um zu verbinden results zu cases (passend zu der neu erworbenen “inds.b” in cases zu rownames in results)\n\nVor der Verknüpfung sollten wir die drei Datenrahmen bereinigen:\n\nBeide dfA und dfB sollten ihre Zeilennummern (“rowname”) in eine richtige Spalte umgewandelt werden.\nSowohl die Spalten in my_matches werden in Klassenzeichen umgewandelt, so dass sie mit den Zeichenrownamen verbunden werden können\n\n\n# Clean data prior to joining\n#############################\n\n# convert cases rownames to a column \ncases_clean &lt;- cases %&gt;% rownames_to_column()\n\n# convert test_results rownames to a column\nresults_clean &lt;- results %&gt;% rownames_to_column()  \n\n# convert all columns in matches dataset to character, so they can be joined to the rownames\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n\n\n# Join matches to dfA, then add dfB\n###################################\n# column \"inds.b\" is added to dfA\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# column(s) from dfB are added \ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\nWie mit dem obigen Code ausgeführt, wird der resultierende Datenrahmen complete enthalten alle Spalten aus beiden cases und results. Viele werden mit den Suffixen “.x” und “.y” angehängt, weil die Spaltennamen sonst doppelt vorkommen würden.\n\n\n\n\n\n\nAlternativ kannst du auch nur die “ursprünglichen” 9 Datensätze in cases mit der/den neuen Spalte(n) aus results zu erhalten, verwende select() auf results vor den Joins ein, so dass es nur rownames und die Spalten enthält, die du hinzufügen willst cases hinzufügen willst (z.B. die Spalte result).\n\ncases_clean &lt;- cases %&gt;% rownames_to_column()\n\nresults_clean &lt;- results %&gt;%\n  rownames_to_column() %&gt;% \n  select(rowname, result)    # select only certain columns \n\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n# joins\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\n\n\n\n\n\n\nWenn du einen der beiden Datensätze nur auf die übereinstimmenden Zeilen beschränken willst, kannst du die folgenden Codes verwenden:\n\ncases_matched &lt;- cases[my_matches$inds.a,]  # Rows in cases that matched to a row in results\nresults_matched &lt;- results[my_matches$inds.b,]  # Rows in results that matched to a row in cases\n\nOder, um nur die übereinstimmenden Zeilen zu sehen nicht übereinstimmen:\n\ncases_not_matched &lt;- cases[!rownames(cases) %in% my_matches$inds.a,]  # Rows in cases that did NOT match to a row in results\nresults_not_matched &lt;- results[!rownames(results) %in% my_matches$inds.b,]  # Rows in results that did NOT match to a row in cases\n\n\n\nProbabilistische Deduplizierung\nDer probabilistische Abgleich kann auch zur Deduplizierung eines Datensatzes verwendet werden. Weitere Methoden zur Deduplizierung findest du auf der Seite zur Deduplizierung.\nHier haben wir mit der cases Datensatz, nennen ihn aber jetzt cases_dup da er 2 zusätzliche Zeilen enthält, die Duplikate der vorherigen Zeilen sein könnten: Siehe “Tony” mit “Anthony”, und “Marialisa Rodrigues” mit “Maria Rodriguez”.\n\n\n\n\n\n\nFühre aus. fastLink() wie zuvor, aber vergleiche die cases_dup Datenrahmen mit sich selbst. Wenn die beiden bereitgestellten Datenrahmen identisch sind, geht die Funktion davon aus, dass du die Duplikate entfernen willst. Beachte, dass wir nicht angeben stringdist.match = oder numeric.match = wie wir es zuvor getan haben.\n\n## Run fastLink on the same dataset\ndedupe_output &lt;- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\ndfA and dfB are identical, assuming deduplication of a single data set.\nSetting return.all to FALSE.\n\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nCalculating the posterior for each pair of matched observations.\nGetting the match patterns for each estimated match.\n\n\nJetzt kannst du die potenziellen Duplikate mit getMatches(). Gib den Datenrahmen als beides an dfA = und dfB = an, und stellen Sie die Ausgabe der fastLink() Funktion als fl.out =. fl.out muss von der Klasse sein fastLink.dedupe sein, oder in anderen Worten, das Ergebnis von fastLink().\n\n## Run getMatches()\ncases_dedupe &lt;- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\n\nIn der Spalte ganz rechts siehst du die doppelten IDs - die letzten beiden Zeilen sind als wahrscheinliche Duplikate der Zeilen 2 und 3 gekennzeichnet.\n\n\n\n\n\n\nUm die Zeilennummern der Zeilen zu ermitteln, die wahrscheinlich Duplikate sind, kannst du die Anzahl der Zeilen pro eindeutigem Wert in der dedupe.ids Spalte zählen und dann filtern, um nur die Zeilen mit mehr als einem Wert zu erhalten. In diesem Fall bleiben also die Zeilen 2 und 3 übrig.\n\ncases_dedupe %&gt;% \n  count(dedupe.ids) %&gt;% \n  filter(n &gt; 1)\n\n  dedupe.ids n\n1          2 2\n2          3 2\n\n\nUm die ganzen Zeilen mit den wahrscheinlichen Duplikaten zu prüfen, gibst du die Zeilennummer in diesen Befehl ein:\n\n# displays row 2 and all likely duplicates of it\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   \n\n   gender   first middle  last   yr mon day district dedupe.ids\n2       M Anthony     B. Smith 1970   9  19    River          2\n10      M    Tony     B. Smith 1970   9  19    River          2",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Daten verknüpfen</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.de.html#binden-und-ausrichten",
    "href": "new_pages/joining_matching.de.html#binden-und-ausrichten",
    "title": "14  Daten verknüpfen",
    "section": "14.4 Binden und Ausrichten",
    "text": "14.4 Binden und Ausrichten\nEine andere Methode, um zwei Datenrahmen zu kombinieren, ist das “Binden” der beiden. Du kannst dir das auch als “Anhängen” oder “Hinzufügen” von Zeilen oder Spalten vorstellen.\nIn diesem Abschnitt geht es auch darum, wie du die Reihenfolge der Zeilen eines Datenrahmens an die Reihenfolge des anderen Datenrahmens anpasst. Dieses Thema wird weiter unten im Abschnitt über das Binden von Spalten behandelt.\n\nZeilen binden\nUm Zeilen eines Datenrahmens mit dem Boden eines anderen Datenrahmens zu verbinden, verwendest du bind_rows() von dplyr. Sie ist sehr umfassend, d.h. jede Spalte, die in einem der beiden Datenrahmen vorhanden ist, wird in der Ausgabe berücksichtigt. Ein paar Hinweise:\n\nAnders als bei der Basis R-Version row.bind(), dplyr’s bind_rows() verlangt nicht, dass die Reihenfolge der Spalten in beiden Datenrahmen gleich ist. Solange die Spaltennamen identisch geschrieben sind, werden sie korrekt ausgerichtet.\nDu kannst optional das Argument .id =. Gib einen Spaltennamen an. Dadurch wird eine neue Spalte erzeugt, die dazu dient, zu identifizieren, aus welchem Datenrahmen jede Zeile ursprünglich stammt.\nDu kannst verwenden bind_rows() auf eine listvon ähnlich strukturierten Datenrahmen verwenden, um sie zu einem Datenrahmen zusammenzufassen. Ein Beispiel findest du im Kapitel [Iteration, Schleifen und Listen] Seite, bei dem es um den Import von mehreren Zeilenlisten mitpurrr.\n\nEin gängiges Beispiel für die Zeilenbindung ist die Bindung einer “Gesamt”-Zeile an eine beschreibende Tabelle, die mit dplyr’s summarise() Funktion. Im Folgenden erstellen wir eine Tabelle mit den Fallzahlen und dem Median der CT-Werte nach Krankenhaus mit einer Gesamtzeile.\nDie Funktion summarise() wird auf die nach Krankenhaus gruppierten Daten angewendet, um einen zusammenfassenden Datenrahmen nach Krankenhaus zu erstellen. Aber die Funktion summarise() erzeugt nicht automatisch eine “Summen”-Zeile, also erstellen wir sie, indem wir die Daten zusammenfassen wieder aber die Daten werden nicht nach Krankenhaus gruppiert. So entsteht ein zweiter Datenrahmen mit nur einer Zeile. Wir können diese Datenrahmen dann miteinander verbinden, um die endgültige Tabelle zu erhalten.\nWeitere Beispiele dieser Art findest du in der [Beschreibende Tabellen] und [Tabellen für die Präsentation] Seiten.\n\n# Create core table\n###################\nhosp_summary &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;%                        # Group data by hospital\n  summarise(                                    # Create new summary columns of indicators of interest\n    cases = n(),                                  # Number of rows per hospital-outcome group     \n    ct_value_med = median(ct_blood, na.rm=T))     # median CT value per group\n\nHier ist die hosp_summary Datenrahmen:\n\n\n\n\n\n\nErstelle einen Datenrahmen mit der “Gesamt”-Statistik (nicht gruppiert nach Krankenhaus). Dies wird nur eine Zeile ergeben.\n\n# create totals\n###############\ntotals &lt;- linelist %&gt;% \n  summarise(\n    cases = n(),                               # Number of rows for whole dataset     \n    ct_value_med = median(ct_blood, na.rm=T))  # Median CT for whole dataset\n\nUnd darunter ist das totals Datenrahmen. Beachte, dass es nur zwei Spalten gibt. Diese Spalten sind auch in hosp_summary enthalten, aber es gibt eine Spalte in hosp_summary die nicht in totals (hospital).\n\n\n\n\n\n\nJetzt können wir die Zeilen zusammenbinden mit bind_rows().\n\n# Bind data frames together\ncombined &lt;- bind_rows(hosp_summary, totals)\n\nJetzt können wir uns das Ergebnis ansehen. Du siehst, dass in der letzten Zeile eine leere NA Wert für die Spalte ausgefüllt wird hospital die nicht in hosp_summary. Wie in den [Tabellen für die Präsentation] Seite erklärt wird, kannst du diese Zelle mit “Gesamt” ausfüllen, indem dureplace_na().\n\n\n\n\n\n\n\n\nSpalten binden\nEs gibt eine ähnliche dplyr Funktion bind_cols() die du verwenden kannst, um zwei Datenrahmen seitlich zu kombinieren. Beachte, dass die Zeilen aneinander angepasst werden nach Position (nicht wie bei einem join oben) - zum Beispiel wird die 12. Zeile in jedem Datenrahmen ausgerichtet.\nIn einem Beispiel verbinden wir mehrere Übersichtstabellen miteinander. Dazu zeigen wir auch, wie man die Reihenfolge der Zeilen in einem Datenrahmen so anordnet, dass sie der Reihenfolge in einem anderen Datenrahmen entspricht, mit match().\nHier definieren wir case_info als einen zusammenfassenden Datenrahmen mit der Anzahl der Fälle und der Anzahl der Todesfälle, aufgeschlüsselt nach Krankenhäusern.\n\n# Case information\ncase_info &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\n\n\n\n\n\n\n\nUnd nehmen wir an, dass hier ein anderer Datenrahmen ist contact_fu der Informationen über den Prozentsatz der exponierten Kontakte enthält, die untersucht und “weiterverfolgt” wurden, wiederum nach Krankenhaus.\n\ncontact_fu &lt;- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)\n\n\n\n\n\n\n\nDie Krankenhäuser sind zwar dieselben, aber in jedem Datenrahmen in einer anderen Reihenfolge. Die einfachste Lösung wäre die Verwendung eines left_join() auf die hospital Spalte zu verwenden, aber du könntest auch bind_cols() mit einem zusätzlichen Schritt.\n\nVerwende match() um die Bestellung auszurichten\nDa die Reihenfolgen unterschiedlich sind, kann eine einfache bind_cols() Befehl dazu führen, dass die Daten nicht übereinstimmen. Um dies zu beheben, können wir verwenden match() von Basis R, um die Zeilen eines Datenrahmens in der gleichen Reihenfolge wie in einem anderen auszurichten. Wir gehen bei diesem Ansatz davon aus, dass es in beiden Datenrahmen keine doppelten Werte gibt.\nWenn wir match() verwenden, lautet die Syntax match(TARGET ORDER VECTOR, DATA FRAME COLUMN TO CHANGE) wobei das erste Argument die gewünschte Reihenfolge ist (entweder ein eigenständiger Vektor oder in diesem Fall eine Spalte in einem Datenrahmen) und das zweite Argument die Spalte im Datenrahmen, die neu geordnet werden soll. Die Ausgabe von match() ist ein Zahlenvektor, der die korrekte Positionsreihenfolge angibt. Du kannst mehr lesen mit ?match.\n\nmatch(case_info$hospital, contact_fu$hospital)\n\n[1] 4 2 3 6 5 1\n\n\nDu kannst diesen numerischen Vektor verwenden, um den Datenrahmen neu zu ordnen - platziere ihn in Untermengenklammern [ ] vor dem Komma. Lies mehr über BasisR Klammer-Subset-Syntax in den [R-Grundlagen] Seite. Der folgende Befehl erstellt einen neuen Datenrahmen, der als der alte Datenrahmen definiert ist, in dem die Zeilen im obigen numerischen Vektor geordnet sind.\n\ncontact_fu_aligned &lt;- contact_fu[match(case_info$hospital, contact_fu$hospital),]\n\n\n\n\n\n\n\nJetzt können wir die Spalten des Datenrahmens in der richtigen Zeilenreihenfolge miteinander verbinden. Beachte, dass einige Spalten doppelt vorhanden sind und mit dem folgenden Befehl bereinigt werden müssen rename(). Lies mehr über bind_rows() hier.\n\nbind_cols(case_info, contact_fu)\n\nNew names:\n• `hospital` -&gt; `hospital...1`\n• `hospital` -&gt; `hospital...4`\n\n\n# A tibble: 6 × 6\n  hospital...1                     cases deaths hospital...4 investigated per_fu\n  &lt;chr&gt;                            &lt;int&gt;  &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt; \n1 Central Hospital                   454    193 St. Mark's … 80%          60%   \n2 Military Hospital                  896    399 Military Ho… 82%          25%   \n3 Missing                           1469    611 Missing      &lt;NA&gt;         &lt;NA&gt;  \n4 Other                              885    395 Central Hos… 78%          20%   \n5 Port Hospital                     1762    785 Port Hospit… 64%          75%   \n6 St. Mark's Maternity Hospital (…   422    199 Other        55%          80%   \n\n\nA Basis R Alternative zu bind_cols ist cbind() die den gleichen Vorgang durchführt.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Daten verknüpfen</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.de.html#ressourcen",
    "href": "new_pages/joining_matching.de.html#ressourcen",
    "title": "14  Daten verknüpfen",
    "section": "14.5 Ressourcen",
    "text": "14.5 Ressourcen\nDie tidyverse Seite über Verbindungen\nDie R for Data Science Seite über relationale Daten\nTh tidyverse Seite auf dplyr über Bindung\nEine Vignette auf fastLink auf der Github-Seite des Pakets\nVeröffentlichung zur Beschreibung der Methodik von fastLink\nDie Veröffentlichung beschreibt RecordLinkage Paket",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Daten verknüpfen</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.de.html",
    "href": "new_pages/deduplication.de.html",
    "title": "15  De-Duplizierung",
    "section": "",
    "text": "15.1 Vorbereitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-Duplizierung</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.de.html#vorbereitung",
    "href": "new_pages/deduplication.de.html#vorbereitung",
    "title": "15  De-Duplizierung",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  tidyverse,   # deduplication, grouping, and slicing functions\n  janitor,     # function for reviewing duplicates\n  stringr)      # for string searches, can be used in \"rolling-up\" values\n\n\n\nDaten importieren\nZur Veranschaulichung verwenden wir einen Beispieldatensatz, der mit dem unten stehenden R-Code erstellt wird.\nBei den Daten handelt es sich um Datensätze von COVID-19-Telefonkonferenzen, einschließlich Konferenzen mit Kontakten und mit Fällen. Die Spalten enthalten recordID (computergeneriert), personID, name, date der Begegnung, time der Begegnung, der purpose der Begegnung (entweder als Fall oder als Kontakt zu befragen), und symptoms_ever (ob die Person bei dieser Begegnung berichtet hat jemals Symptome zu haben).\nHier ist der Code zum Erstellen der obs Datensatzes:\n\nobs &lt;- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %&gt;% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))\n\n\n15.1.0.1 Hier ist der Datenrahmen {#dedup_data .unnumbered}\nVerwende die Filterfelder oben, um die Begegnungen für jede Person zu überprüfen.\n\n\n\n\n\n\nWenn du die Daten durchgehst, solltest du einige Dinge beachten:\n\nDie ersten beiden Datensätze sind 100%ige Duplikate, einschließlich doppelter recordID (muss ein Computerfehler sein!)\nDie zweiten beiden Zeilen sind Duplikate, in allen Spalten außer für recordID\nMehrere Personen hatten mehrere telefonische Begegnungen, zu verschiedenen Daten und Zeiten und als Kontakte und/oder Fälle\nBei jedem Treffen wurde die Person gefragt, ob sie jemals Symptome hatten, und einige dieser Informationen fehlen.\n\nUnd hier ist eine kurze Zusammenfassung der Personen und der Ziele ihrer Begegnungen, indem sie tabyl() von Hausmeister:\n\nobs %&gt;% \n  tabyl(name, purpose)\n\n    name case contact\n    adam    1       2\n  amrish    1       3\n   brian    1       2\n  mariah    1       2\n natalie    1       0\n  nikhil    0       2\n  raquel    0       2\n   smita    0       1",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-Duplizierung</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.de.html#deduplizierung",
    "href": "new_pages/deduplication.de.html#deduplizierung",
    "title": "15  De-Duplizierung",
    "section": "15.2 Deduplizierung",
    "text": "15.2 Deduplizierung\nIn diesem Abschnitt wird beschrieben, wie man doppelte Zeilen in einem Datenrahmen überprüft und entfernt. Außerdem wird gezeigt, wie du mit doppelten Elementen in einem Vektor umgehst.\n\n\nUntersuche doppelte Zeilen\nUm Zeilen mit Duplikaten schnell zu überprüfen, kannst du Folgendes verwenden get_dupes() aus dem Hausmeister Paket. Standardmäßig werden alle Spalten bei der Auswertung von Duplikaten berücksichtigt - die von der Funktion zurückgegebenen Zeilen sind 100% Duplikate unter Berücksichtigung der Werte in allen Spalten.\nIn der obs Datenrahmen sind die ersten beiden Zeilen 100% Duplikate - sie haben in jeder Spalte den gleichen Wert (einschließlich der recordID Spalte, die soll eindeutig sein soll - das muss eine Computerpanne sein). Der zurückgegebene Datenrahmen enthält automatisch eine neue Spalte dupe_count auf der rechten Seite, die die Anzahl der Zeilen mit dieser Kombination von doppelten Werten anzeigt.\n\n# 100% duplicates across all columns\nobs %&gt;% \n  janitor::get_dupes()\n\n\n\n\n\n\n\nSiehe die Originaldaten\nWenn wir uns jedoch entscheiden, zu ignorieren recordID sind auch die 3. und 4. Zeile Duplikate voneinander. Das heißt, sie haben in allen Spalten die gleichen Werte außer für recordID. Du kannst bestimmte Spalten angeben, die in der Funktion ignoriert werden sollen, indem du eine - Minus-Symbol.\n\n# Duplicates when column recordID is not considered\nobs %&gt;% \n  janitor::get_dupes(-recordID)         # if multiple columns, wrap them in c()\n\n\n\n\n\n\n\nDu kannst die zu berücksichtigenden Spalten auch positiv angeben. Im Folgenden werden nur Zeilen berücksichtigt, die die gleichen Werte in den name und purpose Spalten haben, werden zurückgegeben. Beachte, dass “amrish” jetzt den Wert dupe_count gleich 3 ist, um seine drei “Kontakt”-Begegnungen widerzuspiegeln.\nScrolle nach links für weitere Zeilen*\n\n# duplicates based on name and purpose columns ONLY\nobs %&gt;% \n  janitor::get_dupes(name, purpose)\n\n\n\n\n\n\n\nSiehe die Originaldaten.\nSiehe ?get_dupes für weitere Details, oder siehe dies Online-Referenz\n\n\n\nNur eindeutige Zeilen behalten\nUm nur eindeutige Zeilen eines Datenrahmens zu behalten, verwende distinct() von dplyr(wie im Abschnitt [Daten bereinigen und Kernfunktionen] Seite). Doppelte Zeilen werden so entfernt, dass nur die erste dieser Zeilen erhalten bleibt. Standardmäßig bedeutet “erste” die höchsterownumber (Reihenfolge der Zeilen von oben nach unten). Es bleiben nur eindeutige Zeilen übrig.\nIm folgenden Beispiel führen wir aus distinct() so aus, dass die Spalte recordID von der Betrachtung ausgeschlossen wird - also zwei doppelte Zeilen werden entfernt. Die erste Zeile (für “adam”) war zu 100% doppelt und wurde entfernt. Auch Zeile 3 (für “amrish”) war in jeder Spalte ein Duplikat. außer recordID (die nicht in Betracht gezogen wird) und wird daher ebenfalls entfernt. Die obs Datensatz n ist jetzt nrow(obs)-2, nicht nrow(obs) Zeilen).\nScrolle nach links, um den gesamten Datenrahmen zu sehen\n\n# added to a chain of pipes (e.g. data cleaning)\nobs %&gt;% \n  distinct(across(-recordID), # reduces data frame to only unique rows (keeps first one of any duplicates)\n           .keep_all = TRUE) \n\n# if outside pipes, include the data as first argument \n# distinct(obs)\n\n\n\n\n\n\n\nVORSICHT! Bei Verwendung von distinct() auf gruppierte Daten anwenden, wird die Funktion auf jede Gruppe angewendet.\nDeduplizieren basierend auf bestimmten Spalten\nDu kannst auch Spalten angeben, die als Grundlage für die Deduplizierung dienen sollen. Auf diese Weise wird die Deduplizierung nur auf Zeilen angewendet, die innerhalb der angegebenen Spalten doppelt sind. Wenn du nicht .keep_all = TRUE festlegst, werden alle nicht genannten Spalten gelöscht.\nIm folgenden Beispiel gilt die Deduplizierung nur für Zeilen, die identische Werte für name und haben. purpose Spalten haben. Somit hat “brian” nur 2 Zeilen statt 3 - seine erste “Kontaktbegegnung und seine einzige”Fall”-Begegnung. Anpassen, so dass Brian’s neueste Begegnung eines jeden Zwecks beibehalten wird, findest du auf der Registerkarte “Aufteilung innerhalb von Gruppen”.\nScrolle nach links, um den gesamten Datenrahmen zu sehen\n\n# added to a chain of pipes (e.g. data cleaning)\nobs %&gt;% \n  distinct(name, purpose, .keep_all = TRUE) %&gt;%  # keep rows unique by name and purpose, retain all columns\n  arrange(name)                                  # arrange for easier viewing\n\n\n\n\n\n\n\nSiehe die Originaldaten.\n\n\n\nElemente in einem Vektor deduplizieren\nDie Funktion duplicated() von Basis R wertet einen Vektor (Spalte) aus und gibt einen logischen Vektor der gleichen Länge zurück (TRUE/FALSE). Wenn ein Wert zum ersten Mal auftaucht, wird FALSE zurückgegeben (kein Duplikat), und wenn der Wert danach noch einmal auftaucht, wird TRUE zurückgegeben. Beachte, wie NA genauso behandelt wird wie jeder andere Wert.\n\nx &lt;- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)\n\n [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nUm nur die duplizierten Elemente zurückzugeben, kannst du den ursprünglichen Vektor mit Hilfe von Klammern unterteilen:\n\nx[duplicated(x)]\n\n[1]  1 NA  4  4  1  2\n\n\nUm nur die eindeutigen Elemente zurückzugeben, verwenden Sie unique() von Basis R. Zum Entfernen NAs aus der Ausgabe zu entfernen, verschachteln na.omit() innerhalb von unique().\n\nunique(x)           # alternatively, use x[!duplicated(x)]\n\n[1]  1  2 NA  4  5\n\nunique(na.omit(x))  # remove NAs \n\n[1] 1 2 4 5\n\n\n\n\n\nverwenden Basis R\nUm doppelte Zeilen zurückzugeben\nIn Basis R kannst du auch sehen, welche Zeilen in einem Datenrahmen 100%ige Duplikate sind df mit dem Befehl duplicated(df) (gibt einen logischen Vektor mit den Zeilen zurück).\nDu kannst also auch die Basisteilmenge verwenden [ ] auf den Datenrahmen anwenden, um die duplizierten Zeilen mit df[duplicated(df),] (vergiss das Komma nicht, das bedeutet, dass du alle Spalten sehen willst!).\nUm eindeutige Zeilen zurückzugeben\nSiehe die obigen Hinweise. Um die einzigartigen Zeilen zu sehen, fügst du den logischen Negator ! vor die duplicated() Funktion an:\ndf[!duplicated(df),]\nUm Zeilen zurückzugeben, die nur in bestimmten Spalten doppelt vorkommen\nUnterteilen Sie die df das ist innerhalb der duplicated() Klammern so dass diese Funktion nur auf bestimmte Spalten der Tabelle wirkt. df.\nUm die Spalten zu spezifizieren, geben Sie die Spaltennummern oder -namen nach einem Komma an (denken Sie daran, dass dies alles innerhalb von der duplicated() Funktion).\nAchte darauf, dass das Komma , außerhalb von nach der duplicated() Funktion auch draußen!\nZum Beispiel, um nur die Spalten 2 bis 5 auf Duplikate zu untersuchen: df[!duplicated(df[, 2:5]),]\nUm nur die Spalten auszuwerten name und purpose nach Duplikaten: df[!duplicated(df[, c(\"name\", \"purpose)]),]",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-Duplizierung</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.de.html#schneiden",
    "href": "new_pages/deduplication.de.html#schneiden",
    "title": "15  De-Duplizierung",
    "section": "15.3 Schneiden",
    "text": "15.3 Schneiden\nUm einen Datenrahmen zu “zerschneiden”, wendest du einen Filter auf die Zeilen nach Zeilennummer/Position an. Dies ist besonders nützlich, wenn du mehrere Zeilen pro Funktionsgruppe (z. B. pro “Person”) hast und nur eine oder einige davon behalten möchtest.\nDie Basis slice() Funktion akzeptiert Zahlen und gibt Zeilen an diesen Positionen zurück. Wenn die angegebenen Zahlen positiv sind, werden nur diese zurückgegeben. Wenn sie negativ sind, werden diese Zeilen nicht zurückgegeben. Die Zahlen müssen entweder alle positiv oder alle negativ sein.\n\nobs %&gt;% slice(4)  # return the 4th row\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n\n\nobs %&gt;% slice(c(2,4))  # return rows 2 and 4\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        1        1   adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n#obs %&gt;% slice(c(2:4))  # return rows 2 through 4\n\nSiehe die Originaldaten.\nEs gibt mehrere Varianten: Diese sollten mit einer Spalte und einer Anzahl von Zeilen versehen werden, die zurückgegeben werden sollen (zu n =).\n\nslice_min() und slice_max() behält nur die Zeile(n) mit dem minimalen oder maximalen Wert der angegebenen Spalte. Dies funktioniert auch, um die “min” und “max” von geordneten Faktoren zurückzugeben.\nslice_head() und slice_tail() - behalte nur die erste oder letzte Zeile(n).\nslice_sample() - behalte nur eine zufällige Auswahl der Zeilen.\n\n\nobs %&gt;% slice_max(encounter, n = 1)  # return rows with the largest encounter number\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n2       13        3 mariah 2020-01-06 08:32         3 contact            No\n3       16        5  brian 2020-01-07 07:59         3    case            No\n\n\nArgumente verwenden n = oder prop = um die Anzahl oder den Anteil der zu behaltenden Zeilen anzugeben. Wenn du die Funktion nicht in einer Pipe-Kette verwendest, gib zuerst das Argument data an (z. B. slice(data, n = 2)). Siehe ?slice für weitere Informationen.\nAndere Argumente:\n.order_by = verwendet in slice_min() und slice_max() ist dies eine Spalte, nach der du vor dem Schneiden sortieren kannst.\nwith_ties = Standardmäßig TRUE, was bedeutet, dass Gleichstände beibehalten werden.\n.preserve = Standardmäßig FALSE. Wenn TRUE, wird die Gruppierungsstruktur nach dem Slicing neu berechnet.\nweight_by = Optionale, numerische Spalte zur Gewichtung (je größer die Zahl, desto wahrscheinlicher ist es, dass die Stichprobe gezogen wird). Auch replace = für die Angabe, ob die Stichprobe mit/ohne Ersetzung durchgeführt wird.\nTIPP: Bei der Verwendung von slice_max() und slice_min() verwenden, müssen Sie die n = (z.B.. n = 2, nicht nur 2). Andernfalls kann es zu einer Fehlermeldung kommen Error:…is not empty. \nHINWEIS: Es kann vorkommen, dass du die Funktion top_n() begegnen, die durch die Funktion slice Funktionen.\n\n\nSchneiden mit Gruppen\nDie slice_*() Funktionen können sehr nützlich sein, wenn sie auf einen gruppierten Datenrahmen angewendet werden, da die Slice-Operation für jede Gruppe separat durchgeführt wird. Verwende die Funktion group_by() in Verbindung mit slice() um die Daten zu gruppieren und aus jeder Gruppe einen Slice zu nehmen.\nDas ist hilfreich, wenn du mehrere Zeilen pro Person hast, aber nur eine davon behalten willst. Du verwendest zunächst group_by() mit Schlüsselspalten, die für jede Person gleich sind, und verwendest dann eine Slice-Funktion für eine Spalte, die sich in den gruppierten Zeilen unterscheidet.\nIm folgenden Beispiel werden nur die neuesten Begegnung pro Person gruppieren wir die Zeilen nach name und verwenden dann slice_max() mit n = 1 auf die date Spalte. Aber Achtung! Um eine Funktion wie slice_max() auf Datumsangaben anzuwenden, muss die Datumsspalte der Klasse Date angehören.\nStandardmäßig werden “Gleichstände” (z. B. dasselbe Datum in diesem Szenario) beibehalten, und wir würden trotzdem mehrere Zeilen für einige Personen (z. B. Adam) erhalten. Um dies zu vermeiden, setzen wir with_ties = FALSE. Wir erhalten dann nur eine Zeile pro Person.\nVORSICHT! Bei Verwendung von arrange(), gib an .by_group = TRUE an, damit die Daten innerhalb jeder Gruppe angeordnet werden.\nGEFAHR! Wenn with_ties = FALSE wird die erste Zeile eines Gleichstandes beibehalten. Das kann trügerisch sein. Bei Mariah hat sie zwei Begegnungen an ihrem letzten Datum (6. Januar) und die erste (früheste) wurde beibehalten. Wahrscheinlich wollen wir ihre spätere Begegnung an diesem Tag beibehalten. Im nächsten Beispiel erfährst du, wie du diese Verknüpfungen “auflösen” kannst. \n\nobs %&gt;% \n  group_by(name) %&gt;%       # group the rows by 'name'\n  slice_max(date,          # keep row per group with maximum date value \n            n = 1,         # keep only the single highest row \n            with_ties = F) # if there's a tie (of date), take the first row\n\n\n\n\n\n\n\nOben kannst du zum Beispiel sehen, dass nur Amrishs Reihe am 5. Januar und nur Brians Reihe am 7. Januar behalten wurde. Siehe die Originaldaten.\n“Krawatten” brechen\nMehrere Slice-Anweisungen können ausgeführt werden, um “Gleichstände” zu brechen. In diesem Fall, wenn eine Person mehrere Begegnungen in ihrem letzten Datum wird die Begegnung mit dem spätesten Zeit gehalten wird (lubridate::hm() wird verwendet, um die Zeichenzeiten in eine sortierbare Zeitklasse umzuwandeln).\nBeachte, dass die eine Zeile, die für “Mariah” am 6. Januar beibehalten wird, Begegnung 3 um 08:32 Uhr ist, nicht Begegnung 2 um 07:25 Uhr.\n\n# Example of multiple slice statements to \"break ties\"\nobs %&gt;%\n  group_by(name) %&gt;%\n  \n  # FIRST - slice by latest date\n  slice_max(date, n = 1, with_ties = TRUE) %&gt;% \n  \n  # SECOND - if there is a tie, select row with latest time; ties prohibited\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)\n\n\n\n\n\n\n\nIm obigen Beispiel wäre es auch möglich gewesen, nach encounter Nummer zu unterteilen, aber wir haben den Slice auf date und time zu Beispielzwecken.\nTIPP: Zur Verwendung slice_max() oder slice_min() für eine “Zeichen”-Spalte zu verwenden, wandeln Sie sie in eine geordneten Faktorklasse!\nSiehe die Originaldaten.\n\n\n\nBehalte alle, aber markiere sie\nWenn du alle Datensätze aufbewahren, aber nur einige für die Analyse markieren möchtest, kannst du einen zweistufigen Ansatz mit einer eindeutigen Datensatz-ID/Begegnungsnummer wählen:\n\nReduziere den ursprünglichen Datenrahmen auf die Zeilen, die analysiert werden sollen. Speichere/behalte diesen reduzierten Datenrahmen.\nMarkiere im ursprünglichen Datenrahmen die entsprechenden Zeilen mit case_when() je nachdem, ob ihr Record Unique Identifier (in diesem Beispiel recordID) im reduzierten Datenrahmen vorhanden ist.\n\n\n# 1. Define data frame of rows to keep for analysis\nobs_keep &lt;- obs %&gt;%\n  group_by(name) %&gt;%\n  slice_max(encounter, n = 1, with_ties = FALSE) # keep only latest encounter per person\n\n\n# 2. Mark original data frame\nobs_marked &lt;- obs %&gt;%\n\n  # make new dup_record column\n  mutate(dup_record = case_when(\n    \n    # if record is in obs_keep data frame\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # all else marked as \"Ignore\" for analysis purposes\n    TRUE                            ~ \"Ignore\"))\n\n# print\nobs_marked\n\n   recordID personID    name       date  time encounter purpose symptoms_ever\n1         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n3         2        2  amrish 2020-01-02 14:20         1 contact            No\n4         3        2  amrish 2020-01-02 14:20         1 contact            No\n5         4        3  mariah 2020-01-05 12:00         1    case            No\n6         5        2  amrish 2020-01-05 16:10         3    case           Yes\n7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes\n8         7        5   brian 2020-01-05 15:20         1 contact            No\n9         8        6   smita 2020-01-05 14:20         1 contact           Yes\n10        9        7  raquel 2020-01-05 12:30         1 contact          &lt;NA&gt;\n11       10        2  amrish 2020-01-02 10:24         2 contact           Yes\n12       11        1    adam 2020-01-05 09:40         2    case            No\n13       12        3  mariah 2020-01-06 07:25         2 contact            No\n14       13        3  mariah 2020-01-06 08:32         3 contact            No\n15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes\n16       15        5   brian 2020-01-06 15:31         2 contact           Yes\n17       16        5   brian 2020-01-07 07:59         3    case            No\n18       17        7  raquel 2020-01-07 11:13         2 contact            No\n19       18        8 natalie 2020-01-07 17:12         1    case            No\n     dup_record\n1        Ignore\n2        Ignore\n3        Ignore\n4        Ignore\n5        Ignore\n6  For analysis\n7        Ignore\n8        Ignore\n9  For analysis\n10       Ignore\n11       Ignore\n12 For analysis\n13       Ignore\n14 For analysis\n15 For analysis\n16       Ignore\n17 For analysis\n18 For analysis\n19 For analysis\n\n\n\n\n\n\n\n\nSiehe die ursprünglichen Daten.\n\n\n\nBerechne die Vollständigkeit der Zeilen\nErstelle eine Spalte, die eine Metrik für die Vollständigkeit der Zeile enthält (Nicht-Fehlbarkeit). Dies kann hilfreich sein, wenn du entscheidest, welche Zeilen beim Duplizieren/Slicen Vorrang vor anderen haben sollen.\nIn diesem Beispiel werden die “Schlüsselspalten”, für die du die Vollständigkeit messen willst, in einem Vektor von Spaltennamen gespeichert.\nDann wird die neue Spalte key_completeness erstellt mit mutate(). Der neue Wert in jeder Zeile wird als berechneter Bruch definiert: die Anzahl der nicht fehlenden Werte in dieser Zeile unter den Schlüsselspalten, geteilt durch die Anzahl der Schlüsselspalten.\nDies beinhaltet die Funktion rowSums() von Basis R. Ebenfalls verwendet wird . der sich innerhalb der Pipe auf den Datenrahmen an diesem Punkt in der Pipe bezieht (in diesem Fall wird er mit Klammern unterteilt []).\nScrolle nach rechts, um mehr Zeilen zu sehen*\n\n# create a \"key variable completeness\" column\n# this is a *proportion* of the columns designated as \"key_cols\" that have non-missing values\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %&gt;% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) \n\n\n\n\n\n\n\nSiehe die Originaldaten.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-Duplizierung</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.de.html#roll-up-werte-str_rollup",
    "href": "new_pages/deduplication.de.html#roll-up-werte-str_rollup",
    "title": "15  De-Duplizierung",
    "section": "15.4 Roll-up Werte {#str_rollup}",
    "text": "15.4 Roll-up Werte {#str_rollup}\nDieser Abschnitt beschreibt:\n\nWie man Werte aus mehreren Zeilen in nur eine Zeile “hochrollt”, mit einigen Variationen\nWie du die Werte in jeder Zelle überschreibst/priorisierst, sobald du sie “aufgerollt” hast\n\nDiese Registerkarte verwendet den Beispieldatensatz aus der Registerkarte Vorbereitung.\n\n\nWerte in eine Zeile hochrechnen\nDas folgende Codebeispiel verwendet group_by() und summarise() um die Zeilen nach Personen zu gruppieren und dann alle eindeutigen Werte innerhalb der gruppierten Zeilen zusammenzufügen. So erhältst du eine Übersichtszeile pro Person. Ein paar Hinweise:\n\nAn alle neuen Spalten wird ein Suffix angehängt (“_roll” in diesem Beispiel)\nWenn du nur eindeutige Werte pro Zelle anzeigen willst, musst du die na.omit() mit unique()\nna.omit() entfernt NA Werte, aber wenn dies nicht gewünscht ist, kann es entfernt werden paste0(.x)…\n\n\n# \"Roll-up\" values into one row per group (per \"personID\") \ncases_rolled &lt;- obs %&gt;% \n  \n  # create groups by name\n  group_by(personID) %&gt;% \n  \n  # order the rows within each group (e.g. by date)\n  arrange(date, .by_group = TRUE) %&gt;% \n  \n  # For each column, paste together all values within the grouped rows, separated by \";\"\n  summarise(\n    across(everything(),                           # apply to all columns\n           ~paste0(na.omit(.x), collapse = \"; \"))) # function is defined which combines non-NA values\n\nDas Ergebnis ist eine Zeile pro Gruppe (ID), wobei die Einträge nach Datum geordnet und zusammengefügt werden. Scrolle nach links, um weitere Zeilen zu sehen\n\n\n\n\n\n\nSiehe die Originaldaten.\nDiese Variante zeigt nur eindeutige Werte:\n\n# Variation - show unique values only \ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                                   # apply to all columns\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # function is defined which combines unique non-NA values\n\n\n\n\n\n\n\nBei dieser Variante wird an jede Spalte ein Suffix angehängt.\nIn diesem Fall “_roll”, um zu zeigen, dass sie gewürfelt wurde:\n\n# Variation - suffix added to column names \ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll is appended to column names\n\n\n\n\n\n\n\n\n\n\nWerte/Hierarchie überschreiben\nWenn du dann alle gewürfelten Werte auswerten und nur einen bestimmten Wert (z.B. den “besten” oder “maximalen” Wert) behalten willst, kannst du mit mutate() für die gewünschten Spalten verwenden, um die case_when() verwenden, die str_detect() von der stringr Paket, um nacheinander nach String-Mustern zu suchen und den Zellinhalt zu überschreiben.\n\n# CLEAN CASES\n#############\ncases_clean &lt;- cases_rolled %&gt;% \n    \n    # clean Yes-No-Unknown vars: replace text with \"highest\" value present in the string\n    mutate(across(c(contains(\"symptoms_ever\")),                     # operates on specified columns (Y/N/U)\n             list(mod = ~case_when(                                 # adds suffix \"_mod\" to new cols; implements case_when()\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # if \"Yes\" is detected, then cell value converts to yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # then, if \"No\" is detected, then cell value converts to no\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # then, if \"Unknown\" is detected, then cell value converts to Unknown\n               TRUE                        ~ as.character(.x)))),   # then, if anything else if it kept as is\n      .keep = \"unused\")                                             # old columns removed, leaving only _mod columns\n\nJetzt kannst du in der Spalte sehen symptoms_ever dass nur “Ja” angezeigt wird, wenn die Person schon einmal “Ja” zu Symptomen gesagt hat.\n\n\n\n\n\n\nSiehe die Originaldaten.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-Duplizierung</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.de.html#probabilistische-datendeduplizierung",
    "href": "new_pages/deduplication.de.html#probabilistische-datendeduplizierung",
    "title": "15  De-Duplizierung",
    "section": "15.5 Probabilistische Datendeduplizierung",
    "text": "15.5 Probabilistische Datendeduplizierung\nManchmal möchtest du “wahrscheinliche” Duplikate auf der Grundlage der Ähnlichkeit (z. B. String-“Abstand”) über mehrere Spalten wie Name, Alter, Geschlecht, Geburtsdatum usw. identifizieren. Du kannst einen probabilistischen Abgleichsalgorithmus anwenden, um wahrscheinliche Duplikate zu identifizieren.\nSiehe die Seite über [Daten verknüpfen] für eine Erklärung dieser Methode. Der Abschnitt über den probabilistischen Abgleich enthält ein Beispiel für die Anwendung dieser Algorithmen zum Vergleich eines Datenrahmens mitsich selbst und so eine probabilistische Deduplizierung durchzuführen.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-Duplizierung</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.de.html#ressourcen",
    "href": "new_pages/deduplication.de.html#ressourcen",
    "title": "15  De-Duplizierung",
    "section": "15.6 Ressourcen",
    "text": "15.6 Ressourcen\nEin Großteil der Informationen auf dieser Seite wurde aus diesen Ressourcen und Vignetten online übernommen:\ndatanovia\ndplyr tidyverse Referenz\ncran janitor vignette",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-Duplizierung</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.de.html",
    "href": "new_pages/iteration.de.html",
    "title": "16  Iteration, Schleifen und Listen",
    "section": "",
    "text": "16.1 Vorbereitung",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteration, Schleifen und Listen</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.de.html#vorbereitung",
    "href": "new_pages/iteration.de.html#vorbereitung",
    "title": "16  Iteration, Schleifen und Listen",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n     rio,         # import/export\n     here,        # file locator\n     purrr,       # iteration\n     grates,      # scales in ggplot\n     tidyverse    # data management and visualization\n)\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteration, Schleifen und Listen</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.de.html#for-schleifen",
    "href": "new_pages/iteration.de.html#for-schleifen",
    "title": "16  Iteration, Schleifen und Listen",
    "section": "16.2 for-Schleifen",
    "text": "16.2 for-Schleifen\n\n16.2.1 for-Schleifen in R {#iter_loops .unnumbered}\nfor-Schleifen werden in R nicht besonders betont, sind aber in anderen Programmiersprachen üblich. Als Anfänger können sie hilfreich sein, um sie zu erlernen und zu üben, weil es einfacher ist, sie zu “erforschen”, zu “entstören” und auf andere Weise genau zu verstehen, was bei jeder Iteration passiert, vor allem, wenn du noch nicht in der Lage bist, deine eigenen Funktionen zu schreiben.\nDu kannst dich schnell durch for-Schleifen zum Iterieren mit gemappten Funktionen mit purrr (siehe Abschnitt unten).\n\n\nKernkomponenten\nA for-Schleife hat drei Hauptbestandteile:\n\nDie Reihenfolge der Elemente, die durchlaufen werden sollen\nDie Operationen die pro Position in der Sequenz durchzuführen sind\nDie Container für die Ergebnisse (optional)\n\nDie grundlegende Syntax lautet: for (item in sequence) {do operations using item}. Beachte die Klammern und die geschweiften Klammern. Die Ergebnisse können auf der Konsole ausgedruckt oder in einem Container-R-Objekt gespeichert werden.\nEine einfache for-Schleife Beispiel ist unten zu sehen.\n\nfor (num in c(1,2,3,4,5)) {  # the SEQUENCE is defined (numbers 1 to 5) and loop is opened with \"{\"\n  print(num + 2)             # The OPERATIONS (add two to each sequence number and print)\n}                            # The loop is closed with \"}\"                            \n\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n\n                             # There is no \"container\" in this example\n\n\n\nSequenz\nDies ist der “for”-Teil einer for-Schleife - Die Operationen werden “für” jedes Element in der Sequenz ausgeführt. Die Sequenz kann eine Reihe von Werten sein (z. B. Namen von Gerichtsbarkeiten, Krankheiten, Spaltennamen, Listenelementen usw.) oder eine Reihe von aufeinanderfolgenden Zahlen (z. B. 1,2,3,4,5). Jede Methode hat ihre eigenen Vorteile, die im Folgenden beschrieben werden.\nDie Grundstruktur einer Sequenzanweisung ist item in vector.\n\nDu kannst jedes beliebige Zeichen oder Wort anstelle von “item” schreiben (z.B. “i”, “num”, “hosp”, “district”, etc.). Der Wert dieses “item” ändert sich bei jeder Iteration der Schleife, wobei jeder Wert im Vektor durchlaufen wird.\nDie Vektor kann aus Zeichenwerten, Spaltennamen oder einer Reihe von Zahlen bestehen - das sind die Werte, die sich bei jeder Iteration ändern werden. Du kannst sie innerhalb der for-Schleife Operationen mit dem Begriff “item” verwenden.\n\nBeispiel: Folge von Zeichenwerten\nIn diesem Beispiel wird eine Schleife für jeden Wert in einem vordefinierten Zeichenvektor mit Krankenhausnamen ausgeführt.\n\n# make vector of the hospital names\nhospital_names &lt;- unique(linelist$hospital)\nhospital_names # print\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n[6] \"Central Hospital\"                    \n\n\nWir haben den Begriff hosp gewählt, um die Werte aus dem Vektor hospital_names. Bei der ersten Iteration der Schleife wird der Wert von hosp sein hospital_names[[1]]. Für die zweite Schleife ist er hospital_names[[2]]. Und so weiter…\n\n# a 'for loop' with character sequence\n\nfor (hosp in hospital_names){       # sequence\n  \n       # OPERATIONS HERE\n  }\n\nBeispiel: Reihenfolge der Spaltennamen\nDies ist eine Abwandlung der obigen Zeichenfolge, bei der die Namen eines bestehenden R-Objekts extrahiert und zum Vektor gemacht werden. Zum Beispiel die Spaltennamen eines Datenrahmens. Praktischerweise werden im Operationscode des for-Schleife können die Spaltennamen verwendet werden, um indexieren (Untermenge) ihres ursprünglichen Datenrahmens\nUnten ist die Sequenz die names() (Spaltennamen) der linelist Datenrahmens. Unser “Element”-Name ist col der im weiteren Verlauf der Schleifen für jeden Spaltennamen stehen wird.\nFür die Zwecke des Beispiels fügen wir den Code für die Operationen innerhalb der for-Schleife ein, der für jeden Wert in der Folge ausgeführt wird. In diesem Code werden die Sequenzwerte (Spaltennamen) verwendet, um zu indizieren (Teilmenge) linelisteiner nach dem anderen. Wie im Kurs [R-Grundlagen] Seite beschrieben, werden doppelte Branches[[ ]] zum Subsumieren verwendet werden. Die resultierende Spalte wird an is.na() und dann an sum() um die Anzahl der fehlenden Werte in der Spalte zu ermitteln. Das Ergebnis wird auf der Konsole ausgegeben - eine Zahl für jede Spalte.\nEin Hinweis zur Indizierung mit Spaltennamen - wenn du auf die Spalte selbst verweist schreibe nicht einfach “col”! col steht nur für den Namen der Spalte! Um auf die gesamte Spalte zu verweisen, musst du den Spaltennamen als Index auf verwenden. linelist über linelist[[col]].\n\nfor (col in names(linelist)){        # loop runs for each column in linelist; column name represented by \"col\" \n  \n  # Example operations code - print number of missing values in column\n  print(sum(is.na(linelist[[col]])))  # linelist is indexed by current value of \"col\"\n     \n}\n\n[1] 0\n[1] 0\n[1] 2087\n[1] 256\n[1] 0\n[1] 936\n[1] 1323\n[1] 278\n[1] 86\n[1] 0\n[1] 86\n[1] 86\n[1] 86\n[1] 0\n[1] 0\n[1] 0\n[1] 2088\n[1] 2088\n[1] 0\n[1] 0\n[1] 0\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 149\n[1] 765\n[1] 0\n[1] 256\n\n\nZahlenreihenfolge\nBei diesem Ansatz ist die Sequenz eine Reihe von aufeinanderfolgenden Zahlen. Der Wert des “Elements” ist also kein Zeichenwert (z. B. “Zentralkrankenhaus” oder “Datum_Untergang”), sondern eine Zahl. Das ist nützlich, um eine Schleife durch Datenrahmen zu ziehen, denn du kannst die “item”-Nummer innerhalb der for-Schleife verwenden, um den Datenrahmen zu indizieren durch Zeilennummer.\nAngenommen, du möchtest eine Schleife durch jede Zeile in deinem Datenrahmen ziehen und bestimmte Informationen extrahieren. Deine “Items” wären dann numerische Zeilennummern. Oft werden “Items” in diesem Fall geschrieben als i.\nDie for-Schleife Prozess könnte mit folgenden Worten erklärt werden: “Für jedes Element in einer Folge von Zahlen von 1 bis zur Gesamtzahl der Zeilen in meinem Datenrahmen mache X”. Bei der ersten Iteration der Schleife wird der Wert von “item” i 1 sein. Für die zweite Iteration, i 2 sein usw.\nSo sieht die Reihenfolge im Code aus: for (i in 1:nrow(linelist)) {OPERATIONS CODE} wo i für das “Element” steht und 1:nrow(linelist) eine Folge von aufeinanderfolgenden Zahlen von 1 bis zur Anzahl der Zeilen in linelist.\n\nfor (i in 1:nrow(linelist)) {  # use on a data frame\n  # OPERATIONS HERE\n}  \n\nWenn die Folge aus Zahlen bestehen soll, du aber von einem Vektor (und nicht von einem Datenrahmen) ausgehst, verwende die Abkürzung seq_along() um eine Zahlenfolge für jedes Element des Vektors zurückzugeben. Zum Beispiel, for (i in seq_along(hospital_names) {OPERATIONS CODE}.\nDer folgende Code gibt tatsächlich Zahlen zurück, die den Wert von i in ihrer jeweiligen Schleife.\n\nseq_along(hospital_names)  # use on a named vector\n\n[1] 1 2 3 4 5 6\n\n\nEin Vorteil der Verwendung von Zahlen in der Sequenz ist, dass es einfach ist, auch die i Nummer als Index für eine Container zu indizieren, in dem die Schleifenausgänge gespeichert werden. Ein Beispiel dafür findest du im Abschnitt Operationen weiter unten.\n\n\nVorgänge\nDas ist der Code innerhalb der geschweiften Klammern { } der for-Schleife. Du möchtest, dass dieser Code für jedes “Element” in der Sequenz. Achte deshalb darauf, dass jeder Teil deines Codes, der sich durch das “Item” ändert, korrekt kodiert ist, damit er sich tatsächlich ändert! Denke z.B. daran, dass du [[ ]] für die Indexierung.\nIm folgenden Beispiel durchlaufen wir jede Zeile in der Datei linelist. Die gender und age Werte jeder Zeile werden zusammengeklebt und im Containerzeichenvektor gespeichert cases_demographics. Beachte, dass wir auch die Indexierung verwenden [[i]] verwenden, um die Schleifenausgabe an der richtigen Stelle im “Container”-Vektor zu speichern.\n\n# create container to store results - a character vector\ncases_demographics &lt;- vector(mode = \"character\", length = nrow(linelist))\n\n# the for loop\nfor (i in 1:nrow(linelist)){\n  \n  # OPERATIONS\n  # extract values from linelist for row i, using brackets for indexing\n  row_gender  &lt;- linelist$gender[[i]]\n  row_age     &lt;- linelist$age_years[[i]]    # don't forget to index!\n     \n  # combine gender-age and store in container vector at indexed location\n  cases_demographics[[i]] &lt;- str_c(row_gender, row_age, sep = \",\") \n\n}  # end for loop\n\n\n# display first 10 rows of container\nhead(cases_demographics, 10)\n\n [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\"\n\n\n\n\nContainer\nManchmal sind die Ergebnisse deines for-Schleife auf der Konsole oder im Plots-Fenster von RStudio ausgegeben werden. In anderen Fällen möchtest du die Ergebnisse in einem “Container” zur späteren Verwendung speichern. Ein solcher Container kann ein Vektor, ein Datenrahmen oder sogar eine Liste sein.\nAm effizientesten ist es, den Container für die Ergebnisse zu erstellen zu ers, bevor bevor man die for-Schleife. In der Praxis bedeutet das, dass du einen leeren Vektor, Datenrahmen oder eine Liste erstellst. Diese können mit folgenden Funktionen erstellt werden vector() für Vektoren oder Listen erstellt werden, oder mit matrix() und data.frame() für einen Datenrahmen.\nLeerer Vektor\nverwenden vector() und gib den mode = basierend auf der erwarteten Klasse der Objekte, die du einfügen willst - entweder “double” (für Zahlen), “character” oder “logical”. Du solltest auch die length = im Voraus festlegen. Dies sollte die Länge deines for-Schleife Sequenz sein.\nAngenommen, du möchtest den Median der Wartezeit bis zur Einlieferung für jedes Krankenhaus speichern. Du würdest “double” verwenden und die Länge auf die Anzahl der erwarteten Ausgaben (die Anzahl der einzelnen Krankenhäuser im Datensatz) setzen.\n\ndelays &lt;- vector(\n  mode = \"double\",                            # we expect to store numbers\n  length = length(unique(linelist$hospital))) # the number of unique hospitals in the dataset\n\nLeerer Datenrahmen\nDu kannst einen leeren Datenrahmen erstellen, indem du die Anzahl der Zeilen und Spalten wie folgt angibst:\n\ndelays &lt;- data.frame(matrix(ncol = 2, nrow = 3))\n\nLeere Liste\nDu möchtest vielleicht einige Plots speichern, die von einem for-Schleife in einer Liste speichern. Eine Liste ist wie ein Vektor, enthält aber andere R-Objekte, die von verschiedenen Klassen sein können. Elemente in einer Liste können eine einzelne Zahl, ein Datenrahmen, ein Vektor und sogar eine andere Liste sein.\nDu initialisierst eine leere Liste mit der gleichen vector() Befehl wie oben, aber mit mode = \"list\". Gib die Länge der Liste an, wie du willst.\n\nplots &lt;- vector(mode = \"list\", length = 16)\n\n\n\nDrucken\nBeachten Sie, dass Sie zum Drucken aus einer for-Schleife zu drucken, musst du wahrscheinlich explizit mit der Funktion print().\nIn diesem Beispiel unten ist die Sequenz ein expliziter Zeichenvektor, der verwendet wird, um die Zeilenliste nach Krankenhaus zu unterteilen. Die Ergebnisse werden nicht in einem Container gespeichert, sondern auf der Konsole mit der Option print() Funktion.\n\nfor (hosp in hospital_names){ \n     hospital_cases &lt;- linelist %&gt;% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}\n\n[1] 885\n[1] 1469\n[1] 422\n[1] 1762\n[1] 896\n[1] 454\n\n\n\n\nTesten deiner for-Schleife\nUm deine Schleife zu testen, kannst du einen Befehl ausführen, der eine temporäre Zuweisung des “Elements” vornimmt, z. B. i &lt;- 10 oder hosp &lt;- \"Central Hospital\". Tu dies außerhalb der Schleife und führe dann nur deinen Operationscode aus (den Code innerhalb der geschweiften Klammern), um zu sehen, ob die erwarteten Ergebnisse erzielt werden.\n\n\nSchleifenplots\nUm alle drei Komponenten (Container, Sequenz und Operationen) zusammenzubringen, wollen wir versuchen, für jedes Krankenhaus eine Epikurve zu zeichnen (siehe Seite über [Epidemie-Kurven]).\nWir können eine schöne Epikurve erstellen von allen der Fälle nach Geschlecht erstellen, indem wir die Inzidenz2 Paket wie unten beschrieben:\n\n# create 'incidence' object\noutbreak &lt;- incidence2::incidence(   \n     x = linelist,                   # dataframe - complete linelist\n     date_index = \"date_onset\",        # date column\n     interval = \"week\",              # aggregate counts weekly\n     groups = \"gender\")               # group values by gender\n     #na_as_group = TRUE)             # missing gender is own group\n\n# tracer la courbe d'épidémie\nggplot(outbreak, # nom de l'objet d'incidence\n        aes(x = date_index, #aesthetiques et axes\n            y = count, \n            fill = gender), # Fill colour of bars by gender\n       color = \"black\"      # Contour colour of bars\n       ) +  \n     geom_col() + \n     facet_wrap(~gender) +\n     theme_bw() + \n     labs(title = \"Outbreak of all cases\", #titre\n          x = \"Counts\", \n          y = \"Date\", \n          fill = \"Gender\", \n          color = \"Gender\")\n\n\n\n\n\n\n\n\nUm ein separates Diagramm für die Fälle eines jeden Krankenhauses zu erstellen, können wir diesen Epikurvencode in eine for-Schleife.\nZuerst speichern wir einen benannten Vektor mit den eindeutigen Namen der Krankenhäuser, hospital_names. Die for-Schleife wird für jeden dieser Namen einmal durchlaufen: for (hosp in hospital_names). Jede Iteration der for-Schleife wird der aktuelle Krankenhausname aus dem Vektor dargestellt als hosp für die Verwendung innerhalb der Schleife.\nInnerhalb der Schleifenoperationen kannst du den R-Code wie gewohnt schreiben, aber das “Item” (hosp in diesem Fall) mit dem Wissen, dass sich sein Wert ändern wird. Innerhalb dieser Schleife:\n\nA filter() wird angewendet auf linelist, so dass die Spalte hospital gleich dem aktuellen Wert von hosp\nDas Inzidenzobjekt wird auf der gefilterten Lineliste erstellt\nDer Plot für das aktuelle Krankenhaus wird erstellt, mit einem sich automatisch anpassenden Titel, der die hosp\nDas Diagramm für das aktuelle Krankenhaus wird zwischengespeichert und dann gedruckt\nDie Schleife geht dann weiter und wiederholt sich mit dem nächsten Krankenhaus in hospital_names\n\n\n# make vector of the hospital names\nhospital_names &lt;- unique(linelist$hospital)\n\n# for each name (\"hosp\") in hospital_names, create and print the epi curve\nfor (hosp in hospital_names) {\n     \n     # create incidence object specific to the current hospital\n     outbreak_hosp &lt;- incidence2::incidence(\n          x = linelist %&gt;% filter(hospital == hosp),   # linelist is filtered to the current hospital\n          date_index = \"date_onset\",\n          interval = \"week\", \n          groups = \"gender\"#,\n          #na_as_group = TRUE\n     )\n     \n      plot_hosp &lt;- ggplot(outbreak_hosp, # incidence object name\n                         aes(x = date_index, #axes\n                             y = count, \n                             fill = gender), # fill colour by gender\n                         color = \"black\"      # colour of bar contour\n                         ) +  \n          geom_col() + \n          facet_wrap(~gender) +\n          theme_bw() + \n          labs(title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\"), #title\n               x = \"Counts\", \n               y = \"Date\", \n               fill = \"Gender\", \n               color = \"Gender\")\n     \n     # With older versions of R, remove the # before na_as_group and use this plot command instead.\n    # plot_hosp &lt;- plot(\n#       outbreak_hosp,\n#       fill = \"gender\",\n#       color = \"black\",\n#       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n#     )\n     \n     #print the plot for hospitals\n     print(plot_hosp)\n     \n} # end the for loop when it has been run for every hospital in hospital_names \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVerfolgen des Fortschritts einer Schleife\nEine Schleife mit vielen Iterationen kann viele Minuten oder sogar Stunden lang laufen. Daher kann es hilfreich sein, den Fortschritt auf der R-Konsole auszugeben. Die if Anweisung kann wie folgt platziert werden innerhalb von der Schleifenoperationen platziert werden, um jede 100ste Zahl zu drucken. Passe sie einfach so an, dass i das “Element” in deiner Schleife ist.\n\n# loop with code to print progress every 100 iterations\nfor (i in seq_len(nrow(linelist))){\n\n  # print progress\n  if(i %% 100==0){    # The %% operator is the remainder\n    print(i)\n\n}",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteration, Schleifen und Listen</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.de.html#purrr-und-listen-iter_purrr",
    "href": "new_pages/iteration.de.html#purrr-und-listen-iter_purrr",
    "title": "16  Iteration, Schleifen und Listen",
    "section": "16.3 purrr und Listen {#iter_purrr}",
    "text": "16.3 purrr und Listen {#iter_purrr}\nEin weiterer Ansatz für iterative Operationen ist die purrr Paket - es ist die tidyverse Ansatz zur Iteration.\nWenn du dieselbe Aufgabe mehrmals ausführen musst, lohnt es sich wahrscheinlich, eine verallgemeinerte Lösung zu erstellen, die du für viele Eingaben verwenden kannst. So kannst du zum Beispiel Plots für mehrere Gerichtsbarkeiten erstellen oder viele Dateien importieren und kombinieren.\nEs gibt noch ein paar andere Vorteile, die purrr - Du kannst es mit Rohren verwenden %&gt;%, es behandelt Fehler besser als normal for-Schleifen und die Syntax ist sehr sauber und einfach! Wenn du eine for-Schleife verwendest, kannst du es wahrscheinlich klarer und prägnanter machen mit purrr!\nDenke daran, dass purrr ist eine funktionales Programmierwerkzeug. Das heißt, die Operationen, die iterativ angewendet werden sollen, werden in Funktionen. Siehe die [Funktionen schreiben] Seite, um zu erfahren, wie du deine eigenen Funktionen schreiben kannst.\npurrr basiert auch fast vollständig auf Listen und Vektoren - Betrachte es also als Anwendung einer Funktion auf jedes Element der Liste/des Vektors!\n\nPakete laden\npurrr ist Teil der tidyverse ist Teil von tidyverse, du musst also kein separates Paket installieren/laden.\n\npacman::p_load(\n     rio,            # import/export\n     here,           # relative filepaths\n     tidyverse,      # data mgmt and viz\n     writexl,        # write Excel file with multiple sheets\n     readxl          # import Excel with multiple sheets\n)\n\n\n\nmap()\nEin Kern purrr Funktion ist map() die eine Funktion auf jedes Eingabeelement einer Liste/eines Vektors, den du angibst, “abbildet” (anwendet).\nDie grundlegende Syntax lautet map(.x = SEQUENCE, .f = FUNCTION, OTHER ARGUMENTS). Ein bisschen ausführlicher:\n\n.x = Sind die Eingänge auf denen die .f Funktion iterativ angewendet wird - z. B. ein Vektor von Zuständigkeitsnamen, Spalten in einem Datenrahmen oder eine Liste von Datenrahmen\n.f = ist die Funktion die auf jedes Element der Tabelle anzuwenden ist. .x Inputs anzuwenden - es könnte eine Funktion sein wie print() sein, die bereits existiert, oder eine eigene Funktion, die du definierst. Die Funktion wird oft nach einer Tilde geschrieben ~ geschrieben (Details weiter unten).\n\nNoch ein paar Hinweise zur Syntax:\n\nWenn für die Funktion keine weiteren Argumente angegeben werden müssen, kann sie ohne Klammern und ohne Tilde geschrieben werden (z.B. .f = mean). Um Argumente anzugeben, die bei jeder Iteration den gleichen Wert haben, gibst du sie innerhalb von map() aber außerhalb der .f = Argumentes, wie zum Beispiel das na.rm = T in map(.x = my_list, .f = mean, na.rm=T).\nDu kannst .x (oder einfach .) innerhalb von der .f = Funktion als Platzhalter für die .x Wert dieser Iteration\nVerwende die Tilde-Syntax (~), um eine bessere Kontrolle über die Funktion zu haben - schreibe die Funktion ganz normal mit Klammern, wie z. B: map(.x = my_list, .f = ~mean(., na.rm = T)). Verwende diese Syntax vor allem dann, wenn sich der Wert eines Arguments bei jeder Iteration ändert, oder wenn es sich um den Wert .x selbst ist (siehe Beispiele unten)\n\nDie Ausgabe der Verwendung von map() ist eine Liste - Eine Liste ist eine Objektklasse wie ein Vektor, deren Elemente aber unterschiedliche Klassen haben können. Eine Liste wird also erzeugt durch map() erzeugte Liste kann also viele Datenrahmen, viele Vektoren, viele Einzelwerte oder sogar viele Listen enthalten! Es gibt alternative Versionen von map() die weiter unten erklärt werden und andere Arten von Ausgaben erzeugen (z. B. map_dfr() um einen Datenrahmen zu erzeugen, map_chr() um Zeichenvektoren zu erzeugen, und map_dbl() um numerische Vektoren zu erzeugen).\n\n16.3.0.1 Beispiel - Excel-Tabellen importieren und kombinieren {#iter_combined .unnumbered}\nLass uns das anhand einer gängigen Aufgabe für Epidemiologen demonstrieren: - Du möchtest eine Excel-Arbeitsmappe mit Falldaten importieren, aber die Daten sind auf verschiedene benannte Blätter in der Arbeitsmappe verteilt. Wie kannst du die Blätter effizient importieren und in einem Datenrahmen zusammenfassen?\nNehmen wir an, wir erhalten die unten stehende Excel-Arbeitsmappe. Jedes Blatt enthält Fälle aus einem bestimmten Krankenhaus.\n\n\n\n\n\n\n\n\n\nHier ist ein Ansatz, bei dem map():\n\nmap() Die Funktion import() so, dass sie für jedes Excel-Blatt ausgeführt wird\nKombiniere die importierten Datenrahmen zu einem einzigen mit bind_rows()\nBehalte dabei den ursprünglichen Blattnamen für jede Zeile bei und speichere diese Information in einer neuen Spalte im endgültigen Datenrahmen\n\nZuerst müssen wir die Blattnamen extrahieren und speichern. Wir geben den Dateipfad der Excel-Arbeitsmappe an die Funktion excel_sheets() aus dem Paket readxl, das die Blattnamen extrahiert. Wir speichern sie in einem Zeichenvektor namens sheet_names.\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\nHier sind die Namen:\n\nsheet_names\n\n[1] \"Central Hospital\"              \"Military Hospital\"            \n[3] \"Missing\"                       \"Other\"                        \n[5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\n\n\nJetzt haben wir diesen Vektor von Namen, map() können wir sie nacheinander an die Funktion import(). In diesem Beispiel wird die sheet_names sind .x und import() ist die Funktion .f.\nRückruf aus dem [Import und Export] Seite, dass bei der Verwendung in Excel-Arbeitsmappen ,import() das Argument akzeptieren kann which = akzeptieren, das das zu importierende Blatt angibt. Innerhalb der .f Funktion import() stellen wir which = .x an, deren Wert sich bei jeder Iteration durch den Vektor ändert sheet_names - zuerst “Zentralkrankenhaus”, dann “Militärkrankenhaus”, usw.\nZu beachten ist - weil wir die map() verwendet haben, werden die Daten in jedem Excel-Blatt als ein separater Datenrahmen innerhalb einer Liste gespeichert. Wir möchten, dass jedes dieser Listenelemente (Datenrahmen) einen Namen haben, bevor wir also sheet_names an map() passieren wir es durch set_names() von purrr, wodurch sichergestellt wird, dass jedes Listenelement den richtigen Namen erhält.\nWir speichern die Ausgabeliste als combined.\n\ncombined &lt;- sheet_names %&gt;% \n  purrr::set_names() %&gt;% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\n\nWenn wir die Ausgabe überprüfen, sehen wir, dass die Daten aus jedem Excel-Blatt mit einem Namen in der Liste gespeichert sind. Das ist gut, aber wir sind noch nicht ganz fertig.\n\n\n\n\n\n\n\n\n\nZum Schluss verwenden wir die Funktion bind_rows() (von dplyr), die eine Liste ähnlich strukturierter Datenrahmen akzeptiert und sie zu einem Datenrahmen kombiniert. Um eine neue Spalte aus dem Listenelement zu erstellen Namen zu erstellen, verwenden wir das Argument .id = und geben ihm den gewünschten Namen für die neue Spalte.\nIm Folgenden findest du die gesamte Befehlssequenz:\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")  # extract sheet names\n \ncombined &lt;- sheet_names %&gt;%                                     # begin with sheet names\n  purrr::set_names() %&gt;%                                        # set their names\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %&gt;%  # iterate, import, save in list\n  bind_rows(.id = \"origin_sheet\") # combine list of data frames, preserving origin in new column  \n\nUnd jetzt haben wir einen Datenrahmen mit einer Spalte, die das Ursprungsblatt enthält!\n\n\n\n\n\n\n\n\n\nEs gibt Variationen von map() die du kennen solltest. Zum Beispiel, map_dfr() einen Datenrahmen zurück, keine Liste. Wir hätten ihn also für die obige Aufgabe verwenden können und hätten keine Zeilen binden müssen. Aber dann hätten wir nicht erfassen können, aus welchem Blatt (Krankenhaus) die einzelnen Fälle stammen.\nAndere Varianten sind map_chr(), map_dbl(). Diese Funktionen sind aus zwei Gründen sehr nützlich. Erstens wandeln sie die Ausgabe einer iterativen Funktion automatisch in einen Vektor (und nicht in eine Liste) um. Zweitens können sie explizit die Klasse steuern, in der die Daten zurückkommen - du stellst sicher, dass deine Daten als Zeichenvektor zurückkommen mit map_chr() oder als numerischer Vektor mit map_dbl(). Darauf kommen wir später in diesem Abschnitt zurück!\nDie Funktionen map_at() und map_if() sind ebenfalls sehr nützlich für die Iteration - mit ihnen kannst du angeben, welche Elemente einer Liste du iterieren sollst! Sie funktionieren, indem sie einfach einen Vektor von Indizes/Namen anwenden (im Fall von map_at()) oder einen logischen Test (im Fall von map_if()).\nNehmen wir ein Beispiel, bei dem wir das erste Blatt der Krankenhausdaten nicht lesen wollten. Wir verwenden map_at() anstelle von map(), und geben die .at = Argument an c(-1) an, was bedeutet nicht das erste Element von .x. Alternativ kannst du auch einen Vektor mit positiven Zahlen oder Namen an .at = geben, um anzugeben, welche Elemente verwendet werden sollen.\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined &lt;- sheet_names %&gt;% \n     purrr::set_names() %&gt;% \n     # exclude the first sheet\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))\n\nBeachte, dass der erste Blattname immer noch als Element der Ausgabeliste erscheint - aber es ist nur ein einstelliger Name (kein Datenrahmen). Du müsstest dieses Element entfernen, bevor du Zeilen bindest. Wie du Listenelemente entfernst und änderst, erfährst du in einem späteren Abschnitt.\n\n\n\nDatensatz aufteilen und exportieren\nIm Folgenden geben wir ein Beispiel dafür, wie man einen Datensatz in Teile aufteilt und dann mit map() Iteration, um jeden Teil als separates Excel-Blatt oder als separate CSV-Datei zu exportieren.\n\nDatensatz teilen\nNehmen wir an, wir haben den vollständigen Fall linelist als Datenrahmen und wollen nun für jedes Krankenhaus eine eigene Liste erstellen und diese als separate CSV-Datei exportieren. Im Folgenden führen wir die folgenden Schritte aus:\nVerwende group_split() (von dplyr) zum Aufteilen der linelist Datenrahmen nach eindeutigen Werten in der Spalte hospital. Die Ausgabe ist eine Liste mit einem Datenrahmen pro Krankenhaus-Teilmenge.\n\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital)\n\nWir können View(linelist_split) ausführen und sehen, dass diese Liste 6 Datenrahmen (“Tibbles”) enthält, die jeweils die Fälle eines Krankenhauses repräsentieren.\n\n\n\n\n\n\n\n\n\nBeachte jedoch, dass die Datenrahmen in der Liste standardmäßig keine Namen haben! Wir möchten, dass jeder Datenrahmen einen Namen hat und dass dieser Name beim Speichern der CSV-Datei verwendet wird.\nEine Möglichkeit, die Namen zu extrahieren, ist die Verwendung von pull() (aus dplyr) zum Extrahieren der hospital Spalte aus jedem Datenrahmen in der Liste zu extrahieren. Um sicherzugehen, wandeln wir die Werte dann in Zeichen um und verwenden dann unique() um den Namen für den jeweiligen Datenrahmen zu erhalten. Alle diese Schritte werden für jeden Datenrahmen über map().\n\nnames(linelist_split) &lt;- linelist_split %&gt;%   # Assign to names of listed data frames \n     # Extract the names by doing the following to each data frame: \n     map(.f = ~pull(.x, hospital)) %&gt;%        # Pull out hospital column\n     map(.f = ~as.character(.x)) %&gt;%          # Convert to character, just in case\n     map(.f = ~unique(.x))                    # Take the unique hospital name\n\nWir können nun sehen, dass jedes Listenelement einen Namen hat. Auf diese Namen kann man über names(linelist_split).\n\n\n\n\n\n\n\n\n\n\nnames(linelist_split)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Missing\"                             \n[4] \"Other\"                               \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\n\nMehr als eine group_split() Spalte\nWenn du die Zeilenliste aufteilen möchtest nach mehr als eine Gruppierungsspalte aufteilen möchtest, z. B. um eine Unterliste nach Krankenhaus UND Geschlecht zu erstellen, brauchst du einen anderen Ansatz für die Benennung der Listenelemente. Dazu musst du die eindeutigen “Gruppenschlüssel” mit group_keys() von dplyr - werden sie als Datenrahmen zurückgegeben. Dann kannst du die Gruppenschlüssel zu Werten kombinieren mit unite() zu Werten kombinieren, wie unten gezeigt, und diese Konglomeratnamen den linelist_split.\n\n# split linelist by unique hospital-gender combinations\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital, gender)\n\n# extract group_keys() as a dataframe\ngroupings &lt;- linelist %&gt;% \n     group_by(hospital, gender) %&gt;%       \n     group_keys()\n\ngroupings      # show unique groupings \n\n# A tibble: 18 × 2\n   hospital                             gender\n   &lt;chr&gt;                                &lt;chr&gt; \n 1 Central Hospital                     f     \n 2 Central Hospital                     m     \n 3 Central Hospital                     &lt;NA&gt;  \n 4 Military Hospital                    f     \n 5 Military Hospital                    m     \n 6 Military Hospital                    &lt;NA&gt;  \n 7 Missing                              f     \n 8 Missing                              m     \n 9 Missing                              &lt;NA&gt;  \n10 Other                                f     \n11 Other                                m     \n12 Other                                &lt;NA&gt;  \n13 Port Hospital                        f     \n14 Port Hospital                        m     \n15 Port Hospital                        &lt;NA&gt;  \n16 St. Mark's Maternity Hospital (SMMH) f     \n17 St. Mark's Maternity Hospital (SMMH) m     \n18 St. Mark's Maternity Hospital (SMMH) &lt;NA&gt;  \n\n\nNun fassen wir die Gruppierungen zusammen, trennen sie durch Bindestriche und weisen sie als Namen von Listenelementen in linelist_split. Dies erfordert einige zusätzliche Zeilen, da wir die NA durch “Fehlend”, verwenden unite() von dplyr um die Spaltenwerte zusammenzufassen (durch Bindestriche getrennt) und dann in einen unbenannten Vektor zu konvertieren, damit er als Namen für linelist_split.\n\n# Combine into one name value \nnames(linelist_split) &lt;- groupings %&gt;% \n     mutate(across(everything(), replace_na, \"Missing\")) %&gt;%  # replace NA with \"Missing\" in all columns\n     unite(\"combined\", sep = \"-\") %&gt;%                         # Unite all column values into one\n     setNames(NULL) %&gt;% \n     as_vector() %&gt;% \n     as.list()\n\n\n\n\nAls Excel-Blätter exportieren\nSo exportieren Sie die Krankenhaus-Listen als eine Excel-Arbeitsmappe mit einer Strichliste pro Blatt können wir einfach die benannte Liste bereitstellen linelist_split an die write_xlsx() Funktion von der writexl Paket. Diese Funktion ermöglicht es, eine Excel-Arbeitsmappe mit mehreren Blättern zu speichern. Die Namen der Listenelemente werden automatisch als Blattnamen übernommen.\n\nlinelist_split %&gt;% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))\n\nDu kannst jetzt die Excel-Datei öffnen und sehen, dass jedes Krankenhaus sein eigenes Blatt hat.\n\n\n\n\n\n\n\n\n\n\n\nExportieren als CSV-Dateien\nDieser Befehl ist etwas komplizierter, aber du kannst auch jede krankenhausspezifische Linienliste als separate CSV-Datei exportieren, mit einem Dateinamen, der dem Krankenhaus entspricht.\nAuch hier verwenden wir map(): Wir nehmen den Vektor der Listenelementnamen (siehe oben) und verwenden map() um durch sie zu iterieren, indem wir export() (aus dem rioPaket, siehe [Import und Export] Seite) auf den Datenrahmen in der Listelinelist_split der diesen Namen trägt. Wir verwenden den Namen auch, um einen eindeutigen Dateinamen zu erstellen. So funktioniert es:\n\nWir beginnen mit dem Vektor der Zeichennamen, der an map() als .x\nDie .f Funktion ist export() die einen Datenrahmen und einen Dateipfad benötigt, in den geschrieben werden soll\nDie Eingabe .x (der Name des Krankenhauses) wird verwendet innerhalb von .f zu extrahieren/indizieren, um dieses spezifische Element von linelist_split Liste. Dies führt dazu, dass jeweils nur ein Datenrahmen an die export().\nZum Beispiel, wenn map() nach “Militärkrankenhaus” iteriert, dann linelist_split[[.x]] ist eigentlich linelist_split[[\"Military Hospital\"]] und liefert somit das zweite Element von linelist_split - das alle Fälle aus dem Militärkrankenhaus enthält.\nDer Dateipfad, der an export() ist dynamisch durch die Verwendung von str_glue()(siehe [Zeichen und Zeichenketten] Seite):\n\nhere() wird verwendet, um die Basis des Dateipfads zu erhalten und den Ordner “data” anzugeben (beachte einfache Anführungszeichen, um die str_glue() doppelten Anführungszeichen)\n\nDann ein Schrägstrich /, und dann wieder der .x das den aktuellen Krankenhausnamen ausgibt, um die Datei identifizierbar zu machen\nSchließlich die Erweiterung “.csv”, die export() verwendet, um eine CSV-Datei zu erstellen\n\n\nnames(linelist_split) %&gt;%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))\n\nJetzt kannst du sehen, dass jede Datei im Ordner “data” des R-Projekts “Epi_R_handbook” gespeichert wird!\n\n\n\n\n\n\n\n\n\n\n\n\nBenutzerdefinierte Funktionen\nVielleicht möchtest du deine eigene Funktion erstellen, die du an map().\nNehmen wir an, wir wollen Epidemiekurven für die Fälle eines jeden Krankenhauses erstellen. Um dies zu tun, verwenden wir purrr unsere .f Funktion kann sein ggplot() und Erweiterungen mit + wie üblich. Da die Ausgabe von map() immer eine Liste ist, werden auch die Plots in einer Liste gespeichert. Da es sich um Plots handelt, können sie extrahiert und mit der Funktion ggarrange() Funktion aus der ggpubr Paket (Dokumentation).\n\n# load package for plotting elements from list\npacman::p_load(ggpubr)\n\n# map across the vector of 6 hospital \"names\" (created earlier)\n# use the ggplot function specified\n# output is a list with 6 ggplots\n\nhospital_names &lt;- unique(linelist$hospital)\n\nmy_plots &lt;- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %&gt;% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\nWenn diese map() Code zu chaotisch aussieht, kannst du das gleiche Ergebnis erzielen, indem du deine spezifischen ggplot() Befehl als benutzerdefinierte Funktion speicherst, zum Beispiel unter dem Namen make_epicurve()). Diese Funktion wird dann innerhalb der map(). .x iterativ durch den Namen des Krankenhauses ersetzt und als hosp_name in der make_epicurve()Funktion. Siehe die Seite über [Funktionen schreiben].\n\n# Create function\nmake_epicurve &lt;- function(hosp_name){\n  \n  ggplot(data = linelist %&gt;% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n\n\n# mapping\nmy_plots &lt;- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\nEine Funktion spaltenübergreifend abbilden\nEin weiterer häufiger Anwendungsfall ist die Zuordnung einer Funktion über mehrere Spalten hinweg. Im Folgenden werden wir map() die Funktion t.test() auf die numerischen Spalten des Datenrahmens linelist und vergleicht die numerischen Werte nach Geschlecht.\nErinnere dich an die Seite über [Einfache statistische Tests] dasst.test() Eingaben im Formelformat annehmen können, wie zum Beispiel t.test(numeric column ~ binary column). In diesem Beispiel gehen wir wie folgt vor:\n\nDie numerischen Spalten von Interesse werden ausgewählt aus linelist - diese werden zu den .x Eingaben für map()\nDie Funktion t.test() wird als die .f Funktion, die auf jede numerische Spalte angewendet wird\nInnerhalb der Klammern von t.test():\n\ndie erste ~ geht dem .f dass map() wird iteriert über .x\ndie .x steht für die aktuelle Spalte, die an die Funktion übergeben wird t.test()\ndie zweite ~ ist Teil der oben beschriebenen t-Test-Gleichung\ndie t.test() Funktion erwartet eine binäre Spalte auf der rechten Seite der Gleichung. Wir liefern den Vektor linelist$gender unabhängig und statisch (beachte, dass er nicht in der select()).\n\n\nmap() gibt eine Liste zurück. Die Ausgabe ist also eine Liste mit t-Testergebnissen - ein Listenelement für jede analysierte numerische Spalte.\n\n# Results are saved as a list\nt.test_results &lt;- linelist %&gt;% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %&gt;%  # keep only some numeric columns to map across\n  map(.f = ~t.test(.x ~ linelist$gender))        # t.test function, with equation NUMERIC ~ CATEGORICAL\n\nSo sieht die Liste aus t.test_results aussieht, wenn sie in RStudio geöffnet (betrachtet) wird. Wir haben die Teile hervorgehoben, die für die Beispiele auf dieser Seite wichtig sind.\n\nOben kannst du sehen, dass die gesamte Liste den Namen t.test_results heißt und fünf Elemente hat. Diese fünf Elemente heißen age, wt_km, ht_cm, ct_blood, temp nach jeder Variable, die in einem t-Test verwendet wurde, mit gender von der linelist.\nJedes dieser fünf Elemente ist selbst eine Liste, mit Elementen innerhalb dieser Listen wie p.value und conf.int. Einige dieser Elemente wie p.value sind einzelne Zahlen, während einige wie estimate aus zwei oder mehr Elementen bestehen (mean in group f und mean in group m).\n\n\n\n\n\n\n\n\n\n\nHinweis: Wenn du eine Funktion nur auf bestimmte Spalten in einem Datenrahmen anwenden willst, kannst du auch einfach die mutate() und across()verwenden, wie im Abschnitt [Reinigung von Daten und Kernfunktionen] Seite erklärt wird. Unten findest du ein Beispiel für die Anwendungas.character() nur auf die Spalten “Alter”. Beachte die Platzierung der Klammern und Kommas.\n\n# convert columns with column name containing \"age\" to class Character\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  \n\n\n\nAuszug aus den Listen\nAls map() eine Ausgabe der Klasse Liste erzeugt, werden wir einige Zeit damit verbringen, zu erörtern, wie man Daten aus Listen extrahiert, indem man die zugehörigen purrr Funktionen. Um dies zu demonstrieren, werden wir die Liste t.test_results aus dem vorherigen Abschnitt. Dies ist eine Liste mit 5 Listen - jede der 5 Listen enthält die Ergebnisse eines t-Tests zwischen einer Spalte aus linelist Datenrahmen und seiner binären Spalte gender. Das Bild im obigen Abschnitt zeigt dir die Listenstruktur.\n\nNamen der Elemente\nUm die Namen der Elemente selbst zu extrahieren, verwendest du einfach names() von base R. In diesem Fall verwenden wir names() auf t.test_results um die Namen jeder Teilliste zurückzugeben, d.h. die Namen der 5 Variablen, für die t-Tests durchgeführt wurden.\n\nnames(t.test_results)\n\n[1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\"    \n\n\n\n\nElemente nach Name oder Position\nUm Listenelemente nach Namen oder nach Position zu extrahieren, kannst du Klammern verwenden [[ ]]verwenden, wie es in den [R-Grundlagen] Seite beschrieben. Im Folgenden verwenden wir doppelte Klammern, um die Liste zu indizierent.tests_results und zeigen das erste Element an, das die Ergebnisse des t-Tests auf age.\n\nt.test_results[[1]] # first element by position\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\nt.test_results[[1]][\"p.value\"] # return element named \"p.value\" from first element  \n\n$p.value\n[1] 2.350374e-96\n\n\nIm Folgenden werden wir jedoch die Verwendung der einfachen und flexiblen purrr Funktionen map() und pluck() um die gleichen Ergebnisse zu erzielen.\n\n\npluck()\npluck() zieht Elemente nach Namen oder nach Position heraus. Um zum Beispiel die Ergebnisse des t-Tests für das Alter zu extrahieren, kannst du Folgendes verwenden pluck() wie folgt:\n\nt.test_results %&gt;% \n  pluck(\"age\")        # alternatively, use pluck(1)\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\n\nIndexiere tiefere Ebenen, indem du die weiteren Ebenen mit Kommas angibst. Im Folgenden wird das Element mit dem Namen “p.value” aus der Liste extrahiert age innerhalb der Liste t.test_results. Du kannst auch Zahlen anstelle von Zeichennamen verwenden.\n\nt.test_results %&gt;% \n  pluck(\"age\", \"p.value\")\n\n[1] 2.350374e-96\n\n\nDu kannst solche inneren Elemente aus allen Elementen der ersten Ebene extrahieren, indem du map() um die pluck() Funktion über jedes Element der ersten Ebene ausführt. Der folgende Code extrahiert zum Beispiel die “p.value”-Elemente aus allen Listen innerhalb t.test_results. Die Liste der t-Testergebnisse ist die .x durch iteriert, pluck() ist die .f Funktion, die iteriert wird, und der Wert “p-value” wird der Funktion übergeben.\n\nt.test_results %&gt;%\n  map(pluck, \"p.value\")   # return every p-value\n\n$age\n[1] 2.350374e-96\n\n$wt_kg\n[1] 2.664367e-182\n\n$ht_cm\n[1] 3.515713e-144\n\n$ct_blood\n[1] 0.4473498\n\n$temp\n[1] 0.5735923\n\n\nAls weitere Alternative, map() bietet eine Abkürzung, bei der du den Namen des Elements in Anführungszeichen schreiben kannst und er wird dann herausgepickt. Wenn du den map() verwendest, ist die Ausgabe eine Liste, während du bei der Verwendung von map_chr() ein benannter Zeichenvektor ist und wenn du map_dbl() ein benannter numerischer Vektor sein wird.\n\nt.test_results %&gt;% \n  map_dbl(\"p.value\")   # return p-values as a named numeric vector\n\n          age         wt_kg         ht_cm      ct_blood          temp \n 2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01 \n\n\nDu kannst mehr darüber lesen pluck() in seinem purrr Dokumentation. Sie hat eine Geschwisterfunktion chuck() die einen Fehler anstelle von NULL zurückgibt, wenn ein Element nicht existiert.\n\n\n\nListe in Datenrahmen umwandeln\nDies ist ein komplexes Thema - im Abschnitt Ressourcen findest du ausführlichere Anleitungen. Dennoch wollen wir dir zeigen, wie du die Liste der t-Testergebnisse in einen Datenrahmen umwandelst. Wir erstellen einen Datenrahmen mit Spalten für die Variable, ihren p-Wert und die Mittelwerte der beiden Gruppen (männlich und weiblich).\nHier sind einige der neuen Ansätze und Funktionen, die wir verwenden werden:\n\nDie Funktion tibble() wird verwendet, um ein Tibble (wie einen Datenrahmen) zu erstellen\n\nWir umgeben die tibble() Funktion mit geschweiften Klammern { } um zu verhindern, dass die gesamte t.test_results nicht als erste Tibble-Spalte gespeichert wird\n\nInnerhalb von tibble() wird jede Spalte explizit erstellt, ähnlich der Syntax von mutate():\n\nDie . steht für t.test_results\nUm eine Spalte mit den Namen der t-Test-Variablen (die Namen der einzelnen Listenelemente) zu erstellen, verwenden wir names() wie oben beschrieben\nUm eine Spalte mit den p-Werten zu erstellen, verwenden wir map_dbl() wie oben beschrieben, um die p.value Elemente und wandeln sie in einen numerischen Vektor um\n\n\n\nt.test_results %&gt;% {\n  tibble(\n    variables = names(.),\n    p         = map_dbl(., \"p.value\"))\n  }\n\n# A tibble: 5 × 2\n  variables         p\n  &lt;chr&gt;         &lt;dbl&gt;\n1 age       2.35e- 96\n2 wt_kg     2.66e-182\n3 ht_cm     3.52e-144\n4 ct_blood  4.47e-  1\n5 temp      5.74e-  1\n\n\nFügen wir nun Spalten hinzu, die die Mittelwerte für jede Gruppe (Männer und Frauen) enthalten.\nDazu müssten wir das Element estimate extrahieren, aber das enthält eigentlich zwei Elemente in sich (mean in group f und mean in group m). Er kann also nicht zu einem Vektor vereinfacht werden mit map_chr() oder map_dbl(). Stattdessen verwenden wir map(), die innerhalb von tibble() verwendet wird, erzeugt eine Spalte der Klassenliste innerhalb der Tibble! Ja, das ist möglich!\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\"))}\n\n# A tibble: 5 × 3\n  variables         p means       \n  &lt;chr&gt;         &lt;dbl&gt; &lt;named list&gt;\n1 age       2.35e- 96 &lt;dbl [2]&gt;   \n2 wt_kg     2.66e-182 &lt;dbl [2]&gt;   \n3 ht_cm     3.52e-144 &lt;dbl [2]&gt;   \n4 ct_blood  4.47e-  1 &lt;dbl [2]&gt;   \n5 temp      5.74e-  1 &lt;dbl [2]&gt;   \n\n\nSobald du diese Listenspalte hast, gibt es mehrere tidyr Funktionen (Teil von tidyverse), die dir helfen, diese “verschachtelten Listenspalten” zu “entschachteln” oder zu “entschachteln”. Lies mehr über sie hier oder indem du vignette(\"rectangle\"). Kurz gefasst:\n\nunnest_wider() - gibt jedem Element einer Listenspalte eine eigene Spalte\nunnest_longer() - gibt jedem Element einer Listenspalte eine eigene Zeile\nhoist() - verhält sich wie unnest_wider() aber du gibst an, welche Elemente entnestet werden sollen\n\nIm Folgenden übergeben wir das Tibble an unnest_wider() und geben dabei die means Spalte (die eine verschachtelte Liste ist). Das Ergebnis ist, dass means durch zwei neue Spalten ersetzt wird, die jeweils die beiden Elemente enthalten, die vorher in jeder means Zelle waren.\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %&gt;% \n  unnest_wider(means)\n\n# A tibble: 5 × 4\n  variables         p `mean in group f` `mean in group m`\n  &lt;chr&gt;         &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 age       2.35e- 96              12.7              19.6\n2 wt_kg     2.66e-182              45.8              59.6\n3 ht_cm     3.52e-144             109.              142. \n4 ct_blood  4.47e-  1              21.2              21.2\n5 temp      5.74e-  1              38.6              38.6\n\n\n\n\nListen verwerfen, behalten und verdichten\nWeil die Arbeit mit purrr so oft mit Listen zu tun hat, werden wir uns kurz mit einigen purrr Funktionen, um Listen zu verändern. Im Abschnitt Ressourcen findest du weitere vollständige Tutorials zu purrr Funktionen.\n\nlist_modify() hat viele Verwendungszwecke, einer davon kann das Entfernen eines Listenelements sein\nkeep() behält die Elemente bei, die in .p = übergebenen Elemente, oder wenn eine Funktion, die an .p = zu TRUE ausgewertet wird\ndiscard() werden die Elemente entfernt, die in .p angegebenen Elemente entfernt, oder wenn eine Funktion, die an .p = zu TRUE ausgewertet wird\ncompact() Entfernt alle leeren Elemente\n\nHier sind einige Beispiele, die die combined Liste, die im obigen Abschnitt über map() verwenden, um mehrere Dateien zu importieren und zu kombinieren erstellt wurde (sie enthält 6 Case-Linelist-Datenrahmen):\nElemente können nach Namen entfernt werden mit list_modify() und dem Setzen des Namens gleich NULL.\n\ncombined %&gt;% \n  list_modify(\"Central Hospital\" = NULL)   # remove list element by name\n\nDu kannst auch Elemente nach Kriterien entfernen, indem du eine “Prädikat”-Gleichung für .p = (eine Gleichung, die entweder TRUE oder FALSE ergibt). Setze eine Tilde ~ vor die Funktion und verwende .x um das Listenelement darzustellen. verwenden keep() werden die Listenelemente, die als TRUE ausgewertet werden, beibehalten. Umgekehrt, wenn du discard() werden die Listenelemente, die TRUE ergeben, entfernt.\n\n# keep only list elements with more than 500 rows\ncombined %&gt;% \n  keep(.p = ~nrow(.x) &gt; 500)  \n\nIm folgenden Beispiel werden Listenelemente verworfen, wenn ihre Klasse kein Datenrahmen ist.\n\n# Discard list elements that are not data frames\ncombined %&gt;% \n  discard(.p = ~class(.x) != \"data.frame\")\n\nDeine Prädikatsfunktion kann auch auf Elemente/Spalten innerhalb jedes Listenelements verweisen. Im folgenden Beispiel werden Listenelemente, die den Mittelwert der Spalte ct_blood über 25 liegt, verworfen werden.\n\n# keep only list elements where ct_blood column mean is over 25\ncombined %&gt;% \n  discard(.p = ~mean(.x$ct_blood) &gt; 25)  \n\nDieser Befehl würde alle leeren Listenelemente entfernen:\n\n# Remove all empty list elements\ncombined %&gt;% \n  compact()\n\n\n\npmap()\nDIESER ABSCHNITT BEFINDET SICH IM AUFBAU",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteration, Schleifen und Listen</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.de.html#funktionen-anwenden",
    "href": "new_pages/iteration.de.html#funktionen-anwenden",
    "title": "16  Iteration, Schleifen und Listen",
    "section": "16.4 Funktionen anwenden",
    "text": "16.4 Funktionen anwenden\nDie Familie der “apply”-Funktionen ist eine Basis R Alternative zu purrr für iterative Operationen. Du kannst mehr über sie lesen hier.",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteration, Schleifen und Listen</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.de.html#ressourcen",
    "href": "new_pages/iteration.de.html#ressourcen",
    "title": "16  Iteration, Schleifen und Listen",
    "section": "16.5 Ressourcen",
    "text": "16.5 Ressourcen\nfür Schleifen mit Data Carpentry\nDie R for Data Science Seite über Iteration\nVignette zum Schreiben/Lesen von Excel-Dateien\nEin Schnurren tutorial von jennybc\nNoch ein Schnurrer tutorial von Rebecca Barter\nEin Schnurren tutorial zu map, pmap und imap\npurrr cheatsheet\npurrr Tipps und Tricks\nBehalten und wegwerfen",
    "crumbs": [
      "Datenmanagement",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteration, Schleifen und Listen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html",
    "href": "new_pages/tables_descriptive.de.html",
    "title": "17  Beschreibende Tabellen",
    "section": "",
    "text": "17.1 Vorbereitung",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html#vorbereitung",
    "href": "new_pages/tables_descriptive.de.html#vorbereitung",
    "title": "17  Beschreibende Tabellen",
    "section": "",
    "text": "Pakete laden\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics \n  gtsummary,    # summary statistics and tests\n  rstatix,      # summary statistics and statistical tests\n  janitor,      # adding totals and percents to tables\n  scales,       # easily convert proportions to percents  \n  flextable     # converting tables to pretty images\n  )\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html#daten-durchsuchen",
    "href": "new_pages/tables_descriptive.de.html#daten-durchsuchen",
    "title": "17  Beschreibende Tabellen",
    "section": "17.2 Daten durchsuchen",
    "text": "17.2 Daten durchsuchen\n\nskimr Paket\nDurch die Verwendung des skimr Paket kannst du einen detaillierten und ästhetisch ansprechenden Überblick über alle Variablen in deinem Datensatz erhalten. Lies mehr über skimr auf seiner github-Seite.\nUnten, die Funktion skim() wird auf die gesamte linelist Datenrahmen angewendet. Es wird ein Überblick über den Datenrahmen und eine Zusammenfassung jeder Spalte (nach Klasse) erstellt.\n\n## get information about each variable in a dataset \nskim(linelist)\n\n\n\n\nData summary\n\n\nName\nlinelist\n\n\nNumber of rows\n5888\n\n\nNumber of columns\n30\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n4\n\n\nfactor\n2\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n0\n1.00\n6\n6\n0\n5888\n0\n\n\noutcome\n1323\n0.78\n5\n7\n0\n2\n0\n\n\ngender\n278\n0.95\n1\n1\n0\n2\n0\n\n\nage_unit\n0\n1.00\n5\n6\n0\n2\n0\n\n\nhospital\n0\n1.00\n5\n36\n0\n6\n0\n\n\ninfector\n2088\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2088\n0.65\n5\n7\n0\n2\n0\n\n\nfever\n249\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n249\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n249\n0.96\n2\n3\n0\n2\n0\n\n\naches\n249\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n249\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n765\n0.87\n5\n5\n0\n1072\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_infection\n2087\n0.65\n2014-03-19\n2015-04-27\n2014-10-11\n359\n\n\ndate_onset\n256\n0.96\n2014-04-07\n2015-04-30\n2014-10-23\n367\n\n\ndate_hospitalisation\n0\n1.00\n2014-04-17\n2015-04-30\n2014-10-23\n363\n\n\ndate_outcome\n936\n0.84\n2014-04-19\n2015-06-04\n2014-11-01\n371\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nage_cat\n86\n0.99\nFALSE\n8\n0-4: 1095, 5-9: 1095, 20-: 1073, 10-: 941\n\n\nage_cat5\n86\n0.99\nFALSE\n17\n0-4: 1095, 5-9: 1095, 10-: 941, 15-: 743\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n0\n1.00\n16.56\n5.79\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nage\n86\n0.99\n16.07\n12.62\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nage_years\n86\n0.99\n16.02\n12.64\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nlon\n0\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n0\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nwt_kg\n0\n1.00\n52.64\n18.58\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n0\n1.00\n124.96\n49.52\n4.00\n91.00\n129.00\n159.00\n295.00\n\n\nct_blood\n0\n1.00\n21.21\n1.69\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n149\n0.97\n38.56\n0.98\n35.20\n38.20\n38.80\n39.20\n40.80\n\n\nbmi\n0\n1.00\n46.89\n55.39\n-1200.00\n24.56\n32.12\n50.01\n1250.00\n\n\ndays_onset_hosp\n256\n0.96\n2.06\n2.26\n0.00\n1.00\n1.00\n3.00\n22.00\n\n\n\n\n\nDu kannst auch die summary() Funktion, von Basis R, um Informationen über einen ganzen Datensatz zu erhalten, aber diese Ausgabe kann schwieriger zu lesen sein als die Verwendung von skimr. Deshalb wird die Ausgabe unten nicht angezeigt, um Platz zu sparen.\n\n## get information about each column in a dataset \nsummary(linelist)\n\n\n\nZusammenfassende Statistik\nDu kannst verwenden Basis R-Funktionen verwenden, um zusammenfassende Statistiken für eine numerische Spalte zu erstellen. Die meisten nützlichen Statistiken für eine numerische Spalte erhältst du mit summary() wie unten beschrieben. Beachte, dass auch der Name des Datenrahmens angegeben werden muss, wie unten gezeigt.\n\nsummary(linelist$age_years)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.02   23.00   84.00      86 \n\n\nDu kannst auf einen bestimmten Teil davon mit Indexklammern zugreifen und ihn speichern []:\n\nsummary(linelist$age_years)[[2]]            # return only the 2nd element\n\n[1] 6\n\n# equivalent, alternative to above by element name\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \n\nDu kannst einzelne Statistiken zurückgeben mit Basis R-Funktionen wie max(), min(), median(), mean(), quantile(), sd(), und range(). Siehe die [R-Grundlagen] Seite für eine vollständige Liste.\nVORSICHT! Wenn deine Daten fehlende Werte enthalten, möchte R, dass du das weißt, und gibt daher NA zurück, es sei denn, du gibst bei den oben genannten mathematischen Funktionen an, dass R fehlende Werte ignorieren soll. na.rm = TRUE.\nDu kannst die get_summary_stats() Funktion von rstatix um zusammenfassende Statistiken zurückzugeben in einem Datenrahmenformat. Das kann hilfreich sein, um spätere Operationen oder Plots mit den Zahlen durchzuführen. Siehe die [Einfache statistische Tests] Seite für weitere Informationen über dierstatix Paket und seine Funktionen.\n\nlinelist %&gt;% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # columns to calculate for\n    type = \"common\")                    # summary stats to return\n\n# A tibble: 5 × 10\n  variable     n   min   max median   iqr  mean     sd    se    ci\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n2 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475\n3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n4 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n5 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html#hausmeister-paket-tbl_janitor",
    "href": "new_pages/tables_descriptive.de.html#hausmeister-paket-tbl_janitor",
    "title": "17  Beschreibende Tabellen",
    "section": "17.3 Hausmeister Paket {#tbl_janitor}",
    "text": "17.3 Hausmeister Paket {#tbl_janitor}\nDie Hausmeister Pakete bietet die tabyl() Funktion, um Tabellen und Kreuztabellen zu erstellen, die mit Hilfsfunktionen “verziert” oder modifiziert werden können, um Prozente, Proportionen, Zählungen usw. anzuzeigen.\nNachfolgend leiten wir die linelist Datenrahmen an Hausmeister Funktionen und drucke das Ergebnis aus. Falls gewünscht, kannst du die resultierenden Tabellen auch mit dem Zuweisungsoperator speichern &lt;-.\n\nEinfache Tabelle\nDie standardmäßige Verwendung von tabyl() auf eine bestimmte Spalte erzeugt die eindeutigen Werte, Zählungen und spaltenweisen “Prozentsätze” (eigentlich Proportionen). Die Proportionen können viele Ziffern haben. Du kannst die Anzahl der Nachkommastellen mit adorn_rounding() wie unten beschrieben.\n\nlinelist %&gt;% tabyl(age_cat)\n\n age_cat    n     percent valid_percent\n     0-4 1095 0.185971467   0.188728025\n     5-9 1095 0.185971467   0.188728025\n   10-14  941 0.159816576   0.162185453\n   15-19  743 0.126188859   0.128059290\n   20-29 1073 0.182235054   0.184936229\n   30-49  754 0.128057065   0.129955188\n   50-69   95 0.016134511   0.016373664\n     70+    6 0.001019022   0.001034126\n    &lt;NA&gt;   86 0.014605978            NA\n\n\nWie du oben sehen kannst, werden fehlende Werte in einer Zeile mit der Aufschrift &lt;NA&gt;. Du kannst sie unterdrücken mit show_na = FALSE. Wenn es keine fehlenden Werte gibt, wird diese Zeile nicht angezeigt. Wenn es fehlende Werte gibt, werden alle Proportionen sowohl als Rohwerte (Nenner inklusive NA Zählungen) und “gültig” (Nenner schließt die NA Zählungen).\nWenn es sich bei der Spalte um einen Klassenfaktor handelt und nur bestimmte Stufen in deinen Daten vorhanden sind, werden trotzdem alle Stufen in der Tabelle angezeigt. Du kannst diese Funktion unterdrücken, indem du angibst show_missing_levels = FALSE. Lies mehr über die [Faktoren] Seite.\n\n\nKreuztabellen\nKreuztabellen werden erstellt, indem eine oder mehrere zusätzliche Spalten innerhalb der tabyl(). Beachte, dass jetzt nur Zählungen zurückgegeben werden - Proportionen und Prozentsätze können mit zusätzlichen Schritten hinzugefügt werden (siehe unten).\n\nlinelist %&gt;% tabyl(age_cat, gender)\n\n age_cat   f   m NA_\n     0-4 640 416  39\n     5-9 641 412  42\n   10-14 518 383  40\n   15-19 359 364  20\n   20-29 468 575  30\n   30-49 179 557  18\n   50-69   2  91   2\n     70+   0   5   1\n    &lt;NA&gt;   0   0  86\n\n\n\n\n17.3.1 Die Tabelle “schmücken” {#tbl_adorn .unnumbered}\nVerwende Hausmeister Funktionen von janitor, um Summen zu addieren, in Proportionen oder Prozente umzurechnen oder die Anzeige anderweitig anzupassen. Oft wirst du die Tabelle durch mehrere dieser Funktionen leiten.\n\n\n\n\n\n\n\nFunktion\nErgebnis\n\n\n\n\nadorn_totals()\nAddiert die Summen (where = “Zeile”, “Spalte” oder “beide”). einstellen name = für “Gesamt”.\n\n\nadorn_percentages()\nKonvertiere Zählungen in Proportionen, mit denominator = “Zeile”, “Spalte” oder “alle”\n\n\nadorn_pct_formatting()\nKonvertiert Proportionen in Prozentwerte. Angeben digits =. Entferne das “%”-Symbol mit affix_sign = FALSE.\n\n\nadorn_rounding()\nSo runden Sie Proportionen auf digits = Stellen. Um Prozente zu runden, verwende adorn_pct_formatting() mit digits =.\n\n\nadorn_ns()\nFüge Zählungen zu einer Tabelle mit Proportionen oder Prozentsätzen hinzu. Gib an. position = “hinten” an, um die Zählungen in Klammern darzustellen, oder “vorne”, um die Prozentsätze in Klammern zu setzen.\n\n\nadorn_title()\nString über Argumente hinzufügen row_name = und/oder col_name =\n\n\n\nAchte auf die Reihenfolge, in der du die oben genannten Funktionen anwendest. Im Folgenden findest du einige Beispiele.\nEine einfache einseitige Tabelle mit Prozenten anstelle der Standardproportionen.\n\nlinelist %&gt;%               # case linelist\n  tabyl(age_cat) %&gt;%       # tabulate counts and proportions by age category\n  adorn_pct_formatting()   # convert proportions to percents\n\n age_cat    n percent valid_percent\n     0-4 1095   18.6%         18.9%\n     5-9 1095   18.6%         18.9%\n   10-14  941   16.0%         16.2%\n   15-19  743   12.6%         12.8%\n   20-29 1073   18.2%         18.5%\n   30-49  754   12.8%         13.0%\n   50-69   95    1.6%          1.6%\n     70+    6    0.1%          0.1%\n    &lt;NA&gt;   86    1.5%             -\n\n\nEine Kreuztabelle mit einer Gesamtzeile und prozentualen Zeilenanteilen.\n\nlinelist %&gt;%                                  \n  tabyl(age_cat, gender) %&gt;%                  # counts by age and gender\n  adorn_totals(where = \"row\") %&gt;%             # add total row\n  adorn_percentages(denominator = \"row\") %&gt;%  # convert counts to proportions\n  adorn_pct_formatting(digits = 1)            # convert proportions to percents\n\n age_cat     f     m    NA_\n     0-4 58.4% 38.0%   3.6%\n     5-9 58.5% 37.6%   3.8%\n   10-14 55.0% 40.7%   4.3%\n   15-19 48.3% 49.0%   2.7%\n   20-29 43.6% 53.6%   2.8%\n   30-49 23.7% 73.9%   2.4%\n   50-69  2.1% 95.8%   2.1%\n     70+  0.0% 83.3%  16.7%\n    &lt;NA&gt;  0.0%  0.0% 100.0%\n   Total 47.7% 47.6%   4.7%\n\n\nEine Kreuztabelle, die so angepasst ist, dass sowohl Zählungen als auch Prozentsätze angezeigt werden.\n\nlinelist %&gt;%                                  # case linelist\n  tabyl(age_cat, gender) %&gt;%                  # cross-tabulate counts\n  adorn_totals(where = \"row\") %&gt;%             # add a total row\n  adorn_percentages(denominator = \"col\") %&gt;%  # convert to proportions\n  adorn_pct_formatting() %&gt;%                  # convert to percents\n  adorn_ns(position = \"front\") %&gt;%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")\n\n                      Gender                            \n Age Category              f              m          NA_\n          0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n          5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n        10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n        15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n        20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n        30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n        50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n          70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n         &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n        Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\n\n\nDrucken der Tabelle\nStandardmäßig wird die Tabellenspalte als Rohdaten auf der R-Konsole ausgegeben.\nAlternativ kannst du das Tabyl auch an flextableoder ein ähnliches Paket übergeben, um es als “hübsches” Bild im RStudio Viewer auszudrucken, das als .png, .jpeg, .html, etc. exportiert werden kann. Dies wird auf der Seite [Tabellen für die Präsentation]. Beachte, dass du beim Drucken auf diese Weise und mitadorn_titles() verwenden, müssen Sie angeben placement = \"combined\".\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% # this is necessary to print as image\n  flextable::flextable() %&gt;%    # convert to pretty image\n  flextable::autofit()          # format to one line per row \n\nAge Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1,095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1,095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%)941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%)743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1,073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%)754 (12.8%)50-692  (0.1%)91  (3.2%)2  (0.7%)95  (1.6%)70+0  (0.0%)5  (0.2%)1  (0.4%)6  (0.1%)0  (0.0%)0  (0.0%)86 (30.9%)86  (1.5%)\n\n\n\n\nVerwendung auf anderen Tischen\nDu kannst verwenden Hausmeister’s adorn_*() Funktionen auf andere Tabellen, wie zum Beispiel die von summarise() und count() von dplyr, oder table() von Basis R. Verlege den Tisch einfach in die gewünschte Hausmeister Funktion. Zum Beispiel:\n\nlinelist %&gt;% \n  count(hospital) %&gt;%   # dplyr function\n  adorn_totals()        # janitor function\n\n                             hospital    n\n                     Central Hospital  454\n                    Military Hospital  896\n                              Missing 1469\n                                Other  885\n                        Port Hospital 1762\n St. Mark's Maternity Hospital (SMMH)  422\n                                Total 5888\n\n\n\n\nSpeichern der Tabelle\nWenn du die Tabelle in ein “hübsches” Bild umwandelst mit einem Paket wie flextable umwandelst, kannst du sie mit Funktionen aus diesem Paket speichern - wie save_as_html(), save_as_word(), save_as_ppt(), und save_as_image() von flextable(wie ausführlicher im Abschnitt [Tabellen für die Präsentation] Seite). Nachfolgend wird die Tabelle als Word-Dokument gespeichert, in dem sie von Hand weiter bearbeitet werden kann.\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% \n  flextable::flextable() %&gt;%                     # convert to image\n  flextable::autofit() %&gt;%                       # ensure only one line per row\n  flextable::save_as_docx(path = \"tabyl.docx\")   # save as Word document to filepath\n\n\n\n\n\n\n\n\n\n\n\n\n17.3.2 Statistik {#janitor_age_out_stats .unnumbered}\nDu kannst statistische Tests auf Tabulatoren anwenden, wie chisq.test() oder fisher.test() aus dem stats Paket, wie unten gezeigt. Beachte, dass fehlende Werte nicht erlaubt sind, daher werden sie in der Tabelle mit show_na = FALSE.\n\nage_by_outcome &lt;- linelist %&gt;% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)\n\n\n    Pearson's Chi-squared test\n\ndata:  age_by_outcome\nX-squared = 6.4931, df = 7, p-value = 0.4835\n\n\nSiehe die Seite über [Einfache statistische Tests] für weiteren Code und Tipps zur Statistik.\n\n\nAndere Tipps\n\nDas Argument einbeziehen na.rm = TRUE ein, um fehlende Werte von den oben genannten Berechnungen auszuschließen.\nWenn du eine adorn_*() Hilfsfunktionen auf Tabellen angewendet werden, die nicht von tabyl() erstellt wurden, können Sie bestimmte Spalten angeben, auf die sie angewendet werden sollen, wie adorn_percentage(,,,c(cases,deaths)) (gib sie im 4. unbenannten Argument an). Die Syntax ist nicht einfach. Verwende zum Beispiel summarise() stattdessen.\nDu kannst mehr Details in der Hausmeister-Seite und dieser tabellarische Vignette.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html#dplyr-paket",
    "href": "new_pages/tables_descriptive.de.html#dplyr-paket",
    "title": "17  Beschreibende Tabellen",
    "section": "17.4 dplyr Paket",
    "text": "17.4 dplyr Paket\ndplyr ist Teil der tidyverse Pakets und ist ein weit verbreitetes Werkzeug zur Datenverwaltung. Tabellen erstellen mit dplyr Funktionen summarise() und count() ist ein nützlicher Ansatz, um zusammenfassende Statistiken zu berechnen, zusammenzufassen nach Gruppen oder Tabellen zu übergeben ggplot().\nsummarise() erstellt eine neuen, zusammenfassenden Datenrahmen. Wenn die Daten nicht gruppiert wird ein einzeiliger Datenrahmen mit den angegebenen zusammenfassenden Statistiken des gesamten Datenrahmens zurückgegeben. Wenn die Daten gruppiert gruppiert, enthält der neue Datenrahmen eine Zeile pro Gruppe(siehe [Daten gruppieren] Seite).\nInnerhalb der summarise() Klammern gibst du die Namen jeder neuen Summenspalte an, gefolgt von einem Gleichheitszeichen und einer statistischen Funktion, die angewendet werden soll.\nTIPP: Die Funktion “Zusammenfassen” funktioniert sowohl mit der britischen als auch mit der amerikanischen Rechtschreibung (summarise() und summarize()).\n\nZählungen erhalten\nDie einfachste Funktion zur Anwendung innerhalb summarise() ist n(). Lass die Klammern leer, um die Anzahl der Zeilen zu zählen.\n\nlinelist %&gt;%                 # begin with linelist\n  summarise(n_rows = n())    # return new summary dataframe with column n_rows\n\n  n_rows\n1   5888\n\n\nNoch interessanter wird es, wenn wir die Daten vorher gruppiert haben.\n\nlinelist %&gt;% \n  group_by(age_cat) %&gt;%     # group data by unique values in column age_cat\n  summarise(n_rows = n())   # return number of rows *per group*\n\n# A tibble: 9 × 2\n  age_cat n_rows\n  &lt;fct&gt;    &lt;int&gt;\n1 0-4       1095\n2 5-9       1095\n3 10-14      941\n4 15-19      743\n5 20-29     1073\n6 30-49      754\n7 50-69       95\n8 70+          6\n9 &lt;NA&gt;        86\n\n\nDer obige Befehl kann verkürzt werden, indem man die count() Funktion stattdessen verwenden. count() macht das Folgende:\n\nSie gruppiert die Daten nach den übergebenen Spalten\nFasst sie zusammen mit n() (Erstellen von Spalten n)\nHebt die Gruppierung der Daten auf\n\n\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\nDu kannst den Namen der Zählspalte von der Standardeinstellung ändern n in einen anderen Namen ändern, indem du ihn mit name =.\nTabellarische Zählungen von zwei oder mehr Gruppierungsspalten werden weiterhin im “langen” Format zurückgegeben, wobei die Zählungen in der nSpalte. Siehe die Seite über [Pivotierung von Daten] um mehr über “lange” und “breite” Datenformate zu erfahren.\n\nlinelist %&gt;% \n  count(age_cat, outcome)\n\n   age_cat outcome   n\n1      0-4   Death 471\n2      0-4 Recover 364\n3      0-4    &lt;NA&gt; 260\n4      5-9   Death 476\n5      5-9 Recover 391\n6      5-9    &lt;NA&gt; 228\n7    10-14   Death 438\n8    10-14 Recover 303\n9    10-14    &lt;NA&gt; 200\n10   15-19   Death 323\n11   15-19 Recover 251\n12   15-19    &lt;NA&gt; 169\n13   20-29   Death 477\n14   20-29 Recover 367\n15   20-29    &lt;NA&gt; 229\n16   30-49   Death 329\n17   30-49 Recover 238\n18   30-49    &lt;NA&gt; 187\n19   50-69   Death  33\n20   50-69 Recover  38\n21   50-69    &lt;NA&gt;  24\n22     70+   Death   3\n23     70+ Recover   3\n24    &lt;NA&gt;   Death  32\n25    &lt;NA&gt; Recover  28\n26    &lt;NA&gt;    &lt;NA&gt;  26\n\n\n\n\nAlle Levels anzeigen\nWenn du eine Spalte der Klasse tabellierst Faktor kannst du sicherstellen, dass alle Ebenen angezeigt werden (nicht nur die Ebenen mit Werten in den Daten), indem du .drop = FALSE in die summarise() oder count() Befehl ein.\nDiese Technik ist nützlich, um deine Tabellen/Diagramme zu standardisieren. Zum Beispiel, wenn du Zahlen für mehrere Untergruppen erstellst oder die Zahl wiederholt für Routineberichte erstellst. In jedem dieser Fälle kann das Vorhandensein von Werten in den Daten schwanken, aber du kannst Ebenen definieren, die konstant bleiben.\nSiehe die Seite über [Faktoren] für weitere Informationen.\n\n\n17.4.1 Proportionen {#tbl_dplyr_prop .unnumbered}\nProportionen können hinzugefügt werden, indem die Tabelle mit der Pipeline mutate() um eine neue Spalte zu erstellen. Definiere die neue Spalte als Zählspalte (n standardmäßig) geteilt durch die sum() der Zählspalte (dies ergibt ein Verhältnis).\nBeachte, dass in diesem Fall, sum() in der mutate() Befehl die Summe der gesamten Spalte zurückgegeben wird n als Nenner für die Proportionen zurück. Wie erklärt auf der Seite Daten gruppieren, wenn sum() verwendet wird in gruppiert Daten (z. B. wenn die mutate() unmittelbar auf eine group_by() Befehl), gibt es Summen zurück nach Gruppe. Wie oben bereits erwähnt, count() beendet seine Aktionen durch die Gruppierung aufhebt. In diesem Szenario erhalten wir also volle Spaltenproportionen.\nUm Prozentwerte einfach darzustellen, kannst du die Proportionen in die Funktion einpacken percent() aus dem Paket skaliert (beachte, dass dies in Klassenzeichen umgewandelt wird).\n\nage_summary &lt;- linelist %&gt;% \n  count(age_cat) %&gt;%                     # group and count by gender (produces \"n\" column)\n  mutate(                                # create percent of column - note the denominator\n    percent = scales::percent(n / sum(n))) \n\n# print\nage_summary\n\n  age_cat    n percent\n1     0-4 1095  18.60%\n2     5-9 1095  18.60%\n3   10-14  941  15.98%\n4   15-19  743  12.62%\n5   20-29 1073  18.22%\n6   30-49  754  12.81%\n7   50-69   95   1.61%\n8     70+    6   0.10%\n9    &lt;NA&gt;   86   1.46%\n\n\nIm Folgenden findest du eine Methode zur Berechnung der Proportionen innerhalb von Gruppen. Sie beruht auf verschiedenen Ebenen der Datengruppierung, die selektiv angewendet und entfernt werden. Zunächst werden die Daten gruppiert nach outcome über group_by(). Dann, count() angewendet. Diese Funktion gruppiert die Daten weiter nach age_cat und gibt die Anzahl für jede outcome- age-cat Kombination. Wichtig ist, dass er seinen Prozess abschließt, count() auch die Gruppierungauf die age_cat Gruppierung auf, so dass die einzige verbleibende Datengruppierung die ursprüngliche Gruppierung nach outcome. Der letzte Schritt der Berechnung der Proportionen (Nenner sum(n)) wird immer noch gruppiert durch outcome.\n\nage_by_outcome &lt;- linelist %&gt;%                  # begin with linelist\n  group_by(outcome) %&gt;%                         # group by outcome \n  count(age_cat) %&gt;%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group\n\n\n\n\n\n\n\n\n\nPlotten\nUm eine “lange” Tabellenausgabe wie oben mit ggplot() ist relativ einfach. Die Daten liegen natürlich im “langen” Format vor, das von der ggplot(). Weitere Beispiele findest du auf den Seiten [ggplot Grundlagen] und [ggplot Tipps].\n\nlinelist %&gt;%                      # begin with linelist\n  count(age_cat, outcome) %&gt;%     # group and tabulate counts by two columns\n  ggplot()+                       # pass new data frame to ggplot\n    geom_col(                     # create bar plot\n      mapping = aes(   \n        x = outcome,              # map outcome to x-axis\n        fill = age_cat,           # map age_cat to the fill\n        y = n))                   # map the counts column `n` to the height\n\n\n\n\n\n\n\n\n\n\nZusammenfassende Statistiken\nEin großer Vorteil von dplyr und summarise() ist die Möglichkeit, erweiterte statistische Zusammenfassungen wie median(), mean(), max(), min(), sd() (Standardabweichung) und Perzentile. Du kannst auch verwenden sum() kannst du auch die Anzahl der Zeilen ausgeben, die bestimmte logische Kriterien erfüllen. Wie oben beschrieben, können diese Ausgaben für den gesamten Datensatz oder nach Gruppen erstellt werden.\nDie Syntax ist dieselbe - innerhalb der summarise() Klammern gibst du die Namen jeder neuen zusammenfassenden Spalte an, gefolgt von einem Gleichheitszeichen und einer statistischen Funktion, die angewendet werden soll. Innerhalb der statistischen Funktion gibst du die Spalte(n) an, die bearbeitet werden soll(en), sowie alle relevanten Argumente (z. B. na.rm = TRUE für die meisten mathematischen Funktionen).\nDu kannst auch Folgendes verwenden sum() verwenden, um die Anzahl der Zeilen zurückzugeben, die ein logisches Kriterium erfüllen. Der Ausdruck darin wird gezählt, wenn er den Wert TRUE. Zum Beispiel:\n\nsum(age_years &lt; 18, na.rm=T)\nsum(gender == \"male\", na.rm=T)\nsum(response %in% c(\"Likely\", \"Very Likely\"))\n\nUnten, linelist werden die Daten zusammengefasst, um die Zeitspanne zwischen dem Auftreten der Symptome und der Krankenhausaufnahme zu beschreiben (Spalte days_onset_hosp), nach Krankenhaus.\n\nsummary_table &lt;- linelist %&gt;%                                        # begin with linelist, save out as new object\n  group_by(hospital) %&gt;%                                             # group all calculations by hospital\n  summarise(                                                         # only the below summary columns will be returned\n    cases       = n(),                                                # number of rows per group\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # max delay\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # mean delay, rounded\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # standard deviation of delays, rounded\n    delay_3     = sum(days_onset_hosp &gt;= 3, na.rm = T),               # number of rows with delay of 3 or more days\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convert previously-defined delay column to percent \n  )\n\nsummary_table  # print\n\n# A tibble: 6 × 7\n  hospital               cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n  &lt;chr&gt;                  &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;      \n1 Central Hospital         454        12        1.9      1.9     108 24%        \n2 Military Hospital        896        15        2.1      2.4     253 28%        \n3 Missing                 1469        22        2.1      2.3     399 27%        \n4 Other                    885        18        2        2.2     234 26%        \n5 Port Hospital           1762        16        2.1      2.2     470 27%        \n6 St. Mark's Maternity …   422        18        2.1      2.3     116 27%        \n\n\nEinige Tipps:\n\nVerwende sum() mit einer logischen Anweisung, um Zeilen zu “zählen”, die bestimmte Kriterien erfüllen (==)\nBeachte die Verwendung von na.rm = TRUE innerhalb mathematischer Funktionen wie sum(), sonst NA wird bei fehlenden Werten zurückgegeben\nVerwenden Sie die Funktion percent() aus der Skalen Paket, um einfach in Prozente umzurechnen\n\neinstellen accuracy = auf 0,1 oder 0,01, um 1 bzw. 2 Nachkommastellen zu erhalten\n\nverwenden round() von Basis R zur Angabe von Dezimalzahlen\nUm diese Statistiken für den gesamten Datensatz zu berechnen, verwende summarise() ohne group_by()\nDu kannst Spalten für spätere Berechnungen (z. B. Nenner) erstellen, die du dann mit select().\n\n\n\nBedingte Statistik\nDu möchtest vielleicht zurückkehren bedingte Statistik - z. B. das Maximum der Zeilen, die bestimmte Kriterien erfüllen. Das kannst du erreichen, indem du die Spalte mit Klammern unterteilst [ ]. Das folgende Beispiel gibt die Höchsttemperatur für Patienten mit oder ohne Fieber an. Beachte jedoch, dass es sinnvoller sein kann, eine weitere Spalte in die Tabelle einzufügen. group_by() Befehl und pivot_wider() (wie gezeigt unten).\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )\n\n# A tibble: 6 × 3\n  hospital                             max_temp_fvr max_temp_no\n  &lt;chr&gt;                                       &lt;dbl&gt;       &lt;dbl&gt;\n1 Central Hospital                             40.4        38  \n2 Military Hospital                            40.5        38  \n3 Missing                                      40.6        38  \n4 Other                                        40.8        37.9\n5 Port Hospital                                40.6        38  \n6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9\n\n\n\n\nZusammenkleben\nDie Funktion str_glue() von stringr ist nützlich, um Werte aus mehreren Spalten in einer neuen Spalte zu kombinieren. In diesem Zusammenhang wird dies typischerweise verwendet nach der summarise() Befehl.\nIm [Zeichen und Zeichenketten] werden verschiedene Optionen für die Kombination von Spalten besprochen, darunterunite(), und paste0(). In diesem Anwendungsfall plädieren wir für str_glue() weil sie flexibler ist als unite() und eine einfachere Syntax hat als paste0().\nUnten, die summary_table Datenrahmen (oben erstellt) so verändert, dass die Spalten delay_mean und delay_sd kombiniert werden, die neue Spalte mit Klammern formatiert wird und die entsprechenden alten Spalten entfernt werden.\nUm die Tabelle ansehnlicher zu machen, wird eine Summenzeile hinzugefügt mit adorn_totals() von Hausmeister (der nicht-numerische Spalten ignoriert). Zum Schluss verwenden wir select() von dplyr um die Spalten neu zu ordnen und in schönere Spaltennamen umzubenennen.\nJetzt kannst du an flextableübergeben und die Tabelle in Word, .png, .jpeg, .html, Powerpoint, RMarkdown, etc. ausgeben! (siehe die [Tabellen für Präsentationen] Seite).\n\nsummary_table %&gt;% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %&gt;%  # combine and format other values\n  select(-c(delay_mean, delay_sd)) %&gt;%                       # remove two old columns   \n  adorn_totals(where = \"row\") %&gt;%                            # add total row\n  select(                                                    # order and rename cols\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )\n\n                        Hospital Name Cases Max delay Mean (sd) Delay 3+ days\n                     Central Hospital   454        12 1.9 (1.9)           108\n                    Military Hospital   896        15 2.1 (2.4)           253\n                              Missing  1469        22 2.1 (2.3)           399\n                                Other   885        18   2 (2.2)           234\n                        Port Hospital  1762        16 2.1 (2.2)           470\n St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116\n                                Total  5888       101         -          1580\n % delay 3+ days\n             24%\n             28%\n             27%\n             26%\n             27%\n             27%\n               -\n\n\n\nPerzentile\nPerzentile und Quantile in dplyr verdienen eine besondere Erwähnung. Um Quantile zurückzugeben, verwendest du quantile() mit den Standardwerten oder gib den/die gewünschten Wert(e) mit probs =.\n\n# get default percentile values of age (0%, 25%, 50%, 75%, 100%)\nlinelist %&gt;% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               0\n2               6\n3              13\n4              23\n5              84\n\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               1\n2              13\n3              23\n4              48\n\n\nWenn du Quantile zurückgeben möchtest nach Gruppe zurückgeben willst, kannst du lange und weniger nützliche Ausgaben erhalten, wenn du einfach eine weitere Spalte zu group_by(). Versuche stattdessen diesen Ansatz: Erstelle eine Spalte für jedes gewünschte Quantilniveau.\n\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )\n\n# A tibble: 6 × 5\n  hospital                               p05   p50   p75   p98\n  &lt;chr&gt;                                &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Central Hospital                         1    12    21  48  \n2 Military Hospital                        1    13    24  45  \n3 Missing                                  1    13    23  48.2\n4 Other                                    1    13    23  50  \n5 Port Hospital                            1    14    24  49  \n6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\n\n\nWährend dplyr summarise() bietet zwar eine bessere Kontrolle, aber du wirst feststellen, dass du alle benötigten Statistiken mit dplyr erstellen kannst. get_summary_stat() aus dem rstatix Paket. Bei gruppierten Daten liefert if die Werte 0%, 25%, 50%, 75% und 100%. Bei der Anwendung auf nicht gruppierte Daten kannst du die Perzentile mit probs = c(.05, .5, .75, .98).\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 6 × 8\n  hospital                         variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;chr&gt;                            &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Central Hospital                 age        445     0     6    12    21     58\n2 Military Hospital                age        884     0     6    14    24     72\n3 Missing                          age       1441     0     6    13    23     76\n4 Other                            age        873     0     6    13    23     69\n5 Port Hospital                    age       1739     0     6    14    24     68\n6 St. Mark's Maternity Hospital (… age        420     0     7    12    22     84\n\n\n\nlinelist %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 1 × 7\n  variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 age       5802     0     6    13    23     84\n\n\n\n\n\nAggregierte Daten zusammenfassen\nWenn du mit aggregierten Daten beginnst verwenden n() die Anzahl der Zeilen zurück, nicht die Summe der aggregierten Zählungen. Um Summen zu erhalten, verwende sum() für die Zählspalte der Daten.\nNehmen wir zum Beispiel an, du beginnst mit dem unten stehenden Datenrahmen mit den Zählungen, genannt linelist_agg - Er zeigt im “langen” Format die Fallzahlen nach Ergebnis und Geschlecht.\nIm Folgenden erstellen wir diesen Beispieldatenrahmen aus linelist Fallzahlen nach Ergebnis und Geschlecht (fehlende Werte wurden der Übersichtlichkeit halber entfernt).\n\nlinelist_agg &lt;- linelist %&gt;% \n  drop_na(gender, outcome) %&gt;% \n  count(outcome, gender)\n\nlinelist_agg\n\n  outcome gender    n\n1   Death      f 1227\n2   Death      m 1228\n3 Recover      f  953\n4 Recover      m  950\n\n\nUm die Zahlen zu summieren (in der Spalte n) nach Gruppe zu summieren, kannst du verwenden summarise() aber setze die neue Spalte gleich sum(n, na.rm=T). Um der Summenoperation ein bedingtes Element hinzuzufügen, kannst du die Untermengenklammer verwenden [] Syntax für die Zählspalte verwenden.\n\nlinelist_agg %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))\n\n# A tibble: 2 × 4\n  outcome total_cases male_cases female_cases\n  &lt;chr&gt;         &lt;int&gt;      &lt;int&gt;        &lt;int&gt;\n1 Death          2455       1228         1227\n2 Recover        1903        950          953\n\n\n\n\nacross() Mehrere Spalten\nDu kannst summarise() über mehrere Spalten hinweg mit across(). Das macht das Leben einfacher, wenn du dieselbe Statistik für viele Spalten berechnen willst. Platziere across() innerhalb von summarise() ein und gib Folgendes an:\n\n.cols = entweder als einen Vektor von Spaltennamen c() oder als “tidyselect”-Hilfsfunktionen (unten erklärt)\n.fns = die auszuführende Funktion (ohne Klammern) - du kannst mehrere innerhalb einer list()\n\nUnten, mean() wird auf mehrere numerische Spalten angewendet. Ein Vektor von Spalten wird explizit benannt, um .cols = und eine einzelne Funktion mean wird angegeben (ohne Klammern), um .fns =. Alle zusätzlichen Argumente für die Funktion (z. B. na.rm=TRUE) werden nach .fns = angegeben und durch ein Komma getrennt.\nEs kann schwierig sein, die richtige Reihenfolge von Klammern und Kommas zu finden, wenn man across(). Denke daran, dass innerhalb von across() die Spalten, die Funktionen und alle zusätzlichen Argumente, die für die Funktionen benötigt werden, enthalten musst.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # columns\n                   .fns = mean,                               # function\n                   na.rm=T))                                  # extra arguments\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `outcome = \"Death\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 3 × 5\n  outcome age_years  temp wt_kg ht_cm\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Death        15.9  38.6  52.6  125.\n2 Recover      16.1  38.6  52.5  125.\n3 &lt;NA&gt;         16.2  38.6  53.0  125.\n\n\nEs können mehrere Funktionen auf einmal ausgeführt werden. Unterhalb der Funktionen mean und sd werden zur Verfügung gestellt .fns = innerhalb einer list(). Du hast die Möglichkeit, Zeichennamen anzugeben (z. B. “mean” und “sd”), die an die neuen Spaltennamen angehängt werden.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # columns\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiple functions \n                   na.rm=T))                                 # extra arguments\n\n# A tibble: 3 × 9\n  outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 Death             15.9         12.3      38.6   0.962       52.6     18.4\n2 Recover           16.1         13.0      38.6   0.997       52.5     18.6\n3 &lt;NA&gt;              16.2         12.8      38.6   0.976       53.0     18.9\n# ℹ 2 more variables: ht_cm_mean &lt;dbl&gt;, ht_cm_sd &lt;dbl&gt;\n\n\nHier sind die “tidyselect”-Hilfsfunktionen, die du zur Verfügung stellen kannst .cols = um Spalten auszuwählen:\n\neverything() - alle anderen nicht genannten Spalten\nlast_col() - die letzte Spalte\nwhere() - wendet eine Funktion auf alle Spalten an und wählt diejenigen aus, die TRUE sind\nstarts_with() - mit einem bestimmten Präfix übereinstimmen. Beispiel: starts_with(\"date\")\nends_with() - passt zu einem bestimmten Suffix. Beispiel: ends_with(\"_end\")\ncontains() - Spalten, die eine Zeichenkette enthalten. Beispiel: contains(\"time\")\nmatches() - Einen regulären Ausdruck (regex) anwenden. Beispiel: contains(\"[pt]al\")\nnum_range() -\nany_of() - passt, wenn die Spalte benannt ist. Nützlich, wenn der Name möglicherweise nicht existiert. Beispiel: any_of(date_onset, date_death, cardiac_arrest)\n\nUm zum Beispiel den Mittelwert jeder numerischen Spalte zurückzugeben, verwende where() und gib die Funktion as.numeric() (ohne Klammern). All dies bleibt innerhalb der across() Befehl.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(\n    .cols = where(is.numeric),  # all numeric columns in the data frame\n    .fns = mean,\n    na.rm=T))\n\n# A tibble: 3 × 12\n  outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6\n2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6\n3 &lt;NA&gt;          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6\n# ℹ 2 more variables: bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\n17.4.2 Drehpunkt breiter {#tbls_pivot_wider .unnumbered}\nWenn du deine Tabelle im “breiten” Format bevorzugst, kannst du sie mit der Funktion tidyr pivot_wider() Funktion. Wahrscheinlich musst du die Spalten umbenennen mit rename(). Weitere Informationen findest du auf der Seite über [Pivotierung von Daten].\nDas folgende Beispiel beginnt mit der “langen” Tabelle age_by_outcome aus der Abschnitt Proportionen. Wir erstellen sie noch einmal und drucken sie aus, um sie zu verdeutlichen:\n\nage_by_outcome &lt;- linelist %&gt;%                  # begin with linelist\n  group_by(outcome) %&gt;%                         # group by outcome \n  count(age_cat) %&gt;%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group\n\n\n\n\n\n\n\nUm weiter zu schwenken, erstellen wir die neuen Spalten aus den Werten in der bestehenden Spalte age_cat (durch Setzen von names_from = age_cat). Wir legen auch fest, dass die neuen Tabellenwerte aus der bestehenden Spalte stammen sollen n stammen, mit values_from = n. Die Spalten, die in unserem Pivot-Befehl nicht erwähnt werden (outcome) bleiben auf der linken Seite unverändert.\n\nage_by_outcome %&gt;% \n  select(-percent) %&gt;%   # keep only counts for simplicity\n  pivot_wider(names_from = age_cat, values_from = n)  \n\n# A tibble: 3 × 10\n# Groups:   outcome [3]\n  outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Death     471   476     438     323     477     329      33     3    32\n2 Recover   364   391     303     251     367     238      38     3    28\n3 &lt;NA&gt;      260   228     200     169     229     187      24    NA    26\n\n\n\n\n17.4.3 Zeilen gesamt {#tbl_dplyr_totals .unnumbered}\nWenn summarise() mit gruppierten Daten arbeitet, erstellt es nicht automatisch eine “Gesamtstatistik”. Im Folgenden werden zwei Ansätze zum Hinzufügen einer Summenzeile vorgestellt:\n\nHausmeister’s adorn_totals()\nWenn deine Tabelle nur aus Zählungen oder Anteilen/Prozenten besteht, die zu einer Gesamtsumme summiert werden können, dann kannst du Folgendes hinzufügen Summe Summen mit Hausmeister’s adorn_totals() wie im obigen Abschnitt beschrieben. Beachte, dass diese Funktion nur die numerischen Spalten summieren kann - wenn du andere Gesamtzusammenfassungsstatistiken berechnen willst, siehe den nächsten Ansatz mit dplyr.\nUnten, linelist nach Geschlecht gruppiert und in einer Tabelle zusammengefasst, in der die Anzahl der Fälle mit bekanntem Ausgang, der Todesfälle und der wiedergefundenen Fälle beschrieben wird. Wenn du die Tabelle auf adorn_totals() fügt unten eine Gesamtzeile hinzu, die die Summe der einzelnen Spalten wiedergibt. Die weitere adorn_*() Funktionen passen die Anzeige wie im Code angegeben an.\n\nlinelist %&gt;% \n  group_by(gender) %&gt;%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Number of rows in group where outcome is not missing\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Number of rows in group where outcome is Death\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Number of rows in group where outcome is Recovered\n  ) %&gt;% \n  adorn_totals() %&gt;%                                # Adorn total row (sums of each numeric column)\n  adorn_percentages(\"col\") %&gt;%                      # Get column proportions\n  adorn_pct_formatting() %&gt;%                        # Convert proportions to percents\n  adorn_ns(position = \"front\")                      # display % and counts (with counts in front)\n\n gender  known_outcome        n_death      n_recover\n      f 2,180  (47.8%) 1,227  (47.5%)   953  (48.1%)\n      m 2,178  (47.7%) 1,228  (47.6%)   950  (47.9%)\n   &lt;NA&gt;   207   (4.5%)   127   (4.9%)    80   (4.0%)\n  Total 4,565 (100.0%) 2,582 (100.0%) 1,983 (100.0%)\n\n\n\n\nsummarise() auf “Gesamt” Daten und dann bind_rows()\nWenn deine Tabelle aus zusammenfassenden Statistiken besteht, wie z. B. median(), mean(), usw., wird die adorn_totals() oben gezeigte Ansatz wird nicht nicht ausreichen. Um zusammenfassende Statistiken für den gesamten Datensatz zu erhalten, musst du sie stattdessen mit einem separaten summarise() Befehl berechnen und die Ergebnisse dann mit der ursprünglichen gruppierten Übersichtstabelle verbinden. Um die Verknüpfung durchzuführen, kannst du Folgendes verwenden bind_rows() from dplyrs, die im Abschnitt [Daten verknüpfen] Seite beschrieben. Unten findest du ein Beispiel:\nDu kannst eine zusammenfassende Tabelle der Ergebnisse erstellen nach Krankenhaus mit group_by() und summarise() wie hier:\n\nby_hospital &lt;- linelist %&gt;% \n  filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%  # Remove cases with missing outcome or hospital\n  group_by(hospital, outcome) %&gt;%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T))               # median CT value per group\n  \nby_hospital # print table\n\n# A tibble: 10 × 4\n# Groups:   hospital [5]\n   hospital                             outcome     N ct_value\n   &lt;chr&gt;                                &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n 1 Central Hospital                     Death     193       22\n 2 Central Hospital                     Recover   165       22\n 3 Military Hospital                    Death     399       21\n 4 Military Hospital                    Recover   309       22\n 5 Other                                Death     395       22\n 6 Other                                Recover   290       21\n 7 Port Hospital                        Death     785       22\n 8 Port Hospital                        Recover   579       21\n 9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\n\n\nUm die Gesamtzahlen zu erhalten, führe dieselbe summarise() Befehl aus, aber gruppiere die Daten nur nach dem Ergebnis (nicht nach dem Krankenhaus), etwa so:\n\ntotals &lt;- linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # These statistics are now by outcome only     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # print table\n\n# A tibble: 2 × 3\n  outcome     N ct_value\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n1 Death    1971       22\n2 Recover  1469       22\n\n\nWir können diese beiden Datenrahmen miteinander verbinden. Beachte, dass by_hospital 4 Spalten hat, während totals 3 Spalten hat. Durch die Verwendung von bind_rows() werden die Spalten nach Namen kombiniert und jeder zusätzliche Platz wird mit NA aufgefüllt (z.B. die Spalte hospital Werte für die beiden neuen totals Zeilen). Nach dem Binden der Zeilen wandeln wir diese Leerzeichen in “Total” um, indem wir replace_na()(siehe [Datenbereinigung und Kernfunktionen] Seite).\n\ntable_long &lt;- bind_rows(by_hospital, totals) %&gt;% \n  mutate(hospital = replace_na(hospital, \"Total\"))\n\nHier ist die neue Tabelle mit den “Gesamt”-Zeilen am unteren Rand.\n\n\n\n\n\n\nDiese Tabelle hat ein “langes” Format, was vielleicht das ist, was du willst. Wahlweise kannst du drehen diese Tabelle breiterum sie besser lesbar zu machen. Siehe den Abschnitt über breiteres Pivoting weiter oben und die [Pivotieren von Daten] Seite. Du kannst auch weitere Spalten hinzufügen und sie schön anordnen. Dieser Code steht unten.\n\ntable_long %&gt;% \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %&gt;%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Death columns\n  arrange(N_Known)                                  # Arrange rows from lowest to highest (Total row at bottom)\n\n# A tibble: 6 × 8\n# Groups:   hospital [6]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n6 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;\n\n\nUnd dann kannst du das Ganze schön als Bild ausdrucken - unten ist die Ausgabe, die mit flextable. Du kannst mehr über dieses Beispiel und wie du diese “hübsche” Tabelle erreichst, in der [Tabellen für die Präsentation] Seite.\n\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html#gtsummary-paket-tbl_gt",
    "href": "new_pages/tables_descriptive.de.html#gtsummary-paket-tbl_gt",
    "title": "17  Beschreibende Tabellen",
    "section": "17.5 gtsummary Paket {#tbl_gt}",
    "text": "17.5 gtsummary Paket {#tbl_gt}\nWenn du deine zusammenfassenden Statistiken in einer hübschen, veröffentlichungsreifen Grafik ausdrucken möchtest, kannst du das gtsummary Paket und seine Funktion tbl_summary(). Der Code kann auf den ersten Blick komplex erscheinen, aber die Ausgaben sehen sehr schön aus und werden in deinem RStudio-Viewer-Panel als HTML-Bild ausgegeben. Lies eine Vignette hier.\nDu kannst auch die Ergebnisse von statistischen Tests in gtsummary Tabellen hinzufügen. Dieser Vorgang wird im Abschnitt gtsummary Abschnitt der Einfache statistische Tests Seite.\nZur Einführung tbl_summary() zeigen wir zunächst das grundlegendste Verhalten, das tatsächlich eine große und schöne Tabelle erzeugt. Dann werden wir im Detail untersuchen, wie man Anpassungen und mehr maßgeschneiderte Tabellen macht.\n\nZusammenfassende Tabelle\nDas Standardverhalten von tbl_summary() ist ziemlich unglaublich - sie nimmt die von dir angegebenen Spalten und erstellt in einem Befehl eine zusammenfassende Tabelle. Die Funktion gibt Statistiken aus, die der Spaltenklasse entsprechen: Median und Interquartilsbereich (IQR) für numerische Spalten und Zählwerte (%) für kategorische Spalten. Fehlende Werte werden in “Unbekannt” umgewandelt. Zur Erläuterung der Statistiken werden unten Fußnoten eingefügt, während oben die Gesamtzahl der N angezeigt wird.\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;%  # keep only the columns of interest\n  tbl_summary()                                                  # default\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n13 (6, 23)\n\n\n    Unknown\n86\n\n\ngender\n\n\n\n\n    f\n2,807 (50%)\n\n\n    m\n2,803 (50%)\n\n\n    Unknown\n278\n\n\noutcome\n\n\n\n\n    Death\n2,582 (57%)\n\n\n    Recover\n1,983 (43%)\n\n\n    Unknown\n1,323\n\n\nfever\n4,549 (81%)\n\n\n    Unknown\n249\n\n\ntemp\n38.80 (38.20, 39.20)\n\n\n    Unknown\n149\n\n\nhospital\n\n\n\n\n    Central Hospital\n454 (7.7%)\n\n\n    Military Hospital\n896 (15%)\n\n\n    Missing\n1,469 (25%)\n\n\n    Other\n885 (15%)\n\n\n    Port Hospital\n1,762 (30%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n422 (7.2%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\nAnpassungen\nJetzt erklären wir dir, wie die Funktion funktioniert und wie du Anpassungen vornehmen kannst. Die wichtigsten Argumente werden im Folgenden erläutert:\nby =\nDu kannst deine Tabelle nach einer Spalte stratifizieren (z. B. nach outcome), um eine 2-Wege-Tabelle zu erstellen.\nstatistic =\nVerwende eine Gleichung, um festzulegen, welche Statistiken angezeigt werden sollen und wie sie dargestellt werden sollen. Die Gleichung hat zwei Seiten, die durch eine Tilde getrennt sind ~. Auf der rechten Seite steht in Anführungszeichen die gewünschte Statistikanzeige und auf der linken Seite die Spalten, für die diese Anzeige gelten soll.\n\nDie rechte Seite der Gleichung verwendet die Syntax von str_glue() von stringr(siehe [Zeichen und Zeichenketten]), wobei der gewünschte Anzeige-String in Anführungszeichen und die Statistik selbst in geschweiften Klammern steht. Du kannst Statistiken wie “n” (für Zähler), “N” (für Nenner), “mean”, “median”, “sd”, “max”, “min”, Perzentile als “p##” wie “p25” oder Prozent der Gesamtzahl als “p” angeben. Siehe?tbl_summary für Details.\nFür die linke Seite der Gleichung kannst du Spalten mit Namen angeben (z. B. age oder c(age, gender)) oder mit Hilfsmitteln wie all_continuous(), all_categorical(), contains(), starts_with(), usw.\n\nEin einfaches Beispiel für eine statistic = Gleichung könnte wie folgt aussehen, um nur den Mittelwert der Spalte age_years:\n\nlinelist %&gt;% \n  select(age_years) %&gt;%         # keep only columns of interest \n  tbl_summary(                  # create summary table\n    statistic = age_years ~ \"{mean}\") # print mean of age\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n16\n\n\n    Unknown\n86\n\n\n\n1 Mean\n\n\n\n\n\n\n\n\n\nEine etwas komplexere Gleichung könnte wie folgt aussehen \"({min}, {max})\" wobei die Maximal- und Minimalwerte in Klammern stehen und durch ein Komma getrennt sind:\n\nlinelist %&gt;% \n  select(age_years) %&gt;%                       # keep only columns of interest \n  tbl_summary(                                # create summary table\n    statistic = age_years ~ \"({min}, {max})\") # print min and max of age\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n(0, 84)\n\n\n    Unknown\n86\n\n\n\n1 (Range)\n\n\n\n\n\n\n\n\n\nDu kannst die Syntax auch für einzelne Spalten oder Spaltentypen differenzieren. In dem komplexeren Beispiel unten wird der Wert, der für statistc = ist eine Liste die angibt, dass die Tabelle für alle kontinuierlichen Spalten den Mittelwert mit der Standardabweichung in Klammern und für alle kategorialen Spalten das n, den Nenner und die Prozentzahl ausgeben soll.\ndigits =\nPasse die Ziffern und Rundungen an. Optional kann festgelegt werden, dass dies nur für fortlaufende Spalten gilt (siehe unten).\nlabel =\nLege fest, wie der Spaltenname angezeigt werden soll. Gib den Spaltennamen und die gewünschte Bezeichnung durch eine Tilde getrennt an. Die Vorgabe ist der Spaltenname.\nmissing_text =\nLege fest, wie fehlende Werte angezeigt werden. Die Standardeinstellung ist “Unbekannt”.\ntype =\nHier kannst du einstellen, wie viele Ebenen der Statistik angezeigt werden sollen. Die Syntax ist ähnlich wie bei statistic = dass du eine Gleichung mit Spalten auf der linken Seite und einem Wert auf der rechten Seite angibst. Zwei häufige Szenarien sind:\n\ntype = all_categorical() ~ \"categorical\" Du erzwingst dichotome Spalten (z. B. fever ja/nein) alle Ebenen statt nur die Zeile “ja” anzeigen\ntype = all_continuous() ~ \"continuous2\" Ermöglicht mehrzeilige Statistiken pro Variable, wie in einem späteren Abschnitt gezeigt\n\nIn dem folgenden Beispiel wird jedes dieser Argumente verwendet, um die ursprüngliche Übersichtstabelle zu ändern:\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;% # keep only columns of interest\n  tbl_summary(     \n    by = outcome,                                               # stratify entire table by outcome\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats and format for continuous columns\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats and format for categorical columns\n    digits = all_continuous() ~ 1,                              # rounding for continuous columns\n    type   = all_categorical() ~ \"categorical\",                 # force all categorical levels to display\n    label  = list(                                              # display labels for column names\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # how missing values should display\n  )\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\n\n\n\n\nAge (years)\n15.9 (12.3)\n16.1 (13.0)\n\n\n    Missing\n32\n28\n\n\nGender\n\n\n\n\n\n\n    f\n1,227 / 2,455 (50%)\n953 / 1,903 (50%)\n\n\n    m\n1,228 / 2,455 (50%)\n950 / 1,903 (50%)\n\n\n    Missing\n127\n80\n\n\nfever\n\n\n\n\n\n\n    no\n458 / 2,460 (19%)\n361 / 1,904 (19%)\n\n\n    yes\n2,002 / 2,460 (81%)\n1,543 / 1,904 (81%)\n\n\n    Missing\n122\n79\n\n\nTemperature\n38.6 (1.0)\n38.6 (1.0)\n\n\n    Missing\n60\n55\n\n\nHospital\n\n\n\n\n\n\n    Central Hospital\n193 / 2,582 (7.5%)\n165 / 1,983 (8.3%)\n\n\n    Military Hospital\n399 / 2,582 (15%)\n309 / 1,983 (16%)\n\n\n    Missing\n611 / 2,582 (24%)\n514 / 1,983 (26%)\n\n\n    Other\n395 / 2,582 (15%)\n290 / 1,983 (15%)\n\n\n    Port Hospital\n785 / 2,582 (30%)\n579 / 1,983 (29%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n199 / 2,582 (7.7%)\n126 / 1,983 (6.4%)\n\n\n\n1 Mean (SD); n / N (%)\n\n\n\n\n\n\n\n\n\n\n\nMehrzeilige Statistiken für kontinuierliche Variablen\nWenn du mehrere Statistikzeilen für kontinuierliche Variablen ausdrucken möchtest, kannst du dies angeben, indem du die Option type = auf “kontinuierlich2” setzt. Du kannst alle zuvor angezeigten Elemente in einer Tabelle zusammenfassen, indem du auswählst, welche Statistiken du anzeigen möchtest. Dazu musst du der Funktion mitteilen, dass du eine Tabelle zurückbekommen möchtest, indem du den Typ als “continuous2” eingibst. Die Anzahl der fehlenden Werte wird als “Unbekannt” angezeigt.\n\nlinelist %&gt;% \n  select(age_years, temp) %&gt;%                      # keep only columns of interest\n  tbl_summary(                                     # create summary table\n    type = all_continuous() ~ \"continuous2\",       # indicate that you want to print multiple statistics \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # line 1: mean and SD\n      \"{median} ({p25}, {p75})\",                   # line 2: median and IQR\n      \"{min}, {max}\")                              # line 3: min and max\n    )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,888\n\n\n\n\nage_years\n\n\n\n\n    Mean (SD)\n16 (13)\n\n\n    Median (IQR)\n13 (6, 23)\n\n\n    Range\n0, 84\n\n\n    Unknown\n86\n\n\ntemp\n\n\n\n\n    Mean (SD)\n38.56 (0.98)\n\n\n    Median (IQR)\n38.80 (38.20, 39.20)\n\n\n    Range\n35.20, 40.80\n\n\n    Unknown\n149\n\n\n\n\n\n\n\n\nEs gibt noch viele andere Möglichkeiten, diese Tabellen zu verändern, wie z. B. das Hinzufügen von p-Werten, das Anpassen von Farben und Überschriften usw. Viele dieser Möglichkeiten werden in der Dokumentation beschrieben (gib ?tbl_summary in der Konsole), und einige sind im Abschnitt über Statistische Tests.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html#basis-r",
    "href": "new_pages/tables_descriptive.de.html#basis-r",
    "title": "17  Beschreibende Tabellen",
    "section": "17.6 Basis R",
    "text": "17.6 Basis R\nDu kannst die Funktion table() verwenden, um Spalten zu tabellieren und Kreuztabellen zu erstellen. Anders als bei den obigen Optionen musst du den Datenrahmen jedes Mal angeben, wenn du auf einen Spaltennamen verweist, wie unten gezeigt.\nVORSICHT! NA (fehlende) Werte werden nicht tabelliert, es sei denn, du gibst das Argument useNA = \"always\" (das auch auf “no” oder “ifany” gesetzt werden kann).\nTIPP: Du kannst die %$% von magrittr um die Notwendigkeit von wiederholten Datenrahmenaufrufen innerhalb von Basis Funktionen zu vermeiden. Zum Beispiel könnte das folgende geschrieben werden linelist %$% table(outcome, useNA = \"always\") \n\ntable(linelist$outcome, useNA = \"always\")\n\n\n  Death Recover    &lt;NA&gt; \n   2582    1983    1323 \n\n\nMehrere Spalten können kreuztabelliert werden, indem du sie nacheinander auflistest, getrennt durch Kommas. Optional kannst du jeder Spalte einen “Namen” geben, z. B. Outcome = linelist$outcome.\n\nage_by_outcome &lt;- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # save table as object\nage_by_outcome   # print table\n\n       \n        Death Recover &lt;NA&gt;\n  0-4     471     364  260\n  5-9     476     391  228\n  10-14   438     303  200\n  15-19   323     251  169\n  20-29   477     367  229\n  30-49   329     238  187\n  50-69    33      38   24\n  70+       3       3    0\n  &lt;NA&gt;     32      28   26\n\n\n\nProportionen\nUm Proportionen zurückzugeben, übergibt man die obige Tabelle an die Funktion prop.table(). Verwende die margins = gibst du an, ob du die Proportionen der Zeilen (1), der Spalten (2) oder der gesamten Tabelle (3) haben möchtest. Der Übersichtlichkeit halber leiten wir die Tabelle in die round() Funktion von Basis R, unter Angabe von 2 Ziffern.\n\n# get proportions of table defined above, by rows, rounded\nprop.table(age_by_outcome, 1) %&gt;% round(2)\n\n       \n        Death Recover &lt;NA&gt;\n  0-4    0.43    0.33 0.24\n  5-9    0.43    0.36 0.21\n  10-14  0.47    0.32 0.21\n  15-19  0.43    0.34 0.23\n  20-29  0.44    0.34 0.21\n  30-49  0.44    0.32 0.25\n  50-69  0.35    0.40 0.25\n  70+    0.50    0.50 0.00\n  &lt;NA&gt;   0.37    0.33 0.30\n\n\n\n\nSummen\nUm Zeilen- und Spaltensummen zu addieren, übergibst du die Tabelle an addmargins(). Das funktioniert sowohl für Zählungen als auch für Proportionen.\n\naddmargins(age_by_outcome)\n\n       \n        Death Recover &lt;NA&gt;  Sum\n  0-4     471     364  260 1095\n  5-9     476     391  228 1095\n  10-14   438     303  200  941\n  15-19   323     251  169  743\n  20-29   477     367  229 1073\n  30-49   329     238  187  754\n  50-69    33      38   24   95\n  70+       3       3    0    6\n  &lt;NA&gt;     32      28   26   86\n  Sum    2582    1983 1323 5888\n\n\n\n\nIn Datenrahmen umwandeln\nKonvertieren einer table() Objekt direkt in einen Datenrahmen umzuwandeln, ist nicht ganz einfach. Ein Ansatz wird im Folgenden gezeigt:\n\nErstelle die Tabelle, ohne Verwendung von useNA = \"always\". Stattdessen konvertieren NA Werte in “(Missing)” mit fct_explicit_na() von forcats.\nAddiere die Summen (optional), indem du auf addmargins()\nRohrleitung zu den Basis R-Funktion as.data.frame.matrix()\nÜbertrage die Tabelle in die tibble Funktion rownames_to_column() und gibt den Namen für die erste Spalte an\nDrucken, Anzeigen oder Exportieren nach Wunsch. In diesem Beispiel verwenden wir flextable() aus Paket flextablewie im Abschnitt [Tabellen für die Präsentation] Seite beschrieben. Dies wird im RStudio-Viewer-Fenster als hübsches HTML-Bild ausgedruckt.\n\n\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %&gt;% \n  addmargins() %&gt;% \n  as.data.frame.matrix() %&gt;% \n  tibble::rownames_to_column(var = \"Age Category\") %&gt;% \n  flextable::flextable()\n\nAge CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.de.html#ressourcen",
    "href": "new_pages/tables_descriptive.de.html#ressourcen",
    "title": "17  Beschreibende Tabellen",
    "section": "17.7 Ressourcen",
    "text": "17.7 Ressourcen\nEin Großteil der Informationen auf dieser Seite wurde aus diesen Ressourcen und Vignetten online übernommen:\ngtsummary\ndplyr",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Beschreibende Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.de.html",
    "href": "new_pages/stat_tests.de.html",
    "title": "18  Einfache statistische Tests",
    "section": "",
    "text": "18.1 Vorbereitung",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Einfache statistische Tests</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.de.html#vorbereitung",
    "href": "new_pages/stat_tests.de.html#vorbereitung",
    "title": "18  Einfache statistische Tests",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics, \n  gtsummary,    # summary statistics and tests\n  rstatix,      # statistics\n  corrr,        # correlation analayis for numeric variables\n  janitor,      # adding totals and percents to tables\n  flextable     # converting tables to HTML\n  )\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Einfache statistische Tests</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.de.html#basis-r",
    "href": "new_pages/stat_tests.de.html#basis-r",
    "title": "18  Einfache statistische Tests",
    "section": "18.2 Basis R",
    "text": "18.2 Basis R\nDu kannst verwenden Basis R-Funktionen verwenden, um statistische Tests durchzuführen. Die Befehle sind relativ einfach und die Ergebnisse werden in die R-Konsole gedruckt, damit du sie einfach betrachten kannst. Allerdings handelt es sich bei den Ausgaben in der Regel um Listen, die schwieriger zu bearbeiten sind, wenn du die Ergebnisse in späteren Operationen verwenden willst.\n\nT-Tests\nA t-test auch “Student’s t-Test” genannt, wird normalerweise verwendet, um festzustellen, ob ein signifikanter Unterschied zwischen den Mittelwerten einer numerischen Variable zwischen zwei Gruppen besteht. Hier zeigen wir dir die Syntax, mit der du diesen Test durchführen kannst, je nachdem, ob sich die Spalten im selben Datenrahmen befinden.\nSyntax 1: Dies ist die Syntax, wenn sich deine numerischen und kategorialen Spalten im selben Datenrahmen befinden. Gib die numerische Spalte auf der linken Seite der Gleichung an und die kategoriale Spalte auf der rechten Seite. Bestimme den Datensatz für data =. Optional kannst du festlegen paired = TRUE, und conf.level = (Standardwert 0,95), und alternative = (entweder “zweiseitig”, “kleiner” oder “größer”). Gib ein. ?t.test für weitere Details ein.\n\n## compare mean age by outcome group with a t-test\nt.test(age_years ~ gender, data = linelist)\n\n\n    Welch Two Sample t-test\n\ndata:  age_years by gender\nt = -21.344, df = 4902.3, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.571920 -6.297975\nsample estimates:\nmean in group f mean in group m \n       12.60207        19.53701 \n\n\nSyntax 2: Mit dieser alternativen Syntax kannst du zwei separate numerische Vektoren vergleichen. Zum Beispiel, wenn die beiden Spalten in verschiedenen Datensätzen sind.\n\nt.test(df1$age_years, df2$age_years)\n\nDu kannst auch einen t-Test verwenden, um festzustellen, ob sich ein Stichprobenmittelwert signifikant von einem bestimmten Wert unterscheidet. Hier führen wir einen t-Test für eine Stichprobe mit dem bekannten/hypothetischen Mittelwert der Grundgesamtheit als mu =:\n\nt.test(linelist$age_years, mu = 45)\n\n\n\nShapiro-Wilk-Test\nDie Shapiro-Wilk-Test kann verwendet werden, um festzustellen, ob eine Stichprobe aus einer normalverteilten Grundgesamtheit stammt (eine Annahme vieler anderer Tests und Analysen, wie z. B. des t-Tests). Er kann jedoch nur bei einer Stichprobe mit 3 bis 5000 Beobachtungen angewendet werden. Bei größeren Stichproben kann ein Quantil-Quantil-Diagramm hilfreich sein.\n\nshapiro.test(linelist$age_years)\n\n\n\nWilcoxon-Rangsummentest\nDer Wilcoxon-Rangsummentest, auch als Mann-Whitney U-Test Der Wilcoxon-Rangsummentest, auch Mann-Whitney-U-Test genannt, wird häufig verwendet, um festzustellen, ob zwei numerische Stichproben aus derselben Verteilung stammen, wenn ihre Grundgesamtheiten nicht normal verteilt sind oder eine ungleiche Varianz aufweisen.\n\n## compare age distribution by outcome group with a wilcox test\nwilcox.test(age_years ~ outcome, data = linelist)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age_years by outcome\nW = 2501868, p-value = 0.8308\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nKruskal-Wallis-Test\nDer Kruskal-Wallis-Test ist eine Erweiterung des Wilcoxon-Rangsummentests, mit dem auf Unterschiede in der Verteilung von mehr als zwei Stichproben getestet werden kann. Wenn nur zwei Stichproben verwendet werden, liefert er die gleichen Ergebnisse wie der Wilcoxon-Rangsummentest.\n\n## compare age distribution by outcome group with a kruskal-wallis test\nkruskal.test(age_years ~ outcome, linelist)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  age_years by outcome\nKruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308\n\n\n\n\nChi-Quadrat-Test\nPearson’s Chi-Quadrat-Test wird zum Testen auf signifikante Unterschiede zwischen kategorialen Gruppen verwendet.\n\n## compare the proportions in each group with a chi-squared test\nchisq.test(linelist$gender, linelist$outcome)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  linelist$gender and linelist$outcome\nX-squared = 0.0011841, df = 1, p-value = 0.9725",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Einfache statistische Tests</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.de.html#rstatix-paket",
    "href": "new_pages/stat_tests.de.html#rstatix-paket",
    "title": "18  Einfache statistische Tests",
    "section": "18.3 rstatix Paket",
    "text": "18.3 rstatix Paket\nDie rstatix Paket bietet die Möglichkeit, statistische Tests durchzuführen und die Ergebnisse in einem “pipe-freundlichen” Rahmen abzurufen. Die Ergebnisse werden automatisch in einem Datenrahmen gespeichert, so dass du spätere Operationen mit den Ergebnissen durchführen kannst. Es ist auch einfach, die Daten, die an die Funktionen übergeben werden, zu gruppieren, sodass die Statistiken für jede Gruppe ausgeführt werden.\n\nZusammenfassende Statistiken\nDie Funktion get_summary_stats() ist eine schnelle Methode, um zusammenfassende Statistiken zu erstellen. Gib einfach deinen Datensatz über die Pipeline an diese Funktion weiter und gib die zu analysierenden Spalten an. Wenn keine Spalten angegeben werden, wird die Statistik für alle Spalten berechnet.\nStandardmäßig wird eine ganze Reihe von zusammenfassenden Statistiken zurückgegeben: n, max, min, Median, 25 %-Pile, 75 %-Pile, IQR, absolute Medianabweichung (mad), Mittelwert, Standardabweichung, Standardfehler und ein Konfidenzintervall für den Mittelwert.\n\nlinelist %&gt;%\n  rstatix::get_summary_stats(age, temp)\n\n# A tibble: 2 × 13\n  variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166\n2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013\n# ℹ 1 more variable: ci &lt;dbl&gt;\n\n\nDu kannst eine Teilmenge der zurückgegebenen Statistiken angeben, indem du einen der folgenden Werte für type =: “full”, “common”, “robust”, “five_number”, “mean_sd”, “mean_se”, “mean_ci”, “median_iqr”, “median_mad”, “quantile”, “mean”, “median”, “min”, “max”.\nSie kann auch mit gruppierten Daten verwendet werden, sodass für jede Gruppierungsvariable eine Zeile zurückgegeben wird:\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  rstatix::get_summary_stats(age, temp, type = \"common\")\n\n# A tibble: 12 × 11\n   hospital     variable     n   min   max median   iqr  mean     sd    se    ci\n   &lt;chr&gt;        &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Central Hos… age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n 2 Central Hos… temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n 3 Military Ho… age        884   0    72     14    18    16.1 12.4   0.417 0.818\n 4 Military Ho… temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n 5 Missing      age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n 6 Missing      temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n 7 Other        age        873   0    69     13    17    16.0 12.5   0.422 0.828\n 8 Other        temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n 9 Port Hospit… age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n10 Port Hospit… temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n11 St. Mark's … age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n12 St. Mark's … temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095\n\n\nDu kannst auch Folgendes verwenden rstatix verwenden, um statistische Tests durchzuführen:\n\n\nT-Test\nVerwende eine Formelsyntax, um die numerischen und kategorischen Spalten anzugeben:\n\nlinelist %&gt;% \n  t_test(age_years ~ gender)\n\n# A tibble: 1 × 10\n  .y.   group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_… f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****        \n\n\nOder verwende ~ 1 und gib an mu = für einen T-Test mit einer Stichprobe. Dies kann auch nach Gruppen erfolgen.\n\nlinelist %&gt;% \n  t_test(age_years ~ 1, mu = 30)\n\n# A tibble: 1 × 7\n  .y.       group1 group2         n statistic    df     p\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age_years 1      null model  5802     -84.2  5801     0\n\n\nFalls zutreffend, können die statistischen Tests nach Gruppen durchgeführt werden, wie unten gezeigt:\n\nlinelist %&gt;% \n  group_by(gender) %&gt;% \n  t_test(age_years ~ 1, mu = 18)\n\n# A tibble: 3 × 8\n  gender .y.       group1 group2         n statistic    df         p\n* &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n3 &lt;NA&gt;   age_years 1      null model   192     -3.80   191 1.96e-  4\n\n\n\n\nShapiro-Wilk-Test\nWie oben erwähnt, muss die Stichprobengröße zwischen 3 und 5000 liegen.\n\nlinelist %&gt;% \n  head(500) %&gt;%            # first 500 rows of case linelist, for example only\n  shapiro_test(age_years)\n\n# A tibble: 1 × 3\n  variable  statistic        p\n  &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 age_years     0.917 6.67e-16\n\n\n\n\nWilcoxon-Rangsummentest\n\nlinelist %&gt;% \n  wilcox_test(age_years ~ gender)\n\n# A tibble: 1 × 9\n  .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****        \n\n\n\n\nKruskal-Wallis-Test\nAuch bekannt als Mann-Whitney-U-Test.\n\nlinelist %&gt;% \n  kruskal_test(age_years ~ outcome)\n\n# A tibble: 1 × 6\n  .y.           n statistic    df     p method        \n* &lt;chr&gt;     &lt;int&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis\n\n\n\n\nChi-Quadrat-Test\nDie Chi-Quadrat-Testfunktion akzeptiert eine Tabelle, also erstellen wir zunächst eine Kreuztabelle. Es gibt viele Möglichkeiten, eine Kreuztabelle zu erstellen (siehe [Beschreibende Tabellen]), aber hier verwenden wirtabyl() von Hausmeister und entferne die linke Spalte der Wertelabels, bevor du sie an chisq_test().\n\nlinelist %&gt;% \n  tabyl(gender, outcome) %&gt;% \n  select(-1) %&gt;% \n  chisq_test()\n\n# A tibble: 1 × 6\n      n statistic     p    df method          p.signif\n* &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;   \n1  5888      3.53 0.473     4 Chi-square test ns      \n\n\nViele, viele weitere Funktionen und statistische Tests können mit rstatix Funktionen durchgeführt werden. Siehe die Dokumentation für rstatix hier online oder indem du ?rstatix eingibst.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Einfache statistische Tests</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.de.html#gtsummary-paket-stats_gt",
    "href": "new_pages/stat_tests.de.html#gtsummary-paket-stats_gt",
    "title": "18  Einfache statistische Tests",
    "section": "18.4 gtsummary Paket {#stats_gt}",
    "text": "18.4 gtsummary Paket {#stats_gt}\nVerwende gtsummary wenn du die Ergebnisse eines statistischen Tests zu einer hübschen Tabelle hinzufügen möchtest, die mit diesem Paket erstellt wurde (wie in der gtsummary Abschnitt des Beschreibenden Tabellen Seite).\nDurchführung von statistischen Vergleichstests mit tbl_summary erfolgt durch Hinzufügen der add_p Funktion zu einer Tabelle hinzufügt und angibt, welcher Test verwendet werden soll. Es ist möglich, für Mehrfachtests korrigierte p-Werte zu erhalten, indem du die Funktion add_q Funktion. ausführen ?tbl_summary für Details aus.\n\nChi-Quadrat-Test\nVergleiche die Proportionen einer kategorialen Variable in zwei Gruppen. Der statistische Standardtest für add_p() auf eine kategoriale Variable wird ein Chi-Quadrat-Test auf Unabhängigkeit mit Stetigkeitskorrektur durchgeführt. Wenn die erwartete Anzahl der Anrufe unter 5 liegt, wird ein exakter Test von Fisher verwendet.\n\nlinelist %&gt;% \n  select(gender, outcome) %&gt;%    # keep variables of interest\n  tbl_summary(by = outcome) %&gt;%  # produce summary table and specify grouping variable\n  add_p()                        # specify what test to perform\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\ngender\n\n\n\n\n&gt;0.9\n\n\n    f\n1,227 (50%)\n953 (50%)\n\n\n\n\n    m\n1,228 (50%)\n950 (50%)\n\n\n\n\n    Unknown\n127\n80\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\nT-Tests\nVergleiche die Differenz der Mittelwerte einer kontinuierlichen Variable in zwei Gruppen. Vergleiche z.B. das Durchschnittsalter nach Patientenergebnis.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%             # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age_years ~ \"{mean} ({sd})\", # specify what statistics to show\n    by = outcome) %&gt;%                        # specify the grouping variable\n  add_p(age_years ~ \"t.test\")                # specify what tests to perform\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n16 (12)\n16 (13)\n0.6\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n\n\n\n\n\n\n\n\n\nWilcoxon-Rangsummentest\nVergleiche die Verteilung einer kontinuierlichen Variable in zwei Gruppen. Der Standard ist die Verwendung des Wilcoxon-Rangsummentests und des Medians (IQR) beim Vergleich zweier Gruppen. Bei nicht-normalverteilten Daten oder beim Vergleich mehrerer Gruppen, ist der Kruskal-Wallis-Test besser geeignet.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (this is default so could remove)\n    by = outcome) %&gt;%                                  # specify the grouping variable\n  add_p(age_years ~ \"wilcox.test\")                     # specify what test to perform (default so could leave brackets empty)\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Wilcoxon rank sum test\n\n\n\n\n\n\n\n\n\n\n\nKruskal-Wallis-Test\nVergleiche die Verteilung einer kontinuierlichen Variable in zwei oder mehr Gruppen, unabhängig davon, ob die Daten normal verteilt sind.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (default, so could remove)\n    by = outcome) %&gt;%                                  # specify the grouping variable\n  add_p(age_years ~ \"kruskal.test\")                    # specify what test to perform\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Kruskal-Wallis rank sum test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Einfache statistische Tests</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.de.html#korrelationen",
    "href": "new_pages/stat_tests.de.html#korrelationen",
    "title": "18  Einfache statistische Tests",
    "section": "18.5 Korrelationen",
    "text": "18.5 Korrelationen\nDie Korrelation zwischen numerischen Variablen kann mit der tidyverse\ncorrr Paket. Es ermöglicht die Berechnung von Korrelationen nach Pearson, Kendall tau oder Spearman rho berechnen. Das Paket erstellt eine Tabelle und hat auch eine Funktion, um um die Werte automatisch darzustellen.\n\ncorrelation_tab &lt;- linelist %&gt;% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %&gt;%   # keep numeric variables of interest\n  correlate()      # create correlation table (using default pearson)\n\ncorrelation_tab    # print\n\n# A tibble: 6 × 7\n  term            generation      age ct_blood days_onset_hosp    wt_kg    ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 generation        NA       -2.22e-2  0.179         -0.288    -0.0302  -0.00942\n2 age               -0.0222  NA        0.00849       -0.000635  0.833    0.877  \n3 ct_blood           0.179    8.49e-3 NA             -0.600    -0.00636  0.0181 \n4 days_onset_hosp   -0.288   -6.35e-4 -0.600         NA         0.0153  -0.00953\n5 wt_kg             -0.0302   8.33e-1 -0.00636        0.0153   NA        0.884  \n6 ht_cm             -0.00942  8.77e-1  0.0181        -0.00953   0.884   NA      \n\n## remove duplicate entries (the table above is mirrored) \ncorrelation_tab &lt;- correlation_tab %&gt;% \n  shave()\n\n## view correlation table \ncorrelation_tab\n\n# A tibble: 6 × 7\n  term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 generation        NA       NA        NA              NA       NA        NA\n2 age               -0.0222  NA        NA              NA       NA        NA\n3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n\n## plot correlations \nrplot(correlation_tab)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Einfache statistische Tests</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.de.html#ressourcen",
    "href": "new_pages/stat_tests.de.html#ressourcen",
    "title": "18  Einfache statistische Tests",
    "section": "18.6 Ressourcen",
    "text": "18.6 Ressourcen\nEin Großteil der Informationen auf dieser Seite wurde aus diesen Ressourcen und Vignetten online übernommen:\ngtsummary dplyr corrr sthda-Korrelation",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Einfache statistische Tests</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.de.html",
    "href": "new_pages/regression.de.html",
    "title": "19  Univariate und multivariable Regression",
    "section": "",
    "text": "19.1 Vorbereitung",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Univariate und multivariable Regression</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.de.html#vorbereitung",
    "href": "new_pages/regression.de.html#vorbereitung",
    "title": "19  Univariate und multivariable Regression",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse,    # data management + ggplot2 graphics, \n  stringr,      # manipulate text strings \n  purrr,        # loop over objects in a tidy way\n  gtsummary,    # summary statistics and tests \n  broom,        # tidy up results from regressions\n  lmtest,       # likelihood-ratio tests\n  parameters,   # alternative to tidy up results from regressions\n  see          # alternative to visualise forest plots\n  )\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.\n\n\n\n\n\n\n\n\nSaubere Daten\n\nErklärende Variablen speichern\nWir speichern die Namen der erklärenden Spalten als einen Zeichenvektor. Dieser wird später referenziert.\n\n## define variables of interest \nexplanatory_vars &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n\n\nIn 1en und 0en umwandeln\nIm Folgenden wandeln wir die erklärenden Spalten von “ja”/“nein”, “m”/“f” und “tot”/“lebendig” in 1 / 0 um mit den Erwartungen der logistischen Regressionsmodelle übereinzustimmen. Um dies effizient zu tun, verwenden across() von dplyr um mehrere Spalten auf einmal zu transformieren. Die Funktion, die wir auf jede Spalte anwenden, lautet case_when() (auch dplyr), die Logik anwendet, um bestimmte Werte in 1en und 0en zu konvertieren. Siehe Abschnitte über across() und case_when() in den Seite Reinigungsdaten und Kernfunktionen).\nHinweis: Das “.” unten steht für die Spalte, die von der across() in diesem Moment bearbeitet wird.\n\n## convert dichotomous variables to 0/1 \nlinelist &lt;- linelist %&gt;%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## for each column listed and \"outcome\"\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## recode male, yes and death to 1\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0,           ## female, no and recover to 0\n      TRUE                            ~ NA_real_)    ## otherwise set to missing\n    )\n  )\n\n\n\nZeilen mit fehlenden Werten verwerfen\nUm Zeilen mit fehlenden Werten zu löschen, kannst du die tidyr Funktion drop_na(). Wir wollen dies jedoch nur für Zeilen tun, in denen Werte in den interessierenden Spalten fehlen.\nAls Erstes müssen wir sicherstellen, dass unsere explanatory_vars Vektor die Spalte age (age hätte zu einem Fehler in der vorherigen case_when() Operation, die nur für dichotome Variablen galt). Dann leiten wir die linelist zu drop_na() um alle Zeilen mit fehlenden Werten aus der outcome Spalte oder einer der explanatory_vars Spalten.\nBevor der Code ausgeführt wird, wird die Anzahl der Zeilen in der linelist ist nrow(linelist).\n\n## add in age_category to the explanatory vars \nexplanatory_vars &lt;- c(explanatory_vars, \"age_cat\")\n\n## drop rows with missing information for variables of interest \nlinelist &lt;- linelist %&gt;% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))\n\nDie Anzahl der verbleibenden Zeilen in linelist ist nrow(linelist).",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Univariate und multivariable Regression</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.de.html#univariate",
    "href": "new_pages/regression.de.html#univariate",
    "title": "19  Univariate und multivariable Regression",
    "section": "19.2 Univariate",
    "text": "19.2 Univariate\nGenau wie auf der Seite über Beschreibende Tabellen hängt es von deinem Anwendungsfall ab, welches R-Paket du verwendest. Wir stellen zwei Optionen für die univariate Analyse vor:\n\nVerwende die Funktionen, die in Basis R verfügbaren Funktionen, um die Ergebnisse schnell auf der Konsole auszugeben. Verwende die Besen Paket, um die Ausgaben aufzuräumen.\nVerwende das gtsummary Paket, um zu modellieren und veröffentlichungsreife Ergebnisse zu erhalten\n\n\n\nBasis R\n\nLineare Regression\nDie Basis R-Funktion lm() führt eine lineare Regression durch und bewertet die Beziehung zwischen numerischen Antworten und erklärenden Variablen, von denen angenommen wird, dass sie eine lineare Beziehung haben.\nGib die Gleichung als Formel an, wobei die Namen der Antwort- und Erklärungsspalten durch eine Tilde getrennt sind ~. Gib außerdem den Datensatz an, der data =. Definiere die Modellergebnisse als R-Objekt, um sie später zu verwenden.\n\nlm_results &lt;- lm(ht_cm ~ age, data = linelist)\n\nDu kannst dann Folgendes ausführen summary() auf die Modellergebnisse anwenden, um die Koeffizienten (Schätzungen), den P-Wert, die Residuen und andere Maße zu sehen.\n\nsummary(lm_results)\n\n\nCall:\nlm(formula = ht_cm ~ age, data = linelist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-128.579  -15.854    1.177   15.887  175.483 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  69.9051     0.5979   116.9   &lt;2e-16 ***\nage           3.4354     0.0293   117.2   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.75 on 4165 degrees of freedom\nMultiple R-squared:  0.7675,    Adjusted R-squared:  0.7674 \nF-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: &lt; 2.2e-16\n\n\nAlternativ kannst du auch die tidy() Funktion aus dem Besen Paket zu ziehen die Ergebnisse in eine Tabelle zu übertragen. Die Ergebnisse zeigen, dass die Körpergröße mit jedem Jahr, das das Alter zunimmt, steigt um 3,5 cm zunimmt und dies ist statistisch signifikant.\n\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    69.9     0.598       117.       0\n2 age             3.44    0.0293      117.       0\n\n\nDu kannst diese Regression dann auch dazu verwenden, um sie zu einer ggplot Dazu müssen wir zuerst die Punkte für die beobachteten Daten und die angepasste Linie in einen Datenrahmen ziehen unter Verwendung der augment() Funktion von Besen.\n\n## pull the regression points and observed data in to one dataset\npoints &lt;- augment(lm_results)\n\n## plot the data using age as the x-axis \nggplot(points, aes(x = age)) + \n  ## add points for height \n  geom_point(aes(y = ht_cm)) + \n  ## add your regression line \n  geom_line(aes(y = .fitted), colour = \"red\")\n\n\n\n\n\n\n\n\nEs ist auch möglich, eine einfache lineare Regression gerade in ggplot unter Verwendung der geom_smooth() Funktion.\n\n## add your data to a plot \n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## show points\n  geom_point() + \n  ## add a linear regression \n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAusführlichere Anleitungen findest du im Abschnitt Ressourcen am Ende dieses Kapitels.\n\n\nLogistische Regression\nDie Funktion glm() aus dem stats Paket (Teil von Basis R) wird verwendet, um verallgemeinerte lineare Modelle (GLM) anzupassen.\nglm() kann für univariate und multivariable logistische Regression verwendet werden (z.B. um Odds Ratios zu ermitteln). Hier sind die wichtigsten Teile:\n\n# arguments for glm()\nglm(formula, family, data, weights, subset, ...)\n\n\nformula = Das Modell wird bereitgestellt, um glm() als Gleichung dargestellt, mit dem Ergebnis auf der linken Seite und den erklärenden Variablen auf der rechten Seite einer Tilde ~.\nfamily = Dies bestimmt die Art des Modells, das ausgeführt werden soll. Für die logistische Regression verwendest du family = \"binomial\", für Poisson verwenden Sie family = \"poisson\". Weitere Beispiele findest du in der Tabelle unten.\ndata = Spezifiziere deinen Datenrahmen\n\nFalls erforderlich, kannst du die Verknüpfungsfunktion auch über die Syntax angeben family = familytype(link = \"linkfunction\")). Du kannst in der Dokumentation mehr über andere Familien und optionale Argumente lesen, wie zum Beispiel weights = und subset = (?glm).\n\n\n\n\n\n\n\nFamilie\nStandard-Linkfunktion\n\n\n\n\n\"binomial\"\n(link = \"logit\")\n\n\n\"gaussian\"\n(link = \"identity\")\n\n\n\"Gamma\"\n(link = \"inverse\")\n\n\n\"inverse.gaussian\"\n(link = \"1/mu^2\")\n\n\n\"poisson\"\n(link = \"log\")\n\n\n\"quasi\"\n(link = \"identity\", variance = \"constant\")\n\n\n\"quasibinomial\"\n(link = \"logit\")\n\n\n\"quasipoisson\"\n(link = \"log\")\n\n\n\nWenn ausgeführt glm() ist es üblich, die Ergebnisse als benanntes R-Objekt zu speichern. Dann kannst du die Ergebnisse auf deiner Konsole ausgeben, indem du summary() ausgeben oder andere Operationen mit den Ergebnissen durchführen (z. B. potenzieren).\nWenn du eine negative Binomialregression durchführen musst, kannst du die MASS Paket verwenden; das glm.nb() verwendet die gleiche Syntax wie glm(). Eine Übersicht über die verschiedenen Regressionen findest du in der UCLA-Statistikseite.\n\n\nUnivariate glm()\nIn diesem Beispiel untersuchen wir den Zusammenhang zwischen verschiedenen Alterskategorien und dem Ergebnis des Todes (im Abschnitt “Vorbereitung” als 1 kodiert). Nachfolgend ist ein univariates Modell für outcome von age_cat. Wir speichern die Modellausgabe als model und drucken sie dann mit summary() auf der Konsole aus. Beachte, dass die angegebenen Schätzungen die Log-Quoten und dass die Basislinie die erste Faktorstufe von age_cat (“0-4”).\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   0.233738   0.072805   3.210  0.00133 **\nage_cat5-9   -0.062898   0.101733  -0.618  0.53640   \nage_cat10-14  0.138204   0.107186   1.289  0.19726   \nage_cat15-19 -0.005565   0.113343  -0.049  0.96084   \nage_cat20-29  0.027511   0.102133   0.269  0.78765   \nage_cat30-49  0.063764   0.113771   0.560  0.57517   \nage_cat50-69 -0.387889   0.259240  -1.496  0.13459   \nage_cat70+   -0.639203   0.915770  -0.698  0.48518   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\nUm die Basisstufe einer bestimmten Variablen zu ändern, stelle sicher, dass die Spalte die Klasse Faktor ist und verschiebe die gewünschte Stufe an die erste Position mit fct_relevel()(siehe Seite über [Faktoren]). Unten nehmen wir zum Beispiel die Spalteage_cat und setzen “20-29” als Basislinie, bevor wir den geänderten Datenrahmen in glm().\n\nlinelist %&gt;% \n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %&gt;% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %&gt;% \n  summary()\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.26125    0.07163   3.647 0.000265 ***\nage_cat0-4   -0.02751    0.10213  -0.269 0.787652    \nage_cat5-9   -0.09041    0.10090  -0.896 0.370220    \nage_cat10-14  0.11069    0.10639   1.040 0.298133    \nage_cat15-19 -0.03308    0.11259  -0.294 0.768934    \nage_cat30-49  0.03625    0.11302   0.321 0.748390    \nage_cat50-69 -0.41540    0.25891  -1.604 0.108625    \nage_cat70+   -0.66671    0.91568  -0.728 0.466546    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nErgebnisse drucken\nFür die meisten Verwendungszwecke müssen einige Änderungen an den obigen Ausgaben vorgenommen werden. Die Funktion tidy() aus dem Paket broom ist praktisch, um die Modellergebnisse darstellbar zu machen.\nHier zeigen wir dir, wie du die Modellergebnisse mit einer Zähltabelle kombinieren kannst.\n\nErhalte die potenzierte log Odds Ratio-Schätzungen und Konfidenzintervalle, indem du das Modell an tidy() und die Einstellung exponentiate = TRUE und conf.int = TRUE.\n\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %&gt;% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%        # exponentiate and produce CIs\n  mutate(across(where(is.numeric), round, digits = 2))  # round all numeric columns\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, digits = 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nNachfolgend ist das ausgegebene Tibble model:\n\n\n\n\n\n\n\nKombiniere diese Modellergebnisse mit einer Tabelle der Zählungen. Nachfolgend erstellen wir eine Kreuztabelle der Zählungen mit dem tabyl() Funktion von Hausmeister, wie sie in den [Beschreibende Tabellen] Seite.\n\n\ncounts_table &lt;- linelist %&gt;% \n  janitor::tabyl(age_cat, outcome)\n\n\n\n\n\n\n\n\n\n\n\nHier ist, was das counts_table Datenrahmen aussieht:\n\n\n\n\n\n\nJetzt können wir die counts_table und die model Ergebnisse horizontal miteinander verbinden mit bind_cols() (dplyr). Denke daran, dass mit bind_cols() die Zeilen in den beiden Datenrahmen perfekt aneinander ausgerichtet sein müssen. Da wir in diesem Code innerhalb einer Pipe-Kette binden, verwenden wir . um das gepipte Objekt darzustellen counts_table da wir es binden an model. Um den Prozess abzuschließen, verwenden wir select() um die gewünschten Spalten und ihre Reihenfolge auszuwählen, und wenden schließlich die Basis R round() Funktion über alle numerischen Spalten, um 2 Nachkommastellen anzugeben.\n\ncombined &lt;- counts_table %&gt;%           # begin with table of counts\n  bind_cols(., model) %&gt;%              # combine with the outputs of the regression \n  select(term, 2:3, estimate,          # select and re-order cols\n         conf.low, conf.high, p.value) %&gt;% \n  mutate(across(where(is.numeric), round, digits = 2)) ## round to 2 decimal places\n\nSo sieht der kombinierte Datenrahmen aus, der mit einer Funktion von R als Bild gedruckt wird flextable. Die [Tabellen für die Präsentation] erklärt, wie man solche Tabellen mitflextable anpasst, oder du kannst zahlreiche andere Pakete verwenden, wie zum Beispiel knitr oder GT.\n\ncombined &lt;- combined %&gt;% \n  flextable::qflextable()\n\n\n\nSchleifen mehrerer univariater Modelle\nIm Folgenden stellen wir eine Methode vor, die glm() und tidy() Für einen einfacheren Ansatz siehe den Abschnitt über gtsummary.\nWenn du die Modelle auf mehrere Expositionsvariablen anwenden willst, um univariate Odds Ratios zu erhalten (d.h. ohne gegenseitige Kontrolle), kannst du den folgenden Ansatz verwenden. Er verwendet str_c() von stringrum univariate Formeln zu erstellen (siehe [Zeichen und Zeichenketten]), führt dieglm() Regression für jede Formel durch, übergibt jede glm() Ausgabe an tidy() und fasst schließlich alle Modellausgänge zusammen mit bind_rows() von tidyr. Dieser Ansatz verwendet map() aus dem Paket purrrzu iterieren - siehe die Seite über [Iteration, Schleifen und Listen] für weitere Informationen zu diesem Werkzeug.\n\nErstelle einen Vektor mit den Spaltennamen der erklärenden Variablen. Wir haben dies bereits als explanatory_vars aus dem Abschnitt Vorbereitung auf dieser Seite.\nVerwende str_c() um mehrere String-Formeln zu erstellen, mit outcome auf der linken Seite, und einem Spaltennamen aus explanatory_vars auf der rechten Seite. Der Zeitraum . ersetzt den Spaltennamen in explanatory_vars.\n\n\nexplanatory_vars %&gt;% str_c(\"outcome ~ \", .)\n\n[1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\" \n[4] \"outcome ~ cough\"   \"outcome ~ aches\"   \"outcome ~ vomit\"  \n[7] \"outcome ~ age_cat\"\n\n\n\nÜbergeben Sie diese String-Formeln an map() und setze ~glm() als die Funktion, die auf jede Eingabe angewendet werden soll. Innerhalb von glm() setzt du die Regressionsformel als as.formula(.x) wobei .x durch die im obigen Schritt definierte String-Formel ersetzt wird. map() durchläuft eine Schleife über jede der String-Formeln und führt für jede eine Regression durch.\nDie Ergebnisse dieser ersten map() werden an eine zweite map() Befehl übergeben, der die tidy() auf die Regressionsergebnisse anwendet.\nSchließlich wird die Ausgabe des zweiten map() (eine Liste von aufgeräumten Datenrahmen) mit bind_rows() zusammengefasst, so dass ein Datenrahmen mit allen univariaten Ergebnissen entsteht.\n\n\nmodels &lt;- explanatory_vars %&gt;%       # begin with variables of interest\n  str_c(\"outcome ~ \", .) %&gt;%         # combine each variable into formula (\"outcome ~ variable of interest\")\n  \n  # iterate through each univariate formula\n  map(                               \n    .f = ~glm(                       # pass the formulas one-by-one to glm()\n      formula = as.formula(.x),      # within glm(), the string formula is .x\n      family = \"binomial\",           # specify type of glm (logistic)\n      data = linelist)) %&gt;%          # dataset\n  \n  # tidy up each of the glm regression outputs from above\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponentiate \n      conf.int = TRUE)) %&gt;%          # return confidence intervals\n  \n  # collapse the list of regression outputs in to one data frame\n  bind_rows() %&gt;% \n  \n  # round all numeric columns\n  mutate(across(where(is.numeric), round, digits = 2))\n\nDieses Mal wird das Endobjekt models länger, weil es jetzt die kombinierten Ergebnisse mehrerer univariater Regressionen enthält. Klicke dich durch, um alle Zeilen der model.\n\n\n\n\n\n\nWie zuvor können wir eine Zähltabelle aus den linelist für jede erklärende Variable erstellen, sie mit models verbinden und eine schöne Tabelle erstellen. Wir beginnen mit den Variablen und iterieren durch sie mit map(). Wir iterieren durch eine benutzerdefinierte Funktion, die das Erstellen einer Zähltabelle mit dplyr Funktionen. Dann werden die Ergebnisse kombiniert und mit dem models Modellergebnissen.\n\n## for each explanatory variable\nuniv_tab_base &lt;- explanatory_vars %&gt;% \n  map(.f = \n    ~{linelist %&gt;%                ## begin with linelist\n        group_by(outcome) %&gt;%     ## group data set by outcome\n        count(.data[[.x]]) %&gt;%    ## produce counts for variable of interest\n        pivot_wider(              ## spread to wide format (as in cross-tabulation)\n          names_from = outcome,\n          values_from = n) %&gt;% \n        drop_na(.data[[.x]]) %&gt;%         ## drop rows with missings\n        rename(\"variable\" = .x) %&gt;%      ## change variable of interest column to \"variable\"\n        mutate(variable = as.character(variable))} ## convert to character, else non-dichotomous (categorical) variables come out as factor and cant be merged\n      ) %&gt;% \n  \n  ## collapse the list of count outputs in to one data frame\n  bind_rows() %&gt;% \n  \n  ## merge with the outputs of the regression \n  bind_cols(., models) %&gt;% \n  \n  ## only keep columns interested in \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %&gt;% \n  \n  ## round decimal places\n  mutate(across(where(is.numeric), round, digits = 2))\n\nIm Folgenden siehst du, wie der Datenrahmen aussieht. Siehe die Seite über [Tabellen für die Präsentation] für Ideen, wie du diese Tabelle in eine hübsche HTML-Ausgabe umwandeln kannst (z. B. mitflextable).\n\n\n\n\n\n\n\n\n\n\n19.2.1 gtsummary Paket {#reg_gt_uni .unnumbered}\nIm Folgenden stellen wir die Verwendung von tbl_uvregression() von der gtsummary Paket. Genau wie auf der Seite über Beschreibende Tabellen, gtsummary Funktionen leisten gute Arbeit bei der Erstellung von Statistiken und professionell aussehende Ergebnisse zu erzeugen. Diese Funktion erstellt eine Tabelle mit univariaten Regressionsergebnissen.\nWir wählen nur die notwendigen Spalten aus der linelist (erklärende Variablen und die Ergebnisvariable) und leiten sie in die tbl_uvregression(). Wir führen eine univariate Regression für jede der Spalten durch, die wir als explanatory_vars definiert haben (Geschlecht, Fieber, Schüttelfrost, Husten, Schmerzen, Erbrechen und Alter_Katze).\nIn der Funktion selbst geben wir die method = als glm (ohne Anführungszeichen), die y = Ergebnis-Spalte (outcome), angeben zu method.args = dass wir die logistische Regression über family = binomial und wir weisen sie an, die Ergebnisse zu potenzieren.\nDie Ausgabe ist HTML und enthält die Zählungen\n\nuniv_tab &lt;- linelist %&gt;% \n  dplyr::select(explanatory_vars, outcome) %&gt;% ## select variables of interest\n\n  tbl_uvregression(                         ## produce univariate table\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = outcome,                            ## define outcome variable\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n## view univariate results table \nuniv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nEs gibt viele Änderungen, die du an dieser Tabellenausgabe vornehmen kannst, wie z. B. die Anpassung der Textbeschriftungen, das Fetten von Zeilen nach ihrem p-Wert usw. Siehe Tutorials hier und anderswo im Internet.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Univariate und multivariable Regression</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.de.html#stratified",
    "href": "new_pages/regression.de.html#stratified",
    "title": "19  Univariate und multivariable Regression",
    "section": "19.3 Stratified",
    "text": "19.3 Stratified\nAn der stratifizierten Analyse wird derzeit noch gearbeitet für gtsummary, Diese Seite wird zu gegebener Zeit aktualisiert.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Univariate und multivariable Regression</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.de.html#multivariabel",
    "href": "new_pages/regression.de.html#multivariabel",
    "title": "19  Univariate und multivariable Regression",
    "section": "19.4 Multivariabel",
    "text": "19.4 Multivariabel\nFür die multivariable Analyse stellen wir wieder zwei Ansätze vor:\n\nglm() und tidy()\ngtsummary Paket\n\nDer Arbeitsablauf ist bei beiden Paketen ähnlich und nur der letzte Schritt, das Zusammenstellen einer endgültigen Tabelle, ist anders.\n\nDurchführen von multivariablen\nHier verwenden wir glm() aber fügen auf der rechten Seite der Gleichung weitere Variablen hinzu, getrennt durch Pluszeichen (+).\nUm das Modell mit all unseren erklärenden Variablen durchzuführen, würden wir Folgendes ausführen:\n\nmv_reg &lt;- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)\n\n\nCall:\nglm(formula = outcome ~ gender + fever + chills + cough + aches + \n    vomit + age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   0.069054   0.131726   0.524    0.600\ngender        0.002448   0.065133   0.038    0.970\nfever         0.004309   0.080522   0.054    0.957\nchills        0.034112   0.078924   0.432    0.666\ncough         0.138584   0.089909   1.541    0.123\naches        -0.070705   0.104078  -0.679    0.497\nvomit         0.086098   0.062618   1.375    0.169\nage_cat5-9   -0.063562   0.101851  -0.624    0.533\nage_cat10-14  0.136372   0.107275   1.271    0.204\nage_cat15-19 -0.011074   0.113640  -0.097    0.922\nage_cat20-29  0.026552   0.102780   0.258    0.796\nage_cat30-49  0.059569   0.116402   0.512    0.609\nage_cat50-69 -0.388964   0.262384  -1.482    0.138\nage_cat70+   -0.647443   0.917375  -0.706    0.480\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5700.2  on 4153  degrees of freedom\nAIC: 5728.2\n\nNumber of Fisher Scoring iterations: 4\n\n\nWenn du zwei Variablen und eine Wechselwirkung zwischen ihnen einbeziehen willst, kannst du sie mit einem Sternchen trennen * anstelle eines +. Trenne sie mit einem Doppelpunkt : wenn du nur die Interaktion angibst. Zum Beispiel:\n\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n\nOptional kannst du diesen Code verwenden, um den vordefinierten Vektor der Spaltennamen zu nutzen und den obigen Befehl mit str_c(). Das kann nützlich sein, wenn sich die Namen deiner erklärenden Variablen ändern oder du sie nicht alle neu eingeben möchtest.\n\n## run a regression with all variables of interest \nmv_reg &lt;- explanatory_vars %&gt;%  ## begin with vector of explanatory column names\n  str_c(collapse = \"+\") %&gt;%     ## combine all names of the variables of interest separated by a plus\n  str_c(\"outcome ~ \", .) %&gt;%    ## combine the names of variables of interest with outcome in formula style\n  glm(family = \"binomial\",      ## define type of glm as logistic,\n      data = linelist)          ## define your dataset\n\n\nErstellen des Modells\nDu kannst dein Modell schrittweise aufbauen und verschiedene Modelle speichern, die bestimmte erklärende Variablen enthalten. Du kannst diese Modelle mit Likelihood-Ratio-Tests vergleichen, indem du lrtest() aus dem Paket lmtest wie unten beschrieben:\nHINWEIS: Mit Basis anova(model1, model2, test = \"Chisq) ergibt die gleichen Ergebnisse \n\nmodel1 &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 &lt;- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)\n\nLikelihood ratio test\n\nModel 1: outcome ~ age_cat\nModel 2: outcome ~ age_cat + gender\n  #Df  LogLik Df Chisq Pr(&gt;Chisq)\n1   8 -2852.6                    \n2   9 -2852.6  1 2e-04     0.9883\n\n\nEine andere Möglichkeit ist, das Modellobjekt zu nehmen und die step() Funktion aus dem stats Paket. Gib an, welche Richtung der Variablenauswahl du bei der Erstellung des Modells verwenden möchtest.\n\n## choose a model using forward selection based on AIC\n## you can also do \"backward\" or \"both\" by adjusting the direction\nfinal_mv_reg &lt;- mv_reg %&gt;%\n  step(direction = \"forward\", trace = FALSE)\n\nDu kannst auch die wissenschaftliche Notation in deiner R-Sitzung ausschalten, um die Übersichtlichkeit zu erhöhen:\n\noptions(scipen=999)\n\nWie im Abschnitt über univariate Analysen beschrieben, übergibst du die Modellausgabe an tidy() um die log Odds und CIs zu potenzieren. Zum Schluss runden wir alle numerischen Spalten auf zwei Dezimalstellen. Scrolle durch, um alle Zeilen zu sehen.\n\nmv_tab_base &lt;- final_mv_reg %&gt;% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%  ## get a tidy dataframe of estimates \n  mutate(across(where(is.numeric), round, digits = 2))          ## round \n\nSo sieht der resultierende Datenrahmen aus:\n\n\n\n\n\n\n\n\n\n\nKombiniere univariate und multivariable\n\nKombinieren mit gtsummary\nDie gtsummary Paket bietet die tbl_regression() Funktion, die die Ausgaben aus einer Regression (glm() in diesem Fall) und eine schöne zusammenfassende Tabelle.\n\n## show results table of final regression \nmv_tab &lt;- tbl_regression(final_mv_reg, exponentiate = TRUE)\n\nSchauen wir uns die Tabelle an:\n\nmv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n1.15\n0.96, 1.37\n0.12\n\n\naches\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n\n\n\n\n\n\n\n\n    0-4\n—\n—\n\n\n\n\n    5-9\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nDu kannst auch mehrere verschiedene Ausgabetabellen kombinieren, die von gtsummary mit der tbl_merge() Funktion. Wir kombinieren nun die multivariablen Ergebnisse mit der gtsummary univariate Ergebnisse, die wir erstellt haben oben:\n\n## combine with univariate results \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # set header names\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nUnivariate\nMultivariable\n\n\nN\nOR1\n95% CI1\np-value\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n1.15\n0.96, 1.37\n0.12\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\nKombiniere mit dplyr\nEine alternative Möglichkeit zur Kombination der glm()/tidy() univariaten und multivariablen Ausgaben ist mit der dplyr Funktionen verknüpft.\n\nVerbinde die univariaten Ergebnisse von vorher (univ_tab_base die Zählungen enthält) mit den aufgeräumten multivariablen Ergebnissen mv_tab_base\nVerwende select() um nur die gewünschten Spalten zu behalten, ihre Reihenfolge festzulegen und sie umzubenennen\nverwenden round() mit zwei Dezimalstellen für alle Spalten, die der Klasse Double angehören\n\n\n## combine univariate and multivariable tables \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %&gt;% \n  ## choose columns and rename them\n  select( # new name =  old name\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %&gt;% \n  mutate(across(where(is.double), round, 2))   \n\n# A tibble: 20 × 11\n   characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval\n   &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)          909  1168    1.28        1.18         1.4       0   \n 2 gender               916  1174    1           0.88         1.13      0.97\n 3 (Intercept)          340   436    1.28        1.11         1.48      0   \n 4 fever               1485  1906    1           0.85         1.17      0.99\n 5 (Intercept)         1472  1877    1.28        1.19         1.37      0   \n 6 chills               353   465    1.03        0.89         1.21      0.68\n 7 (Intercept)          272   309    1.14        0.97         1.34      0.13\n 8 cough               1553  2033    1.15        0.97         1.37      0.11\n 9 (Intercept)         1636  2114    1.29        1.21         1.38      0   \n10 aches                189   228    0.93        0.76         1.14      0.51\n11 (Intercept)          931  1144    1.23        1.13         1.34      0   \n12 vomit                894  1198    1.09        0.96         1.23      0.17\n13 (Intercept)          338   427    1.26        1.1          1.46      0   \n14 age_cat5-9           365   433    0.94        0.77         1.15      0.54\n15 age_cat10-14         273   396    1.15        0.93         1.42      0.2 \n16 age_cat15-19         238   299    0.99        0.8          1.24      0.96\n17 age_cat20-29         345   448    1.03        0.84         1.26      0.79\n18 age_cat30-49         228   307    1.07        0.85         1.33      0.58\n19 age_cat50-69          35    30    0.68        0.41         1.13      0.13\n20 age_cat70+             3     2    0.53        0.07         3.2       0.49\n# ℹ 4 more variables: mv_or &lt;dbl&gt;, mvv_ci_low &lt;dbl&gt;, mv_ci_high &lt;dbl&gt;,\n#   mv_pval &lt;dbl&gt;",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Univariate und multivariable Regression</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.de.html#waldgrundstück",
    "href": "new_pages/regression.de.html#waldgrundstück",
    "title": "19  Univariate und multivariable Regression",
    "section": "19.5 Waldgrundstück",
    "text": "19.5 Waldgrundstück\nIn diesem Abschnitt wird gezeigt, wie du ein Diagramm mit den Ergebnissen deiner Regression erstellst. Es gibt zwei Möglichkeiten: Du kannst selbst ein Diagramm erstellen, indem du ggplot2 erstellen oder eine Meta-Paket namens easystats (ein Paket, das viele Pakete enthält).\nSiehe die Seite über [ggplot Grundlagen] wenn du nicht vertraut bist mit demggplot2 Plot-Paket vertraut bist.\n\n\nggplot2 Paket\nDu kannst einen Waldplot erstellen mit ggplot() erstellen, indem du Elemente der multivariablen Regressionsergebnisse einzeichnest. Füge die Ebenen des Plots mit diesen “Geoms” hinzu:\n\nSchätzungen mit geom_point()\nKonfidenzintervallen mit geom_errorbar()\neiner vertikalen Linie bei OR = 1 mit geom_vline()\n\nBevor du zeichnest, kannst du Folgendes verwenden fct_relevel() aus dem forcats Paket, um die Reihenfolge der Variablen/Niveaus auf der y-Achse festzulegen. ggplot()kann sie in alphanumerischer Reihenfolge anzeigen, was bei diesen Alterskategoriewerten nicht gut funktionieren würde (“30” würde vor “5” erscheinen). Siehe die Seite über [Faktoren] für weitere Details.\n\n## remove the intercept term from your multivariable results\nmv_tab_base %&gt;% \n  \n  #set order of levels to appear along y-axis\n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %&gt;%\n  \n  # remove \"intercept\" row from plot\n  filter(term != \"(Intercept)\") %&gt;% \n  \n  ## plot with variable on the y axis and estimate (OR) on the x axis\n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## show the estimate as a point\n  geom_point() + \n  \n  ## add in an error bar for the confidence intervals\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## show where OR = 1 is for reference as a dashed line\n  geom_vline(xintercept = 1, linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\neasystats Pakete\nEine Alternative, wenn du nicht den feinen Grad an Kontrolle haben willst, den ggplot2 bietet, ist die Verwendung einer Kombination aus easystats Paketen.\nDie Funktion model_parameters() aus dem Parametern Paket macht das Äquivalent der Besen Paketfunktion tidy(). Die siehe Paket akzeptiert dann diese Ausgaben und erstellt einen Standard-Waldplot als ggplot() Objekt.\n\npacman::p_load(easystats)\n\n## remove the intercept term from your multivariable results\nfinal_mv_reg %&gt;% \n  model_parameters(exponentiate = TRUE) %&gt;% \n  plot()",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Univariate und multivariable Regression</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.de.html#ressourcen",
    "href": "new_pages/regression.de.html#ressourcen",
    "title": "19  Univariate und multivariable Regression",
    "section": "19.6 Ressourcen",
    "text": "19.6 Ressourcen\nDer Inhalt dieser Seite wurde durch diese Ressourcen und Vignetten online beeinflusst:\nLineare Regression in R\ngtsummary\nUCLA-Statistikseite\nsthda schrittweise Regression",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Univariate und multivariable Regression</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html",
    "href": "new_pages/missing_data.de.html",
    "title": "20  Fehlende Daten",
    "section": "",
    "text": "20.1 Vorbereitung",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html#vorbereitung",
    "href": "new_pages/missing_data.de.html#vorbereitung",
    "title": "20  Fehlende Daten",
    "section": "",
    "text": "Pakete laden\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,           # import/export\n  tidyverse,     # data mgmt and viz\n  naniar,        # assess and visualize missingness\n  mice           # missing data imputation\n)\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.\n\n\n\n\n\n\n\n\nKonvertierung fehlt beim Import\nAchte beim Importieren deiner Daten auf Werte, die als fehlend klassifiziert werden sollten. Zum Beispiel 99, 999, “Fehlend”, leere Zellen (““) oder Zellen mit einem Leerzeichen (” “). Du kannst sie umwandeln in NA (Rs Version von fehlenden Daten) während des Datenimports umwandeln.\nSiehe die Seite zum Importieren von Seiten auf Fehlende Daten für Details, da die genaue Syntax je nach Dateityp variiert.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html#fehlende-werte-in-r",
    "href": "new_pages/missing_data.de.html#fehlende-werte-in-r",
    "title": "20  Fehlende Daten",
    "section": "20.2 Fehlende Werte in R",
    "text": "20.2 Fehlende Werte in R\nIm Folgenden untersuchen wir, wie fehlende Werte in R dargestellt und bewertet werden, sowie einige angrenzende Werte und Funktionen.\n\nNA\nIn R werden fehlende Werte durch einen reservierten (speziellen) Wert dargestellt - NA. Beachte, dass dieser typisiert wird ohne Anführungszeichen. “NA” ist anders und ist ein normaler Zeichenwert (auch ein Beatles-Text aus dem Song Hey Jude).\nIn deinen Daten gibt es vielleicht noch andere Möglichkeiten, fehlende Angaben darzustellen, z. B. “99”, “Missing” oder “Unknown” - vielleicht hast du sogar einen leeren Zeichenwert ““, der”leer” aussieht, oder ein einzelnes Leerzeichen ” “. Sei dir dessen bewusst und überlege, ob du sie umwandeln in NA während des Imports oder während der Datenbereinigung mit na_if().\nBei der Datenbereinigung kannst du auch in die andere Richtung konvertieren - indem du alle NA zu “Missing” oder ähnlichem mit replace_na() oder mit fct_explicit_na() für Faktoren.\n\n\nVersionen von NA\nDie meiste Zeit, NA für einen fehlenden Wert und alles funktioniert gut. Unter bestimmten Umständen kann es jedoch erforderlich sein, dass du Abweichungen von NA spezifisch für eine Objektklasse (Zeichen, numerisch, etc.). Das kommt zwar selten vor, aber du solltest dir dessen bewusst sein.\nDas typische Szenario dafür ist die Erstellung einer neuen Spalte mit der Option dplyr Funktion case_when(). Wie in der Beschreibung der Reinigung von Daten und Kernfunktionen beschrieben, wertet diese Funktion jede Zeile im Datenrahmen aus, prüft, ob die Zeile bestimmte logische Kriterien erfüllt (rechte Seite des Codes), und weist den richtigen neuen Wert zu (linke Seite des Codes). Wichtig: Alle Werte auf der rechten Seite müssen der gleichen Klasse ange.\n\nlinelist &lt;- linelist %&gt;% \n  \n  # Create new \"age_years\" column from \"age\" column\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,       # if age is given in years, assign original value\n    age_unit == \"months\" ~ age/12,    # if age is given in months, divide by 12\n    is.na(age_unit)      ~ age,       # if age UNIT is missing, assume years\n    TRUE                 ~ NA_real_)) # any other circumstance, assign missing\n\nWenn du willst NA auf der rechten Seite haben willst, musst du eventuell eine der speziellen NA Optionen angeben, die unten aufgeführt sind. Wenn die anderen Werte auf der rechten Seite Zeichen sind, solltest du stattdessen “Missing” verwenden oder andernfalls NA_character_. Wenn sie alle numerisch sind, verwende NA_real_. Wenn es sich um Daten oder logische Werte handelt, kannst du NA.\n\nNA - Verwendung für Daten oder logisches TRUE/FALSE\nNA_character_ - Verwendung für Zeichen\nNA_real_ - für numerische Zeichen verwenden\n\nAuch hier ist es unwahrscheinlich, dass du auf diese Variationen stoßen wirst es sei denn, du verwendest case_when() um eine neue Spalte zu erstellen. Siehe die R-Dokumentation über NA für weitere Informationen.\n\n\nNULL\nNULL ist ein weiterer reservierter Wert in R. Er ist die logische Darstellung einer Aussage, die weder wahr noch falsch ist. Er wird von Ausdrücken oder Funktionen zurückgegeben, deren Werte undefiniert sind. Im Allgemeinen solltest du NULL nicht als Wert zuweisen, es sei denn, du schreibst Funktionen oder vielleicht eine [Shiny-App][Dashboards mit Shiny] zurückgeben NULL in bestimmten Szenarien.\nDie Nullstellung kann wie folgt bewertet werden is.null() und die Umrechnung kann mit as.null().\nSiehe dies Blogbeitrag über den Unterschied zwischen NULL und NA.\n\n\nNaN\nUnmögliche Werte werden durch den speziellen Wert NaN. Ein Beispiel dafür ist, wenn du R zwingst, 0 durch 0 zu dividieren. Du kannst dies mit is.nan(). Du kannst auch auf ergänzende Funktionen stoßen, z. B. is.infinite() und is.finite().\n\n\nInf\nInf steht für einen unendlichen Wert, zum Beispiel, wenn du eine Zahl durch 0 teilst.\nEin Beispiel dafür, wie sich das auf deine Arbeit auswirken könnte: Nehmen wir an, du hast einen Vektor/Spalte z die diese Werte enthält: z &lt;- c(1, 22, NA, Inf, NaN, 5)\nWenn du die max() auf die Spalte anwenden willst, um den höchsten Wert zu finden, kannst du die na.rm = TRUE verwenden, um die NA aus der Berechnung zu entfernen, aber die Inf und NaN bleiben und Inf zurückgegeben werden. Um dies zu lösen, kannst du Klammern verwenden [ ] und is.finite() verwenden, um eine Untermenge zu bilden, so dass nur endliche Werte für die Berechnung verwendet werden: max(z[is.finite(z)]).\n\nz &lt;- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # returns NA\nmax(z, na.rm=T)                  # returns Inf\nmax(z[is.finite(z)])             # returns 22\n\n\n\nBeispiele\n\n\n\nR-Befehl\nErgebnis\n\n\n\n\n5 / 0\nInf\n\n\n0 / 0\nNaN\n\n\n5 / NA\nNA\n\n\n`5 / Inf\n0\n\n\nNA - 5\nNA\n\n\nInf / 5\nInf\n\n\nclass(NA)\n“logisch”\n\n\nclass(NaN)\n“numerisch”\n\n\nclass(Inf)\n“numerisch”\n\n\nclass(NULL)\n“NULL”\n\n\n\n“NAs durch Zwang eingeführt” ist eine häufige Warnmeldung. Das kann passieren, wenn du versuchst, eine unzulässige Konvertierung vorzunehmen, z. B. wenn du einen Zeichenwert in einen Vektor einfügst, der ansonsten numerisch ist.\n\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))\n\nWarning: NAs introduced by coercion\n\n\n[1] 10 20 NA 40\n\n\nNULL wird in einem Vektor ignoriert.\n\nmy_vector &lt;- c(25, NA, 10, NULL)  # define\nmy_vector                         # print\n\n[1] 25 NA 10\n\n\nDie Abweichung von einer Zahl ergibt NA.\n\nvar(22)\n\n[1] NA",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html#nützliche-funktionen",
    "href": "new_pages/missing_data.de.html#nützliche-funktionen",
    "title": "20  Fehlende Daten",
    "section": "20.3 Nützliche Funktionen",
    "text": "20.3 Nützliche Funktionen\nDie folgenden Funktionen sind nützlich Basis R-Funktionen, wenn du fehlende Werte auswertest oder behandelst:\n\nis.na() und !is.na()\nVerwende is.na()um fehlende Werte zu identifizieren, oder verwenden Sie das Gegenteil (mit ! vorangestellt), um nicht fehlende Werte zu identifizieren. Diese beiden geben einen logischen Wert zurück (TRUE oder FALSE). Denke daran, dass du sum() den resultierenden Vektor zum Zählen der Anzahl TRUE z.B.. sum(is.na(linelist$date_outcome)).\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n\n!is.na(my_vector)\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\nsum(is.na(my_vector))\n\n[1] 2\n\n\n\n\nna.omit()\nWenn diese Funktion auf einen Datenrahmen angewendet wird, entfernt sie Zeilen mit jeder fehlenden Werten. Sie ist auch von Basis R.\nWenn sie auf einen Vektor angewendet wird, entfernt sie NA Werte aus dem Vektor, auf den er angewandt wird. Zum Beispiel:\n\nna.omit(my_vector)\n\n[1]  1  4 56  5 22\nattr(,\"na.action\")\n[1] 4 6\nattr(,\"class\")\n[1] \"omit\"\n\n\n\n\ndrop_na()\nDies ist ein tidyrFunktion, die nützlich ist in einer [Pipeline zur Datenbereinigung][Datenbereinigung und Kernfunktionen]. Wenn sie mit leeren Klammern ausgeführt wird, entfernt sie Zeilen mitjeder fehlenden Werten. Wenn Spaltennamen in den Klammern angegeben werden, werden Zeilen mit fehlenden Werten in diesen Spalten gelöscht. Du kannst auch die “tidyselect”-Syntax verwenden, um die Spalten anzugeben.\n\nlinelist %&gt;% \n  drop_na(case_id, date_onset, age) # drops rows missing values for any of these columns\n\n\n\nna.rm = TRUE\nWenn du eine mathematische Funktion ausführst, wie z.B. max(), min(), sum() oder mean(), wenn es welche gibt NA Werte vorhanden sind, ist der zurückgegebene Wert NA. Dieses Standardverhalten ist beabsichtigt, damit du gewarnt wirst, wenn irgendwelche Daten fehlen.\nDu kannst dies vermeiden, indem du fehlende Werte aus der Berechnung entfernst. Dazu fügst du das Argument na.rm = TRUE (“na.rm” steht für “remove NA”).\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     \n\n[1] NA\n\nmean(my_vector, na.rm = TRUE)\n\n[1] 17.6",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html#missingness-in-einem-datenrahmen-bewerten",
    "href": "new_pages/missing_data.de.html#missingness-in-einem-datenrahmen-bewerten",
    "title": "20  Fehlende Daten",
    "section": "20.4 Missingness in einem Datenrahmen bewerten",
    "text": "20.4 Missingness in einem Datenrahmen bewerten\nDu kannst das Paket verwenden naniar verwenden, um Missingness im Datenrahmen zu bewerten und zu visualisieren linelist.\n\n# install and/or load package\npacman::p_load(naniar)\n\n\nQuantifizierung der Lückenhaftigkeit\nUm den Prozentsatz aller fehlenden Werte zu ermitteln, verwende pct_miss(). Verwende n_miss() um die Anzahl der fehlenden Werte zu ermitteln.\n\n# percent of ALL data frame values that are missing\npct_miss(linelist)\n\n[1] 6.688745\n\n\nDie beiden folgenden Funktionen geben den prozentualen Anteil der Zeilen zurück, in denen ein Wert fehlt bzw. die vollständig ausgefüllt sind. Denke daran, dass NA fehlend bedeutet, und dass ``““or” “` nicht als fehlend gezählt wird.\n\n# Percent of rows with any value missing\npct_miss_case(linelist)   # use n_complete() for counts\n\n[1] 69.12364\n\n\n\n# Percent of rows that are complete (no values missing)  \npct_complete_case(linelist) # use n_complete() for counts\n\n[1] 30.87636\n\n\n\n\nFehlende Angaben visualisieren\nDie gg_miss_var() Funktion zeigt dir die Anzahl (oder %) der fehlenden Werte in jeder Spalte an. Ein paar Feinheiten:\n\nDu kannst dem Argument einen Spaltennamen (nicht in Anführungszeichen) hinzufügen facet = um die Darstellung nach Gruppen zu sehen\nStandardmäßig werden Zählungen anstelle von Prozenten angezeigt, ändere dies mit show_pct = TRUE\nDu kannst Achsen- und Titelbeschriftungen wie bei einer normalen ggplot() mit + labs(...)\n\n\ngg_miss_var(linelist, show_pct = TRUE)\n\n\n\n\n\n\n\n\nHier werden die Daten gepiped %&gt;% in die Funktion geleitet. Die facet = Argument wird auch zum Aufteilen der Daten verwendet.\n\nlinelist %&gt;% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n\n\n\n\n\n\n\n\nDu kannst vis_miss() kannst du den Datenrahmen als Heatmap visualisieren, die anzeigt, ob ein Wert fehlt oder nicht. Du kannst auch select() bestimmte Spalten aus dem Datenrahmen entfernen und nur diese Spalten an die Funktion weitergeben.\n\n# Heatplot of missingness across the entire data frame  \nvis_miss(linelist)\n\n\n\n\n\n\n\n\n\n\nMissingness-Beziehungen erforschen und visualisieren\nWie visualisierst du etwas, das nicht da ist??? Standardmäßig, ggplot() werden Punkte mit fehlenden Werten aus den Diagrammen entfernt.\nnaniar bietet eine Lösung über geom_miss_point(). Wenn du ein Streudiagramm mit zwei Spalten erstellst, werden Datensätze, bei denen einer der Werte fehlt und der andere Wert vorhanden ist, angezeigt, indem die fehlenden Werte auf einen Wert gesetzt werden, der 10 % niedriger ist als der niedrigste Wert in der Spalte, und indem sie farblich hervorgehoben werden.\nIm folgenden Streudiagramm sind die roten Punkte Datensätze, bei denen der Wert für eine Spalte vorhanden ist, aber der Wert für die andere Spalte fehlt. So kannst du die Verteilung der fehlenden Werte im Verhältnis zu den nicht fehlenden Werten sehen.\n\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\n\n\n\n\n\n\n\n\nSo bewertest du fehlende Werte im Datenrahmen nach einer anderen Spalte geschichtet betrachten gg_miss_fct() die eine Heatmap der prozentualen Missingness im Datenrahmen liefert nach einem Faktor/einer kategorischen Spalte (oder einem Datum):\n\ngg_miss_fct(linelist, age_cat5)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat5 = (function (x) ...`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\nℹ The deprecated feature was likely used in the naniar package.\n  Please report the issue at &lt;https://github.com/njtierney/naniar/issues&gt;.\n\n\n\n\n\n\n\n\n\nDiese Funktion kann auch mit einer Datumsspalte verwendet werden, um zu sehen, wie sich die Fehlzeiten im Laufe der Zeit verändert haben:\n\ngg_miss_fct(linelist, date_onset)\n\nWarning: Removed 29 rows containing missing values (`geom_tile()`).\n\n\n\n\n\n\n\n\n\n\n\n“Schatten”-Spalten\nEine weitere Möglichkeit, fehlende Werte in einer Spalte durch Werte in einer zweiten Spalte zu visualisieren, ist die Verwendung des “Schattens”, der naniar erstellen kann. bind_shadow() erstellt eine Binärdatei NA/nicht NA Spalte für jede bestehende Spalte und bindet alle diese neuen Spalten mit dem Anhang “_NA” an den ursprünglichen Datensatz. Dadurch verdoppelt sich die Anzahl der Spalten - siehe unten:\n\nshadowed_linelist &lt;- linelist %&gt;% \n  bind_shadow()\n\nnames(shadowed_linelist)\n\n [1] \"case_id\"                 \"generation\"             \n [3] \"date_infection\"          \"date_onset\"             \n [5] \"date_hospitalisation\"    \"date_outcome\"           \n [7] \"outcome\"                 \"gender\"                 \n [9] \"age\"                     \"age_unit\"               \n[11] \"age_years\"               \"age_cat\"                \n[13] \"age_cat5\"                \"hospital\"               \n[15] \"lon\"                     \"lat\"                    \n[17] \"infector\"                \"source\"                 \n[19] \"wt_kg\"                   \"ht_cm\"                  \n[21] \"ct_blood\"                \"fever\"                  \n[23] \"chills\"                  \"cough\"                  \n[25] \"aches\"                   \"vomit\"                  \n[27] \"temp\"                    \"time_admission\"         \n[29] \"bmi\"                     \"days_onset_hosp\"        \n[31] \"case_id_NA\"              \"generation_NA\"          \n[33] \"date_infection_NA\"       \"date_onset_NA\"          \n[35] \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n[37] \"outcome_NA\"              \"gender_NA\"              \n[39] \"age_NA\"                  \"age_unit_NA\"            \n[41] \"age_years_NA\"            \"age_cat_NA\"             \n[43] \"age_cat5_NA\"             \"hospital_NA\"            \n[45] \"lon_NA\"                  \"lat_NA\"                 \n[47] \"infector_NA\"             \"source_NA\"              \n[49] \"wt_kg_NA\"                \"ht_cm_NA\"               \n[51] \"ct_blood_NA\"             \"fever_NA\"               \n[53] \"chills_NA\"               \"cough_NA\"               \n[55] \"aches_NA\"                \"vomit_NA\"               \n[57] \"temp_NA\"                 \"time_admission_NA\"      \n[59] \"bmi_NA\"                  \"days_onset_hosp_NA\"     \n\n\nDiese “Schattenspalten” können verwendet werden, um den Anteil der fehlenden Werte in einer beliebigen anderen Spalte darzustellen.\nDie folgende Grafik zeigt zum Beispiel den Anteil der fehlenden Datensätze days_onset_hosp (Anzahl der Tage vom Auftreten der Symptome bis zum Krankenhausaufenthalt) nach dem Wert des Datensatzes in date_hospitalisation. Im Wesentlichen stellst du die Dichte der Spalte auf der x-Achse dar, schichtest aber die Ergebnisse (color =) nach einer Schattenspalte von Interesse. Diese Analyse funktioniert am besten, wenn die x-Achse eine numerische oder eine Datumsspalte ist.\n\nggplot(data = shadowed_linelist,          # data frame with shadow columns\n  mapping = aes(x = date_hospitalisation, # numeric or date column\n                colour = age_years_NA)) + # shadow column of interest\n  geom_density()                          # plots the density curves\n\n\n\n\n\n\n\n\nDu kannst diese “Schattenspalten” auch verwenden, um eine statistische Zusammenfassung zu schichten, wie unten gezeigt:\n\nlinelist %&gt;%\n  bind_shadow() %&gt;%                # create the shows cols\n  group_by(date_outcome_NA) %&gt;%    # shadow col for stratifying\n  summarise(across(\n    .cols = age_years,             # variable of interest for calculations\n    .fns = list(\"mean\" = mean,     # stats to calculate\n                \"sd\" = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # other arguments for the stat calculations\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `date_outcome_NA = !NA`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 2 × 6\n  date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min\n  &lt;fct&gt;                    &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 !NA                       16.0         12.6          158.             0\n2 NA                        16.2         12.9          167.             0\n# ℹ 1 more variable: age_years_max &lt;dbl&gt;\n\n\nEine alternative Möglichkeit, den Anteil der fehlenden Werte einer Spalte im Zeitverlauf darzustellen, findest du unten. Sie tut nicht mit naniar. Dieses Beispiel zeigt den Prozentsatz der wöchentlichen Beobachtungen, die fehlen).\n\nAggregiere die Daten zu einer sinnvollen Zeiteinheit (Tage, Wochen usw.) und fasse den Anteil der Beobachtungen mit NA (und alle anderen Werte von Interesse)\nZeichne den Anteil der fehlenden Beobachtungen als Linie mit ggplot()\n\nIm Folgenden fügen wir der Linienliste eine neue Spalte für die Woche hinzu, gruppieren die Daten nach Woche und berechnen dann den Prozentsatz der Datensätze dieser Woche, in denen der Wert fehlt. (Hinweis: Wenn du den Prozentsatz von 7 Tagen ermitteln willst, sieht die Berechnung etwas anders aus).\n\noutcome_missing &lt;- linelist %&gt;%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %&gt;%   # create new week column\n  group_by(week) %&gt;%                                             # group the rows by week\n  summarise(                                                     # summarize each week\n    n_obs = n(),                                                  # number of records\n    \n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),        # number of records missing the value\n    outcome_p_miss  = outcome_missing / n_obs,                    # proportion of records missing the value\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),           # number of records as dead\n    outcome_p_dead  = outcome_dead / n_obs) %&gt;%                   # proportion of records as dead\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %&gt;%         # pivot all columns except week, to long format for ggplot\n  filter(stringr::str_detect(statistic, \"_p_\"))                  # keep only the proportion values\n\nDann stellen wir den Anteil der fehlenden Werte als Linie nach Woche dar. Die [ggplot Grundlagen] Seite, falls du mit dem ggplot-Programm nicht vertraut bist .ggplot2 Plot-Paket vertraut bist.\n\nggplot(data = outcome_missing)+\n    geom_line(\n      mapping = aes(x = week, y = value, group = statistic, color = statistic),\n      size = 2,\n      stat = \"identity\")+\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\"))+\n    scale_y_continuous(breaks = c(seq(0,1,0.1)))+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html#daten-mit-fehlenden-werten-verwenden",
    "href": "new_pages/missing_data.de.html#daten-mit-fehlenden-werten-verwenden",
    "title": "20  Fehlende Daten",
    "section": "20.5 Daten mit fehlenden Werten verwenden",
    "text": "20.5 Daten mit fehlenden Werten verwenden\n\nZeilen mit fehlenden Werten herausfiltern\nUm Zeilen mit fehlenden Werten schnell zu entfernen, verwendest du die dplyr Funktion drop_na().\nDas Original linelist hat nrow(linelist) Zeilen. Die angepasste Anzahl der Zeilen wird unten angezeigt:\n\nlinelist %&gt;% \n  drop_na() %&gt;%     # remove rows with ANY missing values\n  nrow()\n\n[1] 1818\n\n\nDu kannst festlegen, dass Zeilen, die in bestimmten Spalten fehlen, weggelassen werden:\n\nlinelist %&gt;% \n  drop_na(date_onset) %&gt;% # remove rows missing date_onset \n  nrow()\n\n[1] 5632\n\n\nDu kannst die Spalten nacheinander auflisten, oder du kannst “tidyselect”-Hilfsfunktionen:\n\nlinelist %&gt;% \n  drop_na(contains(\"date\")) %&gt;% # remove rows missing values in any \"date\" column \n  nrow()\n\n[1] 3029\n\n\n\n\n\nHandhabung NA in ggplot()\nOft ist es sinnvoll, die Anzahl der ausgeschlossenen Werte in einer Beschriftung anzugeben. Nachfolgend ein Beispiel:\nIn ggplot() kannst du hinzufügen labs() und darin eine caption =. In der Beschriftung kannst du str_glue() von stringr Paket, um Werte dynamisch in einen Satz einzufügen, damit sie sich an die Daten anpassen. Ein Beispiel findest du unten:\n\nBeachten Sie die Verwendung von \\n für eine neue Zeile.\nWenn mehrere Spalten dazu beitragen, dass Werte nicht dargestellt werden (z. B. Alter oder Geschlecht, wenn diese in der Darstellung berücksichtigt werden), musst du auch nach diesen Spalten filtern, um die nicht angezeigte Zahl korrekt zu berechnen.\n\n\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} from Central Hospital;\n  {nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown.\"))  \n\nManchmal ist es einfacher, die Zeichenkette als Objekt in Befehlen zu speichern, bevor die ggplot() Befehls zu speichern und einfach auf das benannte String-Objekt innerhalb des str_glue().\n\n\n\nNA in Faktoren\nWenn deine Spalte von Interesse ein Faktor ist, verwende fct_explicit_na() aus der forcats Paket zu konvertieren NAWerte in einen Zeichenwert umzuwandeln. Weitere Details findest du in der [Faktoren] Seite. Standardmäßig ist der neue Wert “(Missing)”, aber das kann über die Optionna_level = Argument angepasst werden.\n\npacman::p_load(forcats)   # load package\n\nlinelist &lt;- linelist %&gt;% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)\n\n[1] \"f\"       \"m\"       \"Missing\"",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html#anrechnung",
    "href": "new_pages/missing_data.de.html#anrechnung",
    "title": "20  Fehlende Daten",
    "section": "20.6 Anrechnung",
    "text": "20.6 Anrechnung\nManchmal ist es bei der Analyse deiner Daten wichtig, “Lücken zu füllen” und fehlende Daten zu imputieren. Du kannst einen Datensatz zwar immer einfach analysieren, nachdem du alle fehlenden Werte entfernt hast, aber das kann in vielerlei Hinsicht Probleme verursachen. Hier sind zwei Beispiele:\n\nWenn du alle Beobachtungen mit fehlenden Werten oder Variablen mit einer großen Menge an fehlenden Daten entfernst, kannst du deine Aussagekraft oder deine Fähigkeit, bestimmte Analysen durchzuführen, verringern. Wie wir bereits herausgefunden haben, hat zum Beispiel nur ein kleiner Teil der Beobachtungen in unserem Linelist-Datensatz keine fehlenden Daten in allen Variablen. Würden wir den Großteil unseres Datensatzes entfernen, würden wir eine Menge Informationen verlieren! Außerdem haben die meisten unserer Variablen eine gewisse Menge an fehlenden Daten - für die meisten Analysen ist es wahrscheinlich auch nicht sinnvoll, jede Variable mit vielen fehlenden Daten herauszunehmen.\nJe nachdem, warum deine Daten fehlen, kann die Analyse nur der nicht fehlenden Daten zu verzerrten oder irreführenden Ergebnissen führen. Wie wir bereits erfahren haben, fehlen zum Beispiel bei einigen Patienten Daten darüber, ob sie wichtige Symptome wie Fieber oder Husten hatten. Es könnte aber auch sein, dass diese Informationen bei Personen, die offensichtlich nicht sehr krank waren, nicht erfasst wurden. In diesem Fall würden wir einige der gesündesten Menschen in unserem Datensatz ausschließen, wenn wir diese Beobachtungen einfach weglassen würden, und das könnte die Ergebnisse verfälschen.\n\nEs ist wichtig, nicht nur zu sehen, wie viele Daten fehlen, sondern auch darüber nachzudenken, warum sie fehlen könnten. Auf diese Weise kannst du entscheiden, wie wichtig es ist, fehlende Daten zu imputieren, und welche Methode zur Imputation fehlender Daten in deiner Situation am besten geeignet ist.\n\nArten von fehlenden Daten\nEs gibt drei allgemeine Arten von fehlenden Daten:\n\nVöllig zufällig fehlende D(MCAR). Das bedeutet, dass es keinen Zusammenhang zwischen der Wahrscheinlichkeit fehlender Daten und einer der anderen Variablen in deinen Daten gibt. Die Wahrscheinlichkeit, dass Daten fehlen, ist in allen Fällen gleich hoch. Wenn du aber Grund zu der Annahme hast, dass deine Daten MCAR sind, wird die Analyse nur der nicht fehlenden Daten ohne Imputation deine Ergebnisse nicht verfälschen (auch wenn du vielleicht etwas an Aussagekraft verlierst). [TODO: Erörtere statistische Tests für MCAR]\nZufälliges Fehlen (MAR). Dieser Name ist eigentlich etwas irreführend, denn MAR bedeutet, dass deine Daten auf eine systematische, vorhersehbare Weise fehlen, die auf den anderen Informationen basiert, die du hast. Zum Beispiel könnte es sein, dass jede Beobachtung in unserem Datensatz mit einem fehlenden Wert für Fieber gar nicht aufgezeichnet wurde, weil bei jedem Patienten mit Schüttelfrost und Schmerzen einfach davon ausgegangen wurde, dass er Fieber hat und seine Temperatur nie gemessen wurde. Wenn das stimmt, könnten wir leicht vorhersagen, dass jede fehlende Beobachtung mit Schüttelfrost und Schmerzen auch Fieber hat, und diese Information nutzen, um unsere fehlenden Daten zu ergänzen. In der Praxis ist das eher ein Spektrum. Wenn ein Patient sowohl Schüttelfrost als auch Schmerzen hat, ist die Wahrscheinlichkeit höher, dass er auch Fieber hat, wenn er seine Temperatur nicht messen lässt, aber nicht immer. Das ist immer noch vorhersehbar, auch wenn es nicht perfekt vorhersehbar ist. Dies ist eine häufige Art von fehlenden Daten\nNicht zufällige fehlende (MNAR). Manchmal wird dies auch als Nicht zufällig fehlend (NMAR). Dabei wird davon ausgegangen, dass die Wahrscheinlichkeit, dass ein Wert fehlt, NICHT systematisch oder anhand der anderen uns vorliegenden Informationen vorhersehbar ist, sondern dass er auch nicht zufällig fehlt. In diesem Fall fehlen die Daten aus unbekannten Gründen oder aus Gründen, über die du keine Informationen hast. In unserem Datensatz fehlen zum Beispiel Informationen über das Alter, weil einige sehr alte Patienten entweder nicht wissen oder sich weigern, ihr Alter anzugeben. In diesem Fall hängen die fehlenden Daten zum Alter mit dem Wert selbst zusammen (und sind daher nicht zufällig) und sind anhand der anderen Informationen, die wir haben, nicht vorhersehbar. MNAR ist komplex und oft ist es am besten, mehr Daten oder Informationen darüber zu sammeln, warum die Daten fehlen, anstatt zu versuchen, sie zu unterstellen.\n\nIm Allgemeinen ist die Imputation von MCAR-Daten oft recht einfach, während MNAR sehr schwierig, wenn nicht sogar unmöglich ist. Viele der gängigen Methoden zur Imputation von Daten gehen von MAR aus.\n\n\nNützliche Pakete\nEinige nützliche Pakete für die Imputation fehlender Daten sind Mmisc, missForest (das Random Forests zur Imputation fehlender Daten verwendet) und mice (Multivariate Imputation durch verkettete Gleichungen). In diesem Abschnitt werden wir nur das mice-Paket verwenden, das eine Vielzahl von Techniken implementiert. Der Betreuer des mice-Pakets hat ein Online-Buch über die Imputation fehlender Daten veröffentlicht, das hier ausführlicher beschrieben wird (https://stefvanbuuren.name/fimd/).\nHier ist der Code zum Laden des Mäusepakets:\n\npacman::p_load(mice)\n\n\n\nMittelwert-Imputation\nWenn du eine einfache Analyse durchführst oder gute Gründe hast, von MCAR auszugehen, kannst du fehlende numerische Werte einfach auf den Mittelwert der Variable setzen. Vielleicht können wir davon ausgehen, dass die fehlenden Temperaturmessungen in unserem Datensatz entweder MCAR oder ganz normale Werte waren. Hier ist der Code, um eine neue Variable zu erstellen, die die fehlenden Temperaturwerte durch den mittleren Temperaturwert in unserem Datensatz ersetzt. In vielen Situationen kann das Ersetzen von Daten durch den Mittelwert jedoch zu Verzerrungen führen, sei also vorsichtig.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\n\nDu könntest auch einen ähnlichen Prozess durchführen, um kategoriale Daten durch einen bestimmten Wert zu ersetzen. Stell dir vor, du wüsstest, dass alle Beobachtungen mit einem fehlenden Wert für das Ergebnis (das “Tod” oder “Genesung” sein kann) tatsächlich Personen sind, die gestorben sind (Hinweis: Das trifft für diesen Datensatz nicht zu):\n\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))\n\n\n\nRegressions-Imputation\nEine etwas fortschrittlichere Methode besteht darin, eine Art statistisches Modell zu verwenden, um vorherzusagen, wie ein fehlender Wert wahrscheinlich sein wird, und ihn durch den vorhergesagten Wert zu ersetzen. Hier ist ein Beispiel für die Erstellung von Vorhersagewerten für alle Beobachtungen, bei denen die Temperatur fehlt, das Alter und das Fieber aber nicht, mithilfe einer einfachen linearen Regression, die den Fieberstatus und das Alter in Jahren als Prädiktoren verwendet. In der Praxis wirst du ein besseres Modell als diesen einfachen Ansatz verwenden wollen.\n\nsimple_temperature_model_fit &lt;- lm(temp ~ fever + age_years, data = linelist)\n\n#using our simple temperature model to predict values just for the observations where temp is missing\npredictions_for_missing_temps &lt;- predict(simple_temperature_model_fit,\n                                        newdata = linelist %&gt;% filter(is.na(temp))) \n\nOder du verwendest denselben Modellierungsansatz mit dem Mäusepaket, um imputierte Werte für die fehlenden Temperaturbeobachtungen zu erstellen:\n\nmodel_dataset &lt;- linelist %&gt;%\n  select(temp, fever, age_years)  \n\ntemp_imputed &lt;- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = F)\n\nWarning: Number of logged events: 1\n\ntemp_imputed_values &lt;- temp_imputed$imp$temp\n\nDies ist derselbe Ansatz wie bei einigen fortgeschritteneren Methoden, z. B. bei der Verwendung des missForest-Pakets, um fehlende Daten durch vorhergesagte Werte zu ersetzen. In diesem Fall ist das Vorhersagemodell ein Random Forest anstelle einer linearen Regression. Du kannst auch andere Arten von Modellen verwenden. Auch wenn dieser Ansatz unter MCAR gut funktioniert, solltest du ein bisschen vorsichtig sein, wenn du glaubst, dass MAR oder MNAR deine Situation besser beschreibt. Die Qualität deiner Imputation hängt davon ab, wie gut dein Vorhersagemodell ist, und selbst bei einem sehr guten Modell kann die Variabilität deiner imputierten Daten unterschätzt werden.\n\n\nLOCF und BOCF\nLast observation carried forward (LOCF) und baseline observation carried forward (BOCF) sind Imputationsmethoden für Zeitreihen/Längsschnittdaten. Die Idee ist, den letzten beobachteten Wert als Ersatz für die fehlenden Daten zu nehmen. Wenn mehrere Werte nacheinander fehlen, sucht die Methode nach dem letzten beobachteten Wert.\nDie fill() Funktion aus dem tidyr Paket kann sowohl für die LOCF- als auch für die BOCF-Imputation verwendet werden (andere Pakete wie HMISC, zoo, und daten.tabelle enthalten ebenfalls Methoden, um dies zu tun). Zum Anzeigen der fill() Syntax zu zeigen, erstellen wir einen einfachen Zeitreihendatensatz, der die Anzahl der Krankheitsfälle für jedes Quartal der Jahre 2000 und 2001 enthält. Allerdings fehlen die Jahreswerte für die folgenden Quartale nach Q1, so dass wir sie imputieren müssen. Die fill()Kreuzung wird auch in der [Daten spiegeln] Seite.\n\n#creating our simple dataset\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n#imputing the missing year values:\ndisease %&gt;% fill(year)\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nHinweis: Stelle sicher, dass deine Daten richtig sortiert sind, bevor du die fill() Funktion verwenden. fill() füllt standardmäßig “nach unten” aus, aber du kannst auch Werte in andere Richtungen unterstellen, indem du die .direction Parameter. Wir können einen ähnlichen Datensatz erstellen, bei dem der Jahreswert nur am Ende des Jahres erfasst wird und für frühere Quartale fehlt:\n\n#creating our slightly different dataset\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n#imputing the missing year values in the \"up\" direction:\ndisease %&gt;% fill(year, .direction = \"up\")\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nIn diesem Beispiel sind LOCF und BOCF eindeutig das Richtige, aber in komplizierteren Situationen kann es schwieriger sein, zu entscheiden, ob diese Methoden geeignet sind. Es kann zum Beispiel sein, dass bei einem Krankenhauspatienten nach dem ersten Tag Laborwerte fehlen. Manchmal kann das bedeuten, dass sich die Laborwerte nicht verändert haben… es kann aber auch bedeuten, dass der Patient sich erholt hat und seine Werte nach dem ersten Tag ganz anders aussehen! Verwende diese Methoden mit Vorsicht.\n\n\nMehrfache Imputation\nDas bereits erwähnte Online-Buch des Autors des Mäusepakets (https://stefvanbuuren.name/fimd/) enthält eine ausführliche Erklärung der multiplen Imputation und warum du sie verwenden solltest. Hier findest du jedoch eine grundlegende Erklärung der Methode:\nBei der multiplen Imputation erstellst du mehrere Datensätze, bei denen die fehlenden Werte mit plausiblen Datenwerten imputiert werden (je nach deinen Forschungsdaten möchtest du vielleicht mehr oder weniger dieser imputierten Datensätze erstellen, aber das Mäusepaket setzt die Standardanzahl auf 5). Der Unterschied besteht darin, dass jeder unterstellte Wert aus einer geschätzten Verteilung entnommen wird (er enthält also einen gewissen Zufallswert). Das hat zur Folge, dass jeder dieser Datensätze leicht unterschiedliche imputierte Werte hat (die nicht fehlenden Daten sind jedoch in jedem dieser imputierten Datensätze gleich). Du verwendest für die Imputation in jedem dieser neuen Datensätze eine Art Vorhersagemodell (mice bietet viele Optionen für Vorhersagemethoden, darunter Prädiktives Mittelwert-Matching, logistische Regression und Zufallsforst), aber das Mäusepaket kann sich um viele der Modellierungsdetails kümmern.\nSobald du diese neuen imputierten Datensätze erstellt hast, kannst du das statistische Modell oder die Analyse, die du für jeden dieser neuen imputierten Datensätze geplant hast, anwenden und die Ergebnisse dieser Modelle zusammenführen. Das funktioniert sehr gut, um Verzerrungen sowohl in MCAR- als auch in vielen MAR-Einstellungen zu reduzieren und führt oft zu genaueren Standardfehlerschätzungen.\nHier ist ein Beispiel für die Anwendung des Multiple-Imputation-Verfahrens zur Vorhersage der Temperatur in unserem Linelist-Datensatz anhand von Alter und Fieberstatus (unser vereinfachter model_dataset von oben):\n\n# imputing missing values for all variables in our model_dataset, and creating 10 new imputed datasets\nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) \n\nWarning: Number of logged events: 1\n\nmodel_fit &lt;- with(multiple_imputation, lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))\n\n         term     estimate    std.error    statistic        df       p.value\n1 (Intercept) 3.703143e+01 0.0270863456 1.367162e+03  26.83673  1.583113e-66\n2   age_years 3.867829e-05 0.0006090202 6.350905e-02 171.44363  9.494351e-01\n3    feveryes 1.978044e+00 0.0193587115 1.021785e+02 176.51325 5.666771e-159\n\n\nHier haben wir die Standardmethode der Mäuse für die Imputation verwendet, nämlich Predictive Mean Matching. Anschließend haben wir diese imputierten Datensätze verwendet, um die Ergebnisse der einfachen linearen Regressionen für jeden dieser Datensätze separat zu schätzen und dann zusammenzuführen. Es gibt viele Details, die wir nicht erwähnt haben, und viele Einstellungen, die du während des Multiple-Imputation-Prozesses mit dem Mäusepaket anpassen kannst. Du wirst zum Beispiel nicht immer numerische Daten haben und vielleicht andere Imputationsmethoden verwenden müssen (du kannst das mice-Paket auch für viele andere Datentypen und Methoden verwenden). Aber für eine robustere Analyse, bei der fehlende Daten ein großes Problem darstellen, ist die Mehrfach-Imputation eine gute Lösung, die nicht immer viel mehr Arbeit macht als eine vollständige Fallanalyse.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.de.html#ressourcen",
    "href": "new_pages/missing_data.de.html#ressourcen",
    "title": "20  Fehlende Daten",
    "section": "20.7 Ressourcen",
    "text": "20.7 Ressourcen\nVignette über die naniar Paket\nGalerie der Visualisierungen fehlender Werte\nOnline Buch über Multiple Imputation in R vom Betreuer der Mäuse Pakets",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fehlende Daten</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.de.html",
    "href": "new_pages/standardization.de.html",
    "title": "21  Standardisierte Sätze",
    "section": "",
    "text": "21.1 Übersicht\nEs gibt zwei Hauptarten der Normung: die direkte und die indirekte Normung. Nehmen wir an, wir möchten die Sterblichkeitsrate nach Alter und Geschlecht für Land A und Land B standardisieren und die standardisierten Raten zwischen diesen Ländern vergleichen.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Standardisierte Sätze</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.de.html#übersicht",
    "href": "new_pages/standardization.de.html#übersicht",
    "title": "21  Standardisierte Sätze",
    "section": "",
    "text": "Für die direkte Standardisierung musst du die Anzahl der Risikobevölkerung und die Anzahl der Todesfälle für jede Alters- und Geschlechtsschicht in Land A und Land B kennen. Eine Schicht in unserem Beispiel könnten Frauen im Alter von 15 bis 44 Jahren sein.\nFür die indirekte Standardisierung musst du nur die Gesamtzahl der Todesfälle und die Alters- und Geschlechtsstruktur jedes Landes kennen. Diese Option ist daher praktikabel, wenn alters- und geschlechtsspezifische Sterberaten oder Bevölkerungszahlen nicht verfügbar sind. Die indirekte Standardisierung ist außerdem bei kleinen Zahlen pro Schicht vorzuziehen, da die Schätzungen bei der direkten Standardisierung durch erhebliche Stichprobenschwankungen beeinflusst werden würden.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Standardisierte Sätze</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.de.html#vorbereitung",
    "href": "new_pages/standardization.de.html#vorbereitung",
    "title": "21  Standardisierte Sätze",
    "section": "21.2 Vorbereitung",
    "text": "21.2 Vorbereitung\nUm zu zeigen, wie die Standardisierung durchgeführt wird, verwenden wir fiktive Bevölkerungs- und Sterbefallzahlen aus Land A und Land B, aufgeschlüsselt nach Alter (in 5-Jahres-Kategorien) und Geschlecht (weiblich, männlich). Um die Datensätze einsatzbereit zu machen, führen wir die folgenden Vorbereitungsschritte durch:\n\nPakete laden\nDatensätze laden\nVerbinde die Bevölkerungs- und Sterbedaten aus den beiden Ländern\nPivotiere länger, damit es eine Zeile pro Alters- und Geschlechtsschicht gibt\nBereinige die Referenzbevölkerung (Weltstandardbevölkerung) und verbinde sie mit den Länderdaten\n\nIn deinem Szenario könnten deine Daten in einem anderen Format vorliegen. Vielleicht sind deine Daten nach Provinz, Stadt oder einem anderen Einzugsgebiet geordnet. Vielleicht hast du eine Zeile für jeden Todesfall und Informationen über Alter und Geschlecht für jeden (oder einen großen Teil) dieser Todesfälle. In diesem Fall solltest du die Seiten über [Daten gruppieren], [Pivotierung von Daten] und [Beschreibende Tabellen] um einen Datensatz mit Ereignis- und Bevölkerungszahlen pro Alters- und Geschlechtsschicht zu erstellen.\nAußerdem brauchen wir eine Referenzbevölkerung, die Standardbevölkerung. Für die Zwecke dieser Übung verwenden wir die world_standard_population_by_sex. Die Weltstandardbevölkerung basiert auf den Bevölkerungen von 46 Ländern und wurde 1960 entwickelt. Es gibt viele “Standardbevölkerungen” - ein Beispiel ist die Website von NHS Schottland ist sehr informativ über die europäische Standardbevölkerung, die Weltstandardbevölkerung und die schottische Standardbevölkerung.\n\n\nPakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n     rio,                 # import/export data\n     here,                # locate files\n     stringr,             # cleaning characters and strings\n     frailtypack,         # needed for dsr, for frailty models\n     dsr,                 # standardise rates\n     PHEindicatormethods, # alternative for rate standardisation\n     tidyverse)           # data management and visualization\n\nVORSICHT! Wenn du eine neuere Version von R hast, wird die dsr Paket nicht direkt von CRAN heruntergeladen werden. Es ist aber immer noch im CRAN-Archiv verfügbar. Du kannst es installieren und benutzen. \nFür Nicht-Mac-Benutzer:\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n\n\n# Other solution that may work\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\n\nFür Mac-Benutzer:\n\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")\n\n\n\nBevölkerungsdaten laden\nSiehe das [Handbuch und Daten herunterladen] Seite findest du Anweisungen, wie du alle Beispieldaten im Handbuch herunterladen kannst. Du kannst die Daten der Seite Standardisierung direkt aus unserem Github-Repository in R importieren, indem du Folgendes ausführstimport() Befehle:\n\n# import demographics for country A directly from Github\nA_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n# import demographics for country B directly from Github\nB_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n# import demographics for country B directly from Github\nstandard_pop_data &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\nZuerst laden wir die demografischen Daten (Anzahl der Männer und Frauen nach 5-Jahres-Altersklassen) für die beiden Länder, die wir vergleichen wollen, “Land A” und “Land B”.\n\n# Country A\nA_demo &lt;- import(\"country_demographics.csv\")\n\n\n\n\n\n\n\n\n# Country B\nB_demo &lt;- import(\"country_demographics_2.csv\")\n\n\n\n\n\n\n\n\n\nLast Tod zählt\nPraktischerweise haben wir auch die Anzahl der Todesfälle während des interessierenden Zeitraums, aufgeschlüsselt nach Alter und Geschlecht. Die Zahlen für jedes Land befinden sich in einer separaten Datei, die unten abgebildet ist.\nTodesfälle in Land A\n\n\n\n\n\n\nTodesfälle in Land B\n\n\n\n\n\n\n\n\nSaubere Populationen und Todesfälle\nWir müssen diese Daten auf folgende Weise verbinden und umwandeln:\n\nKombiniere die Länderbevölkerungen in einem Datensatz und pivote “long”, sodass jede Alters- und Geschlechtsschicht eine Zeile ist.\nKombiniere die Sterbefälle der Länder in einem Datensatz und pivote “long”, damit jede Alters- und Geschlechtsschicht eine Zeile ist.\nVerbinde die Sterbefälle mit den Bevölkerungen\n\nZuerst kombinieren wir die Länderbevölkerungsdatensätze, machen einen längeren Pivot und führen kleinere Bereinigungen durch. Siehe die Seite über [Pivotieren von Daten] für weitere Details.\n\npop_countries &lt;- A_demo %&gt;%  # begin with country A dataset\n     bind_rows(B_demo) %&gt;%        # bind rows, because cols are identically named\n     pivot_longer(                       # pivot longer\n          cols = c(m, f),                   # columns to combine into one\n          names_to = \"Sex\",                 # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Population\") %&gt;%     # name for new column containing the numeric values pivoted\n     mutate(Sex = recode(Sex,            # re-code values for clarity\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\n\nDie kombinierten Bevölkerungsdaten sehen jetzt wie folgt aus (klicke dich durch, um die Länder A und B zu sehen):\n\n\n\n\n\n\nUnd jetzt führen wir ähnliche Operationen mit den beiden Sterbedatensätzen durch.\n\ndeaths_countries &lt;- A_deaths %&gt;%    # begin with country A deaths dataset\n     bind_rows(B_deaths) %&gt;%        # bind rows with B dataset, because cols are identically named\n     pivot_longer(                  # pivot longer\n          cols = c(Male, Female),        # column to transform into one\n          names_to = \"Sex\",              # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Deaths\") %&gt;%      # name for new column containing the numeric values pivoted\n     rename(age_cat5 = AgeCat)      # rename for clarity\n\nDie Daten zu den Todesfällen sehen jetzt so aus und enthalten Daten aus beiden Ländern:\n\n\n\n\n\n\nWir verknüpfen nun die Sterbefälle und die Bevölkerungsdaten anhand gemeinsamer Spalten Country, age_cat5, und Sex. Dies fügt die Spalte Deaths.\n\ncountry_data &lt;- pop_countries %&gt;% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\n\nWir können jetzt klassifizieren Sex, age_cat5, und Country als Faktoren und legen die Reihenfolge der Ebenen mit fct_relevel() Funktion aus dem forcatsPaket, wie auf der Seite über [Faktoren]. Beachte, dass die Klassifizierung der Faktorstufen die Daten nicht sichtbar verändert, aber diearrange() Befehl sortiert die Daten nach Land, Altersklasse und Geschlecht.\n\ncountry_data &lt;- country_data %&gt;% \n  mutate(\n    Country = fct_relevel(Country, \"A\", \"B\"),\n      \n    Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n        \n    age_cat5 = fct_relevel(\n      age_cat5,\n      \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n      \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n      \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n      \"60-64\", \"65-69\", \"70-74\",\n      \"75-79\", \"80-84\", \"85\")) %&gt;% \n          \n  arrange(Country, age_cat5, Sex)\n\n\n\n\n\n\n\nVORSICHT! Wenn du nur wenige Todesfälle pro Schicht hast, solltest du 10- oder 15-Jahres-Kategorien anstelle von 5-Jahres-Kategorien für das Alter verwenden.\n\n\nReferenzbevölkerung laden\nFür die direkte Standardisierung importieren wir schließlich die Referenzbevölkerung (weltweite “Standardbevölkerung” nach Geschlecht)\n\n# Reference population\nstandard_pop_data &lt;- import(\"world_standard_population_by_sex.csv\")\n\n\n\n\n\n\n\n\n\n\nSaubere Referenzpopulation\nDie Werte der Alterskategorien in der country_data und standard_pop_data Datenrahmen müssen angeglichen werden.\nDerzeit werden die Werte der Spalte age_cat5 aus den standard_pop_data Datenrahmens das Wort “Jahre” und “Plus”, während die Werte der Spalte country_data Datenrahmens nicht. Wir müssen dafür sorgen, dass die Werte der Alterskategorien übereinstimmen. Wir verwenden str_replace_all() aus dem stringrPaket, wie auf der Seite über [Zeichen und Zeichenketten], um diese Muster ohne Leerzeichen zu ersetzen\"\".\nAußerdem ist das Paket dsr erwartet, dass in der Standardpopulation die Spalte mit den Zählungen als \"pop\". Also benennen wir diese Spalte entsprechend um.\n\n# Remove specific string from column values\nstandard_pop_clean &lt;- standard_pop_data %&gt;%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"),   # remove \"year\"\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"),    # remove \"plus\"\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %&gt;%   # remove \" \" space\n     \n     rename(pop = WorldStandardPopulation)   # change col name to \"pop\", as this is expected by dsr package\n\nVORSICHT! Wenn du versuchst, die str_replace_all() ein Plus zu entfernen Symbol funktioniert nicht, weil es ein spezielles Symbol ist. “Entkomme dem Sonderzeichen, indem du zwei Schrägstriche voranstellst, wie in str_replace_call(column, \"\\\\+\", \"\"). \n\n\n21.2.1 Datensatz mit Standardbevölkerung erstellen {#standard_all .unnumbered}\nSchließlich wird das Paket PHEindicatormethods, detailliert unten erwartet, dass die Standardpopulationen mit den Ereignis- und Bevölkerungszahlen der Länder verknüpft werden. Wir werden also einen Datensatz erstellen all_data für diesen Zweck.\n\nall_data &lt;- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))\n\nDieser vollständige Datensatz sieht wie folgt aus:",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Standardisierte Sätze</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.de.html#dsr-paket",
    "href": "new_pages/standardization.de.html#dsr-paket",
    "title": "21  Standardisierte Sätze",
    "section": "21.3 dsr Paket",
    "text": "21.3 dsr Paket\nIm Folgenden demonstrieren wir die Berechnung und den Vergleich direkt standardisierter Raten mit dem dsr Paket. Die dsr Paket kannst du direkt standardisierte Raten berechnen und vergleichen (keine indirekt standardisierten Raten!).\nIm Abschnitt zur Datenaufbereitung haben wir separate Datensätze für die Länderzahlen und die Standardbevölkerung erstellt:\n\ndie country_data Objekt, das eine Bevölkerungstabelle mit der Anzahl der Bevölkerung und der Anzahl der Todesfälle pro Schicht und Land ist\ndie standard_pop_clean Objekt, das die Anzahl der Bevölkerung pro Schicht für unsere Referenzbevölkerung, die Weltstandardbevölkerung, enthält\n\nWir werden diese separaten Datensätze für die dsr Ansatz.\n\n\nStandardisierte Raten\nIm Folgenden berechnen wir die Raten pro Land, die direkt für Alter und Geschlecht standardisiert sind. Wir verwenden die dsr() Funktion.\nBemerkenswert - dsr() erwartet einen Datenrahmen für die Länderbevölkerung und die Anzahl der Ereignisse (Todesfälle), und ein separaten Datenrahmen mit der Referenzpopulation. Außerdem wird erwartet, dass in diesem Datensatz der Referenzbevölkerung der Name der Spalte mit der Zeiteinheit “pop” lautet (wir haben dies im Abschnitt Datenvorbereitung sichergestellt).\nEs gibt viele Argumente, die im Code unten aufgeführt sind. Besonders hervorzuheben, event = wird auf die Spalte Deaths gesetzt, und die fu = (“Follow-up”) wird auf die Spalte Population Spalte. Wir setzen die Untergruppen des Vergleichs als Spalte Country und wir standardisieren auf der Grundlage von age_cat5 und Sex. Den letzten beiden Spalten wird kein bestimmtes Argument zugewiesen. Siehe ?dsr für Details.\n\n# Calculate rates per country directly standardized for age and sex\nmortality_rate &lt;- dsr::dsr(\n     data = country_data,  # specify object containing number of deaths per stratum\n     event = Deaths,       # column containing number of deaths per stratum \n     fu = Population,      # column containing number of population per stratum\n     subgroup = Country,   # units we would like to compare\n     age_cat5,             # other columns - rates will be standardized by these\n     Sex,\n     refdata = standard_pop_clean, # reference population data frame, with column called pop\n     method = \"gamma\",      # method to calculate 95% CI\n     sig = 0.95,            # significance level\n     mp = 100000,           # we want rates per 100.000 population\n     decimals = 2)          # number of decimals)\n\n\n# Print output as nice-looking HTML table\nknitr::kable(mortality_rate) # show mortality rate before and after direct standardization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubgroup\nNumerator\nDenominator\nCrude Rate (per 1e+05)\n95% LCL (Crude)\n95% UCL (Crude)\nStd Rate (per 1e+05)\n95% LCL (Std)\n95% UCL (Std)\n\n\n\n\nA\n11344\n86790567\n13.07\n12.83\n13.31\n23.57\n23.08\n24.06\n\n\nB\n9955\n52898281\n18.82\n18.45\n19.19\n19.33\n18.46\n20.22\n\n\n\n\n\nOben sehen wir, dass Land A zwar eine niedrigere rohe Sterblichkeitsrate hat als Land B, aber eine höhere standardisierte Rate nach direkter Alters- und Geschlechtsstandardisierung.\n\n\n\nStandardisierte Ratenquoten\n\n# Calculate RR\nmortality_rr &lt;- dsr::dsrr(\n     data = country_data, # specify object containing number of deaths per stratum\n     event = Deaths,      # column containing number of deaths per stratum \n     fu = Population,     # column containing number of population per stratum\n     subgroup = Country,  # units we would like to compare\n     age_cat5,\n     Sex,                 # characteristics to which we would like to standardize \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",      # reference for comparison\n     estimate = \"ratio\",  # type of estimate\n     sig = 0.95,          # significance level\n     mp = 100000,         # we want rates per 100.000 population\n     decimals = 2)        # number of decimals\n\n# Print table\nknitr::kable(mortality_rr) \n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Ratio (RR)\n95% LCL (RR)\n95% UCL (RR)\n\n\n\n\nA\nB\n23.57\n1.22\n1.17\n1.27\n\n\nB\nB\n19.33\n1.00\n0.94\n1.06\n\n\n\n\n\nDie standardisierte Sterblichkeitsrate ist in Land A 1,22 Mal höher als in Land B (95% CI 1,17-1,27).\n\n\n\nStandardisierter Ratenunterschied\n\n# Calculate RD\nmortality_rd &lt;- dsr::dsrr(\n     data = country_data,       # specify object containing number of deaths per stratum\n     event = Deaths,            # column containing number of deaths per stratum \n     fu = Population,           # column containing number of population per stratum\n     subgroup = Country,        # units we would like to compare\n     age_cat5,                  # characteristics to which we would like to standardize\n     Sex,                        \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",            # reference for comparison\n     estimate = \"difference\",   # type of estimate\n     sig = 0.95,                # significance level\n     mp = 100000,               # we want rates per 100.000 population\n     decimals = 2)              # number of decimals\n\n# Print table\nknitr::kable(mortality_rd) \n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Difference (RD)\n95% LCL (RD)\n95% UCL (RD)\n\n\n\n\nA\nB\n23.57\n4.24\n3.24\n5.24\n\n\nB\nB\n19.33\n0.00\n-1.24\n1.24\n\n\n\n\n\nLand A hat 4,24 zusätzliche Todesfälle pro 100.000 Einwohner (95% CI 3,24-5,24) im Vergleich zu Land A.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Standardisierte Sätze</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.de.html#pheindicatormethods-paket-standard_phe",
    "href": "new_pages/standardization.de.html#pheindicatormethods-paket-standard_phe",
    "title": "21  Standardisierte Sätze",
    "section": "21.4 PHEindicatormethods Paket {#standard_phe }",
    "text": "21.4 PHEindicatormethods Paket {#standard_phe }\nEine andere Möglichkeit, standardisierte Sätze zu berechnen, ist mit dem PHE-Indikator-Methoden Paket. Mit diesem Paket kannst du sowohl direkt als auch indirekt standardisierte Raten berechnen. Wir werden beides zeigen.\nIn diesem Abschnitt wird das all_data Datenrahmen, der am Ende des Abschnitts “Vorbereitung” erstellt wurde. Dieser Datenrahmen enthält die Länderbevölkerungen, Todesfälle und die Weltstandard-Referenzbevölkerung. Du kannst ihn ansehen hier.\n\n\nDirekt standardisierte Sätze\nIm Folgenden gruppieren wir die Daten zunächst nach Ländern und übergeben sie dann an die Funktion phe_dsr() um direkt standardisierte Raten pro Land zu erhalten.\nHinweis: Die Referenzbevölkerung (Standardbevölkerung) kann als Spalte innerhalb des länderspezifischen Datenrahmens oder als separater Vektor. Wenn sie innerhalb des länderspezifischen Datenrahmens bereitgestellt werden, müssen Sie die stdpoptype = \"field\". Wenn es sich um einen Vektor handelt, musst du stdpoptype = \"vector\". Im letzteren Fall musst du sicherstellen, dass die Reihenfolge der Zeilen nach Schichten sowohl im länderspezifischen Daten-Frame als auch in der Bezugsbevölkerung gleich ist, da die Datensätze nach Position abgeglichen werden. In unserem Beispiel unten haben wir die Referenzbevölkerung als Spalte im länderspezifischen Datenrahmen angegeben.\nSiehe die Hilfe zu ?phr_dsr oder die Links im Abschnitt Referenzen für weitere Informationen.\n\n# Calculate rates per country directly standardized for age and sex\nmortality_ds_rate_phe &lt;- all_data %&gt;%\n     group_by(Country) %&gt;%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          stdpop = pop,               # standard populations for each stratum\n          stdpoptype = \"field\")       # either \"vector\" for a standalone vector or \"field\" meaning std populations are in the data  \n\n# Print table\nknitr::kable(mortality_ds_rate_phe)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\ntotal_count\ntotal_pop\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\nA\n11344\n86790567\n23.56686\n23.08107\n24.05944\n95%\ndsr per 100000\nDobson\n\n\nB\n9955\n52898281\n19.32549\n18.45516\n20.20882\n95%\ndsr per 100000\nDobson\n\n\n\n\n\n\n\n\n21.4.1 Indirekt standardisierte Sätze {#standard_indirect .unnumbered}\nFür die indirekte Standardisierung brauchst du eine Referenzpopulation mit der Anzahl der Todesfälle und der Anzahl der Bevölkerung pro Schicht. In diesem Beispiel werden wir die Raten für Land A berechnen mit Land B als Referenzbevölkerung als die standard_pop_clean die Referenzbevölkerung nicht die Anzahl der Todesfälle pro Schicht enthält.\nIm Folgenden erstellen wir zunächst die Referenzbevölkerung von Land B. Dann kombinieren wir die Mortalitäts- und Bevölkerungsdaten für Land A mit der Referenzbevölkerung und übergeben sie an die Funktion calculate_ISRate() weiter, um indirekt standardisierte Raten zu erhalten. Natürlich kannst du es auch umgekehrt machen.\nHinweis: In unserem Beispiel unten wird die Referenzpopulation als separater Datenrahmen bereitgestellt. In diesem Fall stellen wir sicher, dass x =, n =, x_ref = und n_ref = Vektoren sind alle nach denselben Werten für die Standardisierungskategorie (Stratum) geordnet wie in unserem länderspezifischen Datenrahmen, da die Datensätze nach Position abgeglichen werden.\nSiehe die Hilfe zu ?phr_isr oder die Links im Abschnitt Referenzen für weitere Informationen.\n\n# Create reference population\nrefpopCountryB &lt;- country_data %&gt;% \n  filter(Country == \"B\") \n\n# Calculate rates for country A indirectly standardized by age and sex\nmortality_is_rate_phe_A &lt;- country_data %&gt;%\n     filter(Country == \"A\") %&gt;%\n     PHEindicatormethods::calculate_ISRate(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          x_ref = refpopCountryB$Deaths,  # reference number of deaths for each stratum\n          n_ref = refpopCountryB$Population)  # reference population for each stratum\n\n# Print table\nknitr::kable(mortality_is_rate_phe_A)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nobserved\nexpected\nref_rate\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\n11344\n15847.42\n18.81914\n13.47123\n13.22446\n13.72145\n95%\nindirectly standardised rate per 100000\nByars",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Standardisierte Sätze</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.de.html#ressourcen",
    "href": "new_pages/standardization.de.html#ressourcen",
    "title": "21  Standardisierte Sätze",
    "section": "21.5 Ressourcen",
    "text": "21.5 Ressourcen\nWenn du ein weiteres reproduzierbares Beispiel sehen möchtest, das dsr finden Sie unter diese Vignette\nFür ein weiteres Beispiel mit PHEindicatormethods gehen Sie bitte zu diese Website\nSiehe die PHE-Indikator-Methoden referenz pdf datei",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Standardisierte Sätze</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.de.html",
    "href": "new_pages/moving_average.de.html",
    "title": "22  Gleitende Durchschnitte",
    "section": "",
    "text": "22.1 Vorbereitung",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Gleitende Durchschnitte</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.de.html#vorbereitung",
    "href": "new_pages/moving_average.de.html#vorbereitung",
    "title": "22  Gleitende Durchschnitte",
    "section": "",
    "text": "Pakete laden\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  tidyverse,      # for data management and viz\n  slider,         # for calculating moving averages\n  tidyquant       # for calculating moving averages within ggplot\n)\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Gleitende Durchschnitte</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.de.html#berechne-mit-schieberegler",
    "href": "new_pages/moving_average.de.html#berechne-mit-schieberegler",
    "title": "22  Gleitende Durchschnitte",
    "section": "22.2 Berechne mit Schieberegler",
    "text": "22.2 Berechne mit Schieberegler\nMit dieser Methode kannst du einen gleitenden Durchschnitt in einem Datenrahmen berechnen, bevor du ihn zeichnest.\nDie Schieber Paket bietet mehrere “Schiebefenster”-Funktionen zur Berechnung von gleitenden Durchschnitten, kumulativen Summen, gleitenden Regressionen usw. Es behandelt einen Datenrahmen als einen Vektor von Zeilen und ermöglicht so eine zeilenweise Iteration über einen Datenrahmen.\nHier sind einige der gängigen Funktionen:\n\nslide_dbl() - iteriert durch eine numerische (daher “_dbl”) Spalte und führt eine Operation mit einem gleitenden Fenster durch\n\nslide_sum() - Rolling Sum Shortcut-Funktion für slide_dbl()\nslide_mean() - gleitender Durchschnitt Abkürzungsfunktion für slide_dbl()\n\nslide_index_dbl() - wendet das gleitende Fenster auf eine numerische Spalte an und verwendet eine separate Spalte, um Index den Verlauf des Fensters (nützlich, wenn das Rolling Window nach Datum erfolgt und einige Daten nicht vorhanden sind)\n\nslide_index_sum() - Rollierende Summen-Verknüpfungsfunktion mit Indizierung\nslide_index_mean() - Rollierender Mittelwert Verknüpfungsfunktion mit Indizierung\n\n\nDie Schieberegler Paket hat viele weitere Funktionen, die im Abschnitt Ressourcen auf dieser Seite behandelt werden. Wir gehen kurz auf die gängigsten ein.\nKernargumente\n\n.x Das erste Argument ist standardmäßig der Vektor, über den iteriert wird und auf den die Funktion angewendet wird.\n.i = für die “Index”-Versionen der Slider Funktionen - eine Spalte für den “Index” der Rolle bereitstellen (siehe Abschnitt unten)\n.f =, das zweite Argument standardmäßig, entweder:\n\nEine Funktion, die ohne Klammern geschrieben wird, wie mean, oder\nEine Formel, die in eine Funktion umgewandelt wird. Zum Beispiel ~ .x - mean(.x) gibt das Ergebnis des aktuellen Wertes minus dem Mittelwert des Fensters zurück\n\nFür weitere Details siehe dies Referenzmaterial\n\nFenstergröße\nLegen Sie die Größe des Fensters fest, indem Sie entweder .before, .after, oder beide Argumente:\n\n.before = - Gib eine ganze Zahl an\n.after = - Eine ganze Zahl bereitstellen\n.complete = - Setzen Sie diese auf TRUE wenn du die Berechnung nur für komplette Fenster durchführen willst\n\nUm zum Beispiel ein 7-Tage-Fenster zu erhalten, das den aktuellen Wert und die sechs vorangegangenen einschließt, verwende .before = 6. Um ein “zentriertes” Fenster zu erhalten, gibst du für beide Werte die gleiche Zahl ein .before = und .after =.\nStandardmäßig, .complete = ist FALSE, d. h., wenn nicht das gesamte Fenster mit Zeilen vorhanden ist, verwenden die Funktionen die verfügbaren Zeilen für die Berechnung. Wenn du TRUE einstellst, werden die Berechnungen nur für vollständige Fenster durchgeführt.\nErweitern des Fensters\nUm zu erreichen kumulativ Operationen zu erreichen, setze die .before = Argument auf Inf. Dadurch wird die Operation mit dem aktuellen Wert und allen davor liegenden Werten durchgeführt.\n\n22.2.1 Rollieren nach Datum {#roll_index .unnumbered}\nDer wahrscheinlichste Anwendungsfall für eine rollierende Berechnung in der angewandten Epidemiologie ist die Untersuchung einer Kennzahl im Laufe der Zeit. Zum Beispiel eine rollierende Messung der Fallzahl, die auf täglichen Fallzahlen basiert.\nWenn du über saubere Zeitreihendaten mit Werten für jedes Datum verfügst, ist es vielleicht in Ordnung, wenn du slide_dbl() zu verwenden, wie es hier in der Zeitreihen und Ausbruchserkennung Seite.\nIn vielen Fällen der angewandten Epidemiologie kann es jedoch vorkommen, dass in deinen Daten Daten Daten fehlen, in denen keine Ereignisse aufgezeichnet sind. In diesen Fällen ist es am besten, die “Index”-Versionen der Schieberegler Funktionen.\n\n\nIndizierte Daten\nIm Folgenden zeigen wir ein Beispiel mit slide_index_dbl() auf der Fall-Liste. Nehmen wir an, unser Ziel ist es, eine rollierende 7-Tage-Inzidenz zu berechnen - die Summe der Fälle in einem rollierenden 7-Tage-Fenster. Wenn du ein Beispiel für einen gleitenden Durchschnitt suchst, findest du es weiter unten im Abschnitt über gruppiertes Rollen.\nZu Beginn wird der Datensatz daily_counts erstellt, der die täglichen Fallzahlen aus dem linelist berechnet mit count() von dplyr.\n\n# make dataset of daily counts\ndaily_counts &lt;- linelist %&gt;% \n  count(date_hospitalisation, name = \"new_cases\")\n\nHier ist die daily_counts Datenrahmen - es gibt nrow(daily_counts) Zeilen, jeder Tag wird durch eine Zeile repräsentiert, aber besonders früh in der Epidemie einige Tage sind nicht vorhanden (an diesen Tagen wurden keine Fälle aufgenommen).\n\n\n\n\n\n\nEs ist wichtig zu wissen, dass eine Standard-Rolling-Funktion (wie slide_dbl() ein Fenster von 7 % verwenden würde Zeilen, nicht 7 Tage. Wenn also irgendwelche Termine fehlen, verlängern sich manche Fenster tatsächlich um mehr als 7 Kalendertage!\nEin “intelligentes” rollendes Fenster kann erreicht werden mit slide_index_dbl(). Der “Index” bedeutet, dass die Funktion einen separate Spalte als “Index” für das rollierende Fenster verwendet. Das Fenster basiert nicht einfach auf den Zeilen des Datenrahmens.\nWenn es sich bei der Indexspalte um ein Datum handelt, kannst du zusätzlich die Ausdehnung des Fensters auf .before = und/oder .after = in Einheiten von lubridate days() oder months(). Wenn du diese Dinge tust, fügt die Funktion abwesende Tage in die Fenster ein, als ob sie da wären (als NA Werte).\nLass uns einen Vergleich anstellen. Im Folgenden berechnen wir die rollierende 7-Tage-Fallinzidenz mit regulären und indizierten Fenstern.\n\nrolling &lt;- daily_counts %&gt;% \n  mutate(                                # create new columns\n    # Using slide_dbl()\n    ###################\n    reg_7day = slide_dbl(\n      new_cases,                         # calculate on new_cases\n      .f = ~sum(.x, na.rm = T),          # function is sum() with missing values removed\n      .before = 6),                      # window is the ROW and 6 prior ROWS\n    \n    # Using slide_index_dbl()\n    #########################\n    indexed_7day = slide_index_dbl(\n        new_cases,                       # calculate on new_cases\n        .i = date_hospitalisation,       # indexed with date_onset \n        .f = ~sum(.x, na.rm = TRUE),     # function is sum() with missing values removed\n        .before = days(6))               # window is the DAY and 6 prior DAYS\n    )\n\nBeobachte, wie in der regulären Spalte für die ersten 7 Zeilen die Anzahl stetig steigt obwohl die Zeilen nicht im Abstand von 7 Tagen zueinander liegen! Die benachbarte “indizierte” Spalte berücksichtigt diese fehlenden Kalendertage, so dass ihre 7-Tage-Summen viel niedriger sind, zumindest in diesem Zeitraum der Epidemie, als die Fälle weiter auseinander lagen.\n\n\n\n\n\n\nJetzt kannst du diese Daten mit folgenden Methoden darstellen ggplot():\n\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n22.2.2 Walzen nach Gruppen {#roll_slider_group .unnumbered}\nWenn du deine Daten gruppierst, bevor du eine Schieberegler Funktion gruppierst, werden die Schiebefenster gruppenweise angewendet. Achte darauf, dass du deine Zeilen in der gewünschten Reihenfolge anordnest nach Gruppe.\nJedes Mal, wenn eine neue Gruppe beginnt, wird das gleitende Fenster neu gestartet. Wenn deine Daten gruppiert sind, musst du also Folgendes beachten und du eingestellt hast .complete = TRUE gesetzt hast, wirst du bei jedem Übergang zwischen den Gruppen leere Werte haben. Wenn sich die Funktion von oben nach unten durch die Zeilen bewegt, wird bei jedem Übergang in der Gruppierungsspalte die Mindestgröße des Fensters neu festgelegt, um eine Berechnung zu ermöglichen.\nSiehe Handbuchseite über [Daten gruppieren] für Details zur Gruppierung von Daten.\nNachfolgend zählen wir die Fälle der Linienliste nach Datum und nach Krankenhaus. Dann ordnen wir die Zeilen in aufsteigender Reihenfolge an, zuerst nach dem Krankenhaus und dann innerhalb dieser Reihenfolge nach dem Datum. Als nächstes setzen wir group_by(). Dann können wir unseren neuen gleitenden Durchschnitt erstellen.\n\ngrouped_roll &lt;- linelist %&gt;%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %&gt;% \n\n  arrange(hospital, date_hospitalisation) %&gt;%   # arrange rows by hospital and then by date\n  \n  group_by(hospital) %&gt;%              # group by hospital \n    \n  mutate(                             # rolling average  \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases,                 # the count of cases per hospital-day\n      .i = date_hospitalisation,      # index on date of admission\n      .f = mean,                      # use mean()                   \n      .before = days(6)               # use the day and the 6 days prior\n      )\n  )\n\nHier ist der neue Datensatz:\n\n\n\n\n\n\nWir können nun die gleitenden Durchschnitte darstellen, indem wir die Daten nach Gruppen aufschlüsseln, indem wir angeben ~ hospital an facet_wrap() in ggplot(). Zum Spaß stellen wir zwei Geometrien dar - a geom_col() zeigt die täglichen Fallzahlen und eine geom_line() zeigt den gleitenden 7-Tage-Durchschnitt.\n\nggplot(data = grouped_roll)+\n  geom_col(                       # plot daly case counts as grey bars\n    mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(                      # plot rolling average as line colored by hospital\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # create mini-plots per hospital\n  theme_classic()+                 # simplify background  \n  theme(legend.position = \"none\")+ # remove legend\n  labs(                            # add plot labels\n    title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")\n\n\n\n\n\n\n\n\nGEFAHR! Wenn du eine Fehlermeldung erhältst “slide() wurde in tsibble 0.9.0 veraltet und ist jetzt nicht mehr verfügbar. Bitte verwende stattdessen slider::slide().” bedeutet das, dass die slide() Funktion aus dem tsibble Paket maskiert die slide() Funktion von Schieber Paket. Behebe dies, indem du das Paket im Befehl angibst, z. B. slider::slide_dbl().",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Gleitende Durchschnitte</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.de.html#berechne-mit-tidyquant-innerhalb-von-ggplot",
    "href": "new_pages/moving_average.de.html#berechne-mit-tidyquant-innerhalb-von-ggplot",
    "title": "22  Gleitende Durchschnitte",
    "section": "22.3 Berechne mit tidyquant innerhalb von ggplot()",
    "text": "22.3 Berechne mit tidyquant innerhalb von ggplot()\nDas Paket tidyquant bietet einen weiteren Ansatz zur Berechnung von gleitenden Durchschnitten - diesmal aus innerhalb von a ggplot() Befehls selbst.\nUnterhalb des linelist werden die Daten nach Datum des Auftretens gezählt und als verblassende Linie dargestellt (alpha &lt; 1). Darüber wird eine Linie eingeblendet, die mit geom_ma() aus dem Paket tidyquant mit einem festgelegten Fenster von 7 Tagen (n = 7) mit bestimmter Farbe und Dicke.\nStandardmäßig geom_ma() einen einfachen gleitenden Durchschnitt (ma_fun = \"SMA\"), aber es können auch andere Typen angegeben werden, wie z. B.:\n\n“EMA” - exponentiell gleitender Durchschnitt (mehr Gewicht für die jüngsten Beobachtungen)\n“WMA” - gewichteter gleitender Durchschnitt (wts werden zur Gewichtung der Beobachtungen im gleitenden Durchschnitt verwendet)\nAndere können in der Funktionsdokumentation gefunden werden\n\n\nlinelist %&gt;% \n  count(date_onset) %&gt;%                 # count cases per day\n  drop_na(date_onset) %&gt;%               # remove cases missing onset date\n  ggplot(aes(x = date_onset, y = n))+   # start ggplot\n    geom_line(                          # plot raw values\n      size = 1,\n      alpha = 0.2                       # semi-transparent line\n      )+             \n    tidyquant::geom_ma(                 # plot moving average\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal()                       # simple background\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\n\n\n\nSiehe dies Vignette für weitere Details zu den Optionen, die in tidyquant.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Gleitende Durchschnitte</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.de.html#ressourcen",
    "href": "new_pages/moving_average.de.html#ressourcen",
    "title": "22  Gleitende Durchschnitte",
    "section": "22.4 Ressourcen",
    "text": "22.4 Ressourcen\nSiehe das hilfreiche Online Vignette für die Slider Paket\nDie Schieber Github-Seite\nA Schieber Vignette\ntidyquant Vignette\nWenn dein Anwendungsfall erfordert, dass du Wochenenden und sogar Feiertage “überspringst”, könnte dir das gefallen almanac Paket.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Gleitende Durchschnitte</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html",
    "href": "new_pages/time_series.de.html",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "",
    "text": "23.1 Übersicht\nDiese Registerkarte demonstriert die Verwendung verschiedener Pakete für die Zeitreihenanalyse. Sie stützt sich hauptsächlich auf Pakete aus der tidyverts Familie, sondern verwendet auch die RECON trending Paket, um Modelle anzupassen, die für die Epidemiologie von Infektionskrankheiten besser geeignet sind.\nIn dem folgenden Beispiel verwenden wir einen Datensatz aus dem Überwachung Paket über Campylobacter in Deutschland (siehe die Kapitel Daten, des Handbuchs für Details). Wenn du jedoch denselben Code auf einen Datensatz anwenden möchtest mit mehreren Ländern oder anderen Schichten durchführen möchtest, findest du eine Beispiel-Codevorlage dafür in der r4epis github repo.\nFolgende Themen werden behandelt:",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#übersicht",
    "href": "new_pages/time_series.de.html#übersicht",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "",
    "text": "Zeitreihendaten\nDeskriptive Analyse\nAnpassen von Regressionen\nBeziehung zwischen zwei Zeitreihen\nAusbruchserkennung\nUnterbrochene Zeitreihen",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#vorbereitung",
    "href": "new_pages/time_series.de.html#vorbereitung",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.2 Vorbereitung",
    "text": "23.2 Vorbereitung\n\nPakete\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und es zur Verwendung lädt. Du kannst Pakete auch laden mit library() von Basis R. Siehe die Seite über R-Grundlagen für weitere Informationen über R-Pakete.\n\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               slider,       # for calculating moving averages\n               imputeTS,     # for filling in missing values\n               feasts,       # for time series decomposition and autocorrelation\n               forecast,     # fit sin and cosin terms to data (note: must load after feasts)\n               trending,     # fit and assess models \n               tmaptools,    # for getting geocoordinates (lon/lat) based on place names\n               ecmwfr,       # for interacting with copernicus sateliate CDS API\n               stars,        # for reading in .nc (climate data) files\n               units,        # for defining units of measurement (climate data)\n               yardstick,    # for looking at model accuracy\n               surveillance  # for aberration detection\n               )\n\n\n\nDaten laden\nDu kannst alle in diesem Handbuch verwendeten Daten über die Anweisungen im Abschnitt [Handbuch und Daten herunterladen] Seite herunterladen.\nDer Beispieldatensatz, der in diesem Abschnitt verwendet wird, sind wöchentliche Zählungen von Campylobacter-Fällen, die zwischen 2001 und 2011 in Deutschland gemeldet wurden.  Du kannst hier klicken, um herunterzuladen diese Datendatei (.xlsx) herunterzuladen.\nDieser Datensatz ist eine reduzierte Version des Datensatzes, der in der Überwachung Paket. (Für Details lade das Überwachungspaket und siehe ?campyDE)\nImportiere diese Daten mit dem import() Funktion aus dem rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import the counts into R\ncounts &lt;- rio::import(\"campylobacter_germany.xlsx\")\n\nDie ersten 10 Zeilen der Zählungen werden unten angezeigt.\n\n\n\n\n\n\n\n\nSaubere Daten\nDer folgende Code stellt sicher, dass die Datumsspalte das richtige Format hat. Für diese Registerkarte verwenden wir die tsibble Paket und damit die yearweek Funktion verwendet werden, um eine Kalenderwochenvariable zu erstellen. Es gibt mehrere andere Möglichkeiten, dies zu tun (siehe die Arbeiten mit Daten Seite für Details), aber für Zeitreihen ist es am besten, innerhalb eines Rahmens zu bleiben (tsibble).\n\n## ensure the date column is in the appropriate format\ncounts$date &lt;- as.Date(counts$date)\n\n## create a calendar week variable \n## fitting ISO definitons of weeks starting on a monday\ncounts &lt;- counts %&gt;% \n     mutate(epiweek = yearweek(date, week_start = 1))\n\n\n\nDownload Klimadaten\nIm Beziehung zwischen zwei Zeitreihen Abschnitt dieser Seite vergleichen wir Campylobacter-Fallzahlen mit Klimadaten.\nKlimadaten für jeden Ort der Welt können von der Copernicus-Plattform der EU heruntergeladen werden. Satelliten herunterladen. Es handelt sich dabei nicht um exakte Messungen, sondern um ein Modell (ähnlich dem Interpolation), aber der Vorteil ist eine globale stündliche Abdeckung sowie Vorhersagen.\nDu kannst jede dieser Klimadaten-Dateien von der Website [Handbuch und Daten herunterladen] Seite herunterladen.\nZu Demonstrationszwecken zeigen wir hier den R-Code zur Verwendung der ecmwfr Paket zu verwenden, um diese Daten aus der Copernicus Klimadatenbank zu beziehen. Du musst ein kostenloses Konto erstellen, damit dies möglich ist. funktionieren. Die Website des Pakets hat eine nützliche Komplettlösung wie man das macht. Im Folgenden findest du einen Beispielcode, der dir zeigt, wie du vorgehen musst, wenn du du die entsprechenden API-Schlüssel hast. Du musst die unten stehenden X durch dein Konto ersetzen IDs. Du musst jeweils ein Jahr Daten herunterladen, da der Server sonst ein Timeout hat.\nWenn du die Koordinaten eines Ortes, von dem du Daten herunterladen möchtest, nicht genau kennst herunterladen möchtest, kannst du die tmaptools Paket verwenden, um die Koordinaten von der offenen Straße zu holen Karten. Eine alternative Option ist das Photon Paket, das allerdings noch nicht auf CRAN veröffentlicht wurde; das Schöne an photon ist, dass es mehr kontextbezogene Daten liefert, wenn es mehrere Treffer für deine Suche gibt.\n\n## retrieve location coordinates\ncoords &lt;- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## pull together long/lats in format for ERA-5 querying (bounding box) \n## (as just want a single point can repeat coords)\nrequest_coords &lt;- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Pulling data modelled from copernicus satellite (ERA-5 reanalysis)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## set up key for weather data \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## run for each year of interest (otherwise server times out)\nfor (i in 2002:2011) {\n  \n  ## pull together a query \n  ## see here for how to do: https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## change request to a list using addin button above (python to list)\n  ## Target is the name of the output file!!\n  request &lt;- request &lt;- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## download the file and store it in the current working directory\n  file &lt;- wf_request(user     = \"XXXXX\",  # user ID (for authentication)\n                     request  = request,  # the request\n                     transfer = TRUE,     # download the file\n                     path     = here::here(\"data\", \"Weather\")) ## path to save the data\n  }\n\n\n\nKlimadaten laden\nUnabhängig davon, ob du die Klimadaten über unser Handbuch heruntergeladen oder den obigen Code verwendet hast, solltest du jetzt 10 Jahre lang Klimadaten-Dateien im selben Ordner auf deinem Computer gespeichert haben.\nVerwende den unten stehenden Code, um diese Dateien in R zu importieren, indem du die Sterne Paket zu importieren.\n\n## define path to weather folder \nfile_paths &lt;- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # replace with your own file path \n  full.names = TRUE)\n\n## only keep those with the current name of interest \nfile_paths &lt;- file_paths[str_detect(file_paths, \"germany\")]\n\n## read in all the files as a stars object \ndata &lt;- stars::read_stars(file_paths)\n\nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \n\n\nSobald diese Dateien als Objekt importiert worden sind data importiert wurden, werden wir sie in einen Datenrahmen umwandeln.\n\n## change to a data frame \ntemp_data &lt;- as_tibble(data) %&gt;% \n  ## add in variables and correct units\n  mutate(\n    ## create an calendar week variable \n    epiweek = tsibble::yearweek(time), \n    ## create a date variable (start of calendar week)\n    date = as.Date(epiweek),\n    ## change temperature from kelvin to celsius\n    t2m = set_units(t2m, celsius), \n    ## change precipitation from metres to millimetres \n    tp  = set_units(tp, mm)) %&gt;% \n  ## group by week (keep the date too though)\n  group_by(epiweek, date) %&gt;% \n  ## get the average per week\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))\n\n`summarise()` has grouped output by 'epiweek'. You can override using the\n`.groups` argument.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#zeitreihendaten",
    "href": "new_pages/time_series.de.html#zeitreihendaten",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.3 Zeitreihendaten",
    "text": "23.3 Zeitreihendaten\nEs gibt eine Reihe verschiedener Pakete zur Strukturierung und Bearbeitung von Zeitreihen Daten. Wie gesagt, werden wir uns auf die tidyverts Familie und damit auf die verwenden die tsibble Paket, um unser Zeitreihenobjekt zu definieren. Einen Datensatz haben als Zeitreihenobjekt definiert ist, ist es viel einfacher, unsere Analyse zu strukturieren.\nDazu verwenden wir die tsibble() Funktion und geben den “Index” an, d.h. die Variable die die Zeiteinheit angibt, die uns interessiert. In unserem Fall ist dies die epiweek Variable.\nWenn wir zum Beispiel einen Datensatz mit wöchentlichen Zählungen nach Bundesländern hätten, würden wir auch können wir die Gruppierungsvariable mit der Option key = Argument angeben. So können wir die Analyse für jede Gruppe durchführen.\n\n## define time series object \ncounts &lt;- tsibble(counts, index = epiweek)\n\nDer Blick auf class(counts) zeigt dir, dass es sich nicht nur um einen aufgeräumten Datenrahmen handelt (“tbl_df”, “tbl”, “data.frame”), sondern auch die zusätzlichen Eigenschaften einer Zeitreihe hat Datenrahmens (“tbl_ts”).\nDu kannst einen schnellen Blick auf deine Daten werfen, indem du ggplot2. Anhand der Grafik sehen wir, dass dass es ein klares saisonales Muster gibt und dass es keine Ausfälle gibt. Allerdings gibt es scheint es jedoch ein Problem mit der Meldung zu Beginn eines jeden Jahres zu geben; die Fälle fallen Die Fälle nehmen in der letzten Woche des Jahres ab und steigen dann in der ersten Woche des nächsten Jahres wieder an.\n\n## plot a line graph of cases by week\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()\n\n\n\n\n\n\n\n\nGEFAHR! Die meisten Datensätze sind nicht so sauber wie dieses Beispiel. Du musst sie wie unten beschrieben auf Duplikate und fehlende Einträge überprüfen. \n\n\nDupliziert\ntsibble lässt keine doppelten Beobachtungen zu. Daher muss jede Zeile eindeutig sein, oder eindeutig innerhalb der Gruppe (key Variable). Das Paket hat einige Funktionen, die helfen, Duplikate zu identifizieren. Dazu gehören are_duplicated() die dir einen TRUE/FALSE-Vektor liefert, der angibt, ob die Zeile ein Duplikat ist, und duplicates() der dir einen Datenrahmen mit den doppelten Zeilen liefert.\nSiehe die Seite auf De-Duplizierung für weitere Informationen darüber, wie du die gewünschten Zeilen auswählst.\n\n## get a vector of TRUE/FALSE whether rows are duplicates\nare_duplicated(counts, index = epiweek) \n\n## get a data frame of any duplicated rows \nduplicates(counts, index = epiweek) \n\n\n\n\nFehlt\nBei unserer kurzen Inspektion oben haben wir festgestellt, dass es keine Mängel gibt, aber wir haben auch aber wir haben auch gesehen, dass es ein Problem mit der Verspätung der Meldungen um Neujahr herum zu geben scheint. Eine Möglichkeit, dieses Problem zu lösen, könnte darin bestehen, diese Werte auf fehlend zu setzen und dann Werte zu imputieren. Die einfachste Form der Imputation von Zeitreihen ist die Ziehung eine gerade Linie zwischen dem letzten nicht fehlenden und dem nächsten nicht fehlenden Wert zu ziehen. Hierfür verwenden wir die imputeTS Funktion des Pakets na_interpolation().\nSiehe die Fehlende Daten Seite für weitere Optionen zur Imputation.\nEine andere Alternative wäre, einen gleitenden Durchschnitt zu berechnen, um zu versuchen, die zu glätten (siehe nächster Abschnitt und die Seite über Gleitende Durchschnitte).\n\n## create a variable with missings instead of weeks with reporting issues\ncounts &lt;- counts %&gt;% \n     mutate(case_miss = if_else(\n          ## if epiweek contains 52, 53, 1 or 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## then set to missing \n          NA_real_, \n          ## otherwise keep the value in case\n          case\n     ))\n\n## alternatively interpolate missings by linear trend \n## between two nearest adjacent points\ncounts &lt;- counts %&gt;% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## to check what values have been imputed compared to the original\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#deskriptive-analyse",
    "href": "new_pages/time_series.de.html#deskriptive-analyse",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.4 Deskriptive Analyse",
    "text": "23.4 Deskriptive Analyse\n\n\n23.4.1 Gleitende Durchschnitte {#timeseries_moving .unnumbered}\nWenn die Daten sehr verrauscht sind (Zählungen springen auf und ab), kann es hilfreich sein, wenn einen gleitenden Durchschnitt zu berechnen. In dem folgenden Beispiel berechnen wir für jede Woche den Durchschnittszahl der Fälle aus den vier vorangegangenen Wochen. Dadurch werden die Daten geglättet, um um sie besser interpretierbar zu machen. In unserem Fall bringt das nicht wirklich viel, also werden wir bleiben wir für die weitere Analyse bei den interpolierten Daten. Siehe die Gleitende Durchschnitte Seite für weitere Details.\n\n## create a moving average variable (deals with missings)\ncounts &lt;- counts %&gt;% \n     ## create the ma_4w variable \n     ## slide over each row of the case variable\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## for each row calculate the name\n                               ~ mean(.x, na.rm = TRUE),\n                               ## use the four previous weeks\n                               .before = 4))\n\n## make a quick visualisation of the difference \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nPeriodizität\nIm Folgenden definieren wir eine benutzerdefinierte Funktion, um ein Periodogramm zu erstellen. Siehe die [Funktionen schreiben] findest du Informationen darüber, wie du Funktionen in R schreibst.\nZuerst wird die Funktion definiert. Ihre Argumente umfassen einen Datensatz mit einer Spalte counts, start_week = die die erste Woche des Datensatzes ist, eine Zahl, die angibt, wie viele Perioden pro Jahr es gibt (z. B. 52, 12), und schließlich der Ausgabestil (siehe Details im Code unten).\n\n## Function arguments\n#####################\n## x is a dataset\n## counts is variable with count data or rates within x \n## start_week is the first week in your dataset\n## period is how many units in a year \n## output is whether you want return spectral periodogram or the peak weeks\n  ## \"periodogram\" or \"weeks\"\n\n# Define function\nperiodogram &lt;- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## make sure is not a tsibble, filter to project and only keep columns of interest\n    prepare_data &lt;- dplyr::as_tibble(x)\n    \n    # prepare_data &lt;- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data &lt;- dplyr::select(prepare_data, {{counts}})\n    \n    ## create an intermediate \"zoo\" time series to be able to use with spec.pgram\n    zoo_cases &lt;- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## get a spectral periodogram not using fast fourier transform \n    periodo &lt;- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## return the peak weeks \n    periodo_weeks &lt;- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## get spectral periodogram for extracting weeks with the highest frequencies \n## (checking of seasonality) \nperiodo &lt;- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## pull spectrum and frequence in to a dataframe for plotting\nperiodo &lt;- data.frame(periodo$freq, periodo$spec)\n\n## plot a periodogram showing the most frequently occuring periodicity \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n\n\n\n\n\n\n\n## get a vector weeks in ascending order \npeak_weeks &lt;- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")\n\nHINWEIS: Es ist möglich, die oben genannten Wochen zu verwenden, um sie zu Sinus- und Kosinustermen zu addieren. Wir werden jedoch eine Funktion verwenden, um diese Terme zu erzeugen (siehe Abschnitt Regression unten) \n\n\n\nZersetzung\nDie klassische Dekomposition wird verwendet, um eine Zeitreihe in mehrere Teile zu zerlegen, die die zusammengenommen das Muster ergeben, das du siehst. Diese verschiedenen Teile sind:\n\nDer Trend-Zyklus (die langfristige Richtung der Daten)\nDie Saisonalität (wiederkehrende Muster)\nDer Zufall (was nach dem Entfernen von Trend und Saison übrig bleibt)\n\n\n## decompose the counts dataset \ncounts %&gt;% \n  # using an additive classical decomposition model\n  model(classical_decomposition(case_int, type = \"additive\")) %&gt;% \n  ## extract the important information from the model\n  components() %&gt;% \n  ## generate a plot \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nAutokorrelation\nDie Autokorrelation gibt Aufschluss über die Beziehung zwischen den Zählungen der einzelnen Wochen und den Wochen davor (Lags genannt).\nDie Verwendung der ACF() Funktion können wir ein Diagramm erstellen, das uns eine Reihe von Linien zeigt für die Beziehung bei verschiedenen Verzögerungen anzeigt. Wenn die Verzögerung 0 ist (x = 0), würde diese Linie immer 1 sein, da sie die Beziehung zwischen einer Beobachtung und sich selbst darstellt (hier nicht gezeigt). Die erste hier gezeigte Linie (x = 1) zeigt die Beziehung zwischen den einzelnen Beobachtungen und der Beobachtung vor ihr (Verzögerung von 1), die zweite zeigt die Beziehung zwischen jeder Beobachtung und der vorletzten Beobachtung (Lag von 2) und so weiter bis Lag von 52, der die Beziehung zwischen jeder Beobachtung und der Beobachtung von 1 Jahr (52 Wochen davor).\nUnter Verwendung der PACF() Funktion (für partielle Autokorrelation) zeigt die gleiche Art von Beziehung aber bereinigt um alle anderen Wochen dazwischen. Dies ist weniger informativ für die Bestimmung Periodizität.\n\n## using the counts dataset\ncounts %&gt;% \n  ## calculate autocorrelation using a full years worth of lags\n  ACF(case_int, lag_max = 52) %&gt;% \n  ## show a plot\n  autoplot()\n\n\n\n\n\n\n\n## using the counts data set \ncounts %&gt;% \n  ## calculate the partial autocorrelation using a full years worth of lags\n  PACF(case_int, lag_max = 52) %&gt;% \n  ## show a plot\n  autoplot()\n\n\n\n\n\n\n\n\nDu kannst die Nullhypothese der Unabhängigkeit in einer Zeitreihe formal testen (d. h. dass sie nicht autokorreliert ist) mit dem Ljung-Box-Test (in der stats Paket). Ein signifikanter p-Wert deutet darauf hin, dass es eine Autokorrelation in den Daten gibt.\n\n## test for independance \nBox.test(counts$case_int, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  counts$case_int\nX-squared = 462.65, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#anpassen-von-regressionen",
    "href": "new_pages/time_series.de.html#anpassen-von-regressionen",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.5 Anpassen von Regressionen",
    "text": "23.5 Anpassen von Regressionen\nEs ist möglich, eine große Anzahl verschiedener Regressionen an eine Zeitreihe anzupassen, Hier zeigen wir jedoch, wie man eine negative Binomialregression anpasst - als da diese für Zähldaten bei Infektionskrankheiten oft am besten geeignet ist.\n\n\nFourier-Terme\nFourier-Terme sind das Äquivalent zu sin- und cosin-Kurven. Der Unterschied ist, dass diese auf der Suche nach der geeignetsten Kombination von Kurven zur Erklärung der deine Daten zu erklären.\nWenn du nur einen Fourier-Term anpasst, wäre dies gleichbedeutend mit der Anpassung einer sin und einem cosin für die am häufigsten auftretende Verzögerung in deinem Periodogramm (in unserem Fall 52 Wochen). Wir verwenden die fourier() Funktion aus dem Prognose Paket.\nIm folgenden Code weisen wir mit der $, als fourier() zwei Spalten zurück (eine eine für sin und eine für cosin) und diese werden dem Datensatz als Liste hinzugefügt, die “Fourier” genannt - aber diese Liste kann dann als normale Variable in der Regression verwendet werden.\n\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  fourier(K = 1)\n\n\n\n\nNegatives Binomial\nEs ist möglich, Regressionen mit der Basis stats oder MASSEN Funktionen (z.B. lm(), glm() und glm.nb()). Wir werden jedoch die von der tendenziell Paket, da dies die Berechnung einer angemessenen Konfidenz und Vorhersageintervalle (die sonst nicht verfügbar sind). Die Syntax ist dieselbe, und du gibst eine Ergebnisvariable und dann eine Tilde (~) an und fügst dann die verschiedenen Expositionsvariablen hinzu, die dich interessieren, getrennt durch ein Plus (+).\nDer andere Unterschied ist, dass wir zuerst das Modell definieren und dann fit() es an die Daten. Das ist nützlich, weil man so mehrere verschiedene Modelle vergleichen kann mit der gleichen Syntax.\nTIPP: Wenn du Raten verwenden möchtest, anstatt Zählungen verwenden möchtest, kannst du die Bevölkerungsvariable als logarithmischen Offset-Term einfügen, indem du offset(log(population). Du müsstest dann die Bevölkerung auf 1 setzen, bevor du verwenden. predict() verwenden, um eine Rate zu erzeugen. \nTIPP: Für die Anpassung komplexerer Modelle wie wie ARIMA oder Prophet, siehe die Fabel Paket.\n\n## define the model you want to fit (negative binomial) \nmodel &lt;- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier)\n\n## fit your model using the counts dataset\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n## calculate confidence intervals and prediction intervals \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\nestimate_res &lt;- data.frame(observed$result)\n\n## plot your regression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nRückstände\nUm zu sehen, wie gut unser Modell zu den beobachteten Daten passt, müssen wir uns die Residuen ansehen. Die Residuen sind die Differenz zwischen den beobachteten Zählungen und den Zählungen aus dem Modell geschätzt. Wir können dies einfach berechnen, indem wir case_int - estimate, aber die residuals() Funktion extrahiert dies für uns direkt aus der Regression.\nIn der folgenden Tabelle sehen wir, dass wir nicht die gesamte Variation erklären können die wir mit dem Modell erklären könnten. Es könnte sein, dass wir mehr Fourier-Terme einbauen sollten, und die Amplitude ansprechen. Für dieses Beispiel lassen wir es aber so, wie es ist. Die Diagramme zeigen, dass unser Modell in den Spitzen und Tälern schlechter abschneidet (wenn die Zählungen (wenn die Zählungen am höchsten und am niedrigsten sind) und dass es eher zu einer Unterschätzung die beobachteten Zählungen unterschätzt.\n\n## calculate the residuals \nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = fitted_model$result[[1]]$residuals)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## are residuals normally distributed (are under or over estimating?)  \nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## compare observed counts to their residuals \n  ## should also be no pattern \nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 336.25, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#beziehung-zwischen-zwei-zeitreihen",
    "href": "new_pages/time_series.de.html#beziehung-zwischen-zwei-zeitreihen",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.6 Beziehung zwischen zwei Zeitreihen",
    "text": "23.6 Beziehung zwischen zwei Zeitreihen\nHier betrachten wir die Verwendung von Wetterdaten (insbesondere der Temperatur) zur Erklärung Campylobacter-Fallzahlen zu erklären.\n\n\nZusammenführung von Datensätzen\nWir können unsere Datensätze mithilfe der Variable Woche zusammenführen. Mehr über das Zusammenführen erfährst du in der Handbuch Abschnitt über Zusammenführen.\n\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts &lt;- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")\n\n\n\n\nDeskriptive Analyse\nStelle deine Daten zunächst grafisch dar, um zu sehen, ob es einen offensichtlichen Zusammenhang gibt. Das folgende Diagramm zeigt, dass es einen klaren Zusammenhang zwischen den Saisonalitäten der beiden Daten gibt Variablen gibt und dass die Temperatur einige Wochen vor der Fallzahl ihren Höhepunkt erreicht. Weitere Informationen zum Pivoting von Daten findest du im Handbuch unter Daten schwenken.\n\ncounts %&gt;% \n  ## keep the variables we are interested \n  select(epiweek, case_int, t2m) %&gt;% \n  ## change your data in to long format\n  pivot_longer(\n    ## use epiweek as your key\n    !epiweek,\n    ## move column names to the new \"measure\" column\n    names_to = \"measure\", \n    ## move cell values to the new \"values\" column\n    values_to = \"value\") %&gt;% \n  ## create a plot with the dataset above\n  ## plot epiweek on the x axis and values (counts/celsius) on the y \n  ggplot(aes(x = epiweek, y = value)) + \n    ## create a separate plot for temperate and case counts \n    ## let them set their own y-axes\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## plot both as a line\n    geom_line()\n\n\n\n\n\n\n\n\n\n\n\nVerzögerungen und Kreuzkorrelation\nUm formal zu testen, welche Wochen am stärksten zwischen den Fällen und der Temperatur verbunden sind. Wir können die Kreuzkorrelationsfunktion verwenden (CCF()) aus den Festen Paket. Du könntest auch visualisieren (statt mit arrange) mit dem autoplot() Funktion.\n\ncounts %&gt;% \n  ## calculate cross-correlation between interpolated counts and temperature\n  CCF(case_int, t2m,\n      ## set the maximum lag to be 52 weeks\n      lag_max = 52, \n      ## return the correlation coefficient \n      type = \"correlation\") %&gt;% \n  ## arange in decending order of the correlation coefficient \n  ## show the most associated lags\n  arrange(-ccf) %&gt;% \n  ## only show the top ten \n  slice_head(n = 10)\n\n# A tsibble: 10 x 2 [1W]\n        lag   ccf\n   &lt;cf_lag&gt; &lt;dbl&gt;\n 1      -4W 0.749\n 2      -5W 0.745\n 3      -3W 0.735\n 4      -6W 0.729\n 5      -2W 0.727\n 6      -7W 0.704\n 7      -1W 0.695\n 8      -8W 0.671\n 9       0W 0.649\n10      47W 0.638\n\n\nDaraus ersehen wir, dass eine Verzögerung von 4 Wochen am stärksten korreliert ist, Wir erstellen also eine verzögerte Temperaturvariable, die wir in unsere Regression einbeziehen.\nGEFAHR! Beachte, dass die ersten vier Wochen unserer Daten in der verzögerten Temperaturvariable fehlen (NA) - denn es gibt nicht vier Wochen vorliegen, von denen wir Daten abrufen können. Um diesen Datensatz mit dem trending predict() Funktion zu verwenden, müssen wir die simulate_pi = FALSE Argument innerhalb predict() weiter unten. Wenn wir die Option simulieren verwenden wollen, dann müssen wir diese fehlenden Daten löschen und als neuen Datensatz speichern, indem wir drop_na(t2m_lag4) zu dem unten stehenden Codeabschnitt hinzufügen.\n\ncounts &lt;- counts %&gt;% \n  ## create a new variable for temperature lagged by four weeks\n  mutate(t2m_lag4 = lag(t2m, n = 4))\n\n\n\n\nNegatives Binomial mit zwei Variablen\nWir passen eine negative Binomialregression wie zuvor an. Dieses Mal fügen wir die Temperaturvariable mit einer Verzögerung von vier Wochen hinzu.\nVORSICHT! Beachten Sie die Verwendung von simulate_pi = FALSE innerhalb der predict() Argument. Das liegt daran, dass das Standardverhalten von trending ist die Verwendung der ciTools Paket, um ein Vorhersageintervall zu schätzen. Das tut nicht funktioniert nicht, wenn es NA Zählungen gibt, und erzeugt auch feinere Intervalle. Siehe ?trending::predict.trending_model_fit für Details. \n\n## define the model you want to fit (negative binomial) \nmodel &lt;- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier + \n    ## use the temperature lagged by four weeks \n    t2m_lag4\n    )\n\n## fit your model using the counts dataset\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n## calculate confidence intervals and prediction intervals \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\nUm die einzelnen Terme zu untersuchen, können wir die ursprüngliche negative Binomialform ziehen Regression aus der trending Format mit get_model() und übergibt dieses an die Besen Paket tidy() Funktion zum Abrufen von potenzierten Schätzungen und zugehörigen Konfidenzintervalle.\nDies zeigt uns, dass die verzögerte Temperatur nach der Kontrolle für Trend und Saisonalität, ähnlich ist wie die Fallzahlen (Schätzung ~ 1) und signifikant damit verbunden ist. Das deutet darauf hin, dass sie eine gute Variable für die Vorhersage zukünftiger Fälle sein könnte. (da Klimaprognosen leicht verfügbar sind).\n\nfitted_model %&gt;% \n  ## extract original negative binomial regression\n  get_fitted_model() #%&gt;% \n\n[[1]]\n\nCall:  glm.nb(formula = case_int ~ epiweek + fourier + t2m_lag4, data = data.frame(counts), \n    init.theta = 32.80689607, link = log)\n\nCoefficients:\n (Intercept)       epiweek  fourierS1-52  fourierC1-52      t2m_lag4  \n   5.825e+00     8.464e-05    -2.850e-01    -1.954e-01     6.672e-03  \n\nDegrees of Freedom: 504 Total (i.e. Null);  500 Residual\n  (4 observations deleted due to missingness)\nNull Deviance:      2015 \nResidual Deviance: 508.2    AIC: 6784\n\n  ## get a tidy dataframe of results\n  #tidy(exponentiate = TRUE, \n  #     conf.int = TRUE)\n\nEine kurze visuelle Inspektion des Modells zeigt, dass es vielleicht besser ist, wenn es die beobachteten Fallzahlen zu schätzen.\n\nestimate_res &lt;- data.frame(observed$result)\n\n## plot your regression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()\n\n\n\n\n\n\n\n\n\nResiduen\nWir untersuchen noch einmal die Residuen, um zu sehen, wie gut unser Modell zu den beobachteten Daten passt. Die Ergebnisse und die Interpretation sind hier ähnlich wie bei der vorherigen Regression, Daher ist es vielleicht sinnvoller, bei dem einfacheren Modell ohne Temperatur zu bleiben.\n\n## calculate the residuals \nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = case_int - estimate)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## are residuals normally distributed (are under or over estimating?)  \nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## compare observed counts to their residuals \n  ## should also be no pattern \nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 339.52, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#ausbruchserkennung",
    "href": "new_pages/time_series.de.html#ausbruchserkennung",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.7 Ausbruchserkennung",
    "text": "23.7 Ausbruchserkennung\nWir werden hier zwei (ähnliche) Methoden zur Erkennung von Ausbrüchen demonstrieren. Die erste baut auf den obigen Abschnitten auf. Wir verwenden die trending Paket, um Regressionen auf die vergangenen Jahre anzupassen und dann vorhersagen, was wir für das nächste Jahr erwarten. Wenn die beobachteten Zahlen über über den Erwartungen, könnte dies auf einen Ausbruch hindeuten. Die zweite Methode basiert auf ähnlichen Prinzipien, verwendet aber die Überwachung paket, das eine Reihe verschiedener Algorithmen zur Erkennung von Aberrationen enthält.\nVORSICHT! Normalerweise interessierst du dich für das aktuelle Jahr (wo du nur die Zählungen bis zur aktuellen Woche kennst). In diesem Beispiel geben wir also vor, dass wir uns in Woche 39 des Jahres 2011 befinden.\n\n\ntrending Paket\nFür diese Methode legen wir eine Basislinie fest (die in der Regel etwa 5 Jahre Daten umfassen sollte). Wir passen eine Regression an die Basisdaten an und verwenden diese dann zur Vorhersage der Schätzungen für das nächste Jahr.\n\n\nStichtag\nEs ist einfacher, die Daten an einer Stelle zu definieren und sie dann in der gesamten Kampagne zu verwenden. Rest deines Codes zu verwenden.\nHier definieren wir ein Startdatum (wann unsere Beobachtungen beginnen) und ein Enddatum (das Ende unseres Basiszeitraums - und der Beginn des Zeitraums, für den wir Vorhersagen treffen wollen). Außerdem legen wir fest, wie viele Wochen das Jahr hat, das uns interessiert (das Jahr, das wir vorhersagen wollen). Wir legen auch fest, wie viele Wochen zwischen unserem Basisgrenzwert und dem Enddatum liegen für das wir eine Vorhersage treffen wollen.\nHINWEIS: In diesem Beispiel tun wir so, als befänden wir uns derzeit Ende September 2011 (“2011 W39”).\n\n## define start date (when observations began)\nstart_date &lt;- min(counts$epiweek)\n\n## define a cut-off week (end of baseline, start of prediction period)\ncut_off &lt;- yearweek(\"2010-12-31\")\n\n## define the last date interested in (i.e. end of prediction)\nend_date &lt;- yearweek(\"2011-12-31\")\n\n## find how many weeks in period (year) of interest\nnum_weeks &lt;- as.numeric(end_date - cut_off)\n\n\n\n\nZeilen hinzufügen\nUm eine Vorhersage in einem aufgeräumten Format machen zu können, brauchen wir die richtige Anzahl von Zeilen in unserem Datensatz haben, d. h. eine Zeile für jede Woche bis zum end_dateoben definiert. Mit dem folgenden Code kannst du diese Zeilen nach einer Gruppierungsvariablen hinzufügen - zum Beispiel Wenn wir mehrere Länder in einem Datensatz haben, können wir nach Land gruppieren und dann Zeilen für jedes Land entsprechend hinzufügen. Die group_by_key() Funktion von tsibble ermöglicht uns diese Gruppierung und übergibt die gruppierten Daten dann an dplyr Funktionen, group_modify() und add_row(). Dann legen wir die Reihenfolge der Wochen zwischen einer nach der maximalen Woche fest die derzeit in den Daten verfügbar ist, und der Endwoche.\n\n## add in missing weeks till end of year \ncounts &lt;- counts %&gt;%\n  ## group by the region\n  group_by_key() %&gt;%\n  ## for each group add rows from the highest epiweek to the end of year\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))\n\n\n\n\nFourier-Terme\nWir müssen unsere Fourier-Terme neu definieren - denn wir wollen sie an die Grundlinie anpassen Datum anpassen und dann diese Terme für das nächste Jahr vorhersagen (extrapolieren). Dazu müssen wir zwei Ausgabelisten aus dem Programm fourier() Funktion miteinander kombinieren; Die erste ist für die Basisdaten, die zweite für die Vorhersage der Jahr von Interesse (durch Definition der h Argument).\nN.b.. Um Zeilen zu binden, müssen wir rbind() (statt tidyverse bind_rows) als die Fourier-Spalten eine Liste sind (also nicht einzeln benannt).\n\n## define fourier terms (sincos) \ncounts &lt;- counts %&gt;% \n  mutate(\n    ## combine fourier terms for weeks prior to  and after 2010 cut-off date\n    ## (nb. 2011 fourier terms are predicted)\n    fourier = rbind(\n      ## get fourier terms for previous years\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek &lt;= cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for 2011 (using baseline data)\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek &lt;= cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = num_weeks\n        )\n      )\n    )\n\n\n\n\nDaten aufteilen und Regression anpassen\nJetzt müssen wir unseren Datensatz in den Basiszeitraum und die Vorhersage aufteilen Zeitraum aufteilen. Dies geschieht mithilfe der dplyr group_split() Funktion nach group_by(), und erstellt eine Liste mit zwei Datenrahmen, einen für die Zeit vor deinem Cut-off und einen für danach.\nWir verwenden dann die purrr Paket pluck() Funktion, um die Datensätze aus dem Liste zu ziehen (entspricht der Verwendung eckiger Klammern, z. B. dat[[1]]), und kann dann die unser Modell an die Basisdaten anpassen und dann die predict() Funktion für unsere Daten nach dem Cut-off.\nSiehe die Seite über [Iteration, Schleifen und Listen] um mehr zu erfahren überpurrr.\nVORSICHT! Beachten Sie die Verwendung von simulate_pi = FALSE innerhalb der predict() Argument. Das liegt daran, dass das Standardverhalten von trending ist die Verwendung der ciTools Paket, um ein Vorhersageintervall zu schätzen. Das tut nicht funktioniert nicht, wenn es NA Zählungen gibt, und erzeugt auch feinere Intervalle. Siehe ?trending::predict.trending_model_fit für Details. \n\n# split data for fitting and prediction\ndat &lt;- counts %&gt;% \n  group_by(epiweek &lt;= cut_off) %&gt;%\n  group_split()\n\n## define the model you want to fit (negative binomial) \nmodel &lt;- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier\n)\n\n# define which data to use for fitting and which for predicting\nfitting_data &lt;- pluck(dat, 2)\npred_data &lt;- pluck(dat, 1) %&gt;% \n  select(case_int, epiweek, fourier)\n\n# fit model \nfitted_model &lt;- trending::fit(model, data.frame(fitting_data))\n\n# get confint and estimates for fitted data\nobserved &lt;- fitted_model %&gt;% \n  predict(simulate_pi = FALSE)\n\n# forecast with data want to predict with \nforecasts &lt;- fitted_model %&gt;% \n  predict(data.frame(pred_data), simulate_pi = FALSE)\n\n## combine baseline and predicted datasets\nobserved &lt;- bind_rows(observed$result, forecasts$result)\n\nWie zuvor können wir unser Modell mit ggplot. Wir markieren Alarme mit roten Punkten hervor, wenn die beobachtete Anzahl über dem 95%-Vorhersageintervall liegt. Dieses Mal fügen wir auch eine vertikale Linie hinzu, um zu kennzeichnen, wann die Vorhersage beginnt.\n\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## plot in points for the observed counts above expected\n  geom_point(\n    data = filter(observed, case_int &gt; upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()\n\nWarning: Removed 13 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\nValidierung der Vorhersage\nNeben der Überprüfung der Residuen ist es auch wichtig zu untersuchen, wie gut dein Modell ist Fälle in der Zukunft vorhersagen kann. So bekommst du einen Eindruck davon, wie zuverlässig dein Schwellenwertwarnungen sind.\nDie herkömmliche Art der Validierung besteht darin, zu sehen, wie gut du die letzten Schwellenwerte vorhersagen kannst. Jahr vor dem aktuellen Jahr vorhersagen kannst (weil du die Zahlen für das “aktuelle Jahr” noch nicht kennst). In unserem Datensatz würden wir zum Beispiel die Daten von 2002 bis 2009 verwenden, um 2010 vorherzusagen, und dann sehen, wie genau diese Vorhersagen sind. Dann passen wir das Modell neu an und berücksichtigen Daten aus dem Jahr 2010 und verwenden diese, um die Zahlen für 2011 vorherzusagen.\nWie in der folgenden Abbildung zu sehen ist Hyndman et al in “Vorhersageprinzipien und Praxis”.\n Abbildung reproduziert mit Genehmigung der Autoren\nDer Nachteil dabei ist, dass du nicht alle verfügbaren Daten verwendest, und es ist nicht das endgültige Modell, das du für die Vorhersage verwendest.\nEine Alternative ist eine Methode namens Kreuzvalidierung. In diesem Szenario musst du alle verfügbaren Daten und passt mehrere Modelle an, um ein Jahr vorauszusagen. Du verwendest immer mehr Daten in jedem Modell, wie in der folgenden Abbildung aus dem gleichen [Hyndman et al Text]((https://otexts.com/fpp3/). Das erste Modell verwendet zum Beispiel das Jahr 2002, um das Jahr 2003 vorherzusagen, das zweite Modell verwendet 2002 und 2003, um 2004 vorherzusagen, und so weiter.  Abbildung reproduziert mit Genehmigung der Autoren\nIm Folgenden verwenden wir purrr Paket map() Funktion, um über jeden Datensatz zu laufen. Dann fassen wir die Schätzungen in einem Datensatz zusammen und führen sie mit den ursprünglichen Fallzahlen zusammen, zur Verwendung der Maßstab Paket zu verwenden, um Maßstäbe für die Genauigkeit zu berechnen. Wir berechnen vier Messgrößen, darunter: Roter mittlerer quadratischer Fehler (RMSE), Mittlerer absoluter Fehler (MAE), Mittlerer absoluter skalierter Fehler (MASE), Mittlerer absoluter Prozentfehler (MAPE).\nVORSICHT! Beachten Sie die Verwendung von simulate_pi = FALSE innerhalb der predict() Argument. Das liegt daran, dass das Standardverhalten von trending ist die Verwendung der ciTools Paket, um ein Vorhersageintervall zu schätzen. Das tut nicht funktioniert nicht, wenn es NA Zählungen gibt, und erzeugt auch feinere Intervalle. Siehe ?trending::predict.trending_model_fit für Details. \n\n## Cross validation: predicting week(s) ahead based on sliding window\n\n## expand your data by rolling over in 52 week windows (before + after) \n## to predict 52 week ahead\n## (creates longer and longer chains of observations - keeps older data)\n\n## define window want to roll over\nroll_window &lt;- 52\n\n## define weeks ahead want to predict \nweeks_ahead &lt;- 52\n\n## create a data set of repeating, increasingly long data\n## label each data set with a unique id\n## only use cases before year of interest (i.e. 2011)\ncase_roll &lt;- counts %&gt;% \n  filter(epiweek &lt; cut_off) %&gt;% \n  ## only keep the week and case counts variables\n  select(epiweek, case_int) %&gt;% \n    ## drop the last x observations \n    ## depending on how many weeks ahead forecasting \n    ## (otherwise will be an actual forecast to \"unknown\")\n    slice(1:(n() - weeks_ahead)) %&gt;%\n    as_tsibble(index = epiweek) %&gt;% \n    ## roll over each week in x after windows to create grouping ID \n    ## depending on what rolling window specify\n    stretch_tsibble(.init = roll_window, .step = 1) %&gt;% \n  ## drop the first couple - as have no \"before\" cases\n  filter(.id &gt; roll_window)\n\n\n## for each of the unique data sets run the code below\nforecasts &lt;- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## only keep the current fold being fit \n  mini_data &lt;- filter(case_roll, .id == i) %&gt;% \n    as_tibble()\n  \n  ## create an empty data set for forecasting on \n  forecast_data &lt;- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## add the forecast data to the original \n  mini_data &lt;- bind_rows(mini_data, forecast_data)\n  \n  ## define the cut off based on latest non missing count data \n  cv_cut_off &lt;- mini_data %&gt;% \n    ## only keep non-missing rows\n    drop_na(case_int) %&gt;% \n    ## get the latest week\n    summarise(max(epiweek)) %&gt;% \n    ## extract so is not in a dataframe\n    pull()\n  \n  ## make mini_data back in to a tsibble\n  mini_data &lt;- tsibble(mini_data, index = epiweek)\n  \n  ## define fourier terms (sincos) \n  mini_data &lt;- mini_data %&gt;% \n    mutate(\n    ## combine fourier terms for weeks prior to  and after cut-off date\n    fourier = rbind(\n      ## get fourier terms for previous years\n      forecast::fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for following year (using baseline data)\n      fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # split data for fitting and prediction\n  dat &lt;- mini_data %&gt;% \n    group_by(epiweek &lt;= cv_cut_off) %&gt;%\n    group_split()\n\n  ## define the model you want to fit (negative binomial) \n  model &lt;- glm_nb_model(\n    ## set number of cases as outcome of interest\n    case_int ~\n      ## use epiweek to account for the trend\n      epiweek +\n      ## use the furier terms to account for seasonality\n      fourier\n  )\n\n  # define which data to use for fitting and which for predicting\n  fitting_data &lt;- pluck(dat, 2)\n  pred_data &lt;- pluck(dat, 1)\n  \n  # fit model \n  fitted_model &lt;- trending::fit(model, fitting_data)\n  \n  # forecast with data want to predict with \n  forecasts &lt;- fitted_model %&gt;% \n    predict(data.frame(pred_data), simulate_pi = FALSE)\n  forecasts &lt;- data.frame(forecasts$result[[1]]) %&gt;% \n       ## only keep the week and the forecast estimate\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## make the list in to a data frame with all the forecasts\nforecasts &lt;- bind_rows(forecasts)\n\n## join the forecasts with the observed\nforecasts &lt;- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## using {yardstick} compute metrics\n  ## RMSE: Root mean squared error\n  ## MAE:  Mean absolute error  \n  ## MASE: Mean absolute scaled error\n  ## MAPE: Mean absolute percent error\nmodel_metrics &lt;- bind_rows(\n  ## in your forcasted dataset compare the observed to the predicted\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %&gt;% \n  ## only keep the metric type and its output\n  select(Metric  = .metric, \n         Measure = .estimate) %&gt;% \n  ## make in to wide format so can bind rows after\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## return model metrics \nmodel_metrics\n\n# A tibble: 1 × 4\n   rmse   mae  mase  mape\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  252.  199.  1.96  17.3\n\n\n\n\n\n\nÜberwachung Paket\nIn diesem Abschnitt verwenden wir das Überwachung Paket, um Warnschwellen zu erstellen basierend auf Algorithmen zur Erkennung von Ausbrüchen. Es gibt mehrere verschiedene Methoden zur Verfügung, wir werden uns hier jedoch auf zwei Optionen konzentrieren. Weitere Informationen findest du in diesen Artikeln über die Anwendung und Theorie der verwendeten Alogirthmen.\nDie erste Option verwendet die verbesserte Farrington-Methode. Diese passt eine negative binomiales glm (einschließlich Trend) und gewichtet vergangene Ausbrüche (Ausreißer) nach unten, um einen Schwellenwert zu schaffen.\nDie zweite Option verwendet die glrnb-Methode. Diese passt auch ein negatives binomiales glm an, enthält aber auch Trend- und Fourier-Terme (daher wird sie hier bevorzugt). Die Regression wird verwendet um den “Kontrollmittelwert” (~angepasste Werte) zu berechnen - er verwendet dann einen berechneten verallgemeinerte Likelihood-Ratio-Statistik, um zu beurteilen, ob es eine Verschiebung des Mittelwerts gibt für jede Woche. Beachte, dass der Schwellenwert für jede Woche die vorherigen Wenn es also eine anhaltende Verschiebung gibt, wird ein Alarm ausgelöst. (Beachte auch, dass der Algorithmus nach jedem Alarm zurückgesetzt wird)\nFür die Arbeit mit dem Überwachung Paket zu arbeiten, müssen wir zunächst ein “Überwachungszeitreihen”-Objekt definieren (unter Verwendung der sts() Funktion), das in die Rahmen.\n\n## define surveillance time series object\n## nb. you can include a denominator with the population object (see ?sts)\ncounts_sts &lt;- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## subset to only keep the year from start_date \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## subset to only keep the week from start_date\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## define the type of data (in this case weekly)\n                  freq = 52)\n\n## define the week range that you want to include (ie. prediction period)\n## nb. the sts object only counts observations without assigning a week or \n## year identifier to them - so we use our data to define the appropriate observations\nweekrange &lt;- cut_off - start_date\n\n\n\nFarrington-Methode\nDann definieren wir jeden unserer Parameter für die Farrington-Methode in einem list. Dann führen wir den Algorithmus mit farringtonFlexible() aus und können dann die Schwellenwert für einen Alarm mit farringtonmethod@upperboundden Schwellenwert in unsere Datensatz aufzunehmen. Es ist auch möglich, ein TRUE/FALSE für jede Woche zu extrahieren, wenn sie einen einen Alarm ausgelöst hat (über dem Schwellenwert lag). farringtonmethod@alarm.\n\n## define control\nctrl &lt;- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch &gt; weekrange),\n  b = 9, ## how many years backwards for baseline\n  w = 2, ## rolling window size in weeks\n  weightsThreshold = 2.58, ## reweighting past outbreaks (improved noufaily method - original suggests 1)\n  ## pastWeeksNotIncluded = 3, ## use all weeks available (noufaily suggests drop 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normally, however 1 is advised in the improved method (i.e. always keep)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## apply farrington flexible method\nfarringtonmethod &lt;- farringtonFlexible(counts_sts, ctrl)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from farrington \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] &lt;- farringtonmethod@upperbound\n\nAnschließend können wir die Ergebnisse wie zuvor in ggplot visualisieren.\n\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nGLRNB-Methode\nÄhnlich wie bei der GLRNB-Methode definieren wir jeden unserer Parameter für die in a list, dann passen wir den Algorithmus an und extrahieren die oberen Schranken.\nVORSICHT! Bei dieser Methode werden die Schwellenwerte mit “roher Gewalt” (ähnlich wie beim Bootstrapping) berechnet, was sehr lange dauern kann!\nSiehe die GLRNB-Vignette für Details.\n\n## define control options\nctrl &lt;- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch &gt; weekrange),\n  mu0 = list(S = 1,    ## number of fourier terms (harmonics) to include\n  trend = TRUE,   ## whether to include trend or not\n  refit = FALSE), ## whether to refit model after each alarm\n  ## cARL = threshold for GLR statistic (arbitrary)\n     ## 3 ~ middle ground for minimising false positives\n     ## 1 fits to the 99%PI of glm.nb - with changes after peaks (threshold lowered for alert)\n   c.ARL = 2,\n   # theta = log(1.5), ## equates to a 50% increase in cases in an outbreak\n   ret = \"cases\"     ## return threshold upperbound as case counts\n  )\n\n## apply the glrnb method\nglrnbmethod &lt;- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from glrnb \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] &lt;- glrnbmethod@upperbound\n\nVisualisiere die Ergebnisse wie zuvor.\n\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#unterbrochene-zeitreihe",
    "href": "new_pages/time_series.de.html#unterbrochene-zeitreihe",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.8 Unterbrochene Zeitreihe",
    "text": "23.8 Unterbrochene Zeitreihe\nUnterbrochene Zeitreihen (auch segmentierte Regression oder Interventionsanalyse genannt), wird häufig verwendet, um die Auswirkungen von Impfstoffen auf das Auftreten von Krankheiten zu bewerten. Sie kann aber auch für die Bewertung der Auswirkungen einer Vielzahl von Interventionen oder Einführungen verwendet werden. Zum Beispiel bei Änderungen von Krankenhausabläufen oder bei der Einführung einer neuen Krankheit Krankheitsstammes in einer Bevölkerung. In diesem Beispiel nehmen wir an, dass ein neuer Stamm von Campylobacter eingeführt wurde Ende 2008 in Deutschland eingeführt wurde, und sehen, ob sich das auf die Zahl der Fälle auswirkt. Wir werden wieder die negative Binomialregression verwenden. Die Regression lautet dieses Mal in zwei Teile aufgeteilt, einen vor der Intervention (bzw. der Einführung des neuen Stammes hier) und einen danach (die Vor- und Nachperiode). So können wir ein Verhältnis der Inzidenzraten berechnen, das die zwei Zeiträume vergleichen. Wenn du die Gleichung erklärst, wird das vielleicht klarer (wenn nicht, dann einfach ignorieren!).\nDie negative Binomialregression kann wie folgt definiert werden:\n\\[\\\\log(Y\\_t)= β\\_0 + β\\_1 \\\\Zeiten t+ β\\_2 \\\\Zeiten δ(t-t\\_0) + β\\_3\\\\Zeiten(t-t\\_0 )^+ + log(pop\\_t) + e\\_t\\]\nWobei: \\(Y\\_t\\)ist die Anzahl der zum Zeitpunkt \\(t\\) beobachteten Fälle\n\\(pop\\_t\\) ist die Bevölkerungsgröße in 100.000ern zum Zeitpunkt \\(t\\) (hier nicht verwendet)\n\\(t\\_0\\) ist das letzte Jahr der Vorperiode (einschließlich der Übergangszeit, falls vorhanden)\n\\(δ(x\\) ist die Indikatorfunktion (sie ist 0, wenn x≤0 und 1, wenn x&gt;0)\n\\((x)^+\\) ist der Abschneideoperator (er ist x, wenn x&gt;0 und sonst 0)\n\\(e\\_t\\) bezeichnet das Residuum Zusätzliche Terme Trend und Saison können nach Bedarf hinzugefügt werden.\n\\(β\\_2 \\\\times δ(t-t\\_0) + β\\_3\\\\times(t-t\\_0 )^+\\) ist die verallgemeinerte lineare Teil der Nach-Periode und ist in der Vor-Periode Null. Das bedeutet, dass die \\(β\\_2\\)- und \\(β\\_3\\)-Schätzungen die Auswirkungen der Intervention sind.\nWir müssen hier die Fourier-Terme ohne Prognose neu berechnen, da wir die alle uns zur Verfügung stehenden Daten verwenden (d.h. rückwirkend). Außerdem müssen wir berechnen die zusätzlichen Terme, die für die Regression benötigt werden.\n\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  fourier(K = 1)\n\n## define intervention week \nintervention_week &lt;- yearweek(\"2008-12-31\")\n\n## define variables for regression \ncounts &lt;- counts %&gt;% \n  mutate(\n    ## corresponds to t in the formula\n      ## count of weeks (could probably also just use straight epiweeks var)\n    # linear = row_number(epiweek), \n    ## corresponds to delta(t-t0) in the formula\n      ## pre or post intervention period\n    intervention = as.numeric(epiweek &gt;= intervention_week), \n    ## corresponds to (t-t0)^+ in the formula\n      ## count of weeks post intervention\n      ## (choose the larger number between 0 and whatever comes from calculation)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n\nMit diesen Termen passen wir dann eine negative Binomialregression an und erhalten eine Tabelle mit der prozentualen Veränderung. Dieses Beispiel zeigt, dass es keine signifikante Veränderung.\nVORSICHT! Beachten Sie die Verwendung von simulate_pi = FALSE innerhalb der predict() Argument. Das liegt daran, dass das Standardverhalten von trending ist die Verwendung der ciTools Paket, um ein Vorhersageintervall zu schätzen. Das tut nicht funktioniert nicht, wenn es NA Zählungen gibt, und erzeugt auch feinere Intervalle. Siehe ?trending::predict.trending_model_fit für Details. \n\n## define the model you want to fit (negative binomial) \nmodel &lt;- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## add in whether in the pre- or post-period \n    intervention + \n    ## add in the time post intervention \n    time_post\n    )\n\n## fit your model using the counts dataset\nfitted_model &lt;- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\n\n## show estimates and percentage change in a table\nfitted_model %&gt;% \n  ## extract original negative binomial regression\n  get_model() %&gt;% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %&gt;% \n  ## only keep the intervention value \n  filter(term == \"intervention\") %&gt;% \n  ## change the IRR to percentage change for estimate and CIs \n  mutate(\n    ## for each of the columns of interest - create a new column\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## apply the formula to calculate percentage change\n            .f = function(i) 100 * (i - 1), \n      ## add a suffix to new column names with \"_perc\"\n      .names = \"{.col}_perc\")\n    ) %&gt;% \n  ## only keep (and rename) certain columns \n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)\n\nWie zuvor können wir die Ergebnisse der Regression visualisieren.\n\nestimate_res &lt;- data.frame(observed$result)\n\nggplot(estimate_res, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()\n\nWarning: Unknown or uninitialised column: `upper_pi`.\n\n\nWarning in max(observed$upper_pi): no non-missing arguments to max; returning\n-Inf",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.de.html#ressourcen",
    "href": "new_pages/time_series.de.html#ressourcen",
    "title": "23  Zeitreihen und Erkennung von Ausbrüchen",
    "section": "23.9 Ressourcen",
    "text": "23.9 Ressourcen\nforecasting: principles and practice lehrbuch\nEPIET Zeitreihenanalyse Fallstudien\nPenn State Kurs Manuskript des Überwachungspakets",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Zeitreihen und Erkennung von Ausbrüchen</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.de.html",
    "href": "new_pages/epidemic_models.de.html",
    "title": "24  Epidemie-Modellierung",
    "section": "",
    "text": "24.1 Übersicht\nEs gibt eine wachsende Zahl von Werkzeugen für die Epidemiemodellierung, mit denen wir mit minimalem Aufwand ziemlich komplexe Analysen durchführen können. Dieser Abschnitt bietet eine einen Überblick darüber, wie diese Tools eingesetzt werden können:\nEs ist nicht als Überblick über die Methodik und die statistischen Methoden gedacht Deshalb finden Sie auf der Registerkarte Ressourcen Links zu einigen dieser Tools. Papieren zu diesem Thema. Vergewissere dich, dass du Folgendes verstanden hast Methoden, bevor du diese Werkzeuge einsetzt; so kannst du sicherstellen, dass du Ergebnisse richtig interpretieren kannst.\nIm Folgenden findest du ein Beispiel für einen der Outputs, die wir in diesem Abschnitt erstellen werden.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Epidemie-Modellierung</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.de.html#übersicht",
    "href": "new_pages/epidemic_models.de.html#übersicht",
    "title": "24  Epidemie-Modellierung",
    "section": "",
    "text": "die effektive Reproduktionszahl R zu schätzent und verwandte Statistiken wie zum Beispiel die Verdopplungszeit\nkurzfristige Prognosen über die künftige Inzidenz erstellen",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Epidemie-Modellierung</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.de.html#vorbereitung",
    "href": "new_pages/epidemic_models.de.html#vorbereitung",
    "title": "24  Epidemie-Modellierung",
    "section": "24.2 Vorbereitung",
    "text": "24.2 Vorbereitung\nWir werden zwei verschiedene Methoden und Pakete für R verwendent Schätzung, nämlich EpiNow und EpiEstim sowie die Projektionen Paket für Vorhersage der Häufigkeit von Fällen.\nDieser Codeabschnitt zeigt, wie die für die Analysen benötigten Pakete geladen werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von BasisR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   epicontacts,  # Analysing transmission networks\n   EpiNow2,      # Rt estimation\n   EpiEstim,     # Rt estimation\n   projections,  # Incidence projections\n   incidence2,   # Handling incidence data\n   epitrix,      # Useful epi functions\n   distcrete     # Discrete delay distributions\n)\n\nWir werden die bereinigte Fall-Lineliste für alle Analysen in diesem Abschnitt verwenden. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen(als .rds-Datei). Siehe das [Handbuch und Daten herunterladen] Seite, um alle in diesem Handbuch verwendeten Beispieldaten herunterzuladen.\n\n# import the cleaned linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Epidemie-Modellierung</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.de.html#r-abschätzent",
    "href": "new_pages/epidemic_models.de.html#r-abschätzent",
    "title": "24  Epidemie-Modellierung",
    "section": "24.3 R abschätzent",
    "text": "24.3 R abschätzent\n\nEpiNow2 vs. EpiEstim\nDie Reproduktionszahl R ist ein Maß für die Übertragbarkeit einer Krankheit und ist definiert als die erwartete Anzahl von Folgeerkrankungen pro infiziertem Fall. In einem anfälligen Population stellt dieser Wert die Basisreproduktion Zahl R0. Da jedoch die Anzahl der anfälligen Individuen in einer einer Population im Laufe eines Ausbruchs oder einer Pandemie ändert, und da verschiedene Maßnahmen durchgeführt werden, ist das am häufigsten verwendete Maß für Übertragbarkeit ist die effektive Reproduktionszahl Rt; dies ist definiert als die erwartete Anzahl von Sekundärfällen pro infiziertem Fall zu einem bestimmten Zeit t.\nDie EpiNow2 Paket bietet den anspruchsvollsten Rahmen für die Schätzung Rt. Es hat zwei entscheidende Vorteile gegenüber dem anderen, häufig verwendeten Paket, EpiEstim:\n\nEs berücksichtigt Verzögerungen bei der Berichterstattung und kann daher R schätzent schätzen, auch wenn die aktuellen Daten unvollständig sind.\nEs schätzt Rt auf Daten der Infektion und nicht nach den Daten der Dies bedeutet, dass die Wirkung einer Intervention erst nach dem Beginn der sich sofort in einer Veränderung von Rt und nicht mit einer Verzögerung.\n\nAllerdings hat es auch zwei entscheidende Nachteile:\n\nSie erfordert die Kenntnis der Verteilung der Erzeugungszeit (d.h. die Verteilung der Verzögerungen zwischen der Infektion eines Primär- und Sekundärfalls), der Inkubationszeit Verteilung der Inkubationszeit (d. h. die Verteilung der Zeitspanne zwischen Infektion und Symptom Symptomausbruch) und jede weitere für deine Daten relevante Verzögerungsverteilung (z. B. wenn du wenn du z.B. Meldedaten hast, brauchst du die Verteilung der Zeitspanne zwischen Symptom und Auftreten bis zur Meldung). Dies ermöglicht zwar eine genauere Schätzung der Rt, EpiEstim benötigt nur die serielle Intervallverteilung (d.h. die Verteilung der Verzögerungen zwischen dem Auftreten der Symptome einer primären und einer Sekundärfall), die möglicherweise die einzige Verteilung ist, die dir zur Verfügung steht.\nEpiNow2 ist deutlich langsamer als EpiEstim anekdotisch gesehen um einen Faktor von etwa 100-1000! Zum Beispiel kann die Schätzung von Rt für die Ausbruchsstichprobe der in diesem Abschnitt betrachtet wird, dauert etwa vier Stunden (dieser Lauf wurde für eine große Iterationen durchgeführt, um eine hohe Genauigkeit zu gewährleisten, und könnte wahrscheinlich reduziert werden, wenn aber es bleibt festzuhalten, dass der Algorithmus langsam ist, wenn im Allgemeinen). Das kann unpraktikabel sein, wenn du deine Daten regelmäßig aktualisierst. Rt schätzt.\n\nFür welches Paket du dich entscheidest, hängt also von den Daten, der Zeit und Rechenressourcen ab, die dir zur Verfügung stehen.\n\n\nEpiNow2\n\nSchätzung von Verzögerungsverteilungen\nDie Verzögerungsverteilungen, die für die Ausführung EpiNow2 hängt von den Daten ab, die du haben. Im Wesentlichen musst du in der Lage sein, die Verzögerung vom Zeitpunkt der Infektion bis zum Datum des Ereignisses, das du zur Schätzung von Rt. Wenn du das Datum des Auftretens verwendest, wäre dies einfach die Inkubationszeit Verteilung. Wenn du die Meldedaten verwendest, benötigst du die Verzögerung von der Infektion bis zur Meldung. Da diese Verteilung wahrscheinlich nicht bekannt ist direkt, EpiNow2 kannst du mehrere Verzögerungsverteilungen miteinander verketten; in In diesem Fall wird die Verzögerung von der Infektion bis zum Auftreten der Symptome (z. B. die Inkubationszeit) (z. B. die Inkubationszeit, die wahrscheinlich bekannt ist) und vom Auftreten der Symptome bis zur Meldung (die du aus den Daten abschätzen kannst).\nDa wir das Datum des Auftretens der Symptome für alle unsere Fälle in der Beispieldatenbank haben, werden wir brauchen wir nur die Verteilung der Inkubationszeit, um unsere Daten zu verknüpfen (z. B. die Daten der Symptombeginns) mit dem Datum der Infektion zu verknüpfen. Wir können diese Verteilung entweder schätzen aus den Daten schätzen oder Werte aus der Literatur verwenden.\nEine Literaturschätzung für die Inkubationszeit von Ebola (aus von diesem Artikel) mit einer Mittelwert von 9,1, einer Standardabweichung von 7,3 und einem Höchstwert von 30 wäre wie folgt festgelegt:\n\nincubation_period_lit &lt;- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n\nBeachte, dass EpiNow2 verlangt, dass diese Verzögerungsverteilungen auf einer log Skala, daher die log Ruf um jeden Wert herum (außer der max Parameter, der, verwirrenderweise auf einer natürlichen Skala angegeben werden muss). Die mean_sd und sd_sd definieren die Standardabweichung der Schätzungen von Mittelwert und Standardabweichung. Als in diesem Fall nicht bekannt sind, wählen wir den recht willkürlichen Wert von 0,1.\nIn dieser Analyse schätzen wir stattdessen die Verteilung der Inkubationszeit aus der Linienliste selbst mit Hilfe der Funktion bootstrapped_dist_fit, die eine Lognormalverteilung an die beobachteten Verzögerungen zwischen Infektion und Ausbruch anpasst in der Linienliste anpasst.\n\n## estimate incubation period\nincubation_period &lt;- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n\nDie andere Verteilung, die wir benötigen, ist die Generationszeit. Da wir Daten über Infektionszeiten und Übertragungswege, können wir dies schätzen Verteilung aus der Lineliste schätzen, indem wir die Verzögerung zwischen den Infektionszeiten der Paare von Ansteckern und Infizierten. Dazu verwenden wir die praktische get_pairwise Funktion aus dem Paket epicontacts das uns erlaubt, paarweise zu berechnen Unterschiede der Linelisteneigenschaften zwischen Übertragungspaaren zu berechnen. Wir erstellen zunächst eine epicontacts-Objekt (siehe [Übertragungsketten] Seite für weitere Details):\n\n## generate contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## generate epicontacts object\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nWir passen dann die Differenz der Infektionszeiten zwischen den Übertragungspaaren an, berechnet mit get_pairwise berechnet wurde, an eine Gamma-Verteilung an:\n\n## estimate gamma generation time\ngeneration_time &lt;- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)\n\n\n\nLaufend EpiNow2\nJetzt müssen wir nur noch die tägliche Inzidenz aus der Linienliste berechnen, was wir tun können leicht mit der dplyr Funktionen group_by() und n(). Hinweis dass EpiNow2 verlangt, dass die Spaltennamen wie folgt lauten date und confirm.\n\n## get incidence from onset dates\ncases &lt;- linelist %&gt;%\n  group_by(date = date_onset) %&gt;%\n  summarise(confirm = n())\n\nWir können dann R schätzent unter Verwendung der epinow Funktion. Einige Anmerkungen zu die Eingaben:\n\nWir können eine beliebige Anzahl von “verketteten” Verzögerungsverteilungen an den delays Argument liefern; wir fügen sie einfach neben dem incubation_period Objekt innerhalb der delay_opts Funktion.\nreturn_output stellt sicher, dass die Ausgabe innerhalb von R zurückgegeben wird und nicht nur in eine Datei gespeichert wird.\nverbose gibt an, dass wir den Fortschritt auslesen wollen.\nhorizon gibt an, für wie viele Tage wir zukünftige Ereignisse hochrechnen wollen.\nWir übergeben zusätzliche Optionen an die stan Argument, um festzulegen, wie lange wir die Schlussfolgerung ausführen wollen. Erhöhen von samples und chains ergibt du eine genauere Schätzung, die die Unsicherheit besser beschreibt. dauert die Durchführung länger.\n\n\n## run epinow\nepinow_res &lt;- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)\n\n\n\nAnalyse der Ergebnisse\nWenn der Code gelaufen ist, können wir ganz einfach eine Zusammenfassung wie folgt erstellen. Scrolle das Bild, um das ganze Ausmaß zu sehen.\n\n## plot summary figure\nplot(epinow_res)\n\n\n\n\n\n\n\n\nWir können uns auch verschiedene zusammenfassende Statistiken ansehen:\n\n## summary table\nepinow_res$summary\n\n                                 measure                  estimate\n                                  &lt;char&gt;                    &lt;char&gt;\n1: New confirmed cases by infection date                4 (2 -- 6)\n2:        Expected change in daily cases                    Unsure\n3:            Effective reproduction no.        0.88 (0.73 -- 1.1)\n4:                        Rate of growth -0.012 (-0.028 -- 0.0052)\n5:          Doubling/halving time (days)          -60 (130 -- -25)\n    numeric_estimate\n              &lt;list&gt;\n1: &lt;data.table[1x9]&gt;\n2:              0.56\n3: &lt;data.table[1x9]&gt;\n4: &lt;data.table[1x9]&gt;\n5: &lt;data.table[1x9]&gt;\n\n\nFür weitere Analysen und benutzerdefinierte Diagramme kannst du auf die zusammengefassten täglichen Schätzungen über $estimates$summarised. Wir konvertieren dies von der Standard data.table in eine tibble für die einfache Verwendung mit dplyr.\n\n## extract summary and convert to tibble\nestimates &lt;- as_tibble(epinow_res$estimates$summarised)\nestimates\n\n\n\n\n\n\n\nMachen wir zum Beispiel ein Diagramm der Verdopplungszeit und Rt. Wir werden nur die ersten Monate des Ausbruchs betrachten, wenn Rt gut ist über eins, um zu vermeiden, dass extrem hohe Verdopplungszeiten gezeichnet werden.\nWir verwenden die Formel log(2)/growth_rate zur Berechnung der Verdopplungszeit aus den geschätzten Wachstumsrate.\n\n## make wide df for median plotting\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date &lt; as.Date(\"2014-09-01\")\n  ) %&gt;%\n  ## convert growth rates to doubling times\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## rename variable to reflect transformation\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## make long df for quantile plotting\ndf_long &lt;- df_wide %&gt;%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credibel\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nEpiEstim\nZum Ausführen EpiEstim zu starten, müssen wir Daten zur täglichen Inzidenz bereitstellen und die Serienintervall (d. h. die Verteilung der Zeitspannen zwischen dem Auftreten der Symptome primären und sekundären Fällen).\nInzidenzdaten können geliefert werden an EpiEstim als Vektor, als Datenrahmen oder als incidence Objekt aus dem Original Inzidenz Paket. Du kannst sogar zwischen Importen unterscheiden und lokal erworbenen Infektionen unterscheiden; siehe die Dokumentation unter ?estimate_R für weitere Einzelheiten.\nWir erstellen die Eingabe mit Inzidenz2. Siehe die Seite über [Epidemische Kurven] für weitere Beispiele mit demInzidenz2 Paket. Da es Aktualisierungen des incidence2 Paket gibt, die nicht vollständig mit dem estimateR() der erwarteten Eingabe übereinstimmen, sind einige kleine zusätzliche Schritte erforderlich. Das Inzidenzobjekt besteht aus einem Tibble mit Daten und der jeweiligen Fallzahl. Wir verwenden complete() von tidyr um sicherzustellen, dass alle Daten enthalten sind (auch die, die keine Fälle haben), und dann rename() die Spalten so an, dass sie mit dem übereinstimmen, was von estimate_R() in einem späteren Schritt.\n\n## get incidence from onset date\ncases &lt;- incidence2::incidence(linelist, date_index = \"date_onset\") %&gt;% # get case counts by day\n  tidyr::complete(date_index = seq.Date(                              # ensure all dates are represented\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %&gt;%                                       # convert NA counts to 0\n  rename(I = count,                                                   # rename to names expected by estimateR\n         dates = date_index)\n\nDas Paket bietet mehrere Optionen für die Angabe des seriellen Intervalls, das Details dazu finden sich in der Dokumentation unter ?estimate_R. Wir werden hier zwei von ihnen behandeln.\n\nVerwendung serieller Intervallschätzungen aus der Literatur\nVerwendung der Option method = \"parametric_si\" können wir manuell den Mittelwert und die Standardabweichung des seriellen Intervalls in einer config Objekt angeben, das mit der Methode Funktion make_config. Wir verwenden einen Mittelwert und eine Standardabweichung von 12,0 bzw. 5,2, die in diesem Papier:\n\n## make config\nconfig_lit &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\n\nWir können dann R schätzent mit dem estimate_R Funktion:\n\ncases &lt;- cases %&gt;% \n     filter(!is.na(date))\n\n\n#create a dataframe for the function estimate_R()\ncases_incidence &lt;- data.frame(dates = seq.Date(from = min(cases$dates),\n                               to = max(cases$dates), \n                               by = 1))\n\ncases_incidence &lt;- left_join(cases_incidence, cases) %&gt;% \n     select(dates, I) %&gt;% \n     mutate(I = ifelse(is.na(I), 0, I))\n\nJoining with `by = join_by(dates)`\n\nepiestim_res_lit &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_lit\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n\nund zeichne eine Zusammenfassung der Ergebnisse:\n\nplot(epiestim_res_lit)\n\n\n\n\n\n\n\n\n\n\nVerwendung serieller Intervallschätzungen aus den Daten\nDa wir Daten über den Zeitpunkt des Auftretens von Symptomen haben und Übertragungswege haben, können wir auch das serielle Intervall aus der Verbindungsliste schätzen, indem wir die Verzögerung berechnen zwischen den Anfangsdaten der Paare aus Ansteckendem und Angestecktem. Wie wir es in der EpiNow2 Abschnitt gemacht haben, werden wir die get_pairwise Funktion aus dem epicontacts die es uns ermöglicht, paarweise Unterschiede zwischen den Linienlisten zu berechnen. Eigenschaften zwischen Übertragungspaaren zu berechnen. Zunächst erstellen wir ein epicontacts-Objekt (siehe [Übertragungsketten] Seite für weitere Details):\n\n## generate contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## generate epicontacts object\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nDann passen wir die Differenz der Anfangsdaten zwischen den Übertragungspaaren an, die wir berechnen mit get_pairwise berechnet wurde, an eine Gamma-Verteilung an. Wir verwenden die praktische fit_disc_gamma von der epitrix Paket für dieses Anpassungsverfahren, da wir eine diskretisierte Verteilung benötigen.\n\n## estimate gamma serial interval\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\nDiese Informationen geben wir dann an die config Objekt, führen EpiEstim erneut aus und zeichne die Ergebnisse auf:\n\n## make config\nconfig_emp &lt;- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## run epiestim\nepiestim_res_emp &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_emp\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n## plot outputs\nplot(epiestim_res_emp)\n\n\n\n\n\n\n\n\n\n\nZeitfenster für die Schätzung festlegen\nDiese Standardoptionen liefern eine wöchentlich gleitende Schätzung und können als Warnung, dass du R schätztt zu früh im Ausbruch für eine genaue Schätzung. Du kannst dies ändern, indem du ein späteres Startdatum für die Schätzung einstellst (siehe unten). Leider, EpiEstim nur eine sehr eine sehr umständliche Möglichkeit, diese Schätzzeiten anzugeben, da du eine Vektor von ganzen Zahlen die sich auf das Start- und Enddatum für jede Zeit beziehen Fenster.\n\n## define a vector of dates starting on June 1st\nstart_dates &lt;- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %&gt;%\n  ## subtract the starting date to convert to numeric\n  `-`(min(cases$dates)) %&gt;%\n  ## convert to integer\n  as.integer()\n\n## add six days for a one week sliding window\nend_dates &lt;- start_dates + 6\n  \n## make config\nconfig_partial &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n\nJetzt führen wir erneut aus EpiEstim und sehen, dass die Schätzungen erst im Juni beginnen:\n\n## run epiestim\nepiestim_res_partial &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## plot outputs\nplot(epiestim_res_partial)\n\n\n\n\n\n\n\n\n\n\nAnalyse der Ergebnisse\nAuf die wichtigsten Ausgaben kann zugegriffen werden über $R. Als Beispiel werden wir einen Plot erstellen von Rt und ein Maß für das “Übertragungspotenzial”, das durch das Produkt aus Rt und die Anzahl der an diesem Tag gemeldeten Fälle; dies stellt die die erwartete Anzahl der Fälle in der nächsten Generation der Infektion.\n\n## make wide dataframe for median\ndf_wide &lt;- epiestim_res_lit$R %&gt;%\n  rename_all(clean_labels) %&gt;%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %&gt;%\n  mutate(\n    ## extract the median date from t_start and t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %&gt;%\n  ## merge in daily incidence data\n  left_join(cases, \"dates\") %&gt;%\n  ## calculate risk across all r estimates\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %&gt;%\n  ## seperate r estimates and risk estimates\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %&gt;%\n  ## assign factor levels\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make long dataframe from quantiles\ndf_long &lt;- df_wide %&gt;%\n  select(-variable, -median) %&gt;%\n  ## seperate r/risk estimates and quantile levels\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %&gt;%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Epidemie-Modellierung</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.de.html#projektion-der-inzidenz",
    "href": "new_pages/epidemic_models.de.html#projektion-der-inzidenz",
    "title": "24  Epidemie-Modellierung",
    "section": "24.4 Projektion der Inzidenz",
    "text": "24.4 Projektion der Inzidenz\n\nEpiNow2\nNeben der Schätzung von Rt, EpiNow2 unterstützt auch die Vorhersage von Rt und Hochrechnungen von Fallzahlen durch Integration mit dem EpiSoon Paket unter der Haube. Alles, was du tun musst, ist die Angabe der horizon Argument in deinem epinow Funktionsaufruf das Argument angeben, wie viele Tage du in die Zukunft projizieren willst; siehe die EpiNow2 Abschnitt unter “Schätzung Rt” für Details, wie man EpiNow2 zum Laufen bringt. In diesem Abschnitt werden wir nur die Ergebnisse dieser Analyse darstellen, die in der epinow_res Objekt gespeichert sind.\n\n## define minimum date for plot\nmin_date &lt;- as.Date(\"2015-03-01\")\n\n## extract summarised estimates\nestimates &lt;-  as_tibble(epinow_res$estimates$summarised)\n\n## extract raw data on case incidence\nobservations &lt;- as_tibble(epinow_res$estimates$observations) %&gt;%\n  filter(date &gt; min_date)\n\n## extract forecasted estimates of case numbers\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date &gt; min_date\n  )\n\n## convert to even longer format for quantile plotting\ndf_long &lt;- df_wide %&gt;%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\nProjektionen\nDie Projektionen von RECON entwickelte Paket macht es sehr einfach, kurze kurzfristige Inzidenzprognosen zu erstellen, für die lediglich die Kenntnis der effektiven Reproduktion Zahl Rt und das serielle Intervall. Hier werden wir behandeln, wie man serielle Intervallschätzungen aus der Literatur verwenden und wie wir unsere eigenen Schätzungen verwenden aus der Lineliste.\n\nVerwendung von seriellen Intervallschätzungen aus der Literatur\nProjektionen erfordert eine diskretisierte serielle Intervallverteilung der Klasse distcrete aus dem Paket distcrete. Wir werden eine Gamma-Verteilung verwenden mit einem Mittelwert von 12,0 und einer Standardabweichung von 5,2, die in diesem Papier. An diese Werte in die Form- und Skalenparameter umzuwandeln, die für ein Gamma Verteilung benötigt werden, verwenden wir die Funktion gamma_mucv2shapescale aus der epitrix Paket.\n\n## get shape and scale parameters from the mean mu and the coefficient of\n## variation (e.g. the ratio of the standard deviation to the mean)\nshapescale &lt;- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## make distcrete object\nserial_interval_lit &lt;- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n\nHier ist ein kurzer Check, um sicherzustellen, dass das serielle Intervall richtig aussieht. Wir greifen auf die Dichte der Gamma-Verteilung zu, die wir gerade definiert haben, indem wir $d, die ist gleichbedeutend mit dem Aufruf dgamma:\n\n## check to make sure the serial interval looks correct\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\n\n\nVerwendung serieller Intervallschätzungen aus den Daten\nDa wir Daten über das Datum des Auftretens der Symptome haben und Übertragungswege haben, können wir auch das serielle Intervall aus der Verbindungsliste schätzen, indem wir die Verzögerung berechnen zwischen den Anfangsdaten der Paare aus Ansteckendem und Angestecktem. Wie wir es in der EpiNow2 Abschnitt gemacht haben, werden wir die get_pairwise Funktion aus dem epicontacts Paket, mit der wir paarweise Unterschiede zwischen den Linienlisten berechnen können Eigenschaften zwischen Übertragungspaaren zu berechnen. Zunächst erstellen wir ein epicontacts-Objekt (siehe [Übertragungsketten] Seite für weitere Details):\n\n## generate contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## generate epicontacts object\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nDann passen wir die Differenz der Anfangsdaten zwischen den Übertragungspaaren an, die wir berechnen mit get_pairwise berechnet wurde, an eine Gamma-Verteilung an. Wir verwenden die praktische fit_disc_gamma von der epitrix Paket für dieses Anpassungsverfahren, da wir eine diskretisierte Verteilung benötigen.\n\n## estimate gamma serial interval\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspect estimate\nserial_interval[c(\"mu\", \"sd\")]\n\n$mu\n[1] 11.51047\n\n$sd\n[1] 7.696056\n\n\n\n\nProjektion der Inzidenz\nUm die zukünftige Inzidenz zu prognostizieren, müssen wir noch die historische Inzidenz in Form einer incidence Objekts sowie eine Stichprobe von plausiblen Rt Werte. Wir werden diese Werte mithilfe der Rt Schätzungen, die von EpiEstim im vorherigen Abschnitt (unter “Schätzung Rt”) und gespeichert in der epiestim_res_emp Objekt. Im folgenden Code, extrahieren wir die Schätzungen für den Mittelwert und die Standardabweichung von Rt für die das letzte Zeitfenster des Ausbruchs (unter Verwendung der tail Funktion, um auf das letzte Element in einem Vektor) und simulieren 1000 Werte aus einer Gamma-Verteilung mit rgamma. Du kannst auch deinen eigenen Vektor von R bereitstellent Werten angeben, die du für die Vorwärtsprojektion verwenden willst.\n\n## create incidence object from dates of onset\ninc &lt;- incidence::incidence(linelist$date_onset)\n\n256 missing observations were removed.\n\n## extract plausible r values from most recent estimate\nmean_r &lt;- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r &lt;- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale &lt;- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r &lt;- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## check distribution\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWir verwenden dann die project() Funktion, um die eigentliche Prognose zu erstellen. Wir legen fest, wie viele Tage wir prognostizieren wollen, indem wir die n_days Argumente an und geben die Anzahl der Simulationen mit der Option n_sim Argument.\n\n## make projection\nproj &lt;- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n\nDann können wir die Inzidenz und die Projektionen mit der Funktion plot() und add_projections() Funktionen. Wir können ganz einfach eine Untermenge der incidence Objekt nur auf nur die neuesten Fälle anzuzeigen, indem wir den Operator für eckige Klammern verwenden.\n\n## plot incidence and projections\nplot(inc[inc$dates &gt; as.Date(\"2015-03-01\")]) %&gt;%\n  add_projections(proj)\n\n\n\n\n\n\n\n\nDu kannst auch ganz einfach die rohen Schätzungen der täglichen Fallzahlen extrahieren, indem du indem du die Ausgabe in einen Datenrahmen umwandelst.\n\n## convert to data frame for raw data\nproj_df &lt;- as.data.frame(proj)\nproj_df",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Epidemie-Modellierung</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.de.html#ressourcen",
    "href": "new_pages/epidemic_models.de.html#ressourcen",
    "title": "24  Epidemie-Modellierung",
    "section": "24.5 Ressourcen",
    "text": "24.5 Ressourcen\n\nHier ist das Papier das beschreibt. die Methodik, die in EpiEstim.\nHier ist das Papier das beschreibt. die Methodik, die in EpiNow2.\nHier ist ein Papier das beschreibt. verschiedene methodische und praktische Überlegungen zur Schätzung von Rt.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Epidemie-Modellierung</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.de.html",
    "href": "new_pages/contact_tracing.de.html",
    "title": "25  Ermittlung von Kontaktpersonen",
    "section": "",
    "text": "25.1 Vorbereitung",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Ermittlung von Kontaktpersonen</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.de.html#vorbereitung",
    "href": "new_pages/contact_tracing.de.html#vorbereitung",
    "title": "25  Ermittlung von Kontaktpersonen",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,          # importing data  \n  here,         # relative file pathways  \n  janitor,      # data cleaning and tables\n  lubridate,    # working with dates\n  epikit,       # age_categories() function\n  apyramid,     # age pyramids\n  tidyverse,    # data manipulation and visualization\n  RColorBrewer, # color palettes\n  formattable,  # fancy tables\n  kableExtra    # table formatting\n)\n\n\n\nDaten importieren\nWir werden Beispieldatensätze von Kontakten und deren “Follow-up” importieren. Diese Daten wurden von der Go.Data API abgerufen und unverschachtelt als “.rds”-Dateien gespeichert.\nDu kannst alle Beispieldaten für dieses Handbuch auf der Seite [Handbuch und Daten herunterladen] Seite herunterladen.\nWenn du die Beispiel-Daten zur Ermittlung von Kontaktpersonen speziell für diese Seite herunterladen möchtest, benutze die drei Download-Links unten:\n Klicke zum Herunterladen die Fallermittlungsdaten (.rds-Datei) \n Klicken Sie zum Herunterladen die Daten der Kontaktregistrierung (.rds-Datei) \n Klick zum Herunterladen die Daten zur Kontaktverfolgung (.rds-Datei) \n\n\n\nIn ihrer ursprünglichen Form in den herunterladbaren Dateien spiegeln die Daten die Daten wider, die von der Go.Data API bereitgestellt werden (erfahre mehr über APIs hier). Für das Beispiel hier werden wir die Daten bereinigen, damit sie auf dieser Seite leichter zu lesen sind. Wenn du eine Go.Data-Instanz verwendest, findest du eine vollständige Anleitung, wie du deine Daten abrufen kannst hier.\nIm Folgenden werden die Datensätze mit der Methode import() Funktion aus der rioPaket. Siehe die Seite über [Import und Export] für verschiedene Möglichkeiten, Daten zu importieren. Wir verwendenhere() um den Dateipfad anzugeben - du solltest den spezifischen Dateipfad für deinen Computer angeben. Wir verwenden dann select() um nur bestimmte Spalten der Daten auszuwählen, um sie für die Demonstration zu vereinfachen.\n\nFalldaten\nDiese Daten sind eine Tabelle mit den Fällen und Informationen über sie.\n\ncases &lt;- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %&gt;% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)\n\nHier sind die nrow(cases) Fälle:\n\n\n\n\n\n\n\n\nDaten der Kontakte\nDiese Daten sind eine Tabelle mit allen Kontakten und Informationen über sie. Auch hier kannst du deinen eigenen Dateipfad angeben. Nach dem Import führen wir ein paar Schritte zur Datenbereinigung durch:\n\nAltersklasse als Faktor festlegen und die Reihenfolge der Ebenen umkehren, so dass die jüngeren Altersklassen an erster Stelle stehen\nNur bestimmte Spalten auswählen und eine davon umbenennen\nZeilen mit fehlender Admin-Ebene 2 künstlich “Djembe” zuordnen, um die Übersichtlichkeit einiger Beispielvisualisierungen zu verbessern\n\n\ncontacts &lt;- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %&gt;% \n  mutate(age_class = forcats::fct_rev(age_class)) %&gt;% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %&gt;% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))\n\nHier sind die nrow(contacts) Zeilen des contacts Datensatzes:\n\n\n\n\n\n\n\n\nFollow-up Daten\nBei diesen Daten handelt es sich um Aufzeichnungen über die “Follow-up”-Interaktionen mit den Kontaktpersonen. Jeder Kontakt sollte 14 Tage lang jeden Tag eine Begegnung haben.\nWir importieren die Daten und führen ein paar Bereinigungsschritte durch. Wir wählen bestimmte Spalten aus und konvertieren außerdem eine Zeichenspalte in Kleinbuchstaben.\n\nfollowups &lt;- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %&gt;% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %&gt;% \n  mutate(followup_status = str_to_lower(followup_status))\n\nHier sind die ersten 50 Zeilen der nrow(followups)-Zeile followups Datensatzes (jede Zeile ist eine Folgeinteraktion, wobei der Ergebnisstatus in der followup_status Spalte):\n\n\n\n\n\n\n\n\nBeziehungsdaten\nHier importieren wir Daten, die die Beziehung zwischen Fällen und Kontakten zeigen. Wir wählen bestimmte Spalten aus, die angezeigt werden sollen.\n\nrelationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)\n\nNachfolgend sind die ersten 50 Zeilen der relationships Datensatzes, der alle Beziehungen zwischen Fällen und Kontakten aufzeichnet.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Ermittlung von Kontaktpersonen</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.de.html#deskriptive-analysen",
    "href": "new_pages/contact_tracing.de.html#deskriptive-analysen",
    "title": "25  Ermittlung von Kontaktpersonen",
    "section": "25.2 Deskriptive Analysen",
    "text": "25.2 Deskriptive Analysen\nDu kannst die Techniken, die auf anderen Seiten dieses Handbuchs behandelt werden, nutzen, um beschreibende Analysen deiner Fälle, Kontakte und ihrer Beziehungen durchzuführen. Im Folgenden findest du einige Beispiele.\n\nDemografische Daten\nWie auf der Seite über [Demografische Pyramiden][Demografische Pyramiden und Likert-Skalen] beschrieben, kannst du die Alters- und Geschlechtsverteilung visualisieren (hier verwenden wir dieapyramide Paket).\n\nAlter und Geschlecht der Kontakte\nIn der folgenden Pyramide wird die Altersverteilung der Kontakte nach Geschlecht verglichen. Beachte, dass Kontakte, denen das Alter fehlt, in einem eigenen Balken oben aufgeführt werden. Du kannst dieses Standardverhalten ändern, aber dann solltest du die Anzahl der fehlenden Kontakte in einer Überschrift aufführen.\n\napyramid::age_pyramid(\n  data = contacts,                                   # use contacts dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"gender\") +                             # gender for halfs of pyramid\n  labs(\n    fill = \"Gender\",                                 # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # title of the plot\n  theme_minimal()                                    # simple background\n\n\n\n\n\n\n\n\nMit der Go.Data-Datenstruktur kann die relationships Datensatz die Altersangaben von Fällen und Kontakten. Du könntest also diesen Datensatz verwenden und eine Alterspyramide erstellen, die die Unterschiede zwischen diesen beiden Personengruppen zeigt. Die relationshipsDatenrahmen wird mutiert, um die numerischen Altersspalten in Kategorien umzuwandeln (siehe die [Datenbereinigung und Kernfunktionen] Seite). Wir pivotieren den Datenrahmen auch länger, um das Plotten mitggplot2(siehe [Pivotieren von Daten]).\n\nrelation_age &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  transmute(                              # transmute is like mutate() but removes all other columns not mentioned\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %&gt;% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # pivot longer\n\n\nrelation_age\n\n# A tibble: 200 × 2\n   category         age_class\n   &lt;chr&gt;            &lt;fct&gt;    \n 1 source_age_class 80+      \n 2 target_age_class 15-19    \n 3 source_age_class &lt;NA&gt;     \n 4 target_age_class 50-54    \n 5 source_age_class &lt;NA&gt;     \n 6 target_age_class 20-24    \n 7 source_age_class 30-34    \n 8 target_age_class 45-49    \n 9 source_age_class 40-44    \n10 target_age_class 30-34    \n# ℹ 190 more rows\n\n\nJetzt können wir diesen transformierten Datensatz mit age_pyramid() wie zuvor zeichnen, aber anstelle von gender durch category (Kontakt, oder Fall).\n\napyramid::age_pyramid(\n  data = relation_age,                               # use modified relationship dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"category\") +                           # by cases and contacts\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # to specify colors AND labels\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts and cases\")+ # title of the plot\n  theme_minimal()                                              # simple background\n\n\n\n\n\n\n\n\nWir können uns auch andere Merkmale wie die berufliche Aufteilung ansehen (z. B. in Form eines Kreisdiagramms).\n\n# Clean dataset and get counts by occupation\nocc_plot_data &lt;- cases %&gt;% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # make NA missing values a category\n         occupation = forcats::fct_infreq(occupation)) %&gt;%   # order factor levels in order of frequency\n  count(occupation)                                          # get counts by occupation\n  \n# Make pie chart\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Known occupations of COVID-19 cases\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nKontakte pro Fall\nDie Anzahl der Kontakte pro Fall kann eine wichtige Kennzahl sein, um die Qualität der Kontaktzählung und die Bereitschaft der Bevölkerung, auf die Maßnahmen der öffentlichen Gesundheit zu reagieren, zu beurteilen.\nJe nach deiner Datenstruktur kann dies mit einem Datensatz bewertet werden, der alle Fälle und Kontakte enthält. In den Go.Data-Datensätzen werden die Verbindungen zwischen Fällen (“Quellen”) und Kontakten (“Ziele”) in den relationships Dataset gespeichert.\nIn diesem Datensatz ist jede Zeile ein Kontakt, und der Quellfall ist in der Zeile aufgeführt. Es gibt keine Kontakte, die Beziehungen zu mehreren Fällen haben, aber wenn es sie gibt, musst du sie vor dem Plotten berücksichtigen (und sie auch untersuchen!).\nWir beginnen damit, die Anzahl der Zeilen (Kontakte) pro Ausgangsfall zu zählen. Dies wird als Datenrahmen gespeichert.\n\ncontacts_per_case &lt;- relationships %&gt;% \n  count(source_visualid)\n\ncontacts_per_case\n\n   source_visualid  n\n1   CASE-2020-0001 13\n2   CASE-2020-0002  5\n3   CASE-2020-0003  2\n4   CASE-2020-0004  4\n5   CASE-2020-0005  5\n6   CASE-2020-0006  3\n7   CASE-2020-0008  3\n8   CASE-2020-0009  3\n9   CASE-2020-0010  3\n10  CASE-2020-0012  3\n11  CASE-2020-0013  5\n12  CASE-2020-0014  3\n13  CASE-2020-0016  3\n14  CASE-2020-0018  4\n15  CASE-2020-0022  3\n16  CASE-2020-0023  4\n17  CASE-2020-0030  3\n18  CASE-2020-0031  3\n19  CASE-2020-0034  4\n20  CASE-2020-0036  1\n21  CASE-2020-0037  3\n22  CASE-2020-0045  3\n23            &lt;NA&gt; 17\n\n\nWir verwenden geom_histogram() um diese Daten als Histogramm darzustellen.\n\nggplot(data = contacts_per_case)+        # begin with count data frame created above\n  geom_histogram(mapping = aes(x = n))+  # print histogram of number of contacts per case\n  scale_y_continuous(expand = c(0,0))+   # remove excess space below 0 on y-axis\n  theme_light()+                         # simplify background\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Ermittlung von Kontaktpersonen</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.de.html#kontaktverfolgung",
    "href": "new_pages/contact_tracing.de.html#kontaktverfolgung",
    "title": "25  Ermittlung von Kontaktpersonen",
    "section": "25.3 Kontaktverfolgung",
    "text": "25.3 Kontaktverfolgung\nDaten zur Ermittlung von Kontaktpersonen enthalten oft “Follow-up”-Daten, die die Ergebnisse der täglichen Symptomkontrollen von Personen in Quarantäne aufzeichnen. Die Analyse dieser Daten kann Aufschluss über die Reaktionsstrategie geben und Kontaktpersonen identifizieren, bei denen das Risiko besteht, dass sie nicht mehr weiterverfolgt werden können oder dass sie erkranken.\n\nDatenbereinigung\nDiese Daten können in einer Vielzahl von Formaten vorliegen. Sie können als Excel-Tabelle im “Breitformat” mit einer Zeile pro Kontakt und einer Spalte pro Follow-up-Tag vorliegen. Siehe [Pivotierung von Daten] findest du eine Beschreibung von “langen” und “breiten” Daten und wie du Daten breiter oder länger machen kannst.\nIn unserem Go.Data-Beispiel werden diese Daten in der Datei followups Datenrahmen gespeichert, der in einem “langen” Format mit einer Zeile pro Folgeinteraktion vorliegt. Die ersten 50 Zeilen sehen wie folgt aus:\n\n\n\n\n\n\nVORSICHT! Hüte dich vor Duplikaten, wenn du mit Nachverfolgungsdaten arbeitest, denn es könnte mehrere fehlerhafte Nachverfolgungen am selben Tag für einen bestimmten Kontakt geben. Vielleicht scheint es ein Fehler zu sein, aber es spiegelt die Realität wider - z.B. könnte ein Kontaktverfolger früh am Tag ein Nachverfolgungsformular einreichen, wenn er den Kontakt nicht erreichen konnte, und ein zweites Formular einreichen, wenn er ihn später erreicht hat. Es hängt vom betrieblichen Kontext ab, wie du mit Duplikaten umgehen willst - achte nur darauf, dass du deine Vorgehensweise klar dokumentierst. \nLos geht’s siehe wie viele “doppelte” Zeilen wir haben:\n\nfollowups %&gt;% \n  count(contact_id, date_of_followup) %&gt;%   # get unique contact_days\n  filter(n &gt; 1)                             # view records where count is more than 1  \n\n  contact_id date_of_followup n\n1       &lt;NA&gt;       2020-09-03 2\n2       &lt;NA&gt;       2020-09-04 2\n3       &lt;NA&gt;       2020-09-05 2\n\n\nIn unseren Beispieldaten sind die einzigen Datensätze, auf die dies zutrifft, diejenigen, denen eine ID fehlt! Diese können wir entfernen. Zur Veranschaulichung zeigen wir dir die Schritte zum Entfernen der Duplikation, damit es nur einen Nachverfolger pro Person und Tag gibt. Siehe die Seite über [De-Duplizierung] für weitere Details. Wir gehen davon aus, dass der letzte Datensatz der richtige ist. Wir nutzen auch die Gelegenheit, diefollowup_number Spalte (der “Tag” der Nachuntersuchung, der zwischen 1 und 14 liegen sollte) zu bereinigen.\n\nfollowups_clean &lt;- followups %&gt;%\n  \n  # De-duplicate\n  group_by(contact_id, date_of_followup) %&gt;%        # group rows per contact-day\n  arrange(contact_id, desc(date_of_followup)) %&gt;%   # arrange rows, per contact-day, by date of follow-up (most recent at top)\n  slice_head() %&gt;%                                  # keep only the first row per unique contact id  \n  ungroup() %&gt;% \n  \n  # Other cleaning\n  mutate(followup_number = replace(followup_number, followup_number &gt; 14, NA)) %&gt;% # clean erroneous data\n  drop_na(contact_id)                               # remove rows with missing contact_id\n\nFür jede Nachuntersuchung haben wir einen Nachuntersuchungsstatus (z. B. ob die Untersuchung stattgefunden hat und wenn ja, ob der Kontakt Symptome hatte oder nicht). Um alle Werte zu sehen, können wir eine schnelle tabyl() (von Hausmeister) oder table() (von BasisR) (siehe [Beschreibende Tabellen]) durchfollowup_status um die Häufigkeit der einzelnen Ergebnisse zu sehen.\nIn diesem Datensatz bedeutet “seen_not_ok” “mit Symptomen gesehen”, und “seen_ok” bedeutet “ohne Symptome gesehen”.\n\nfollowups_clean %&gt;% \n  tabyl(followup_status)\n\n followup_status   n    percent\n          missed  10 0.02325581\n   not_attempted   5 0.01162791\n   not_performed 319 0.74186047\n     seen_not_ok   6 0.01395349\n         seen_ok  90 0.20930233\n\n\n\n\nPlotten über die Zeit\nDa die Daten kontinuierlich sind, werden wir ein Histogramm verwenden, um sie mit date_of_followup der x-Achse zugewiesen. Wir können ein “gestapeltes” Histogramm erstellen, indem wir eine fill = Argument innerhalb aes() angeben, das wir der Spalte followup_status. Folglich kannst du den Titel der Legende mit der Option fill = Argument von labs().\nWir sehen, dass die Kontaktpersonen in Wellen identifiziert wurden (die vermutlich mit den Epidemiewellen der Fälle übereinstimmen) und dass sich die Nachverfolgung im Laufe der Epidemie nicht verbessert zu haben scheint.\n\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # show all factor levels (followup_status) in the legend, even those not used\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # dynamic subtitle\n\n\n\n\n\n\n\n\nVORSICHT! Wenn du viele Diagramme vorbereitest (z. B. für mehrere Gerichtsbarkeiten), solltest du darauf achten, dass die Legenden auch bei unterschiedlichem Grad der Datenvervollständigung oder Datenzusammensetzung gleich aussehen. Es kann vorkommen, dass nicht alle Nachverfolgungsstatus in den Daten vorhanden sind, aber du möchtest trotzdem, dass diese Kategorien in den Legenden erscheinen. In ggplots (wie oben) kannst du die drop = FALSE Argument der scale_fill_discrete(). In Tabellen verwendest du tabyl() die die Anzahl für alle Faktorstufen anzeigt, oder wenn du count() von dplyr füge das Argument .drop = FALSE um die Zählungen für alle Faktorstufen einzubeziehen.\n\n\nTägliches individuelles Tracking\nWenn dein Ausbruch klein genug ist, möchtest du vielleicht jeden Kontakt einzeln betrachten und seinen Status im Verlauf der Nachverfolgung sehen. Zum Glück ist dies followups Datensatz bereits eine Spalte mit der Tages-“Nummer” der Nachuntersuchung (1-14). Wenn diese Spalte in deinen Daten nicht vorhanden ist, kannst du sie erstellen, indem du die Differenz zwischen dem Datum der Begegnung und dem Datum, an dem die Nachsorge für den Kontakt beginnen sollte, berechnest.\nEin praktischer Visualisierungsmechanismus (wenn die Zahl der Fälle nicht zu groß ist) kann ein Heatplot sein, der mit geom_tile(). Weitere Details findest du in der [Wärmebilddarstellung] Seite.\n\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # grey gridlines\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))\n\n\n\n\n\n\n\n\n\n\nAnalyse nach Gruppe\nVielleicht werden diese Nachverfolgungsdaten auf täglicher oder wöchentlicher Basis für betriebliche Entscheidungen betrachtet. Vielleicht möchtest du eine aussagekräftigere Untergliederung nach geografischen Gebieten oder nach Kontaktverfolgungsteams. Wir können dies erreichen, indem wir die Spalten folgendermaßen anpassen group_by().\n\nplot_by_region &lt;- followups_clean %&gt;%                                        # begin with follow-up dataset\n  count(admin_1_name, admin_2_name, followup_status) %&gt;%   # get counts by unique region-status (creates column 'n' with counts)\n  \n  # begin ggplot()\n  ggplot(                                         # begin ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # reorder admin factor levels by the numeric values in column 'n'\n                  y = n,                            # heights of bar from column 'n'\n                  fill = followup_status,           # color stacked bars by their status\n                  label = n))+                      # to pass to geom_label()              \n  geom_col()+                                     # stacked bars, mapping inherited from above \n  geom_text(                                      # add text, mapping inherited from above\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # Simplify background\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # introduce facets \n\nplot_by_region",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Ermittlung von Kontaktpersonen</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.de.html#kpi-tabellen",
    "href": "new_pages/contact_tracing.de.html#kpi-tabellen",
    "title": "25  Ermittlung von Kontaktpersonen",
    "section": "25.4 KPI-Tabellen",
    "text": "25.4 KPI-Tabellen\nEs gibt eine Reihe verschiedener Leistungsindikatoren (Key Performance Indicators, KPIs), die auf verschiedenen Untergliederungsebenen und über verschiedene Zeiträume hinweg berechnet und verfolgt werden können, um die Leistung der Kontaktverfolgung zu überwachen. Wenn du dir die Berechnungen und das grundlegende Tabellenformat einmal zurechtgelegt hast, ist es relativ einfach, die verschiedenen KPIs auszutauschen.\nEs gibt zahlreiche Quellen für KPIs zur Ermittlung von Kontaktpersonen, wie zum Beispiel diese von ResolveToSaveLives.org. Der größte Teil der Arbeit besteht darin, deine Datenstruktur durchzugehen und alle Einschluss- und Ausschlusskriterien zu durchdenken. Im Folgenden zeigen wir ein paar Beispiele, die die Go.Data-Metadatenstruktur verwenden:\n\n\n\n\n\n\n\n\n\nKategorie\nIndikator\nGo.Data Zähler\nGo.Data Nenner\n\n\n\n\nProzessindikator - Geschwindigkeit der Kontaktverfolgung\n% der Fälle, die innerhalb von 24 Stunden nach der Fallmeldung befragt und isoliert wurden\nANZAHL DER case_id WO (date_of_reporting -\n\n\n\n\ndate_of_data_entry) &lt; 1 Tag AND (isolation_startdate - date_of_data_entry) &lt; 1 Tag | ZAEHLUNG VON case_id | | Prozessindikator - Geschwindigkeit der Kontaktverfolgung | % der Kontakte, die innerhalb von 24 Stunden nach der Kontaktaufnahme benachrichtigt und unter Quarantäne gestellt wurden | ANZAHL DER contact_id WO followup_status == “SEEN_NOT_OK” ODER “SEEN_OK” UND date_of_followup - date_of_reporting &lt; 1 Tag | ZAEHLUNG VON contact_id | | Prozessindikator - Vollständigkeit der Tests | % neue symptomatische Fälle, die innerhalb von 3 Tagen nach Auftreten der Symptome getestet und befragt werden | ANZAHL DER case_id WO (date_of_reporting - date_of_onset) &lt; =3 Tage | ZAEHLUNG VON case_id | | Ergebnisindikator - Insgesamt | % neue Fälle in der bestehenden Kontaktliste | ANZAHL DER case_id WO was_contact == “TRUE” | ZAEHLUNG VON case_id |\nIm Folgenden werden wir ein Beispiel für die Erstellung einer schönen Tabelle zur Anzeige der Kontaktverfolgung in den Verwaltungsbereichen durchgehen. Am Ende werden wir die Tabelle für die Präsentation mit dem formattable Paket (du kannst aber auch andere Pakete verwenden wie flextable- siehe [Tabellen für die Präsentation]).\nWie du eine solche Tabelle erstellst, hängt von der Struktur deiner Begleitpersonendaten ab. Verwende die [Beschreibende Tabellen] Seite, um zu erfahren, wie du Daten zusammenfassen kannst, indem dudplyr Funktionen.\nWir werden eine Tabelle erstellen, die dynamisch ist und sich ändert, wenn sich die Daten ändern. Um die Ergebnisse interessant zu machen, werden wir eine report_date ein, damit wir die Tabelle an einem bestimmten Tag simulieren können (wir wählen den 10. Juni 2020). Die Daten werden auf dieses Datum gefiltert.\n\n# Set \"Report date\" to simulate running the report with data \"as of\" this date\nreport_date &lt;- as.Date(\"2020-06-10\")\n\n# Create follow-up data to reflect the report date.\ntable_data &lt;- followups_clean %&gt;% \n  filter(date_of_followup &lt;= report_date)\n\nBasierend auf unserer Datenstruktur machen wir nun Folgendes:\n\nBeginnen wir mit der followups Daten und fassen sie so zusammen, dass sie für jeden einzelnen Kontakt enthalten:\n\n\nDas Datum der letzten Aufzeichnung (unabhängig vom Status der Begegnung)\nDas Datum der letzten Begegnung, bei der der Kontakt “gesehen” wurde\nDer Status der letzten Begegnung, bei der der Kontakt “gesehen” wurde (z. B. mit Symptomen, ohne Symptome)\n\n\nVerbinde diese Daten mit den Kontaktdaten, die weitere Informationen enthalten, wie z. B. den allgemeinen Kontaktstatus, das Datum der letzten Exposition gegenüber einem Fall usw. Außerdem werden wir für jeden Kontakt interessante Kennzahlen berechnen, z. B. die Tage seit der letzten Exposition.\nWir gruppieren die erweiterten Kontaktdaten nach geografischen Regionen (admin_2_name) und berechnen zusammenfassende Statistiken pro Region\nZum Schluss formatieren wir die Tabelle für die Präsentation schön\n\nZuerst fassen wir die Folgedaten zusammen, um die Informationen zu erhalten, die uns interessieren:\n\nfollowup_info &lt;- table_data %&gt;% \n  group_by(contact_id) %&gt;% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %&gt;% \n  ungroup()\n\nSo sehen diese Daten aus:\n\n\n\n\n\n\nJetzt fügen wir diese Informationen der contacts Datensatz hinzufügen und einige zusätzliche Spalten berechnen.\n\ncontacts_info &lt;- followup_info %&gt;% \n  right_join(contacts, by = \"contact_id\") %&gt;% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\n\nSo sehen diese Daten aus. Hinweis contacts Spalte auf der rechten Seite und die neue berechnete Spalte ganz rechts.\n\n\n\n\n\n\nAls Nächstes fassen wir die Kontaktdaten nach Regionen zusammen, um einen übersichtlichen Datenrahmen mit zusammenfassenden statistischen Spalten zu erhalten.\n\ncontacts_table &lt;- contacts_info %&gt;% \n  \n  group_by(`Admin 2` = admin_2_name) %&gt;%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure &lt; 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure &gt;= 8 & days_since_exposure &lt; 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen &gt;= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %&gt;% \n    \n  arrange(desc(`Registered contacts`))\n\n\n\n\n\n\n\nUnd jetzt wenden wir das Styling der formattable und knitr Pakete, einschließlich einer Fußnote, die das “As of”-Datum anzeigt.\n\ncontacts_table %&gt;%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %&gt;%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %&gt;%\n  kable_styling(\"hover\", full_width = FALSE) %&gt;%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %&gt;% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf contacts currently under follow up\n\n\nStatus of last visit\n\n\n\nAdmin 2\nRegistered contacts\nActive contacts\nIn first week\nIn second week\nBecame case\nLost to follow up\nNever seen\nFollowed up - signs\nFollowed up - no signs\nNot Followed up\n\n\n\n\nDjembe \n59\n30\n44\n0\n2\n15\n22\n0\n0\n0\n\n\nTrumpet\n3\n1\n3\n0\n0\n0\n0\n0\n0\n0\n\n\nVenu \n2\n0\n0\n0\n2\n0\n2\n0\n0\n0\n\n\nCongas \n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\nCornet \n1\n0\n1\n0\n1\n0\n1\n0\n0\n0\n\n\n\nNote: \n\n\n\n\n\n\n\n\n\n\n\n\n Data are current to Jun 10 2020",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Ermittlung von Kontaktpersonen</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.de.html#übertragungsmatrizen",
    "href": "new_pages/contact_tracing.de.html#übertragungsmatrizen",
    "title": "25  Ermittlung von Kontaktpersonen",
    "section": "25.5 Übertragungsmatrizen",
    "text": "25.5 Übertragungsmatrizen\nWie im Abschnitt [Wärmediagramme] beschrieben, kannst du eine Matrix erstellen, die zeigt, wer wen infiziert hat, indem dugeom_tile().\nWenn neue Kontakte erstellt werden, speichert Go.Data diese Beziehungsinformationen in der relationships API-Endpunkt. Wir sehen die ersten 50 Zeilen dieses Datensatzes unten. Das bedeutet, dass wir mit relativ wenigen Schritten ein Wärmebild erstellen können, da jeder Kontakt bereits mit seinem Ausgangsfall verknüpft ist.\n\n\n\n\n\n\nWie oben bei der Alterspyramide, die Fälle und Kontakte vergleicht, können wir die wenigen Variablen auswählen, die wir brauchen, und Spalten mit kategorischen Altersgruppen sowohl für die Quellen (Fälle) als auch für die Ziele (Kontakte) erstellen.\n\nheatmap_ages &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  mutate(                              # transmute is like mutate() but removes all other columns\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \n\nWie zuvor beschrieben, erstellen wir Kreuztabellen;\n\ncross_tab &lt;- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab\n\n            target_cases\nsource_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54\n       0-4     0   0     0     0     0     0     0     0     0     1     0\n       5-9     0   0     1     0     0     0     0     1     0     0     0\n       10-14   0   0     0     0     0     0     0     0     0     0     0\n       15-19   0   0     0     0     0     0     0     0     0     0     0\n       20-24   1   1     0     1     2     0     2     1     0     0     0\n       25-29   1   2     0     0     0     0     0     0     0     0     0\n       30-34   0   0     0     0     0     0     0     0     1     1     0\n       35-39   0   2     0     0     0     0     0     0     0     1     0\n       40-44   0   0     0     0     1     0     2     1     0     3     1\n       45-49   1   2     2     0     0     0     3     0     1     0     3\n       50-54   1   2     1     2     0     0     1     0     0     3     4\n       55-59   0   1     0     0     1     1     2     0     0     0     0\n       60-64   0   0     0     0     0     0     0     0     0     0     0\n       65-69   0   0     0     0     0     0     0     0     0     0     0\n       70-74   0   0     0     0     0     0     0     0     0     0     0\n       75-79   0   0     0     0     0     0     0     0     0     0     0\n       80+     1   0     0     2     1     0     0     0     1     0     0\n            target_cases\nsource_cases 55-59 60-64 65-69 70-74 75-79 80+\n       0-4       1     0     0     0     0   0\n       5-9       1     0     0     0     0   0\n       10-14     0     0     0     0     0   0\n       15-19     0     0     0     0     0   0\n       20-24     1     0     0     0     0   1\n       25-29     0     0     0     0     0   0\n       30-34     1     0     0     0     0   0\n       35-39     0     0     0     0     0   0\n       40-44     1     0     0     0     1   1\n       45-49     2     1     0     0     0   1\n       50-54     1     0     1     0     0   1\n       55-59     0     0     0     0     0   0\n       60-64     0     0     0     0     0   0\n       65-69     0     0     0     0     0   0\n       70-74     0     0     0     0     0   0\n       75-79     0     0     0     0     0   0\n       80+       0     0     0     0     0   0\n\n\nin ein Langformat mit Proportionen umwandeln;\n\nlong_prop &lt;- data.frame(prop.table(cross_tab))\n\nund erstelle eine Heatmap für das Alter.\n\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = target_cases,         # x-axis is case age\n      y = source_cases,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # labels\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Ermittlung von Kontaktpersonen</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.de.html#ressourcen",
    "href": "new_pages/contact_tracing.de.html#ressourcen",
    "title": "25  Ermittlung von Kontaktpersonen",
    "section": "25.6 Ressourcen",
    "text": "25.6 Ressourcen\nhttps://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting\nhttps://worldhealthorganization.github.io/godata/\nhttps://community-godata.who.int/",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Ermittlung von Kontaktpersonen</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html",
    "href": "new_pages/survey_analysis.de.html",
    "title": "26  Umfrage-Analyse",
    "section": "",
    "text": "26.1 Übersicht\nDiese Seite demonstriert die Verwendung verschiedener Pakete für die Umfrageanalyse.\nDie meisten Umfrage-R-Pakete basieren auf dem Umfrage Paket um eine gewichtete Analyse durchzuführen. Wir verwenden Umfrage als auch srvyr (ein Wrapper für Umfrage die eine Codierung im Stil von Tidyverse ermöglicht) und gtsummary (ein Wrapper für Umfrage die es ermöglicht, Tabellen zu veröffentlichen). Während die ursprüngliche Umfrage Paket keine Kodierung im Tidyverse-Stil zulässt, hat es den zusätzlichen Vorteil, dass es umfragegewichtete generalisierte lineare Modelle (die wir zu einem späteren Zeitpunkt auf dieser Seite hinzufügen werden). Wir werden auch die Verwendung einer Funktion aus der sitrep Paket, um Stichprobengewichte zu erstellen (n.b Dieses Paket ist derzeit noch nicht auf CRAN verfügbar, kann aber von github installiert werden).\nDer Großteil dieser Seite basiert auf der Arbeit für die “R4Epis” Projekt; Für detaillierten Code und R-markdown Vorlagen siehe die “R4Epis” github Seite. Einige der Umfrage paketbasierte Code basiert auf frühen Versionen von EPIET-Fallstudien.\nDiese Seite befasst sich derzeit nicht mit der Berechnung des Stichprobenumfangs oder der Probenahme. Einen einfach zu bedienenden Stichprobenberechner findest du unter OpenEpi. Die GIS-Grundlagen Seite des Handbuchs einen Abschnitt über räumliche Zufallsstichproben enthalten, und diese Seite wird einen Abschnitt über Stichprobenrahmen und die Berechnung des Stichprobenumfangs enthalten.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#übersicht",
    "href": "new_pages/survey_analysis.de.html#übersicht",
    "title": "26  Umfrage-Analyse",
    "section": "",
    "text": "Umfragedaten\nBeobachtungszeit\nGewichtung\nEntwurfsobjekte der Umfrage\nDeskriptive Analyse\nGewichtete Proportionen\nGewichtete Raten",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#vorbereitung",
    "href": "new_pages/survey_analysis.de.html#vorbereitung",
    "title": "26  Umfrage-Analyse",
    "section": "26.2 Vorbereitung",
    "text": "26.2 Vorbereitung\n\nPakete\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und es zur Verwendung lädt. Du kannst Pakete auch laden mit library() von BasisR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\nHier demonstrieren wir auch die Verwendung des p_load_gh() Funktion von pacman um ein Paket von Github zu installieren und zu laden, das noch nicht auf CRAN veröffentlicht worden ist.\n\n## load packages from CRAN\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               survey,       # for survey functions\n               srvyr,        # dplyr wrapper for survey package\n               gtsummary,    # wrapper for survey package to produce tables\n               apyramid,     # a package dedicated to creating age pyramids\n               patchwork,    # for combining ggplots\n               ggforce       # for alluvial/sankey plots\n               ) \n\n## load packages from github\npacman::p_load_gh(\n     \"R4EPI/sitrep\"          # for observation time / weighting functions\n)\n\n\n\nDaten laden\nDer in diesem Abschnitt verwendete Beispieldatensatz:\n\nDaten aus der fiktiven Sterblichkeitserhebung.\nfiktive Bevölkerungszahlen für das Erhebungsgebiet.\nDatenwörterbuch für die fiktiven Daten der Sterblichkeitserhebung.\n\nEs basiert auf der von der Ethikkommission der MSF OCA genehmigten Erhebung. Die fiktive Datensatz wurde im Rahmen der “R4Epis”-Projekts. Dies alles basiert auf Daten, die mit KoboToolbox, eine Software zur Datenerfassung, die auf Open Data Kit.\nMit Kobo kannst du sowohl die gesammelten Daten als auch das Datenwörterbuch exportieren. für diesen Datensatz zu exportieren. Wir empfehlen dies dringend, da es die Datenbereinigung vereinfacht. und ist nützlich, um Variablen/Fragen nachzuschlagen.\nTIPP: Das Kobo Datenwörterbuch hat variable Namen in der Spalte “Name” auf dem Erhebungsbogen. Mögliche Werte für jede Variable sind in der Tabelle “Auswahl” angegeben. In der Registerkarte “Choices” hat “Name” den verkürzten Wert und die “label::english” und “label::french” haben die entsprechenden langen Versionen. Die Verwendung der epidict Paket msf_dict_survey() Funktion zum Importieren eines Kobo Wörterbuch-Excel-Datei zu importieren, wird diese für dich umformatiert, damit du sie einfach zum Umkodieren verwenden kannst. \nVORSICHT! Der Beispieldatensatz ist nicht derselbe wie ein Export (wie in Kobo exportierst du verschiedene Fragebogenebenen einzeln)\n\nsiehe den Abschnitt mit den Umfragedaten unten, um die verschiedenen Ebenen zusammenzuführen.\n\nDer Datensatz wird mit dem import() Funktion aus der rio Paket. Siehe die Seite auf Import und Export für verschiedene Möglichkeiten, Daten zu importieren.\n\n# import the survey data\nsurvey_data &lt;- rio::import(\"survey_data.xlsx\")\n\n# import the dictionary into R\nsurvey_dict &lt;- rio::import(\"survey_dict.xlsx\") \n\nDie ersten 10 Zeilen der Umfrage werden unten angezeigt.\n\n\n\n\n\n\nWir wollen auch die Daten der Stichprobenpopulation importieren, damit wir die geeignete Gewichte erstellen können. Diese Daten können in verschiedenen Formaten vorliegen, aber wir möchten Wir würden jedoch vorschlagen, dass sie wie unten abgebildet aussehen (sie können einfach in eine Excel-Datei eingegeben werden).\n\n# import the population data\npopulation &lt;- rio::import(\"population.xlsx\")\n\nDie ersten 10 Zeilen der Umfrage werden unten angezeigt.\n\n\n\n\n\n\nBei Clustererhebungen möchtest du vielleicht Erhebungsgewichte auf Clusterebene hinzufügen. Du kannst diese Daten wie oben beschrieben einlesen. Wenn es nur einige wenige Zählungen gibt, kannst du sie alternativ wie folgt eingeben in ein Tibble. In jedem Fall brauchst du eine Spalte mit einer Clusterkennung, die der mit deinen Umfragedaten übereinstimmt, und eine weitere Spalte mit der Anzahl der Haushalte in jedem Cluster.\n\n## define the number of households in each cluster\ncluster_counts &lt;- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))\n\n\n\nSaubere Daten\nIm Folgenden wird sichergestellt, dass die Datumsspalte das richtige Format hat. Es gibt verschiedene andere Möglichkeiten, dies zu tun (siehe die Arbeiten mit Datumsangaben Seite), aber mit dem Wörterbuch ist es schnell und einfach, Daten zu definieren.\nWir erstellen auch eine Altersgruppenvariable, indem wir die age_categories() Funktion von epikit - siehe Daten bereinigen Handbuch für Details. Außerdem erstellen wir eine Zeichenvariable, die definiert, welcher Bezirk die verschiedenen Cluster sind.\nSchließlich kodieren wir alle Ja/Nein-Variablen in WAHR/FALSCH-Variablen um - andernfalls können diese nicht von der Umfrage Proportionsfunktionen.\n\n## select the date variable names from the dictionary \nDATEVARS &lt;- survey_dict %&gt;% \n  filter(type == \"date\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## filter to match the column names of your data\n  pull(name) # select date vars\n  \n## change to dates \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## add those with only age in months to the year variable (divide by twelve)\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## define age group variable\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## create a character variable based off groups of a different variable \nsurvey_data &lt;- survey_data %&gt;% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## select the yes/no variable names from the dictionary \nYNVARS &lt;- survey_dict %&gt;% \n  filter(type == \"yn\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## filter to match the column names of your data\n  pull(name) # select yn vars\n  \n## change to dates \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(all_of(YNVARS), str_detect, pattern = \"yes\")`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#umfrage-daten",
    "href": "new_pages/survey_analysis.de.html#umfrage-daten",
    "title": "26  Umfrage-Analyse",
    "section": "26.3 Umfrage-Daten",
    "text": "26.3 Umfrage-Daten\nEs gibt zahlreiche verschiedene Stichprobenpläne, die für Umfragen verwendet werden können. Hier werden wir Code für demonstrieren:\n\nStratifiziert\nCluster\nStratifiziert und geclustert\n\nWie oben beschrieben (je nachdem, wie du deinen Fragebogen gestaltest), werden die Daten für für jede Ebene als separater Datensatz aus Kobo exportiert werden. In unserem Beispiel gibt es gibt es eine Ebene für Haushalte und eine Ebene für Einzelpersonen innerhalb dieser Haushalte.\nDiese beiden Ebenen sind durch einen eindeutigen Identifikator verbunden. Für den Kobo-Datensatz ist diese Variable “_index” auf Haushaltsebene, die mit dem “_parent_index” auf der individuellen Ebene übereinstimmt. Dadurch werden neue Zeilen für den Haushalt mit jeder passenden Person erstellt, siehe den Abschnitt im Handbuch über Verknüpfung für Details.\n\n## join the individual and household data to form a complete data set\nsurvey_data &lt;- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## create a unique identifier by combining indeces of the two levels \nsurvey_data &lt;- survey_data %&gt;% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#beobachtungszeit",
    "href": "new_pages/survey_analysis.de.html#beobachtungszeit",
    "title": "26  Umfrage-Analyse",
    "section": "26.4 Beobachtungszeit",
    "text": "26.4 Beobachtungszeit\nFür Mortalitätserhebungen wollen wir wissen, wie lange jede Person in der um eine angemessene Sterblichkeitsrate für unseren Zeitraum berechnen zu können von Interesse zu berechnen. Dies ist nicht für alle Erhebungen relevant, aber insbesondere für die Sterblichkeit Sterblichkeitserhebungen ist dies wichtig, da sie häufig unter mobilen oder vertriebenen Menschen durchgeführt werden. Bevölkerungsgruppen durchgeführt werden.\nDazu legen wir zunächst den Zeitraum fest, der uns interessiert, auch bekannt als Recall (d.h. die Zeit, die die Teilnehmer bei der Beantwortung ihrer Fragen angeben sollen). Fragen). Diesen Zeitraum können wir dann nutzen, um unpassende Daten als fehlend zu markieren, d.h. wenn Todesfälle von außerhalb des interessierenden Zeitraums gemeldet werden.\n\n## set the start/end of recall period\n## can be changed to date variables from dataset \n## (e.g. arrival date & date questionnaire)\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end   = as.Date(\"2018-05-01\")\n  )\n\n\n# set inappropriate dates to NA based on rules \n## e.g. arrivals before start, departures departures after end\nsurvey_data &lt;- survey_data %&gt;%\n      mutate(\n           arrived_date = if_else(arrived_date &lt; recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date &lt; recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date &gt; recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date &gt; recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n\nMit unseren Datumsvariablen können wir dann das Start- und Enddatum für jede Person festlegen. Wir können die find_start_date() Funktion von sitrep um die Ursachen für und dann die Differenz zwischen den Tagen (Personenzeit) zu berechnen.\nStartdatum: Frühestes geeignetes Ankunftsdatum innerhalb deines Rückrufzeitraums Entweder der Beginn deines Rückrufzeitraums (den du im Voraus festlegst), oder ein Datum nach Beginn des Rückrufs, falls zutreffend (z. B. Ankünfte oder Geburten)\nEnddatum: Frühestes geeignetes Abgangsereignis innerhalb deines Rückrufzeitraums Entweder das Ende deines Rückrufzeitraums oder ein Datum vor dem Ende des Rückrufs falls zutreffend (z. B. Abgänge, Todesfälle)\n\n## create new variables for start and end dates/causes\nsurvey_data &lt;- survey_data %&gt;% \n     ## choose earliest date entered in survey\n     ## from births, household arrivals, and camp arrivals \n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end   = \"recall_end\",\n                  datecol      = \"startdate\",\n                  datereason   = \"startcause\" \n                 ) %&gt;%\n     ## choose earliest date entered in survey\n     ## from camp departures, death and end of the study\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end   = \"recall_end\",\n                datecol      = \"enddate\",\n                datereason   = \"endcause\" \n               )\n\n\n## label those that were present at the start/end (except births/deaths)\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(\n       ## fill in start date to be the beginning of recall period (for those empty) \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## set the start cause to present at start if equal to recall period \n       ## unless it is equal to the birth date \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## fill in end date to be end of recall period (for those empty) \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## set the end cause to present at end if equall to recall end \n       ## unless it is equal to the death date\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## Define observation time in days\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(obstime = as.numeric(enddate - startdate))",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#gewichtung",
    "href": "new_pages/survey_analysis.de.html#gewichtung",
    "title": "26  Umfrage-Analyse",
    "section": "26.5 Gewichtung",
    "text": "26.5 Gewichtung\nEs ist wichtig, dass du fehlerhafte Beobachtungen streichst, bevor du die Gewichte der Umfrage hinzufügst. Wenn du zum Beispiel Beobachtungen mit negativer Beobachtungszeit hast, musst du überprüfen (dies kannst du mit der Funktion assert_positive_timespan() Funktion von sitrep. Eine andere Sache ist, wenn du leere Zeilen löschen willst (z.B. mit drop_na(uid)) oder Duplikate entfernen willst (siehe Handbuchabschnitt über [Entdoppelung] für Details). Diejenigen, die keine Zustimmung haben, müssen ebenfalls gelöscht werden.\nIn diesem Beispiel filtern wir nach den Fällen, die wir löschen wollen, und speichern sie in einem separaten Datenrahmen - so können wir diejenigen beschreiben, die von der Umfrage ausgeschlossen wurden. Dann verwenden wir die anti_join() Funktion von dplyr um diese weggelassenen Fälle zu entfernen aus unseren Umfragedaten zu entfernen.\nGEFAHR! Du kannst keine fehlenden Werte in deiner Gewichtsvariable oder einer der für deinen Erhebungsentwurf relevanten Variablen haben (z. B. Alter, Geschlecht, Schicht- oder Clustervariablen).\n\n## store the cases that you drop so you can describe them (e.g. non-consenting \n## or wrong village/cluster)\ndropped &lt;- survey_data %&gt;% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## use the dropped cases to remove the unused rows from the survey data set  \nsurvey_data &lt;- anti_join(survey_data, dropped, by = names(dropped))\n\nWie oben erwähnt, zeigen wir, wie du Gewichte für drei verschiedene Studien hinzufügen kannst (Stratified, Cluster und Stratified Cluster). Diese erfordern Informationen über die Grundgesamtheit und/oder die befragten Cluster. Wir verwenden für dieses Beispiel den geschichteten Cluster-Code, aber je nachdem, welcher Code der für dein Studiendesign am besten geeignet ist.\n\n# stratified ------------------------------------------------------------------\n# create a variable called \"surv_weight_strata\"\n# contains weights for each individual - by age group, sex and health district\nsurvey_data &lt;- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## cluster ---------------------------------------------------------------------\n\n# get the number of people of individuals interviewed per household\n# adds a variable with counts of the household (parent) index variable\nsurvey_data &lt;- survey_data %&gt;%\n  add_count(index, name = \"interviewed\")\n\n\n## create cluster weights\nsurvey_data &lt;- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# stratified and cluster ------------------------------------------------------\n# create a survey weight for cluster and strata\nsurvey_data &lt;- survey_data %&gt;%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#entwurfsobjekte-der-umfrage",
    "href": "new_pages/survey_analysis.de.html#entwurfsobjekte-der-umfrage",
    "title": "26  Umfrage-Analyse",
    "section": "26.6 Entwurfsobjekte der Umfrage",
    "text": "26.6 Entwurfsobjekte der Umfrage\nErstelle ein Umfragedesign-Objekt entsprechend deines Studienentwurfs. Wird wie ein Datenrahmen zur Berechnung von Gewichtsanteilen usw. verwendet. Vergewissere dich, dass alle notwendigen Variablen zuvor erstellt wurden.\nEs gibt vier Optionen, kommentiere die aus, die du nicht verwendest:\n\nEinfach zufällig\nGeschichtet\nCluster\nGeschichtetes Cluster\n\nFür diese Vorlage tun wir so, als ob wir die Umfragen in zwei separaten Clustern schichten (Gesundheitsbezirke A und B). Um Gesamtschätzungen zu erhalten, müssen wir also Cluster- und Schichtgewichte kombinieren.\nWie bereits erwähnt, gibt es zwei Pakete, die dies ermöglichen. Das klassische Variante ist Umfrage und dann gibt es noch ein Wrapper-Paket namens srvyr das tidyverse-freundliche Objekte und Funktionen erstellt. Wir werden beides demonstrieren, aber beachte, dass der Großteil des Codes in diesem Kapitel die srvyr basierte Objekte. Die einzige Ausnahme ist, dass die gtsummary Paket nur akzeptiert Umfrage Objekte.\n\n26.6.1 Übersicht Paket\nDie Umfrage Paket nutzt effektiv Basis R Kodierung und ist daher nicht möglich, Pipes zu verwenden (%&gt;%) oder andere dplyr Syntax. Mit der Umfrage Paket verwenden wir die svydesign() Funktion, um eine Umfrage zu definieren Objekt mit entsprechenden Clustern, Gewichten und Schichten.\nHINWEIS: wir müssen die tilde verwenden (~) vor den Variablen verwenden, da das Paket die Basis R Syntax der Zuweisung von Variablen auf der Grundlage von Formeln. \n\n# simple random ---------------------------------------------------------------\nbase_survey_design_simple &lt;- svydesign(ids = ~1, # 1 for no cluster ids\n                   weights = NULL,               # No weight added\n                   strata = NULL,                # sampling was simple (no strata)\n                   data = survey_data            # have to specify the dataset\n                  )\n\n## stratified ------------------------------------------------------------------\nbase_survey_design_strata &lt;- svydesign(ids = ~1,  # 1 for no cluster ids\n                   weights = ~surv_weight_strata, # weight variable created above\n                   strata = ~health_district,     # sampling was stratified by district\n                   data = survey_data             # have to specify the dataset\n                  )\n\n# cluster ---------------------------------------------------------------------\nbase_survey_design_cluster &lt;- svydesign(ids = ~village_name, # cluster ids\n                   weights = ~surv_weight_cluster, # weight variable created above\n                   strata = NULL,                 # sampling was simple (no strata)\n                   data = survey_data              # have to specify the dataset\n                  )\n\n# stratified cluster ----------------------------------------------------------\nbase_survey_design &lt;- svydesign(ids = ~village_name,      # cluster ids\n                   weights = ~surv_weight_cluster_strata, # weight variable created above\n                   strata = ~health_district,             # sampling was stratified by district\n                   data = survey_data                     # have to specify the dataset\n                  )\n\n\n\n26.6.2 Srvyr Paket\nMit dem srvyr Paket können wir die as_survey_design() Funktion, die die gleichen Argumente wie oben hat, aber Pipes erlaubt (%&gt;%), und deshalb müssen wir nicht die Tilde (~).\n\n## simple random ---------------------------------------------------------------\nsurvey_design_simple &lt;- survey_data %&gt;% \n  as_survey_design(ids = 1, # 1 for no cluster ids \n                   weights = NULL, # No weight added\n                   strata = NULL # sampling was simple (no strata)\n                  )\n## stratified ------------------------------------------------------------------\nsurvey_design_strata &lt;- survey_data %&gt;%\n  as_survey_design(ids = 1, # 1 for no cluster ids\n                   weights = surv_weight_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )\n## cluster ---------------------------------------------------------------------\nsurvey_design_cluster &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster, # weight variable created above\n                   strata = NULL # sampling was simple (no strata)\n                  )\n\n## stratified cluster ----------------------------------------------------------\nsurvey_design &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#deskriptive-analyse",
    "href": "new_pages/survey_analysis.de.html#deskriptive-analyse",
    "title": "26  Umfrage-Analyse",
    "section": "26.7 Deskriptive Analyse",
    "text": "26.7 Deskriptive Analyse\nGrundlegende deskriptive Analysen und Visualisierungen werden ausführlich in anderen in anderen Kapiteln des Handbuchs ausführlich behandelt, so dass wir hier nicht näher darauf eingehen werden. Einzelheiten findest du in den Kapiteln über Beschreibende Tabellen, statistische Tests, Tabellen für die Präsentation, ggplot Grundlagen und R Markdown Berichte.\nIn diesem Abschnitt werden wir uns darauf konzentrieren, wie du Verzerrungen in deiner Stichprobe untersuchst und visualisierst. Wir werden uns auch mit der Visualisierung von Bevölkerungsströmen in einer Umfrage befassen. Anschwemmungs-/Sankey-Diagramme.\nGenerell solltest du die folgenden deskriptiven Analysen in Betracht ziehen:\n\nEndgültige Anzahl von Clustern, Haushalten und Einzelpersonen\nAnzahl der ausgeschlossenen Personen und die Gründe für den Ausschluss\nMittlere (Bandbreite) Anzahl der Haushalte pro Cluster und Personen pro Haushalt\n\n\n26.7.1 Stichprobenverzerrung\nVergleiche die Proportionen in jeder Altersgruppe zwischen deiner Stichprobe und der Grundgesamtheit. Das ist wichtig, um eine mögliche Verzerrung der Stichprobe zu erkennen. Du könntest dies auch wiederholen, indem du die Verteilung nach Geschlecht betrachtest.\nBeachte, dass diese p-Werte nur indikativ sind und eine beschreibende Diskussion (oder (oder die Visualisierung mit den Alterspyramiden unten) der Verteilungen in deiner Stichprobe im Vergleich zur Ausgangspopulation ist wichtiger als der Binomialtest selbst. Das liegt daran, dass eine Erhöhung des Stichprobenumfangs in den meisten Fällen dazu führt, dass Unterschiede, die nach der Gewichtung deiner Daten irrelevant sein können.\n\n## counts and props of the study population\nag &lt;- survey_data %&gt;% \n  group_by(age_group) %&gt;% \n  drop_na(age_group) %&gt;% \n  tally() %&gt;% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## counts and props of the source population\npropcount &lt;- population %&gt;% \n  group_by(age_group) %&gt;%\n    tally(population) %&gt;%\n    mutate(proportion = n / sum(n))\n\n## bind together the columns of two tables, group by age, and perform a \n## binomial test to see if n/total is significantly different from population\n## proportion.\n  ## suffix here adds to text to the end of columns in each of the two datasets\nleft_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %&gt;%\n  group_by(age_group) %&gt;%\n  ## broom::tidy(binom.test()) makes a data frame out of the binomial test and\n  ## will add the variables p.value, parameter, conf.low, conf.high, method, and\n  ## alternative. We will only use p.value here. You can include other\n  ## columns if you want to report confidence intervals\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %&gt;%\n  unnest(cols = c(binom)) %&gt;% # important for expanding the binom.test data frame\n  mutate(proportion_pop = proportion_pop * 100) %&gt;%\n  ## Adjusting the p-values to correct for false positives \n  ## (because testing multiple age groups). This will only make \n  ## a difference if you have many age categories\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %&gt;%\n                      \n  ## Only show p-values over 0.001 (those under report as &lt;0.001)\n  mutate(p.value = ifelse(p.value &lt; 0.001, \n                          \"&lt;0.001\", \n                          as.character(round(p.value, 3)))) %&gt;% \n  \n  ## rename the columns appropriately\n  select(\n    \"Age group\" = age_group,\n    \"Study population (n)\" = n,\n    \"Study population (%)\" = proportion,\n    \"Source population (n)\" = n_pop,\n    \"Source population (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )\n\n# A tibble: 5 × 6\n# Groups:   Age group [5]\n  `Age group` `Study population (n)` `Study population (%)`\n  &lt;chr&gt;                        &lt;int&gt;                  &lt;dbl&gt;\n1 0-2                             12                 0.0256\n2 3-14                            42                 0.0896\n3 15-29                           64                 0.136 \n4 30-44                           52                 0.111 \n5 45+                            299                 0.638 \n# ℹ 3 more variables: `Source population (n)` &lt;dbl&gt;,\n#   `Source population (%)` &lt;dbl&gt;, `P-value` &lt;chr&gt;\n\n\n\n\n26.7.2 Demografische Pyramiden\nDemografische Pyramiden (oder Alters-Geschlechts-Pyramiden) sind eine einfache Möglichkeit, die Verteilung der Bevölkerung zu visualisieren. in deiner Umfragepopulation zu visualisieren. Es lohnt sich auch, die Erstellung von beschreibende Tabellen des Alters und Geschlecht nach Erhebungsschichten. Wir werden anhand der apyramid Paket verwenden, da es gewichtete Proportionen mit unserem oben erstellten Umfrageentwurfsobjekt. Andere Optionen für die Erstellung demografischen Pyramiden werden in diesem Kapitel des Handbuchs ausführlich behandelt. Wir werden auch eine Wrapper-Funktion von apyramid namens age_pyramid() was ein paar Zeilen spart Codierung für die Erstellung eines Plots mit Proportionen einspart.\nWie beim formalen Binomialtest für Unterschiede, der oben in der Stichprobenverzerrung Abschnitt beschrieben, geht es hier darum, zu visualisieren, ob unsere Stichprobenpopulation sich wesentlich von der Ausgangspopulation unterscheidet und ob die Gewichtung die diesen Unterschied ausgleicht. Dazu verwenden wir die Patchwork Paket, um unsere ggplot Visualisierungen nebeneinander darzustellen; für Details siehe den Abschnitt über Kombinieren von Plots in ggplot-Tipps Kapitel des Handbuchs. Wir werden unsere Ausgangspopulation, unsere ungewichtete Umfragepopulation und unsere gewichtete Grundgesamtheit. Du kannst dir auch überlegen, ob du die einzelnen Schichten deiner Erhebung visualisieren willst - in unserem Beispiel in unserem Beispiel wäre das mit dem Argument stack_by  = \"health_district\" (siehe ?plot_age_pyramid für Details).\nHINWEIS: Die x- und y-Achsen sind in Pyramiden gespiegelt \n\n## define x-axis limits and labels ---------------------------------------------\n## (update these numbers to be the values for your graph)\nmax_prop &lt;- 35      # choose the highest proportion you want to show \nstep &lt;- 5           # choose the space you want beween labels \n\n## this part defines vector using the above numbers with axis breaks\nbreaks &lt;- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## this part defines vector using the above numbers with axis limits\nlimits &lt;- c(max_prop/100 * -1, max_prop/100)\n\n## this part defines vector using the above numbers with axis labels\nlabels &lt;-  c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## create plots individually  --------------------------------------------------\n\n## plot the source population \n## nb: this needs to be collapsed for the overall population (i.e. removing health districts)\nsource_population &lt;- population %&gt;%\n  ## ensure that age and sex are factors\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %&gt;% \n  group_by(age_group, sex) %&gt;% \n  ## add the counts for each health district together \n  summarise(population = sum(population)) %&gt;% \n  ## remove the grouping so can calculate overall proportion\n  ungroup() %&gt;% \n  mutate(proportion = population / sum(population)) %&gt;% \n  ## plot pyramid \n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## only show the y axis label (otherwise repeated in all three plots)\n  labs(title = \"Source population\", \n       y = \"\", \n       x = \"Age group (years)\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## plot the unweighted sample population \nsample_population &lt;- age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Unweighted sample population\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## plot the weighted sample population \nweighted_population &lt;- survey_design %&gt;% \n  ## make sure the variables are factors\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %&gt;%\n  age_pyramid(\n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Weighted sample population\", \n       y = \"\", \n       x = \"\")  + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## combine all three plots  ----------------------------------------------------\n## combine three plots next to eachother using + \nsource_population + sample_population + weighted_population + \n  ## only show one legend and define theme \n  ## note the use of & for combining theme with plot_layout()\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\",                    # move legend to bottom\n        legend.title = element_blank(),                # remove title\n        text = element_text(size = 18),                # change text size\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # turn x-axis text\n       )\n\n\n\n\n\n\n\n\n\n\n26.7.3 Alluvial/Sankey-Diagramm\nDie Visualisierung von Ausgangspunkten und Ergebnissen für Einzelpersonen kann sehr hilfreich sein, um einen Überblick zu bekommen. Die Anwendung für mobile Bevölkerungsgruppen ist ziemlich offensichtlich, aber es gibt auch zahlreiche andere Anwendungsmöglichkeiten, z. B. für Kohorten oder jede andere Situation in denen es Zustandsübergänge für Individuen gibt. Diese Diagramme haben mehrere verschiedene Namen, darunter Anschwemmungen, Sankey und Parallelmengen - die Details sind im Kapitel des Handbuchs über Diagramme und Tabellen.\n\n## summarize data\nflow_table &lt;- survey_data %&gt;%\n  count(startcause, endcause, sex) %&gt;%  # get counts \n  gather_set_data(x = c(\"startcause\", \"endcause\"))     # change format for plotting\n\n\n## plot your dataset \n  ## on the x axis is the start and end causes\n  ## gather_set_data generates an ID for each possible combination\n  ## splitting by y gives the possible start/end combos\n  ## value as n gives it as counts (could also be changed to proportion)\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## colour lines by sex \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) +\n  ## fill in the label boxes grey\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") +\n  ## change text colour and angle (needs to be adjusted)\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) +\n  ## remove axis labels\n  theme_void()+\n  ## move legend to bottom\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#gewichtete-proportionen",
    "href": "new_pages/survey_analysis.de.html#gewichtete-proportionen",
    "title": "26  Umfrage-Analyse",
    "section": "26.8 Gewichtete Proportionen",
    "text": "26.8 Gewichtete Proportionen\nIn diesem Abschnitt wird beschrieben, wie du Tabellen für gewichtete Zählungen und Anteile erstellst, mit den dazugehörigen Konfidenzintervallen und dem Designeffekt. Es gibt vier verschiedene Optionen, die Funktionen aus den folgenden Paketen verwenden: Umfrage, srvyr, sitrep und gtsummary. Für minimale Codierung, um eine Standard-Epidemiologie-Tabelle zu erstellen, würden wir empfehlen die sitrep Funktion - die ein Wrapper ist für srvyr Code ist; beachte dass dieser noch nicht auf CRAN ist und sich in Zukunft ändern kann. Ansonsten ist der Umfrage Code wahrscheinlich langfristig am stabilsten sein, während srvyr am besten in die Arbeitsabläufe von tidyverse passen wird. Während gtsummary Funktionen viel Potenzial haben, scheinen sie experimentell und unvollständig zu sein zum Zeitpunkt des Schreibens.\n\n26.8.1 Umfrage Paket\nWir können das svyciprop() Funktion aus Umfrage um gewichtete Proportionen zu erhalten und die dazugehörigen 95%-Konfidenzintervalle zu erhalten. Ein geeigneter Designeffekt kann sein extrahiert werden, indem die svymean() anstelle von svyprop() Funktion. Es ist erwähnenswert, dass svyprop() anscheinend nur Variablen zwischen 0 und 1 (oder TRUE/FALSE) zu akzeptieren, sodass kategorische Variablen nicht funktionieren.\nHINWEIS: Funktionen von Umfrage auch akzeptieren srvyr Designobjekte, aber hier haben wir die Umfrage Entwurfsobjekt verwendet, nur um die Konsistenz zu gewährleisten \n\n## produce weighted counts \nsvytable(~died, base_survey_design)\n\ndied\n     FALSE       TRUE \n1406244.43   76213.01 \n\n## produce weighted proportions\nsvyciprop(~died, base_survey_design, na.rm = T)\n\n              2.5% 97.5%\ndied 0.0514 0.0208  0.12\n\n## get the design effect \nsvymean(~died, base_survey_design, na.rm = T, deff = T) %&gt;% \n  deff()\n\ndiedFALSE  diedTRUE \n 3.755508  3.755508 \n\n\nWir können die Funktionen von Umfrage zu einer Funktion kombinieren, die die wir im Folgenden selbst definieren, genannt svy_prop; und wir können diese Funktion dann verwenden zusammen mit map() aus dem Paket purrr verwenden, um über mehrere Variablen zu iterieren und eine Tabelle zu erstellen. Siehe das Handbuch Iteration Kapitel für Details zu purrr.\n\n# Define function to calculate weighted counts, proportions, CI and design effect\n# x is the variable in quotation marks \n# design is your survey design object\n\nsvy_prop &lt;- function(design, x) {\n  \n  ## put the variable of interest in a formula \n  form &lt;- as.formula(paste0( \"~\" , x))\n  ## only keep the TRUE column of counts from svytable\n  weighted_counts &lt;- svytable(form, design)[[2]]\n  ## calculate proportions (multiply by 100 to get percentages)\n  weighted_props &lt;- svyciprop(form, design, na.rm = TRUE) * 100\n  ## extract the confidence intervals and multiply to get percentages\n  weighted_confint &lt;- confint(weighted_props) * 100\n  ## use svymean to calculate design effect and only keep the TRUE column\n  design_eff &lt;- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## combine in to one data frame\n  full_table &lt;- cbind(\n    \"Variable\"        = x,\n    \"Count\"           = weighted_counts,\n    \"Proportion\"      = weighted_props,\n    weighted_confint, \n    \"Design effect\"   = design_eff\n    )\n  \n  ## return table as a dataframe\n  full_table &lt;- data.frame(full_table, \n             ## remove the variable names from rows (is a separate column now)\n             row.names = NULL)\n  \n  ## change numerics back to numeric\n  full_table[ , 2:6] &lt;- as.numeric(full_table[, 2:6])\n  \n  ## return dataframe\n  full_table\n}\n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  svy_prop, design = base_survey_design) %&gt;% \n  ## collapse list in to a single data frame\n  bind_rows() %&gt;% \n  ## round \n  mutate(across(where(is.numeric), round, digits = 1))\n\n  Variable    Count Proportion X2.5. X97.5. Design.effect\n1     left 701199.1       47.3  39.2   55.5           2.4\n2     died  76213.0        5.1   2.1   12.1           3.8\n3  arrived 761799.0       51.4  40.9   61.7           3.9\n\n\n\n\n26.8.2 Srvyr Paket\nMit srvyr können wir dplyr Syntax verwenden, um eine Tabelle zu erstellen. Beachte, dass die survey_mean() Funktion verwendet wird und das Proportionsargument angegeben wird, und dass dieselbe Funktion auch zur Berechnung des Designeffekts verwendet wird. Das liegt daran, dass srvyr um die beiden Umfrage Paketfunktionen svyciprop() und svymean(), die im obigen Abschnitt verwendet werden.\nHINWEIS: Es scheint nicht möglich zu sein, Proportionen von kategorialen Variablen mit srvyr zu erhalten. Wenn du das brauchst, schau dir den Abschnitt unten an und benutze sitrep \n\n## use the srvyr design object\nsurvey_design %&gt;% \n  summarise(\n    ## produce the weighted counts \n    counts = survey_total(died), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(died, deff = TRUE)) %&gt;% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(counts, props, props_low, props_upp, deff_deff)\n\n# A tibble: 1 × 5\n  counts props props_low props_upp deff_deff\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 76213.  5.14      2.08      12.1      3.76\n\n\nAuch hier könnten wir eine Funktion schreiben, die dann über mehrere Variablen iteriert, indem wir die purrr Paket. Siehe das Handbuch Iteration Kapitel für Details zu purrr.\n\n# Define function to calculate weighted counts, proportions, CI and design effect\n# design is your survey design object\n# x is the variable in quotation marks \n\n\nsrvyr_prop &lt;- function(design, x) {\n  \n  summarise(\n    ## using the survey design object\n    design, \n    ## produce the weighted counts \n    counts = survey_total(.data[[x]]), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(.data[[x]], deff = TRUE)) %&gt;% \n  ## add in the variable name\n  mutate(variable = x) %&gt;% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  ~srvyr_prop(.x, design = survey_design)) %&gt;% \n  ## collapse list in to a single data frame\n  bind_rows()\n\n# A tibble: 3 × 6\n  variable  counts props props_low props_upp deff_deff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 left     701199. 47.3      39.2       55.5      2.38\n2 died      76213.  5.14      2.08      12.1      3.76\n3 arrived  761799. 51.4      40.9       61.7      3.93\n\n\n\n\n26.8.3 Sitrep Paket\nDas tab_survey() Funktion von sitrep ist ein Wrapper für srvyr und ermöglicht Damit kannst du mit minimalem Programmieraufwand gewichtete Tabellen erstellen. Außerdem kannst du damit berechnen gewichtete Proportionen für kategoriale Variablen zu berechnen.\n\n## using the survey design object\nsurvey_design %&gt;% \n  ## pass the names of variables of interest unquoted\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE,   # calculate the design effect\n             pretty = TRUE  # merge the proportion and 95%CI\n             )\n\nWarning: removing 257 missing value(s) from `education_level`\n\n\n# A tibble: 9 × 5\n  variable        value            n  deff ci               \n  &lt;chr&gt;           &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            \n1 arrived         TRUE       761799.  3.93 51.4% (40.9-61.7)\n2 arrived         FALSE      720658.  3.93 48.6% (38.3-59.1)\n3 left            TRUE       701199.  2.38 47.3% (39.2-55.5)\n4 left            FALSE      781258.  2.38 52.7% (44.5-60.8)\n5 died            TRUE        76213.  3.76 5.1% (2.1-12.1)  \n6 died            FALSE     1406244.  3.76 94.9% (87.9-97.9)\n7 education_level higher     171644.  4.70 42.4% (26.9-59.7)\n8 education_level primary    102609.  2.37 25.4% (16.2-37.3)\n9 education_level secondary  130201.  6.68 32.2% (16.5-53.3)\n\n\n\n\n26.8.4 Gtsummary Paket\nMit gtsummary scheint es noch keine eingebauten Funktionen zu geben, die das Vertrauen Intervalle oder Designeffekte hinzuzufügen. Hier zeigen wir, wie man eine Funktion zum Hinzufügen von Konfidenzintervallen definiert und dann Konfidenzintervalle zu einem gtsummary Tabelle hinzu, die mit der Funktion tbl_svysummary() Funktion.\n\nconfidence_intervals &lt;- function(data, variable, by, ...) {\n  \n  ## extract the confidence intervals and multiply to get percentages\n  props &lt;- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## extract the confidence intervals \n  as.numeric(confint(props) * 100) %&gt;% ## make numeric and multiply for percentage\n    round(., digits = 1) %&gt;%           ## round to one digit\n    c(.) %&gt;%                           ## extract the numbers from matrix\n    paste0(., collapse = \"-\")          ## combine to single character\n}\n\n## using the survey package design object\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died),   ## define variables want to include\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %&gt;% ## define stats of interest\n  add_n() %&gt;%  ## add the weighted total \n  add_stat(fns = everything() ~ confidence_intervals) %&gt;% ## add CIs\n  ## modify the column headers\n  modify_header(\n    list(\n      n ~ \"**Weighted total (N)**\",\n      stat_0 ~ \"**Weighted Count**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )\n\n\n\n\n\n\n\n\nCharacteristic\nWeighted total (N)\nWeighted Count1\n95%CI\n\n\n\n\narrived\n1,482,457\n761,799 (51%)\n40.9-61.7\n\n\nleft\n1,482,457\n701,199 (47%)\n39.2-55.5\n\n\ndied\n1,482,457\n76,213 (5.1%)\n2.1-12.1\n\n\n\n1 n (%)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#gewichtete-verhältnisse",
    "href": "new_pages/survey_analysis.de.html#gewichtete-verhältnisse",
    "title": "26  Umfrage-Analyse",
    "section": "26.9 Gewichtete Verhältnisse",
    "text": "26.9 Gewichtete Verhältnisse\nAuch für gewichtete Quoten (z. B. für Sterblichkeitsquoten) kannst du die Umfrage oder die srvyr Paket. Du könntest auch Funktionen schreiben (ähnlich wie die oben genannten), um über die folgenden Punkte zu iterieren mehrere Variablen zu iterieren. Du könntest auch eine Funktion erstellen für gtsummary wie oben aber derzeit hat es keine eingebauten Funktionen.\n\n26.9.1 Umfrage Paket\n\nratio &lt;- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci &lt;- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)\n\n      obstime    2.5 %   97.5 %\ndied 5.981922 1.194294 10.76955\n\n\n\n\n26.9.2 Srvyr Paket\n\nsurvey_design %&gt;% \n  ## survey ratio used to account for observation time \n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )\n\n# A tibble: 1 × 3\n  mortality mortality_low mortality_upp\n      &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1      5.98         0.349          11.6",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.de.html#ressourcen",
    "href": "new_pages/survey_analysis.de.html#ressourcen",
    "title": "26  Umfrage-Analyse",
    "section": "26.10 Ressourcen",
    "text": "26.10 Ressourcen\nUCLA-Statistikseite\nUmfragedaten kostenlos auswerten\nsrvyr packge\ngtsummary Paket\nEPIET-Erhebung Fallstudien",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Umfrage-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.de.html",
    "href": "new_pages/survival_analysis.de.html",
    "title": "27  Survival-Analyse",
    "section": "",
    "text": "27.1 Übersicht\nÜberlebensanalyse konzentriert sich darauf, für ein bestimmtes Individuum oder eine Gruppe von Individuen einen bestimmten Zeitpunkt zu beschreiben, der den Ausfall (Auftreten einer Krankheit, Heilung von einer Krankheit, Tod, Rückfall nach Ansprechen auf die Behandlung…), der nach einer Zeitspanne eintritt, die Ausfallzeit (oder Nachlaufzeit in kohorten- bzw. bevölkerungsbasierten Studien), während der die Personen beobachtet werden. Um die Ausfallzeit zu bestimmen, ist es dann notwendig, einen Ursprungszeitpunkt zu definieren (das kann das Einschlussdatum, das Datum der Diagnose usw. sein).\nDas Ziel der Inferenz für die Überlebensanalyse ist dann die Zeit zwischen einem Ursprung und einem Ereignis. In der aktuellen medizinischen Forschung wird sie häufig in klinischen Studien eingesetzt, um z. B. die Wirkung einer Behandlung zu beurteilen, oder in der Krebsepidemiologie, um eine Vielzahl von Krebsüberlebensmaßen zu bewerten.\nSie wird in der Regel ausgedrückt durch die Überlebenswahrscheinlichkeit das ist die Wahrscheinlichkeit, dass das Ereignis von Interesse bis zu einer Dauer t nicht eingetreten ist.\nZensieren Zensierung: Eine Zensierung findet statt, wenn am Ende der Nachbeobachtung bei einigen Personen das gewünschte Ereignis noch nicht eingetreten ist und somit die tatsächliche Zeit bis zum Ereignis unbekannt ist. Wir werden uns hier hauptsächlich auf die rechte Zensierung konzentrieren, aber weitere Details zur Zensierung und zur Überlebensanalyse im Allgemeinen findest du in den Referenzen.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Survival-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.de.html#vorbereitung",
    "href": "new_pages/survival_analysis.de.html#vorbereitung",
    "title": "27  Survival-Analyse",
    "section": "27.2 Vorbereitung",
    "text": "27.2 Vorbereitung\n\nPakete laden\nUm Überlebensanalysen in R durchzuführen, ist eines der am häufigsten verwendeten Pakete das survival Paket. Wir installieren es zunächst und laden es dann zusammen mit den anderen Paketen, die wir in diesem Abschnitt verwenden werden:\nIn diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\nAuf dieser Seite geht es um Überlebensanalysen mit der Lineliste, die auf den meisten der vorherigen Seiten verwendet wurde und an der wir einige Änderungen vornehmen, um angemessene Überlebensdaten zu erhalten.\n\n\nDatensatz importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import linelist\nlinelist_case_data &lt;- rio::import(\"linelist_cleaned.rds\")\n\n\n\nDatenmanagement und -umwandlung\nKurz gesagt, können Überlebensdaten mit den folgenden drei Merkmalen beschrieben werden:\n\nDie abhängige Variable oder Antwort ist die Wartezeit bis zum Eintreten eines genau definierten Ereignisses,\ndie Beobachtungen zensiert sind, d. h., dass für einige Einheiten das interessierende Ereignis zum Zeitpunkt der Analyse der Daten noch nicht eingetreten ist, und\nes gibt Prädiktoren oder erklärende Variablen, deren Einfluss auf die Wartezeit wir bewerten oder kontrollieren wollen.\n\nDaher werden wir verschiedene Variablen erstellen, um diese Struktur zu berücksichtigen, und die Überlebensanalyse durchführen.\nWir definieren:\n\neinen neuen Datenrahmen linelist_surv für diese Analyse\ndas Ereignis, das uns interessiert, ist “Tod” (daher ist unsere Überlebenswahrscheinlichkeit die Wahrscheinlichkeit, nach einer bestimmten Zeit nach dem Ursprungszeitpunkt noch zu leben),\ndie Nachbeobachtungszeit (futime) als die Zeit zwischen dem Zeitpunkt des Auftretens und dem Zeitpunkt des Ergebnisses in Tagen,\nzensierte Patienten als solche, die sich erholten oder bei denen das Endergebnis nicht bekannt ist, d.h. das Ereignis “Tod” wurde nicht beobachtet (event=0).\n\nVORSICHT! Da in einer echten Kohortenstudie die Informationen über den Zeitpunkt des Beginns und das Ende der Nachbeobachtung bekannt sind, wenn die Personen beobachtet werden, werden wir Beobachtungen entfernen, bei denen das Datum des Beginns oder das Datum des Ergebnisses unbekannt ist. Auch die Fälle, in denen das Datum des Beginns der Krankheit später liegt als das Datum des Ausgangs, werden entfernt, da sie als falsch angesehen werden.\nTIPP: Da das Filtern auf ein Datum, das größer (&gt;) oder kleiner (&lt;) ist, Zeilen mit fehlenden Werten entfernen kann, werden bei Anwendung des Filters auf die falschen Daten auch die Zeilen mit fehlenden Daten entfernt.\nWir verwenden dann case_when() um eine Spalte zu erstellen age_cat_small zu erstellen, in der es nur 3 Alterskategorien gibt.\n\n#create a new data called linelist_surv from the linelist_case_data\n\nlinelist_surv &lt;-  linelist_case_data %&gt;% \n     \n  dplyr::filter(\n       # remove observations with wrong or missing dates of onset or date of outcome\n       date_outcome &gt; date_onset) %&gt;% \n  \n  dplyr::mutate(\n       # create the event var which is 1 if the patient died and 0 if he was right censored\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # create the var on the follow-up time in days\n       futime = as.double(date_outcome - date_onset), \n    \n       # create a new age category variable with only 3 strata levels\n       age_cat_small = dplyr::case_when( \n            age_years &lt; 5  ~ \"0-4\",\n            age_years &gt;= 5 & age_years &lt; 20 ~ \"5-19\",\n            age_years &gt;= 20   ~ \"20+\"),\n       \n       # previous step created age_cat_small var as character.\n       # now convert it to factor and specify the levels.\n       # Note that the NA values remain NA's and are not put in a level \"unknown\" for example,\n       # since in the next analyses they have to be removed.\n       age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n       )\n\nTIPP: Wir können die neuen Spalten, die wir erstellt haben, überprüfen, indem wir eine Zusammenfassung in der futime und eine Kreuztabellierung zwischen event und outcome aus der sie erstellt wurde. Neben dieser Überprüfung ist es eine gute Angewohnheit, die mediane Nachbeobachtungszeit mitzuteilen, wenn man die Ergebnisse der Überlebensanalyse interpretiert.\n\nsummary(linelist_surv$futime)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    6.00   10.00   11.98   16.00   64.00 \n\n# cross tabulate the new event var and the outcome var from which it was created\n# to make sure the code did what it was intended to\nlinelist_surv %&gt;% \n  tabyl(outcome, event)\n\n outcome    0    1\n   Death    0 1952\n Recover 1547    0\n    &lt;NA&gt; 1040    0\n\n\nJetzt stellen wir die neue age_cat_small var und die alte age_cat col gegenüber, um korrekte Zuordnungen sicherzustellen\n\nlinelist_surv %&gt;% \n  tabyl(age_cat_small, age_cat)\n\n age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n           0-4 834   0     0     0     0     0     0   0   0\n          5-19   0 852   717   575     0     0     0   0   0\n           20+   0   0     0     0   862   554    69   5   0\n          &lt;NA&gt;   0   0     0     0     0     0     0   0  71\n\n\nNun überprüfen wir die ersten 10 Beobachtungen der linelist_surv Daten auf bestimmte Variablen hin (einschließlich der neu erstellten).\n\nlinelist_surv %&gt;% \n  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %&gt;% \n  head(10)\n\n   case_id age_cat_small date_onset date_outcome outcome event futime\n1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\n\n\nWir können auch die Spalten kreuztabellieren age_cat_small und gender um mehr Details über die Verteilung dieser neuen Spalte nach Geschlecht zu erhalten. Wir verwenden tabyl() und die zieren Funktionen von Hausmeisterwie in den [Beschreibende Tabellen] Seite.\n\n\nlinelist_surv %&gt;% \n  tabyl(gender, age_cat_small, show_na = F) %&gt;% \n  adorn_totals(where = \"both\") %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\")\n\n gender         0-4          5-19           20+          Total\n      f 482 (22.4%) 1,184 (54.9%)   490 (22.7%) 2,156 (100.0%)\n      m 325 (15.0%)   880 (40.6%)   960 (44.3%) 2,165 (100.0%)\n  Total 807 (18.7%) 2,064 (47.8%) 1,450 (33.6%) 4,321 (100.0%)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Survival-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.de.html#grundlagen-der-überlebensanalyse",
    "href": "new_pages/survival_analysis.de.html#grundlagen-der-überlebensanalyse",
    "title": "27  Survival-Analyse",
    "section": "27.3 Grundlagen der Überlebensanalyse",
    "text": "27.3 Grundlagen der Überlebensanalyse\n\nAufbau eines Surv-Typ-Objekts\nWir verwenden zunächst Surv() von Überleben um ein Survival-Objekt aus den Spalten für die Nachlaufzeit und das Ereignis zu erstellen.\nDas Ergebnis eines solchen Schrittes ist ein Objekt vom Typ Surv das die Zeitinformationen und die Angabe, ob das Ereignis von Interesse (Tod) beobachtet wurde, zusammenfasst. Dieses Objekt wird schließlich auf der rechten Seite der nachfolgenden Modellformeln verwendet (siehe Dokumentation).\n\n# Use Suv() syntax for right-censored data\nsurvobj &lt;- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\n\n\n\n\n\n\nZur Erinnerung: Hier sind die ersten 10 Zeilen der linelist_surv Daten, wobei nur einige wichtige Spalten angezeigt werden.\n\nlinelist_surv %&gt;% \n  select(case_id, date_onset, date_outcome, futime, outcome, event) %&gt;% \n  head(10)\n\n   case_id date_onset date_outcome futime outcome event\n1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n3   893f25 2014-05-21   2014-05-29      8 Recover     0\n4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n6   369449 2014-06-02   2014-06-07      5   Death     1\n7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n8   1389ca 2014-06-05   2014-06-09      4   Death     1\n9   2978ac 2014-06-06   2014-06-15      9   Death     1\n10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n\n\nUnd hier sind die ersten 10 Elemente der survobj. Es wird im Wesentlichen als Vektor der Nachverfolgungszeit gedruckt, mit “+”, um anzuzeigen, ob eine Beobachtung rechtszensiert wurde. Sieh dir an, wie die Zahlen oben und unten übereinstimmen.\n\n#print the 50 first elements of the vector to see how it presents\nhead(survobj, 10)\n\n [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+\n\n\n\n\nErste Analysen durchführen\nDann beginnen wir unsere Analyse mit der survfit() Funktion, um eine Survfit-Objekt zu erzeugen, das den Standardberechnungen für Kaplan Meier (KM)-Schätzungen der gesamten (marginalen) Überlebenskurve, die in Wirklichkeit eine Stufenfunktion mit Sprüngen zu den beobachteten Ereigniszeitpunkten sind. Die endgültige survfit-Objekt enthält eine oder mehrere Überlebenskurven und wird mit der Methode Surv Objekts als Antwortvariable in der Modellformel erstellt.\nHINWEIS: Die Kaplan-Meier-Schätzung ist eine nichtparametrische Maximum-Likelihood-Schätzung (MLE) der Überlebensfunktion. (siehe Ressourcen für weitere Informationen).\nDie Zusammenfassung dieser survfit-Objekts ergibt eine so genannte Lebenstabelle. Für jeden Zeitschritt der Nachbereitung (time), in dem ein Ereignis eintrat (in aufsteigender Reihenfolge):\n\ndie Anzahl der Personen, die ein Risiko hatten, das Ereignis zu entwickeln (Personen, die das Ereignis noch nicht hatten oder zensiert wurden: n.risk)\nPersonen, die das Ereignis entwickelt haben (n.event)\nund aus dem oben Gesagten: die Wahrscheinlichkeit von nicht das Ereignis zu entwickeln (die Wahrscheinlichkeit, nicht zu sterben oder über diesen Zeitpunkt hinaus zu überleben)\nschließlich werden der Standardfehler und das Konfidenzintervall für diese Wahrscheinlichkeit abgeleitet und angezeigt\n\nWir passen die KM-Schätzungen mit der Formel an, wobei das zuvor überlebte Objekt “survobj” die Antwortvariable ist. Mit “~ 1” führen wir das Modell für das Gesamtüberleben aus.\n\n# fit the KM estimates using a formula where the Surv object \"survobj\" is the response variable.\n# \"~ 1\" signifies that we run the model for the overall survival  \nlinelistsurv_fit &lt;-  survival::survfit(survobj ~ 1)\n\n#print its summary for more details\nsummary(linelistsurv_fit)\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1   4539      30    0.993 0.00120        0.991        0.996\n    2   4500      69    0.978 0.00217        0.974        0.982\n    3   4394     149    0.945 0.00340        0.938        0.952\n    4   4176     194    0.901 0.00447        0.892        0.910\n    5   3899     214    0.852 0.00535        0.841        0.862\n    6   3592     210    0.802 0.00604        0.790        0.814\n    7   3223     179    0.757 0.00656        0.745        0.770\n    8   2899     167    0.714 0.00700        0.700        0.728\n    9   2593     145    0.674 0.00735        0.660        0.688\n   10   2311     109    0.642 0.00761        0.627        0.657\n   11   2081     119    0.605 0.00788        0.590        0.621\n   12   1843      89    0.576 0.00809        0.560        0.592\n   13   1608      55    0.556 0.00823        0.540        0.573\n   14   1448      43    0.540 0.00837        0.524        0.556\n   15   1296      31    0.527 0.00848        0.511        0.544\n   16   1152      48    0.505 0.00870        0.488        0.522\n   17   1002      29    0.490 0.00886        0.473        0.508\n   18    898      21    0.479 0.00900        0.462        0.497\n   19    798       7    0.475 0.00906        0.457        0.493\n   20    705       4    0.472 0.00911        0.454        0.490\n   21    626      13    0.462 0.00932        0.444        0.481\n   22    546       8    0.455 0.00948        0.437        0.474\n   23    481       5    0.451 0.00962        0.432        0.470\n   24    436       4    0.447 0.00975        0.428        0.466\n   25    378       4    0.442 0.00993        0.423        0.462\n   26    336       3    0.438 0.01010        0.419        0.458\n   27    297       1    0.436 0.01017        0.417        0.457\n   29    235       1    0.435 0.01030        0.415        0.455\n   38     73       1    0.429 0.01175        0.406        0.452\n\n\nBei der Verwendung von summary() können wir die Option hinzufügen times hinzufügen und bestimmte Zeiten angeben, zu denen wir die Überlebensinformationen sehen wollen\n\n#print its summary at specific times\nsummary(linelistsurv_fit, times = c(5,10,20,30,60))\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    5   3899     656    0.852 0.00535        0.841        0.862\n   10   2311     810    0.642 0.00761        0.627        0.657\n   20    705     446    0.472 0.00911        0.454        0.490\n   30    210      39    0.435 0.01030        0.415        0.455\n   60      2       1    0.429 0.01175        0.406        0.452\n\n\nWir können auch die Option print() Funktion verwenden. Die print.rmean = TRUE Argument wird verwendet, um die mittlere Überlebenszeit und ihren Standardfehler (se) zu erhalten.\nHINWEIS: Die eingeschränkte mittlere Überlebenszeit (RMST) ist ein spezifisches Überlebensmaß, das in der Krebsüberlebensanalyse immer häufiger verwendet wird und oft als Fläche unter der Überlebenskurve definiert wird, wenn wir die Patienten bis zur eingeschränkten Zeit T beobachten (weitere Einzelheiten im Abschnitt Ressourcen).\n\n# print linelistsurv_fit object with mean survival time and its se. \nprint(linelistsurv_fit, print.rmean = TRUE)\n\nCall: survfit(formula = survobj ~ 1)\n\n        n events rmean* se(rmean) median 0.95LCL 0.95UCL\n[1,] 4539   1952   33.1     0.539     17      16      18\n    * restricted mean with upper limit =  64 \n\n\nTIPP: Wir können die surv-Objekt direkt in der survfit() Funktion einfügen und eine Codezeile speichern. Das sieht dann so aus: linelistsurv_quick &lt;-  survfit(Surv(futime, event) ~ 1, data=linelist_surv).\n\n\nKumulative Gefahr\nNeben der summary() Funktion können wir auch die str() Funktion verwenden, die mehr Details über die Struktur der survfit() Objekts. Es ist eine Liste mit 16 Elementen.\nUnter diesen Elementen ist ein wichtiges: cumhaz, das ein numerischer Vektor ist. Dieser könnte aufgezeichnet werden, um die kumulative Gefahr, mit dem Gefahr ist die augenblickliche Rate des Auftretens von Ereignissen (siehe Referenzen).\n\nstr(linelistsurv_fit)\n\nList of 16\n $ n        : int 4539\n $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n $ type     : chr \"right\"\n $ logse    : logi TRUE\n $ conf.int : num 0.95\n $ conf.type: chr \"log\"\n $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n $ call     : language survfit(formula = survobj ~ 1)\n - attr(*, \"class\")= chr \"survfit\"\n\n\n\n\n\nKaplan-Meir-Kurven aufzeichnen\nSobald die KM-Schätzungen angepasst sind, können wir die Wahrscheinlichkeit, bis zu einem bestimmten Zeitpunkt am Leben zu sein, mithilfe der grundlegenden plot() Funktion, die die “Kaplan-Meier-Kurve” zeichnet. Mit anderen Worten: Die untenstehende Kurve ist eine konventionelle Darstellung der Überlebenserfahrung in der gesamten Patientengruppe.\nWir können die minimale und maximale Nachbeobachtungszeit auf der Kurve schnell überprüfen.\nEine einfache Art der Interpretation ist, dass zum Zeitpunkt Null alle Teilnehmer noch leben und die Überlebenswahrscheinlichkeit dann 100% beträgt. Diese Wahrscheinlichkeit nimmt im Laufe der Zeit ab, da die Patienten sterben. Der Anteil der Teilnehmer, die mehr als 60 Tage der Nachbeobachtung überleben, liegt bei etwa 40%.\n\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\",    # x-axis label\n     ylab=\"Survival Probability\",   # y-axis label\n     main= \"Overall survival curve\" # figure title\n     )\n\n\n\n\n\n\n\n\nDas Konfidenzintervall der KM-Überlebensschätzungen wird ebenfalls standardmäßig eingezeichnet und kann durch Hinzufügen der Option abgewählt werden conf.int = FALSE zum plot() Befehl hinzufügen.\nDa das Ereignis von Interesse “Tod” ist, führt das Zeichnen einer Kurve, die die Komplemente der Überlebensanteile beschreibt, zum Zeichnen der kumulativen Sterblichkeitsanteile. Dies kann mit lines() durchgeführt werden, das Informationen zu einem bestehenden Diagramm hinzufügt.\n\n# original plot\nplot(\n  linelistsurv_fit,\n  xlab = \"Days of follow-up\",       \n  ylab = \"Survival Probability\",       \n  mark.time = TRUE,              # mark events on the curve: a \"+\" is printed at every event\n  conf.int = FALSE,              # do not plot the confidence interval\n  main = \"Overall survival curve and cumulative mortality\"\n  )\n\n# draw an additional curve to the previous plot\nlines(\n  linelistsurv_fit,\n  lty = 3,             # use different line type for clarity\n  fun = \"event\",       # draw the cumulative events instead of the survival \n  mark.time = FALSE,\n  conf.int = FALSE\n  )\n\n# add a legend to the plot\nlegend(\n  \"topright\",                               # position of legend\n  legend = c(\"Survival\", \"Cum. Mortality\"), # legend text \n  lty = c(1, 3),                            # line types to use in the legend\n  cex = .85,                                # parametes that defines size of legend text\n  bty = \"n\"                                 # no box type to be drawn for the legend\n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Survival-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.de.html#vergleich-der-überlebenskurven",
    "href": "new_pages/survival_analysis.de.html#vergleich-der-überlebenskurven",
    "title": "27  Survival-Analyse",
    "section": "27.4 Vergleich der Überlebenskurven",
    "text": "27.4 Vergleich der Überlebenskurven\nUm das Überleben innerhalb verschiedener Gruppen unserer beobachteten Teilnehmer oder Patienten zu vergleichen, müssen wir uns zunächst ihre jeweiligen Überlebenskurven ansehen und dann Tests durchführen, um den Unterschied zwischen unabhängigen Gruppen zu bewerten. Dieser Vergleich kann sich auf Gruppen beziehen, die nach Geschlecht, Alter, Behandlung, Komorbidität…\n\nLog-Rank-Test\nDer Log-Rank-Test ist ein beliebter Test, der die gesamte Überlebenserfahrung zwischen zwei oder mehr unabhängigen Gruppen und kann als Test dafür angesehen werden, ob die Überlebenskurven identisch (überlappend) sind oder nicht (Nullhypothese: kein Unterschied im Überleben zwischen den Gruppen). Die survdiff() Funktion der Überlebenspakets ermöglicht die Durchführung des Log-Rank-Tests, wenn wir angeben rho = 0 (das ist die Standardeinstellung). Die Testergebnisse geben eine Chi-Quadrat-Statistik zusammen mit einem p-Wert an, da die Log-Rank-Statistik annähernd wie eine Chi-Quadrat-Teststatistik verteilt ist.\nZunächst versuchen wir, die Überlebenskurven nach Geschlecht zu vergleichen. Dazu versuchen wir zunächst, sie zu visualisieren (zu prüfen, ob sich die beiden Überlebenskurven überschneiden). Eine neue survfit-Objekt wird mit einer etwas anderen Formel erstellt. Dann wird das survdiff-Objekt erstellt werden.\nDurch die Angabe von ~ gender auf der rechten Seite der Formel angeben, wird nicht mehr die Gesamtüberlebenszeit, sondern das Geschlecht dargestellt.\n\n# create the new survfit object based on gender\nlinelistsurv_fit_sex &lt;-  survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n\nJetzt können wir die Überlebenskurven nach Geschlecht darstellen. Wirf einen Blick auf die Bestellung der Strata-Ebenen in der Spalte Geschlecht an, bevor du die Farben und die Legende definierst.\n\n# set colors\ncol_sex &lt;- c(\"lightgreen\", \"darkgreen\")\n\n# create plot\nplot(\n  linelistsurv_fit_sex,\n  col = col_sex,\n  xlab = \"Days of follow-up\",\n  ylab = \"Survival Probability\")\n\n# add legend\nlegend(\n  \"topright\",\n  legend = c(\"Female\",\"Male\"),\n  col = col_sex,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n\n\n\n\n\n\n\n\nUnd nun können wir den Test der Differenz zwischen den Überlebenskurven berechnen, indem wir survdiff()\n\n#compute the test of the difference between the survival curves\nsurvival::survdiff(\n  Surv(futime, event) ~ gender, \n  data = linelist_surv\n  )\n\nCall:\nsurvival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n\nn=4321, 218 observations deleted due to missingness.\n\n            N Observed Expected (O-E)^2/E (O-E)^2/V\ngender=f 2156      924      909     0.255     0.524\ngender=m 2165      929      944     0.245     0.524\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\nWir sehen, dass sich die Überlebenskurve für Frauen und die für Männer überschneiden und der Log-Rank-Test keinen Hinweis auf einen Überlebensunterschied zwischen Frauen und Männern liefert.\nEinige andere R-Pakete ermöglichen es, die Überlebenskurven für verschiedene Gruppen darzustellen und den Unterschied auf einmal zu testen. Die Verwendung des ggsurvplot() Funktion aus dem survminer Paket können wir auch die gedruckten Risikotabellen für jede Gruppe sowie den p-Wert aus dem Log-Rank-Test in unsere Kurve einfügen.\nVORSICHT! survminer Funktionen erfordern, dass du das Survival-Objekt angibst und die Daten angeben, die zur Anpassung des Survival-Objekts verwendet werden. Denke daran, dies zu tun, um unspezifische Fehlermeldungen zu vermeiden. \n\nsurvminer::ggsurvplot(\n    linelistsurv_fit_sex, \n    data = linelist_surv,          # again specify the data used to fit linelistsurv_fit_sex \n    conf.int = FALSE,              # do not show confidence interval of KM estimates\n    surv.scale = \"percent\",        # present probabilities in the y axis in %\n    break.time.by = 10,            # present the time axis with an increment of 10 days\n    xlab = \"Follow-up days\",\n    ylab = \"Survival Probability\",\n    pval = T,                      # print p-value of Log-rank test \n    pval.coord = c(40,.91),        # print p-value at these plot coordinates\n    risk.table = T,                # print the risk table at bottom \n    legend.title = \"Gender\",       # legend characteristics\n    legend.labs = c(\"Female\",\"Male\"),\n    font.legend = 10, \n    palette = \"Dark2\",             # specify color palette \n    surv.median.line = \"hv\",       # draw horizontal and vertical lines to the median survivals\n    ggtheme = theme_light()        # simplify plot background\n)\n\n\n\n\n\n\n\n\nWir wollen vielleicht auch auf Unterschiede in der Überlebensrate nach der Infektionsquelle (Kontaminationsquelle) testen.\nIn diesem Fall liefert der Log-Rank-Test genügend Hinweise auf einen Unterschied in den Überlebenswahrscheinlichkeiten bei alpha= 0.005. Die Überlebenswahrscheinlichkeiten für Patienten, die sich auf Beerdigungen infiziert haben, sind höher als die Überlebenswahrscheinlichkeiten für Patienten, die sich an anderen Orten infiziert haben, was auf einen Überlebensvorteil hindeutet.\n\nlinelistsurv_fit_source &lt;-  survfit(\n  Surv(futime, event) ~ source,\n  data = linelist_surv\n  )\n\n# plot\nggsurvplot( \n  linelistsurv_fit_source,\n  data = linelist_surv,\n  size = 1, linetype = \"strata\",   # line types\n  conf.int = T,\n  surv.scale = \"percent\",  \n  break.time.by = 10, \n  xlab = \"Follow-up days\",\n  ylab= \"Survival Probability\",\n  pval = T,\n  pval.coord = c(40,.91),\n  risk.table = T,\n  legend.title = \"Source of \\ninfection\",\n  legend.labs = c(\"Funeral\", \"Other\"),\n  font.legend = 10,\n  palette = c(\"#E7B800\",\"#3E606F\"),\n  surv.median.line = \"hv\", \n  ggtheme = theme_light()\n)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Survival-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.de.html#cox-regressionsanalyse",
    "href": "new_pages/survival_analysis.de.html#cox-regressionsanalyse",
    "title": "27  Survival-Analyse",
    "section": "27.5 Cox-Regressionsanalyse",
    "text": "27.5 Cox-Regressionsanalyse\nDie Cox-Proportional-Hazards-Regression ist eine der beliebtesten Regressionsmethoden für die Überlebensanalyse. Es können auch andere Modelle verwendet werden, denn das Cox-Modell erfordert wichtige Annahmen die für eine angemessene Anwendung überprüft werden müssen, wie z. B. die Proportional-Hazards-Annahme: siehe Referenzen.\nIn einem proportionalen Cox-Hazard-Regressionsmodell ist das Maß für den Effekt die Hazard-Rate (HR), die das Risiko des Versagens (oder in unserem Beispiel das Risiko des Todes) angibt, wenn der Teilnehmer bis zu einem bestimmten Zeitpunkt überlebt hat. Normalerweise sind wir daran interessiert, zu vergleichen unabhängigen Gruppen hinsichtlich ihres Risikos zu vergleichen, und wir verwenden ein Hazard Ratio, das einem Odds Ratio im Rahmen einer multiplen logistischen Regressionsanalyse entspricht. Die cox.ph() Funktion aus der Überleben Paket wird zur Anpassung des Modells verwendet. Die Funktion cox.zph() von Überleben Paket kann verwendet werden, um die Proportional-Hazards-Annahme für die Anpassung eines Cox-Regressionsmodells zu testen.\nHINWEIS: Eine Wahrscheinlichkeit muss im Bereich von 0 bis 1 liegen. Die Gefahr stellt jedoch die erwartete Anzahl von Ereignissen pro Zeiteinheit dar.\n\nWenn die Hazard Ratio für einen Prädiktor nahe bei 1 liegt, hat dieser Prädiktor keinen Einfluss auf das Überleben,\nWenn die HR kleiner als 1 ist, ist der Prädiktor schützend (d. h. er ist mit einer verbesserten Überlebensrate verbunden),\nund wenn die HR größer als 1 ist, dann ist der Prädiktor mit einem erhöhten Risiko (oder einer geringeren Überlebensrate) verbunden.\n\n\nAnpassen eines Cox-Modells\nWir können zunächst ein Modell anpassen, um die Auswirkungen von Alter und Geschlecht auf die Überlebensrate zu ermitteln. Indem wir das Modell einfach ausdrucken, haben wir die Informationen über:\n\ndie geschätzten Regressionskoeffizienten coef die den Zusammenhang zwischen den Prädiktoren und dem Ergebnis quantifizieren,\nihr Exponentialwert (für die Interpretierbarkeit, exp(coef)), der die Hazard Ratio,\nihr Standardfehler se(coef),\nden z-Score: wie viele Standardfehler der geschätzte Koeffizient von 0 entfernt ist,\nund der p-Wert: die Wahrscheinlichkeit, dass der geschätzte Koeffizient 0 sein könnte.\n\nDie summary() Funktion, die auf das Cox-Modell-Objekt angewendet wird, liefert weitere Informationen, wie das Konfidenzintervall der geschätzten HR und die verschiedenen Testwerte.\nDer Effekt der ersten Kovariate gender wird in der ersten Zeile dargestellt. genderm (männlich) gedruckt, was bedeutet, dass die erste Strata-Ebene (“f”), d. h. die weibliche Gruppe, die Referenzgruppe für das Geschlecht ist. Die Interpretation des Testparameters ist also die von Männern im Vergleich zu Frauen. Der p-Wert zeigt an, dass es keine ausreichenden Beweise für eine Auswirkung des Geschlechts auf das erwartete Risiko oder für einen Zusammenhang zwischen dem Geschlecht und der Gesamtmortalität gibt.\nDer gleiche Mangel an Beweisen wird auch bei der Altersgruppe festgestellt.\n\n#fitting the cox model\nlinelistsurv_cox_sexage &lt;-  survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#printing the model fitted\nlinelistsurv_cox_sexage\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n                      coef exp(coef) se(coef)      z     p\ngenderm           -0.03149   0.96900  0.04767 -0.661 0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n\nLikelihood ratio test=2.8  on 3 df, p=0.4243\nn= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n#summary of the model\nsummary(linelistsurv_cox_sexage)\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n  n= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n                      coef exp(coef) se(coef)      z Pr(&gt;|z|)\ngenderm           -0.03149   0.96900  0.04767 -0.661    0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ngenderm               0.969     1.0320    0.8826     1.064\nage_cat_small5-19     1.099     0.9103    0.9680     1.247\nage_cat_small20+      1.052     0.9509    0.9176     1.205\n\nConcordance= 0.514  (se = 0.007 )\nLikelihood ratio test= 2.8  on 3 df,   p=0.4\nWald test            = 2.78  on 3 df,   p=0.4\nScore (logrank) test = 2.78  on 3 df,   p=0.4\n\n\nEs war interessant, das Modell auszuführen und die Ergebnisse zu betrachten, aber ein erster Blick, um zu überprüfen, ob die Proportional Hazards-Annahmen eingehalten werden, könnte helfen, Zeit zu sparen.\n\ntest_ph_sexage &lt;- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage\n\n              chisq df    p\ngender        0.454  1 0.50\nage_cat_small 0.838  2 0.66\nGLOBAL        1.399  3 0.71\n\n\nHINWEIS: Ein zweites Argument namens Methode kann bei der Berechnung des Cox-Modells angegeben werden, um festzulegen, wie Gleichstände behandelt werden. Die Standard ist “efron”, und die anderen Optionen sind “breslow” und “exact”.\nIn einem weiteren Modell fügen wir weitere Risikofaktoren hinzu, z. B. die Infektionsquelle und die Anzahl der Tage zwischen dem Auftreten der Infektion und der Aufnahme. Dieses Mal überprüfen wir zunächst die Proportionalitätsannahme, bevor wir fortfahren.\nIn diesem Modell haben wir einen kontinuierlichen Prädiktor (days_onset_hosp). In diesem Fall interpretieren wir die Parameterschätzungen als den Anstieg des erwarteten Logarithmus des relativen Risikos für jede Erhöhung des Prädiktors um eine Einheit, wobei die anderen Prädiktoren konstant bleiben. Zunächst überprüfen wir die Annahme der proportionalen Gefährdung.\n\n#fit the model\nlinelistsurv_cox &lt;-  coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#test the proportional hazard model\nlinelistsurv_ph_test &lt;- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test\n\n                   chisq df       p\ngender           0.45062  1    0.50\nage_years        0.00199  1    0.96\nsource           1.79622  1    0.18\ndays_onset_hosp 31.66167  1 1.8e-08\nGLOBAL          34.08502  4 7.2e-07\n\n\nDie grafische Überprüfung dieser Annahme kann mit folgender Funktion durchgeführt werden ggcoxzph() aus der survminer Paket.\n\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n\n\n\n\n\n\n\n\nDie Ergebnisse des Modells zeigen, dass es einen negativen Zusammenhang zwischen der Dauer zwischen Aufnahmebeginn und Aufnahme und der Gesamtmortalität gibt. Das erwartete Risiko ist bei einer Person, die einen Tag später eingeliefert wird, 0,9-mal niedriger als bei einer anderen Person, wobei das Geschlecht konstant bleibt. Oder einfacher ausgedrückt: Ein Anstieg der Dauer vom Krankheitsbeginn bis zur Aufnahme um eine Einheit ist mit einer 10,7%igen (coef *100) Rückgang des Sterberisikos verbunden.\nDie Ergebnisse zeigen auch einen positiven Zusammenhang zwischen der Infektionsquelle und der Gesamtmortalität. Das heißt, dass das Sterberisiko (1,21-fach) für Patienten, die eine andere Infektionsquelle als eine Beerdigung hatten, erhöht ist.\n\n#print the summary of the model\nsummary(linelistsurv_cox)\n\nCall:\ncoxph(formula = Surv(futime, event) ~ gender + age_years + source + \n    days_onset_hosp, data = linelist_surv)\n\n  n= 2772, number of events= 1180 \n   (1767 observations deleted due to missingness)\n\n                     coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \ngenderm          0.004710  1.004721  0.060827  0.077   0.9383    \nage_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \nsourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \ndays_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\ngenderm            1.0047     0.9953    0.8918    1.1319\nage_years          0.9978     1.0023    0.9930    1.0025\nsourceother        1.1953     0.8366    1.0133    1.4100\ndays_onset_hosp    0.9012     1.1097    0.8764    0.9267\n\nConcordance= 0.566  (se = 0.009 )\nLikelihood ratio test= 71.31  on 4 df,   p=1e-14\nWald test            = 59.22  on 4 df,   p=4e-12\nScore (logrank) test = 59.54  on 4 df,   p=4e-12\n\n\nWir können diesen Zusammenhang anhand einer Tabelle überprüfen:\n\nlinelist_case_data %&gt;% \n  tabyl(days_onset_hosp, outcome) %&gt;% \n  adorn_percentages() %&gt;%  \n  adorn_pct_formatting()\n\n days_onset_hosp Death Recover   NA_\n               0 44.3%   31.4% 24.3%\n               1 46.6%   32.2% 21.2%\n               2 43.0%   32.8% 24.2%\n               3 45.0%   32.3% 22.7%\n               4 41.5%   38.3% 20.2%\n               5 40.0%   36.2% 23.8%\n               6 32.2%   48.7% 19.1%\n               7 31.8%   38.6% 29.5%\n               8 29.8%   38.6% 31.6%\n               9 30.3%   51.5% 18.2%\n              10 16.7%   58.3% 25.0%\n              11 36.4%   45.5% 18.2%\n              12 18.8%   62.5% 18.8%\n              13 10.0%   60.0% 30.0%\n              14 10.0%   50.0% 40.0%\n              15 28.6%   42.9% 28.6%\n              16 20.0%   80.0%  0.0%\n              17  0.0%  100.0%  0.0%\n              18  0.0%  100.0%  0.0%\n              22  0.0%  100.0%  0.0%\n              NA 52.7%   31.2% 16.0%\n\n\nWir müssen überlegen und untersuchen, warum dieser Zusammenhang in den Daten besteht. Eine mögliche Erklärung könnte sein, dass Patienten, die lange genug leben, um später eingewiesen zu werden, zu Beginn eine weniger schwere Krankheit hatten. Eine andere, vielleicht wahrscheinlichere Erklärung ist, dass dieses Muster nicht die Realität widerspiegelt, da wir einen simulierten Fake-Datensatz verwendet haben!\n\n\n\nWalddiagramme\nAnschließend können wir die Ergebnisse des Cox-Modells mithilfe der praktischen Forest Plots mit der ggforest() Funktion der survminer-Pakets.\n\nggforest(linelistsurv_cox, data = linelist_surv)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Survival-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.de.html#zeitabhängige-kovariaten-in-überlebensmodellen",
    "href": "new_pages/survival_analysis.de.html#zeitabhängige-kovariaten-in-überlebensmodellen",
    "title": "27  Survival-Analyse",
    "section": "27.6 Zeitabhängige Kovariaten in Überlebensmodellen",
    "text": "27.6 Zeitabhängige Kovariaten in Überlebensmodellen\nEinige der folgenden Abschnitte wurden mit Genehmigung aus einem hervorragenden Einführung in die Überlebensanalyse in R von Dr. Emily Zabor\nIm letzten Abschnitt haben wir uns mit der Cox-Regression befasst, um Zusammenhänge zwischen interessierenden Kovariaten und Überlebensergebnissen zu untersuchen, aber diese Analysen setzen voraus, dass die Kovariate zu Beginn gemessen werden, d.h. bevor die Nachbeobachtungszeit für das Ereignis beginnt.\nWas passiert, wenn du an einer Kovariate interessiert bist, die zu Beginn der nach Beginn der Nachbeobachtungszeit gemessen wird? Oder wenn du eine Kovariable hast, die sich im Laufe der Zeit ändern kann?\nVielleicht arbeitest du zum Beispiel mit klinischen Daten, bei denen du Laborwerte des Krankenhauses wiederholt gemessen hast, die sich im Laufe der Zeit ändern können. Dies ist ein Beispiel für eine Zeitabhängige Kovariate. Um dies zu berücksichtigen, brauchst du ein spezielles Setup, aber glücklicherweise ist das Cox-Modell sehr flexibel und diese Art von Daten kann auch mit Tools aus dem Überleben Paket modelliert werden.\n\nAufbau der zeitabhängigen Kovariate\nDie Analyse von zeitabhängigen Kovariaten in R erfordert die Einrichtung eines speziellen Datensatzes. Wenn du daran interessiert bist, sieh dir das ausführliche Papier des Autors der Überleben Pakets Verwendung zeitabhängiger Kovariaten und zeitabhängiger Koeffizienten im Cox-Modell.\nHierfür verwenden wir einen neuen Datensatz aus der SemiCompRisks Paket namens BMT der Daten von 137 Knochenmarktransplantationspatienten enthält. Die Variablen, auf die wir uns konzentrieren werden, sind:\n\nT1 - Zeit (in Tagen) bis zum Tod oder zur letzten Nachuntersuchung\ndelta1 - Todesindikator; 1-Tot, 0-Leben\nTA - Zeit (in Tagen) bis zur akuten Graft-versus-Host-Krankheit\ndeltaA - Indikator für akute Graft-versus-Host-Krankheit;\n\n1 - Entwickelte akute Graft-versus-Host-Krankheit\n0 - Nie eine akute Transplantat-gegen-Wirt-Krankheit entwickelt\n\n\nWir laden diesen Datensatz aus der Überleben Paket, indem wir die Basis R-Befehl data(), der zum Laden von Daten verwendet werden kann, die bereits in einem geladenen R-Paket enthalten sind. Der Datenrahmen BMT wird in deiner R-Umgebung erscheinen.\n\ndata(BMT, package = \"SemiCompRisks\")\n\n\nEindeutigen Patientenidentifikator hinzufügen\nEs gibt keine eindeutige ID-Spalte in der BMT Daten, die wir brauchen, um die gewünschte Art von Datensatz zu erstellen. Wir verwenden also die Funktion rowid_to_column() aus den tidyverse Paket tibble um eine neue id-Spalte zu erstellen, die my_id (fügt am Anfang des Datenrahmens eine Spalte mit fortlaufenden Zeilennummern hinzu, beginnend bei 1). Wir nennen den Datenrahmen bmt.\n\nbmt &lt;- rowid_to_column(BMT, \"my_id\")\n\nDer Datensatz sieht jetzt wie folgt aus:\n\n\n\n\n\n\n\n\nErweitern der Patientenzeilen\nAls Nächstes verwenden wir die tmerge() Funktion mit der event() und tdc() Hilfsfunktionen, um den umstrukturierten Datensatz zu erstellen. Unser Ziel ist es, den Datensatz so umzustrukturieren, dass für jeden Patienten eine eigene Zeile für jedes Zeitintervall erstellt wird, in dem er einen anderen Wert für deltaA. In diesem Fall kann jeder Patient höchstens zwei Zeilen haben, je nachdem, ob er während des Erhebungszeitraums eine akute Graft-versus-Host-Krankheit entwickelt hat. Wir nennen unseren neuen Indikator für die Entwicklung der akuten Graft-versus-Host-Krankheit agvhd.\n\ntmerge() erstellt einen langen Datensatz mit mehreren Zeitintervallen für die verschiedenen Kovariatenwerte für jeden Patienten\nevent() erstellt den neuen Ereignisindikator, der zu den neu erstellten Zeitintervallen passt\ntdc() erstellt die Spalte für die zeitabhängige Kovariate, agvhd die zu den neu erstellten Zeitintervallen passt\n\n\ntd_dat &lt;- \n  tmerge(\n    data1 = bmt %&gt;% select(my_id, T1, delta1), \n    data2 = bmt %&gt;% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\n\nUm zu sehen, was das bewirkt, schauen wir uns die Daten für die ersten 5 einzelnen Patienten an.\nDie Variablen, die in den ursprünglichen Daten von Interesse waren, sahen wie folgt aus:\n\nbmt %&gt;% \n  select(my_id, T1, delta1, TA, deltaA) %&gt;% \n  filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1   TA deltaA\n1     1 2081      0   67      1\n2     2 1602      0 1602      0\n3     3 1496      0 1496      0\n4     4 1462      0   70      1\n5     5 1433      0 1433      0\n\n\nDer neue Datensatz für dieselben Patienten sieht wie folgt aus:\n\ntd_dat %&gt;% \n  filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1 tstart tstop death agvhd\n1     1 2081      0      0    67     0     0\n2     1 2081      0     67  2081     0     1\n3     2 1602      0      0  1602     0     0\n4     3 1496      0      0  1496     0     0\n5     4 1462      0      0    70     0     0\n6     4 1462      0     70  1462     0     1\n7     5 1433      0      0  1433     0     0\n\n\nJetzt haben einige unserer Patienten zwei Zeilen im Datensatz, die den Intervallen entsprechen, in denen sie einen anderen Wert unserer neuen Variable haben, agvhd. Zum Beispiel hat Patient 1 jetzt zwei Zeilen mit einem agvhd Wert von Null von Zeitpunkt 0 bis Zeitpunkt 67 und einen Wert von 1 von Zeitpunkt 67 bis Zeitpunkt 2081.\n\n\n\nCox-Regression mit zeitabhängigen Kovariaten\nNachdem wir nun unsere Daten umgestaltet und die neuen zeitabhängigen aghvd lassen Sie uns ein einfaches Cox-Regressionsmodell mit einer einzelnen Variable anpassen. Wir können die gleiche coxph() Funktion wie zuvor verwenden, wir müssen nur unsere Surv() Funktion ändern, um sowohl die Start- als auch die Stoppzeit für jedes Intervall mit der time1 = und time2 = Argumente.\n\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    agvhd, data = td_dat)\n\n  n= 163, number of events= 80 \n\n        coef exp(coef) se(coef)    z Pr(&gt;|z|)\nagvhd 0.3351    1.3980   0.2815 1.19    0.234\n\n      exp(coef) exp(-coef) lower .95 upper .95\nagvhd     1.398     0.7153    0.8052     2.427\n\nConcordance= 0.535  (se = 0.024 )\nLikelihood ratio test= 1.33  on 1 df,   p=0.2\nWald test            = 1.42  on 1 df,   p=0.2\nScore (logrank) test = 1.43  on 1 df,   p=0.2\n\n\nAuch hier visualisieren wir die Ergebnisse des Cox-Modells mithilfe der ggforest() Funktion aus dem survminer-Paket.:\n\nggforest(bmt_td_model, data = td_dat)\n\n\n\n\n\n\n\n\nWie du aus dem Forest Plot, dem Konfidenzintervall und dem p-Wert ersehen kannst, scheint es im Rahmen unseres einfachen Modells keinen starken Zusammenhang zwischen Tod und akuter Graft-versus-Host-Krankheit zu geben.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Survival-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.de.html#ressourcen",
    "href": "new_pages/survival_analysis.de.html#ressourcen",
    "title": "27  Survival-Analyse",
    "section": "27.7 Ressourcen",
    "text": "27.7 Ressourcen\nSurvival-Analyse Teil I: Grundlegende Konzepte und erste Analysen\nSurvival-Analyse in R\nÜberlebensanalyse in der Forschung zu Infektionskrankheiten: Die Beschreibung von Ereignissen in der Zeit\nKapitel über fortgeschrittene Überlebensmodelle Princeton\nVerwendung zeitabhängiger Kovariaten und zeitabhängiger Koeffizienten im Cox-Modell\nÜberlebensanalyse Spickzettel R\nSurvminer Spickzettel\nPapier über verschiedene Überlebensmaße für Krebsregisterdaten mit Rcode als Zusatzmaterial",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Survival-Analyse</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html",
    "href": "new_pages/gis.de.html",
    "title": "28  GIS-Grundlagen",
    "section": "",
    "text": "28.1 Übersicht\nRäumliche Aspekte deiner Daten können eine Menge Einblicke in die Situation des Ausbruchs geben und Fragen beantworten wie:\nDer aktuelle Schwerpunkt dieser GIS-Seite liegt auf den Bedürfnissen angewandter Epidemiologen bei der Reaktion auf Ausbrüche. Wir werden grundlegende Methoden der räumlichen Datenvisualisierung erkunden, indem wir tmap und ggplot2 Pakete. Wir werden auch einige der grundlegenden Methoden zur Verwaltung und Abfrage von Geodaten mit dem sf Paket. Zum Schluss werden wir kurz auf die Konzepte von räumlichen Statistik wie räumliche Beziehungen, räumliche Autokorrelation und räumliche Regression mit Hilfe des spdep Paket.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#übersicht",
    "href": "new_pages/gis.de.html#übersicht",
    "title": "28  GIS-Grundlagen",
    "section": "",
    "text": "Wo sind die aktuellen Krankheitsherde?\nWie haben sich die Hotspots im Laufe der Zeit verändert?\nWie sieht es mit dem Zugang zu Gesundheitseinrichtungen aus? Sind irgendwelche Verbesserungen nötig?",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#schlüsselbegriffe",
    "href": "new_pages/gis.de.html#schlüsselbegriffe",
    "title": "28  GIS-Grundlagen",
    "section": "28.2 Schlüsselbegriffe",
    "text": "28.2 Schlüsselbegriffe\nIm Folgenden stellen wir einige wichtige Begriffe vor. Für eine gründliche Einführung in GIS und räumliche Analysen empfehlen wir dir, eines der längeren Tutorials oder Kurse zu besuchen, die im Abschnitt Referenzen aufgeführt sind.\nGeografisches Informationssystem (GIS) - Ein GIS ist ein Rahmen oder eine Umgebung zum Sammeln, Verwalten, Analysieren und Visualisieren von räumlichen Daten.\n\nGIS-Software\nEinige gängige GIS-Software ermöglicht eine Point-and-Click-Interaktion für die Kartenerstellung und räumliche Analyse. Diese Tools haben den Vorteil, dass du keinen Code lernen musst und dass du Symbole und Funktionen einfach manuell auswählen und auf einer Karte platzieren kannst. Hier sind zwei beliebte Programme:\nArcGIS - Eine kommerzielle GIS-Software, die von der Firma ESRI entwickelt wurde und sehr beliebt, aber ziemlich teuer ist.\nQGIS - Eine kostenlose Open-Source-GIS-Software, die fast alles kann, was ArcGIS auch kann. Du kannst QGIS hier herunterladen\nDie Verwendung von R als GIS kann anfangs etwas einschüchternd wirken, da es anstelle von “Zeigen und Klicken” eine “Befehlszeilenschnittstelle” hat (du musst programmieren, um das gewünschte Ergebnis zu erhalten). Dies ist jedoch ein großer Vorteil, wenn du immer wieder Karten erstellen oder eine Analyse erstellen musst, die reproduzierbar ist.\n\n\nRäumliche Daten\nDie beiden wichtigsten Formen von Geodaten, die in GIS verwendet werden, sind Vektor- und Rasterdaten:\nVektordaten - Vektordaten sind das gebräuchlichste Format für Geodaten im GIS und bestehen aus geometrischen Merkmalen wie Scheitelpunkten und Pfaden. Vektorielle Geodaten können in drei weit verbreitete Typen unterteilt werden:\n\nPunkte - Ein Punkt besteht aus einem Koordinatenpaar (x,y), das einen bestimmten Ort in einem Koordinatensystem darstellt. Punkte sind die grundlegendste Form von Geodaten und können verwendet werden, um einen Fall (z. B. die Wohnung eines Patienten) oder einen Ort (z. B. ein Krankenhaus) auf einer Karte zu kennzeichnen.\nLinien - Eine Linie besteht aus zwei miteinander verbundenen Punkten. Linien haben eine bestimmte Länge und können z. B. Straßen oder Flüsse kennzeichnen.\nPolygone - Ein Polygon besteht aus mindestens drei Liniensegmenten, die durch Punkte verbunden sind. Polygone haben sowohl eine Länge (d.h. den Umfang der Fläche) als auch ein Flächenmaß. Polygone können verwendet werden, um ein Gebiet (z. B. ein Dorf) oder eine Struktur (z. B. die tatsächliche Fläche eines Krankenhauses) festzuhalten.\n\nRasterdaten - Ein alternatives Format für räumliche Daten, Rasterdaten, ist eine Matrix aus Zellen (z. B. Pixel), wobei jede Zelle Informationen wie Höhe, Temperatur, Neigung, Waldbedeckung usw. enthält. Oft handelt es sich dabei um Luftaufnahmen, Satellitenbilder usw. Rasterdaten können auch als “Basiskarten” unter Vektordaten verwendet werden.\n\n\nVisualisierung räumlicher Daten\nUm räumliche Daten auf einer Karte visuell darstellen zu können, benötigt die GIS-Software ausreichende Informationen darüber, wo die verschiedenen Merkmale im Verhältnis zueinander liegen sollen. Wenn du Vektordaten verwendest, was bei den meisten Anwendungsfällen der Fall ist, werden diese Informationen in der Regel in einem Shapefile gespeichert:\nShapefiles - Ein Shapefile ist ein gängiges Datenformat zur Speicherung von “Vektor”-Geodaten, die aus Linien, Punkten oder Polygonen bestehen. Ein einzelnes Shapefile ist eigentlich eine Sammlung von mindestens drei Dateien - .shp, .shx und .dbf. Alle diese Unterdateien müssen sich in einem bestimmten Verzeichnis (Ordner) befinden, damit das Shapefile gelesen werden kann. Die zugehörigen Dateien können in einem ZIP-Ordner komprimiert werden, um sie per E-Mail zu versenden oder von einer Website herunterzuladen.\nDas Shapefile enthält Informationen über die Merkmale selbst und darüber, wo sie auf der Erdoberfläche zu finden sind. Das ist wichtig, denn während die Erde ein Globus ist, sind Karten in der Regel zweidimensional. Die Entscheidung, wie räumliche Daten “geglättet” werden, kann einen großen Einfluss auf das Aussehen und die Interpretation der resultierenden Karte haben.\nKoordinatenreferenzsysteme (CRS) - Ein CRS ist ein koordinatenbasiertes System, das verwendet wird, um geografische Merkmale auf der Erdoberfläche zu lokalisieren. Es hat ein paar wichtige Komponenten:\n\nKoordinatensystem - Es gibt viele verschiedene Koordinatensysteme, also stelle sicher, dass du weißt, aus welchem System deine Koordinaten stammen. Üblich sind Breiten- und Längengrade, aber du kannst auch UTM Koordinaten.\nEinheiten - Kenne die Einheiten für dein Koordinatensystem (z.B. Dezimalgrad, Meter)\nDatum - Eine bestimmte modellierte Version der Erde. Sie wurden im Laufe der Jahre überarbeitet. Stelle also sicher, dass deine Kartenebenen das gleiche Datum verwenden.\nProjektion - Ein Verweis auf die mathematische Gleichung, die verwendet wurde, um die wirklich runde Erde auf eine flache Oberfläche (Karte) zu projizieren.\n\nDenke daran, dass du räumliche Daten auch zusammenfassen kannst, ohne die unten gezeigten Kartierungswerkzeuge zu verwenden. Manchmal reicht eine einfache Tabelle nach Geografie (z. B. Bezirk, Land usw.)!",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#erste-schritte-mit-gis",
    "href": "new_pages/gis.de.html#erste-schritte-mit-gis",
    "title": "28  GIS-Grundlagen",
    "section": "28.3 Erste Schritte mit GIS",
    "text": "28.3 Erste Schritte mit GIS\nEs gibt ein paar wichtige Dinge, die du für die Erstellung einer Karte brauchst und an die du denken musst. Dazu gehören:\n\nA Datensatz – kann in einem räumlichen Datenformat vorliegen (z. B. Shapefiles, wie oben beschrieben) oder auch in einem nicht-räumlichen Format (z. B. als csv-Datei).\nWenn dein Datensatz nicht in einem räumlichen Format vorliegt, brauchst du außerdem eine Referenzdatensatz. Referenzdaten bestehen aus der räumlichen Darstellung der Daten und den zugehörigen Attributen Dazu gehört auch Material mit Standort- und Adressinformationen zu bestimmten Merkmalen.\n\nWenn du mit vordefinierten geografischen Grenzen arbeitest (z. B. Verwaltungsregionen), sind Referenz-Shapefiles oft frei verfügbar und können von einer Regierungsbehörde oder einer Datenaustauschorganisation heruntergeladen werden. Im Zweifelsfall ist es ratsam, bei Google nach “[Regionen] Shapefile”\nWenn du Adressinformationen, aber keine Längen- und Breitengrade hast, musst du eventuell eine Geokodierungsmaschine verwenden, um die räumlichen Referenzdaten für deine Datensätze zu erhalten.\n\nEine Idee über wie du die Daten präsentieren willst die Informationen in deinen Datensätzen für dein Zielpublikum darstellen willst. Es gibt viele verschiedene Arten von Karten, und es ist wichtig, dass du dir überlegst, welche Art von Karte am besten zu deinen Bedürfnissen passt.\n\n\nArten von Karten zur Visualisierung deiner Daten\nChoropleth-Karte - Eine Art von thematischer Karte, bei der Farben, Schattierungen oder Muster verwendet werden, um geografische Regionen im Verhältnis zu ihrem Wert eines Attributs darzustellen. Ein größerer Wert kann zum Beispiel durch eine dunklere Farbe dargestellt werden als ein kleinerer Wert. Diese Art von Karte ist besonders nützlich, um eine Variable und ihre Veränderungen in bestimmten Regionen oder geopolitischen Gebieten zu veranschaulichen.\n\n\n\n\n\n\n\n\n\nHeatmap zur Falldichte - eine Art von thematischer Karte, bei der Farben verwendet werden, um die Intensität eines Wertes darzustellen, aber keine definierten Regionen oder geopolitischen Grenzen zur Gruppierung von Daten verwendet werden. Diese Art von Karte wird in der Regel zur Darstellung von “Hot Spots” oder Gebieten mit einer hohen Dichte oder Konzentration von Punkten verwendet.\n\n\n\n\n\n\n\n\n\nPunktdichtekarte - ein thematischer Kartentyp, der Punkte verwendet, um Attributwerte in deinen Daten darzustellen. Diese Art von Karte eignet sich am besten, um die Streuung deiner Daten zu visualisieren und visuell nach Clustern zu suchen.\nProportionale Symbolkarte (Karte mit abgestuften Symbolen) - Eine thematische Karte, die einer Choroplethenkarte ähnelt, bei der jedoch der Wert eines Attributs nicht mit einer Farbe, sondern mit einem Symbol (in der Regel einem Kreis) im Verhältnis zum Wert angegeben wird. So kann zum Beispiel ein größerer Wert durch ein größeres Symbol angezeigt werden als ein kleinerer Wert. Diese Art von Karte eignet sich am besten, wenn du die Größe oder Menge deiner Daten über geografische Regionen hinweg visualisieren willst.\nDu kannst auch mehrere verschiedene Arten von Visualisierungen kombinieren, um komplexe geografische Muster darzustellen. Zum Beispiel sind die Fälle (Punkte) in der Karte unten nach der nächstgelegenen Gesundheitseinrichtung eingefärbt (siehe Legende). Die großen roten Kreise zeigen Einzugsgebiete von Gesundheitseinrichtungen Die großen roten Kreise zeigen die Einzugsgebiete der Gesundheitseinrichtungen in einem bestimmten Radius an, die hellroten Punkte die Fälle, die außerhalb eines Einzugsgebiets lagen:\n\n\n\n\n\n\n\n\n\nHinweis: Der Hauptfokus dieser GIS-Seite liegt auf dem Kontext der Reaktion auf Ausbrüche vor Ort. Daher wird der Inhalt der Seite die grundlegenden räumlichen Datenmanipulationen, Visualisierungen und Analysen abdecken.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#vorbereitung",
    "href": "new_pages/gis.de.html#vorbereitung",
    "title": "28  GIS-Grundlagen",
    "section": "28.4 Vorbereitung",
    "text": "28.4 Vorbereitung\n\nPakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,           # to import data\n  here,          # to locate files\n  tidyverse,     # to clean, handle, and plot the data (includes ggplot2 package)\n  sf,            # to manage spatial data using a Simple Feature format\n  tmap,          # to produce simple maps, works for both interactive and static maps\n  janitor,       # to clean column names\n  OpenStreetMap, # to add OSM basemap in ggplot map\n  spdep          # spatial statistics\n  )\n\nEinen Überblick über alle R-Pakete, die sich mit räumlichen Daten befassen, findest du auf der CRAN “Spatial Task View”.\n\n\nBeispielhafte Falldaten\nZu Demonstrationszwecken arbeiten wir mit einer Zufallsstichprobe von 1000 Fällen aus der simulierten Ebola-Epidemie linelist Datenrahmen arbeiten (aus rechnerischen Gründen ist es einfacher, in diesem Handbuch mit weniger Fällen zu arbeiten). Wenn du mitmachen willst, klicke hier, um die “saubere” Linienliste herunterzuladen (als .rds-Datei).\nDa wir eine Stichprobe der Fälle nehmen, können deine Ergebnisse etwas anders aussehen als hier gezeigt, wenn du die Codes selbst ausführst.\nImportiere Daten mit dem import() Funktion aus dem rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import clean case linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")  \n\nAls nächstes wählen wir eine Zufallsstichprobe von 1000 Zeilen mit sample() aus Basis R.\n\n# generate 1000 random row numbers, from the number of rows in linelist\nsample_rows &lt;- sample(nrow(linelist), 1000)\n\n# subset linelist to keep only the sample rows, and all columns\nlinelist &lt;- linelist[sample_rows,]\n\nJetzt wollen wir das umwandeln linelist der Klasse dataframe, in ein Objekt der Klasse “sf” (spatial features) umwandeln. Da die Zeilenliste zwei Spalten “lon” und “lat” enthält, die den Längen- und Breitengrad des Wohnorts eines jeden Falles angeben, ist das ganz einfach.\nWir verwenden das Paket sf (räumliche Merkmale) und seine Funktion st_as_sf() um das neue Objekt zu erstellen, rufen wir linelist_sf. Dieses neue Objekt sieht im Wesentlichen genauso aus wie die Linelist, aber die Spalten lon und lat wurden als Koordinatenspalten bezeichnet, und es wurde ein Koordinatenreferenzsystem (CRS) für die Anzeige der Punkte zugewiesen. 4326 identifiziert unsere Koordinaten als basierend auf dem World Geodetic System 1984 (WGS84) - das der Standard für GPS-Koordinaten ist.\n\n# Create sf object\nlinelist_sf &lt;- linelist %&gt;%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\n\nSo ist das ursprüngliche linelist Datenrahmen aussieht. In dieser Demonstration verwenden wir nur die Spalte date_onset und geometry (die aus den obigen Feldern für Längen- und Breitengrad gebildet wurde und die letzte Spalte im Datenrahmen ist).\n\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )\n\n\n\n\n\n\n\nShapefiles der Verwaltungsgrenzen\nSierra Leone: Shapefiles der Verwaltungsgrenzen\nIm Vorfeld haben wir alle administrativen Grenzen für Sierra Leone vom Humanitarian Data Exchange (HDX) heruntergeladen Website hier. Alternativ kannst du diese und alle anderen Beispieldaten für dieses Handbuch auch über unser R-Paket herunterladen, wie in der [Handbuch und Daten herunterladen] Seite erklärt wird.\nJetzt machen wir Folgendes, um das Admin Level 3 Shapefile in R zu speichern:\n\nImportiere das Shapefile\nBereinige die Spaltennamen\nZeilen filtern, um nur Bereiche von Interesse zu erhalten\n\nUm ein Shapefile zu importieren, verwenden wir die read_sf() Funktion von sf. Sie erhält den Dateipfad über here(). - in unserem Fall befindet sich die Datei innerhalb unseres R-Projekts in den Unterordnern “data”, “gis” und “shp” mit dem Dateinamen “sle_adm3.shp” (siehe Seiten über [Importieren und Exportieren] und [R-Projekte] für weitere Informationen). Du musst deinen eigenen Dateipfad angeben.\nAls nächstes verwenden wir clean_names() aus dem Hausmeister Paket, um die Spaltennamen des Shapefiles zu standardisieren. Wir verwenden auch filter() um nur die Zeilen zu behalten, deren admin2name “Western Area Urban” oder “Western Area Rural” lautet.\n\n# ADM3 level clean\nsle_adm3 &lt;- sle_adm3_raw %&gt;%\n  janitor::clean_names() %&gt;% # standardize column names\n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filter to keep certain areas\n\nUnten kannst du sehen, wie das Shapefile nach dem Import und der Bereinigung aussieht. Scrolle nach rechts um zu sehen, dass es Spalten mit Verwaltungsebene 0 (Land), Verwaltungsebene 1, Verwaltungsebene 2 und schließlich Verwaltungsebene 3 gibt. Jede Ebene hat einen Zeichennamen und einen eindeutigen Bezeichner “pcode”. Der pcode erweitert sich mit jeder aufsteigenden Verwaltungsebene, z.B. SL (Sierra Leone) -&gt; SL04 (Western) -&gt; SL0410 (Western Area Rural) -&gt; SL040101 (Koya Rural).\n\n\n\n\n\n\n\n\nBevölkerungsdaten\nSierra Leone: Bevölkerung nach ADM3\nDiese Daten können wiederum von HDX heruntergeladen werden (Link hier) oder über unser epirhandbookR-Paket, wie auf der [auf dieser Seite][Handbuch und Daten herunterladen]. Wir verwendenimport() um die .csv-Datei zu laden. Wir übergeben die importierte Datei auch an clean_names() um die Syntax der Spaltennamen zu standardisieren.\n\n# Population by ADM3\nsle_adm3_pop &lt;- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %&gt;%\n  janitor::clean_names()\n\nSo sieht die Bevölkerungsdatei aus. Scrolle nach rechts, um zu sehen, dass jedes Bundesland Spalten mit male Bevölkerung, female bevölkerung, total Bevölkerung und die Aufteilung der Bevölkerung in Spalten nach Altersgruppen.\n\n\n\n\n\n\n\n\nGesundheitseinrichtungen\nSierra Leone: Daten zu Gesundheitseinrichtungen von OpenStreetMap\nAuch hier haben wir die Standorte der Gesundheitseinrichtungen von HDX heruntergeladen hieroder über die Anweisungen im [Handbuch und Daten herunterladen] Seite.\nWir importieren das Shapefile der Anlagenpunkte mit read_sf() ein, bereinigen erneut die Spaltennamen und filtern dann nur die Punkte, die entweder als “Krankenhaus”, “Klinik” oder “Ärzte” gekennzeichnet sind.\n\n# OSM health facility shapefile\nsle_hf &lt;- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %&gt;% \n  janitor::clean_names() %&gt;%\n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))\n\nHier ist der resultierende Datenrahmen - nach rechts scrollen um den Namen der Einrichtung zu sehen und geometry Koordinaten.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#koordinaten-einzeichnen",
    "href": "new_pages/gis.de.html#koordinaten-einzeichnen",
    "title": "28  GIS-Grundlagen",
    "section": "28.5 Koordinaten einzeichnen",
    "text": "28.5 Koordinaten einzeichnen\nDer einfachste Weg, X-Y-Koordinaten (Längen-/Breitengrad, Punkte) zu zeichnen, ist in diesem Fall, sie als Punkte direkt aus dem Feld linelist_sf Objekt zu zeichnen, das wir im Vorbereitungsabschnitt erstellt haben.\nDas Paket tmap bietet einfache Mapping-Funktionen für den statischen (“Plot”-Modus) und den interaktiven (“View”-Modus) mit nur wenigen Zeilen Code. Das tmap Syntax ist ähnlich wie die von ggplot2 Die Befehle werden mit den folgenden Worten aneinander gehängt +. Lesen Sie mehr Details in diesem Vignette.\n\nStellen Sie die tmap Modus. In diesem Fall verwenden wir den “Plot”-Modus, der statische Ausgaben erzeugt.\n\n\ntmap_mode(\"plot\") # choose either \"view\" or \"plot\"\n\nUnten sind die Punkte einzeln aufgetragen.tm_shape() wird mit dem linelist_sf Objekten. Wir fügen dann Punkte über tm_dots() und geben dabei die Größe und Farbe an. Weil linelist_sf ein sf-Objekt ist, haben wir die beiden Spalten mit den Längen- und Breitenkoordinaten und dem Koordinatenreferenzsystem (CRS) bereits festgelegt:\n\n# Just the cases (points)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n\n\n\n\n\n\n\n\nDie Punkte allein sagen uns aber nicht viel. Deshalb sollten wir auch die Verwaltungsgrenzen abbilden:\nAuch hier verwenden wir tm_shape() (siehe Dokumentation), aber statt des Shapefiles der Fallpunkte stellen wir das Shapefile der Verwaltungsgrenzen (Polygone) zur Verfügung.\nMit der bbox = Argument (bbox steht für “bounding box”) können wir die Koordinatengrenzen angeben. Zuerst zeigen wir die Kartenanzeige ohne bbox und dann mit ihr.\n\n# Just the administrative boundaries (polygons)\ntm_shape(sle_adm3) +               # admin boundaries shapefile\n  tm_polygons(col = \"#F7F7F7\")+    # show polygons in light grey\n  tm_borders(col = \"#000000\",      # show borders with color and line weight\n             lwd = 2) +\n  tm_text(\"admin3name\")            # column text to display for each polygon\n\n\n# Same as above, but with zoom from bounding box\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # corner\n                  -13.2, 8.5)) +  # corner\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnd jetzt beide Punkte und Polygone zusammen:\n\n# All together\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # give title to map\n\n\n\n\n\n\n\n\nEinen guten Vergleich der Mapping-Optionen in R findest du hier Blog-Beitrag.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#spatial-joins",
    "href": "new_pages/gis.de.html#spatial-joins",
    "title": "28  GIS-Grundlagen",
    "section": "28.6 Spatial joins",
    "text": "28.6 Spatial joins\nDu bist vielleicht vertraut mit beitretenvon Daten aus einem Datensatz mit einem anderen vertraut. Mehrere Methoden werden im Abschnitt [Daten verknüpfen] Seite dieses Handbuchs beschrieben. Eine räumliche Verknüpfung dient einem ähnlichen Zweck, nutzt aber die räumlichen Beziehungen aus. Anstatt sich auf gemeinsame Werte in den Spalten zu verlassen, um Beobachtungen korrekt abzugleichen, kannst du ihre räumlichen Beziehungen nutzen, z. B. wenn ein Merkmalinnerhalb von einem anderen liegt, oder der nächstgelegene Nachbar zu einem anderen, oder innerhalb einer Puffer eines bestimmten Radius von einem anderen, usw.\nDie sf Paket bietet verschiedene Methoden für räumliche Verknüpfungen. Weitere Informationen über die st_join-Methode und räumliche Join-Typen findest du in dieser Referenz.\n\nPunkte im Polygon\nRäumliche Zuordnung von Verwaltungseinheiten zu Fällen\nHier ergibt sich ein interessantes Rätsel: Die Fallliste enthält keine Informationen über die Verwaltungseinheiten der Fälle. Obwohl es ideal ist, solche Informationen während der ersten Datenerhebungsphase zu sammeln, können wir den einzelnen Fällen auch Verwaltungseinheiten auf der Grundlage ihrer räumlichen Beziehungen zuweisen (d. h. ein Punkt schneidet ein Polygon).\nIm Folgenden werden wir unsere Fallstandorte (Punkte) mit den ADM3-Grenzen (Polygone) räumlich überschneiden:\n\nBeginne mit der Lineliste (Punkte)\nRäumliche Verknüpfung mit den Grenzen, wobei die Art der Verknüpfung auf “st_intersects” eingestellt wird\nVerwende select() um nur bestimmte Spalten der neuen Verwaltungsgrenzen zu behalten\n\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects)\n\nAlle Spalten von sle_adms wurden der Zeilenliste hinzugefügt! Jeder Fall hat jetzt Spalten, in denen die Verwaltungsebene angegeben ist, in die er fällt. In diesem Beispiel wollen wir nur zwei der neuen Spalten beibehalten (Verwaltungsebene 3), also müssen wir select() die alten Spaltennamen und nur die beiden zusätzlichen von Interesse:\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects) %&gt;% \n  \n  # Keep the old column names and two new admin ones of interest\n  select(names(linelist_sf), admin3name, admin3pcod)\n\nUnten siehst du die ersten zehn Fälle und ihre Zuständigkeiten der Verwaltungsebene 3 (ADM3), die auf der Grundlage der räumlichen Schnittpunkte mit den Polygonformen festgelegt wurden.\n\n# Now you will see the ADM3 names attached to each case\nlinelist_adm %&gt;% select(case_id, admin3name, admin3pcod)\n\nSimple feature collection with 1000 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -13.27101 ymin: 8.448383 xmax: -13.20578 ymax: 8.491748\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     case_id     admin3name admin3pcod                   geometry\n4846  38d7b2        East II   SL040204 POINT (-13.21976 8.481365)\n5743  f0297e       West III   SL040208 POINT (-13.26075 8.486371)\n1609  2591c9 Mountain Rural   SL040102 POINT (-13.22016 8.463424)\n3050  bbd971         West I   SL040206 POINT (-13.25261 8.487592)\n3058  506fbe       East III   SL040205  POINT (-13.20908 8.46375)\n1403  920c1b Mountain Rural   SL040102 POINT (-13.21439 8.453792)\n5801  6cddda        East II   SL040204 POINT (-13.22397 8.486486)\n4849  f13395 Mountain Rural   SL040102 POINT (-13.21968 8.450015)\n1082  51b8e2     Central II   SL040202  POINT (-13.2399 8.485439)\n2305  b1ecb7 Mountain Rural   SL040102 POINT (-13.21394 8.463133)\n\n\nJetzt können wir unsere Fälle nach Verwaltungseinheiten beschreiben - etwas, das wir vor der räumlichen Verknüpfung nicht tun konnten!\n\n# Make new dataframe containing counts of cases by administrative unit\ncase_adm3 &lt;- linelist_adm %&gt;%          # begin with linelist with new admin cols\n  as_tibble() %&gt;%                      # convert to tibble for better display\n  group_by(admin3pcod, admin3name) %&gt;% # group by admin unit, both by name and pcode \n  summarise(cases = n()) %&gt;%           # summarize and count rows\n  arrange(desc(cases))                     # arrange in descending order\n\ncase_adm3\n\n# A tibble: 10 × 3\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;\n 1 SL040102   Mountain Rural   278\n 2 SL040208   West III         239\n 3 SL040207   West II          174\n 4 SL040204   East II          124\n 5 SL040201   Central I         64\n 6 SL040203   East I            52\n 7 SL040206   West I            29\n 8 SL040202   Central II        21\n 9 SL040205   East III          17\n10 &lt;NA&gt;       &lt;NA&gt;               2\n\n\nWir können auch ein Balkendiagramm der Fallzahlen nach Verwaltungseinheit erstellen.\nIn diesem Beispiel beginnen wir die ggplot() mit dem linelist_adm an, damit wir Faktor-Funktionen wie fct_infreq()anwenden, die die Balken nach Häufigkeit ordnet (siehe Seite über [Faktoren] für Tipps).\n\nggplot(\n    data = linelist_adm,                       # begin with linelist containing admin unit info\n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # x-axis is admin units, ordered by frequency (reversed)\n  geom_bar()+                                # create bars, height is number of rows\n  coord_flip()+                              # flip X and Y axes for easier reading of adm units\n  theme_classic()+                           # simplify background\n  labs(                                      # titles and labels\n    x = \"Admin level 3\",\n    y = \"Number of cases\",\n    title = \"Number of cases, by adminstative unit\",\n    caption = \"As determined by a spatial join, from 1000 randomly sampled cases from linelist\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nNächster Nachbar\nSuche nach der nächstgelegenen Gesundheitseinrichtung / dem Einzugsgebiet\nEs kann nützlich sein, zu wissen, wo sich die Gesundheitseinrichtungen in Bezug auf die Krankheitsherde befinden.\nWir können die st_nearest_feature Join-Methode aus der st_join() Funktion (sf Paket), um die nächstgelegene Gesundheitseinrichtung für einzelne Fälle zu visualisieren.\n\nWir beginnen mit der Shapefile-Lineliste linelist_sf\nWir verbinden räumlich mit sle_hf die Standorte von Gesundheitseinrichtungen und Kliniken (Punkte)\n\n\n# Closest health facility to each case\nlinelist_sf_hf &lt;- linelist_sf %&gt;%                  # begin with linelist shapefile  \n  st_join(sle_hf, join = st_nearest_feature) %&gt;%   # data from nearest clinic joined to case data \n  select(case_id, osm_id, name, amenity) %&gt;%       # keep columns of interest, including id, name, type, and geometry of healthcare facility\n  rename(\"nearest_clinic\" = \"name\")                # re-name for clarity\n\nWir sehen unten (die ersten 50 Zeilen), dass jeder Fall nun Daten über die nächstgelegene Klinik/das nächstgelegene Krankenhaus hat\n\n\n\n\n\n\nWir können sehen, dass “Den Clinic” die nächstgelegene Gesundheitseinrichtung für etwa 30 % der Fälle ist.\n\n# Count cases by health facility\nhf_catchment &lt;- linelist_sf_hf %&gt;%   # begin with linelist including nearest clinic data\n  as.data.frame() %&gt;%                # convert from shapefile to dataframe\n  count(nearest_clinic,              # count rows by \"name\" (of clinic)\n        name = \"case_n\") %&gt;%         # assign new counts column as \"case_n\"\n  arrange(desc(case_n))              # arrange in descending order\n\nhf_catchment                         # print to console\n\n                         nearest_clinic case_n\n1                            Den Clinic    368\n2       Shriners Hospitals for Children    320\n3         GINER HALL COMMUNITY HOSPITAL    180\n4                             panasonic     56\n5 Princess Christian Maternity Hospital     28\n6                     ARAB EGYPT CLINIC     24\n7                  MABELL HEALTH CENTER     12\n8                                  &lt;NA&gt;     12\n\n\nUm die Ergebnisse zu visualisieren, können wir tmap - verwenden, diesmal im interaktiven Modus zur leichteren Betrachtung\n\ntmap_mode(\"view\")   # set tmap mode to interactive  \n\n# plot the cases and clinic points \ntm_shape(linelist_sf_hf) +            # plot cases\n  tm_dots(size=0.08,                  # cases colored by nearest clinic\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # plot clinic facilities in large black dots\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # overlay with name of facility\ntm_view(set.view = c(-13.2284, 8.4699, 13), # adjust zoom (center coords, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cases, colored by nearest clinic\")\n\n\n\n\n\n\n\nPuffer\nWir können auch untersuchen, wie viele Fälle innerhalb von 2,5 km (~30 Minuten) Fußweg von der nächsten Gesundheitseinrichtung entfernt sind.\nHinweis: Für genauere Entfernungsberechnungen ist es besser, dein sf-Objekt auf das jeweilige lokale Kartenprojektionssystem wie UTM (Erde projiziert auf eine ebene Fläche) zu projizieren. In diesem Beispiel halten wir uns der Einfachheit halber an das geografische Koordinatensystem World Geodetic System (WGS84) (die Erde wird als kugelförmige / runde Fläche dargestellt, daher sind die Einheiten in Dezimalgraden). Wir verwenden eine allgemeine Umrechnung von: 1 Dezimalgrad = ~111km.\nWeitere Informationen über Kartenprojektionen und Koordinatensysteme findest du hier Esri-Artikel. Diese Blog spricht über verschiedene Arten von Kartenprojektionen und wie man eine geeignete Projektion je nach Interessengebiet und Kontext deiner Karte/Analyse auswählen kann.\nErste erstellst du einen kreisförmigen Puffer mit einem Radius von ~2,5 km um jede Gesundheitseinrichtung. Dies geschieht mit der Funktion st_buffer() von tmap. Da die Einheit der Karte in Längen- und Breitengraden angegeben ist, wird “0,02” so interpretiert. Wenn dein Kartenkoordinatensystem in Metern angegeben ist, muss die Zahl in Metern angegeben werden.\n\nsle_hf_2k &lt;- sle_hf %&gt;%\n  st_buffer(dist=0.02)       # decimal degrees translating to approximately 2.5km \n\nUnten stellen wir die Pufferzonen selbst dar, mit dem :\n\ntmap_mode(\"plot\")\n# Create circular buffers\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # plot clinic facilities in large red dots\n  tm_dots(size=0.3, col='black')      \n\n\n\n\n\n\n\n\n*Zweite schneiden wir diese Puffer mit den Fällen (Punkten), indem wir st_join() und der Verknüpfungsart von st_intersects. Das heißt, die Daten aus den Puffern werden mit den Punkten verbunden, die sie schneiden.\n\n# Intersect the cases with the buffers\nlinelist_sf_hf_2k &lt;- linelist_sf_hf %&gt;%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %&gt;%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %&gt;%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n\nJetzt können wir die Ergebnisse zählen: nrow(linelist_sf_hf_2k[is.na(linelist_sf_hf_2k$osm_id.y),]) von 1000 Fällen haben sich mit keinem Puffer gekreuzt (dieser Wert fehlt) und leben somit mehr als 30 Minuten Fußweg von der nächsten Gesundheitseinrichtung entfernt.\n\n# Cases which did not get intersected with any of the health facility buffers\nlinelist_sf_hf_2k %&gt;% \n  filter(is.na(osm_id.y)) %&gt;%\n  nrow()\n\n[1] 1000\n\n\nWir können die Ergebnisse so visualisieren, dass die Fälle, die sich mit keinem Puffer überschnitten haben, rot erscheinen.\n\ntmap_mode(\"view\")\n\n# First display the cases in points\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# plot clinic facilities in large black dots\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# Then overlay the health facility buffers in polylines\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# Highlight cases that are not part of any health facility buffers\n# in red dots  \ntm_shape(linelist_sf_hf_2k %&gt;%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# add title  \ntm_layout(title = \"Cases by clinic catchment area\")\n\n\n\n\n\n\n\nAndere räumliche Verknüpfungen\nAlternative Werte für das Argument join umfassen (aus dem Dokumentation)\n\nst_contains_properly\nst_beinhaltet\nst_abgedeckt_von\nst_bedeckt\nst_Kreuze\nst_disjoint\nst_equals_exact\nst_equals\nst_ist_innerhalb_der_Entfernung\nst_nearest_feature\nst_overlaps\nst_touches\nst_innerhalb",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#choropleth-karten",
    "href": "new_pages/gis.de.html#choropleth-karten",
    "title": "28  GIS-Grundlagen",
    "section": "28.7 Choropleth-Karten",
    "text": "28.7 Choropleth-Karten\nChoropleth-Karten können nützlich sein, um deine Daten nach vordefinierten Gebieten zu visualisieren, in der Regel Verwaltungseinheiten oder Gesundheitsgebiete. Bei der Bekämpfung von Krankheitsausbrüchen kann dies z.B. helfen, die Ressourcen gezielt für bestimmte Gebiete mit hohen Erkrankungsraten einzusetzen.\nNachdem wir allen Fällen die Namen der Verwaltungseinheiten zugewiesen haben (siehe Abschnitt über räumliche Verknüpfungen oben), können wir mit der Zuordnung der Fallzahlen zu den einzelnen Gebieten beginnen (Choroplethenkarten).\nDa wir auch Bevölkerungsdaten nach ADM3 haben, können wir diese Informationen in die case_adm3 Tabelle hinzufügen, die wir zuvor erstellt haben.\nWir beginnen mit dem im vorherigen Schritt erstellten Datenrahmen case_adm3 erstellt wurde, der eine zusammenfassende Tabelle für jede Verwaltungseinheit und die Anzahl der Fälle enthält.\n\nDie Bevölkerungsdaten sle_adm3_pop werden mit einer left_join() from dplyr auf der Grundlage gemeinsamer Werte in allen Spalten admin3pcod in der case_adm3 Datenrahmen, und Spalte adm_pcode im sle_adm3_popDatenrahmen. Siehe Seite über [Verbinden von Daten]).\nselect() wird auf den neuen Datenrahmen angewendet, um nur die nützlichen Spalten zu behalten - total ist die Gesamtbevölkerung\nDie Fälle pro 10.000 Einwohner werden als neue Spalte mit mutate()\n\n\n# Add population data and calculate cases per 10K population\ncase_adm3 &lt;- case_adm3 %&gt;% \n     left_join(sle_adm3_pop,                             # add columns from pop dataset\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %&gt;%  # join based on common values across these two columns\n     select(names(case_adm3), total) %&gt;%                 # keep only important columns, including total population\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # make new column with case rate per 10000, rounded to 3 decimals\n\ncase_adm3                                                # print to console for viewing\n\n# A tibble: 10 × 5\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases  total case_10kpop\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;  &lt;int&gt;       &lt;dbl&gt;\n 1 SL040102   Mountain Rural   278  33993       81.8 \n 2 SL040208   West III         239 210252       11.4 \n 3 SL040207   West II          174 145109       12.0 \n 4 SL040204   East II          124  99821       12.4 \n 5 SL040201   Central I         64  69683        9.18\n 6 SL040203   East I            52  68284        7.62\n 7 SL040206   West I            29  60186        4.82\n 8 SL040202   Central II        21  23874        8.80\n 9 SL040205   East III          17 500134        0.34\n10 &lt;NA&gt;       &lt;NA&gt;               2     NA       NA   \n\n\nVerbinde diese Tabelle mit dem ADM3-Polygonshapefile für die Kartierung\n\ncase_adm3_sf &lt;- case_adm3 %&gt;%                 # begin with cases & rate by admin unit\n  left_join(sle_adm3, by=\"admin3pcod\") %&gt;%    # join to shapefile data by common column\n  select(objectid, admin3pcod,                # keep only certain columns of interest\n         admin3name = admin3name.x,           # clean name of one column\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %&gt;%                        # keep geometry so polygons can be plotted\n  drop_na(objectid) %&gt;%                       # drop any empty rows\n  st_as_sf()                                  # convert to shapefile\n\nKartierung der Ergebnisse\n\n# tmap mode\ntmap_mode(\"plot\")               # view static map\n\n# plot polygons\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # color by number of cases column\n        tm_text(\"admin3name\")   # name display\n\n\n\n\n\n\n\n\nWir können auch die Inzidenzraten abbilden\n\n# Cases per 10K population\ntmap_mode(\"plot\")             # static viewing mode\n\n# plot\ntm_shape(case_adm3_sf) +                # plot polygons\n  tm_polygons(\"case_10kpop\",            # color by column containing case rate\n              breaks=c(0, 10, 50, 100), # define break points for colors\n              palette = \"Purples\"       # use a purple color palette\n              ) +\n  tm_text(\"admin3name\")                 # display text",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#kartierung-mit-ggplot2",
    "href": "new_pages/gis.de.html#kartierung-mit-ggplot2",
    "title": "28  GIS-Grundlagen",
    "section": "28.8 Kartierung mit ggplot2",
    "text": "28.8 Kartierung mit ggplot2\nWenn du bereits vertraut bist mit der Verwendung von ggplot2 kennst, kannst du stattdessen dieses Paket verwenden, um statische Karten deiner Daten zu erstellen. Die geom_sf() Funktion zeichnet verschiedene Objekte, je nachdem, welche Merkmale (Punkte, Linien oder Polygone) in deinen Daten enthalten sind. Du kannst zum Beispiel Folgendes verwenden geom_sf() in einer ggplot() mit sf Daten mit Polygongeometrie, um eine Choroplethenkarte zu erstellen.\nUm zu veranschaulichen, wie das funktioniert, können wir mit dem ADM3-Polygone-Shapefile beginnen, das wir zuvor verwendet haben. Wir erinnern uns, dass dies die Regionen der Verwaltungsebene 3 in Sierra Leone sind:\n\nsle_adm3\n\nSimple feature collection with 12 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 20\n   objectid admin3name   admin3pcod admin3ref_n admin2name admin2pcod admin1name\n *    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n 1      155 Koya Rural   SL040101   Koya Rural  Western A… SL0401     Western   \n 2      156 Mountain Ru… SL040102   Mountain R… Western A… SL0401     Western   \n 3      157 Waterloo Ru… SL040103   Waterloo R… Western A… SL0401     Western   \n 4      158 York Rural   SL040104   York Rural  Western A… SL0401     Western   \n 5      159 Central I    SL040201   Central I   Western A… SL0402     Western   \n 6      160 East I       SL040203   East I      Western A… SL0402     Western   \n 7      161 East II      SL040204   East II     Western A… SL0402     Western   \n 8      162 Central II   SL040202   Central II  Western A… SL0402     Western   \n 9      163 West III     SL040208   West III    Western A… SL0402     Western   \n10      164 West I       SL040206   West I      Western A… SL0402     Western   \n11      165 West II      SL040207   West II     Western A… SL0402     Western   \n12      167 East III     SL040205   East III    Western A… SL0402     Western   \n# ℹ 13 more variables: admin1pcod &lt;chr&gt;, admin0name &lt;chr&gt;, admin0pcod &lt;chr&gt;,\n#   date &lt;date&gt;, valid_on &lt;date&gt;, valid_to &lt;date&gt;, shape_leng &lt;dbl&gt;,\n#   shape_area &lt;dbl&gt;, rowcacode0 &lt;chr&gt;, rowcacode1 &lt;chr&gt;, rowcacode2 &lt;chr&gt;,\n#   rowcacode3 &lt;chr&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\nWir können die left_join() Funktion von dplyr um die Daten, die wir dem Shapefile-Objekt zuordnen möchten, hinzuzufügen. In diesem Fall werden wir die Funktion case_adm3 Datenrahmen verwenden, den wir zuvor erstellt haben, um die Fallzahlen nach Verwaltungsregionen zusammenzufassen; wir können jedoch jeden Datenrahmen auf die gleiche Weise abbilden.\n\nsle_adm3_dat &lt;- sle_adm3 %&gt;% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join = retain only if in both data objects\n\nselect(sle_adm3_dat, admin3name.x, cases) # print selected variables to console\n\nSimple feature collection with 9 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 9 × 3\n  admin3name.x   cases                                                  geometry\n  &lt;chr&gt;          &lt;int&gt;                                        &lt;MULTIPOLYGON [°]&gt;\n1 Mountain Rural   278 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.4…\n2 Central I         64 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.48…\n3 East I            52 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.49…\n4 East II          124 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.4…\n5 Central II        21 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.4…\n6 West III         239 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.4…\n7 West I            29 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.49…\n8 West II          174 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.4…\n9 East III          17 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.4…\n\n\nUm ein Säulendiagramm der Fallzahlen nach Region zu erstellen, verwende ggplot2 zu erstellen, könnten wir dann Folgendes aufrufen geom_col() wie folgt aufrufen:\n\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # reorder x axis by descending 'cases'\n               y=cases)) +                                  # y axis is number of cases by region\n  theme_bw() +\n  labs(                                                     # set figure text\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # angle x-axis labels 45 degrees to fit better\n\n\n\n\n\n\n\n\nWenn wir Folgendes verwenden wollen ggplot2 verwenden, um stattdessen eine Choropleth-Karte der Fallzahlen zu erstellen, können wir eine ähnliche Syntax verwenden, um die geom_sf() Funktion:\n\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # set fill to vary by case count variable\n\n\n\n\n\n\n\n\nWir können dann das Aussehen unserer Karte mit einer Grammatik anpassen, die für alle Fälle einheitlich ist. ggplot2 ist, zum Beispiel:\n\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # change color gradient\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # set figure text\n       subtitle = \"Admin level 3\"\n  )\n\n\n\n\n\n\n\n\nFür R-Benutzer, die mit der Arbeit mit ggplot2, geom_sf() bietet eine einfache und direkte Implementierung, die für einfache Kartenvisualisierungen geeignet ist. Um mehr zu erfahren, lies die geom_sf() Vignette oder die ggplot2-Buch.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#basiskarten",
    "href": "new_pages/gis.de.html#basiskarten",
    "title": "28  GIS-Grundlagen",
    "section": "28.9 Basiskarten",
    "text": "28.9 Basiskarten\n\nOpenStreetMap\nIm Folgenden beschreiben wir, wie man eine Basiskarte für eine ggplot2 Karte mit OpenStreetMap-Features erstellt. Alternative Methoden sind die Verwendung von ggmap das eine kostenlose Registrierung bei Google erfordert (Details).\nOpenStreetMap ist ein gemeinschaftliches Projekt zur Erstellung einer frei bearbeitbaren Karte der Welt. Die zugrundeliegenden Geodaten (z. B. die Standorte von Städten, Straßen, Naturmerkmalen, Flughäfen, Schulen, Krankenhäusern, Straßen usw.) werden als das wichtigste Ergebnis des Projekts angesehen.\nZuerst laden wir die OpenStreetMap Paket, aus dem wir unsere Basiskarte beziehen.\nDann erstellen wir das Objekt map an, das wir mit der Funktion openmap() von OpenStreetMap Paket (Dokumentation). Wir bieten das Folgende:\n\nupperLeft und lowerRight Zwei Koordinatenpaare, die die Grenzen der Basiskachel angeben\n\nIn diesem Fall haben wir die Maximal- und Minimalwerte aus den Zeilen der Linienliste eingegeben, damit die Karte dynamisch auf die Daten reagieren kann\n\nzoom = (bei Null wird sie automatisch ermittelt)\ntype = welche Art von Basiskarte - wir haben hier mehrere Möglichkeiten aufgelistet und der Code verwendet derzeit die erste ([1]) “osm”\nmergeTiles = Wir haben TRUE gewählt, damit die Basisdateien alle zu einer einzigen zusammengeführt werden\n\n\n# load package\npacman::p_load(OpenStreetMap)\n\n# Fit basemap by range of lat/long coordinates. Choose tile type\nmap &lt;- OpenStreetMap::openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # limits of basemap tile\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\n\nWenn wir diese Basiskarte jetzt plotten, indem wir autoplot.OpenStreetMap() von OpenStreetMap Paket, siehst du, dass die Einheiten auf den Achsen nicht die Koordinaten für Breiten- und Längengrade sind. Es wird ein anderes Koordinatensystem verwendet. Um die Fallwohnungen (die in Lat/Long gespeichert sind) korrekt anzuzeigen, muss dies geändert werden.\n\nautoplot.OpenStreetMap(map)\n\n\n\n\n\n\n\n\nDeshalb wollen wir die Karte mit dem Befehl “Latitude/Longitude” in Latitude/Longitude umwandeln. openproj() Funktion von OpenStreetMap Paket. Wir liefern die Basiskarte map und geben auch das gewünschte Koordinatenreferenzsystem (CRS) an. Wir tun dies, indem wir die Zeichenkette “proj.4” für die WGS 1984-Projektion angeben, aber du kannst das CRS auch auf andere Weise angeben. (siehe diese Seite um besser zu verstehen, was eine proj.4-Zeichenkette ist)\n\n# Projection WGS84\nmap_latlon &lt;- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n\nWenn wir nun die Grafik erstellen, sehen wir, dass die Achsen Breiten- und Längengradkoordinaten enthalten. Das Koordinatensystem wurde umgewandelt. Jetzt werden unsere Fälle korrekt dargestellt, wenn sie überlagert werden!\n\n# Plot map. Must use \"autoplot\" in order to work with ggplot\nautoplot.OpenStreetMap(map_latlon)\n\n\n\n\n\n\n\n\nSiehe die Tutorials hier und hier für weitere Informationen.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#konturierte-dichte-heatmaps",
    "href": "new_pages/gis.de.html#konturierte-dichte-heatmaps",
    "title": "28  GIS-Grundlagen",
    "section": "28.10 Konturierte Dichte Heatmaps",
    "text": "28.10 Konturierte Dichte Heatmaps\nIm Folgenden wird beschrieben, wie du eine konturierte Dichte-Heatmap von Fällen über einer Basiskarte erstellst, beginnend mit einer Linienliste (eine Zeile pro Fall).\n\nErstelle eine Basiskarte aus OpenStreetMap, wie oben beschrieben\nPlotten der Fälle aus linelist unter Verwendung der Spalten für Längen- und Breitengrad\nKonvertiere die Punkte in eine Dichte-Heatmap mit stat_density_2d() von ggplot2,\n\nWenn wir eine Basiskarte mit Längen- und Breitenkoordinaten haben, können wir unsere Fälle anhand der Längen- und Breitenkoordinaten ihres Wohnorts aufzeichnen.\nAufbauend auf der Funktion autoplot.OpenStreetMap() um die Basiskarte zu erstellen, ggplot2 Funktionen einfach hinzufügen, wie zum Beispiel mit geom_point() unten gezeigt:\n\n# Plot map. Must be autoplotted to work with ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # begin with the basemap\n  geom_point(                                       # add xy points from linelist lon and lat columns \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # drop legend entirely\n  labs(x = \"Longitude\",                             # titles & labels\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n\n\n\n\n\n\n\n\nDie obige Karte könnte schwierig zu interpretieren sein, vor allem wenn sich die Punkte überschneiden. Deshalb kannst du stattdessen eine 2D-Dichtekarte erstellen, indem du die ggplot2 Funktion stat_density_2d(). Du verwendest immer noch die Breiten- und Längenkoordinaten der Lineliste, aber es wird eine 2D-Kernel-Dichte-Schätzung durchgeführt und die Ergebnisse werden mit Höhenlinien dargestellt - wie eine topografische Karte. Lies die vollständige Dokumentation hier.\n\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")\n\n\n\n\n\n\n\n\n\n\nZeitreihen-Heatmap\nDie obige Dichte-Heatmap zeigt kumulierte Fälle. Wir können den Ausbruch über Zeit und Raum hinweg untersuchen, indem wir die Heatmap anhand der Monat des Symptomausbruchs die aus der Linienliste abgeleitet wurde.\nWir beginnen im linelist und erstellen eine neue Spalte mit dem Jahr und dem Monat des Beginns. Die format() Funktion von Basis R ändert, wie ein Datum angezeigt wird. In diesem Fall wollen wir “JJJJ-MM”.\n\n# Extract month of onset\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examine the values \ntable(linelist$date_onset_ym, useNA = \"always\")\n\n\n2014-04 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 \n      1       6      25      36      86     210     193     115      88      78 \n2015-02 2015-03 2015-04    &lt;NA&gt; \n     50      43      19      50 \n\n\nJetzt führen wir die Facettierung einfach über ggplot2 auf die Dichte-Heatmap anwenden. facet_wrap() wird angewendet, wobei die neue Spalte als Zeile verwendet wird. Der Übersichtlichkeit halber setzen wir die Anzahl der Facettenspalten auf 3.\n\n# packages\npacman::p_load(OpenStreetMap, tidyverse)\n\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # facet the plot by month-year of onset\n  facet_wrap(~ date_onset_ym, ncol = 4)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#räumliche-statistik",
    "href": "new_pages/gis.de.html#räumliche-statistik",
    "title": "28  GIS-Grundlagen",
    "section": "28.11 Räumliche Statistik",
    "text": "28.11 Räumliche Statistik\nBisher haben wir uns vor allem mit der Visualisierung von räumlichen Daten beschäftigt. In einigen Fällen bist du vielleicht auch an der Verwendung von räumlichen Statistiken um die räumlichen Beziehungen der Attribute in deinen Daten zu quantifizieren. Dieser Abschnitt gibt dir einen kurzen Überblick über die wichtigsten Konzepte der räumlichen Statistik und schlägt dir einige Ressourcen vor, die du nutzen kannst, wenn du umfassendere räumliche Analysen durchführen möchtest.\n\nRäumliche Beziehungen\nBevor wir eine räumliche Statistik berechnen können, müssen wir die Beziehungen zwischen den Merkmalen in unseren Daten beschreiben. Es gibt viele Möglichkeiten, räumliche Beziehungen zu konzeptualisieren, aber ein einfaches und allgemein anwendbares Modell ist das der Adjazenz - Das heißt, dass wir eine geografische Beziehung zwischen Gebieten erwarten, die eine gemeinsame Grenze haben oder “benachbart” sind.\nWir können die Adjazenzbeziehungen zwischen den Polygonen der Verwaltungsregionen in der sle_adm3 Daten, die wir verwenden, mit dem spdep Paket verwendet haben. Wir werden angeben Königin contiguity, was bedeutet, dass Regionen Nachbarn sind, wenn sie mindestens einen Punkt entlang ihrer Grenzen teilen. Die Alternative wäre Turm In unserem Fall, mit unregelmäßigen Polygonen, ist die Unterscheidung trivial, aber in manchen Fällen kann die Wahl zwischen Dame und Turm einflussreich sein.\n\nsle_nb &lt;- spdep::poly2nb(sle_adm3_dat, queen=T) # create neighbors \nsle_adjmat &lt;- spdep::nb2mat(sle_nb)    # create matrix summarizing neighbor relationships\nsle_listw &lt;- spdep::nb2listw(sle_nb)   # create listw (list of weights) object -- we will need this later\n\nsle_nb\n\nNeighbour list object:\nNumber of regions: 9 \nNumber of nonzero links: 30 \nPercentage nonzero weights: 37.03704 \nAverage number of links: 3.333333 \n\nround(sle_adjmat, digits = 2)\n\n  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\nattr(,\"call\")\nspdep::nb2mat(neighbours = sle_nb)\n\n\nDie oben abgebildete Matrix zeigt die Beziehungen zwischen den 9 Regionen in unserem sle_adm3 Daten. Ein Wert von 0 bedeutet, dass zwei Regionen nicht benachbart sind, während jeder Wert ungleich 0 auf eine Nachbarschaftsbeziehung hinweist. Die Werte in der Matrix sind so skaliert, dass jede Region eine Gesamtzeilengewichtung von 1 hat.\nEin besserer Weg, diese Nachbarschaftsbeziehungen zu visualisieren, ist, sie grafisch darzustellen:\n\nplot(sle_adm3_dat$geometry) +                                           # plot region boundaries\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # add neighbor relationships\n\n\n\n\n\n\n\n\nWir haben einen Adjazenzansatz verwendet, um benachbarte Polygone zu identifizieren; die von uns identifizierten Nachbarn werden manchmal auch als kontiguitätsbasierte Nachbarn. Dies ist jedoch nur eine Möglichkeit, um die Regionen auszuwählen, von denen erwartet wird, dass sie in einer geografischen Beziehung stehen. Die gebräuchlichsten alternativen Ansätze zur Identifizierung geografischer Beziehungen erzeugen entfernungsbasierte Nachbarn; kurz gesagt, sind dies:\n\nK-Nächste Nachbarn - Basierend auf dem Abstand zwischen den Zentren (dem geografisch gewichteten Mittelpunkt jeder Polygonregion) wählst du die n nächstgelegenen Regionen als Nachbarn aus. Es kann auch ein Schwellenwert für die maximale Entfernung festgelegt werden. In spdep kannst du verwenden knearneigh() (siehe Dokumentation).\nAbstand Schwelle Nachbarn - Wähle alle Nachbarn innerhalb eines Entfernungsschwellenwerts aus. In spdep können diese Nachbarschaftsbeziehungen identifiziert werden mit dnearneigh() (siehe Dokumentation).\n\n\n\nRäumliche Autokorrelation\nDas oft zitierte erste Gesetz der Geografie von Tobler besagt, dass “alles mit allem zusammenhängt, aber nahe Dinge mehr als entfernte Dinge”. In der Epidemiologie bedeutet das oft, dass das Risiko für eine bestimmte gesundheitliche Auswirkung in einer bestimmten Region den benachbarten Regionen ähnlicher ist als den weit entfernten. Dieses Konzept ist formalisiert worden als räumliche Autokorrelation - die statistische Eigenschaft, dass sich geografische Merkmale mit ähnlichen Werten im Raum anhäufen. Statistische Maße der räumlichen Autokorrelation können verwendet werden, um das Ausmaß der räumlichen Anhäufung zu quantifizieren in deinen Daten zu quantifizieren, zu lokalisieren, wo die Clusterbildung auftritt und gemeinsame Muster der räumlichen Autokorrelation zu identifizieren zwischen verschiedenen Variablen in deinen Daten. Dieser Abschnitt gibt einen Überblick über einige gängige Maße der räumlichen Autokorrelation und wie man sie in R berechnet.\nMoran’s I - Dies ist eine globale zusammenfassende Statistik der Korrelation zwischen dem Wert einer Variablen in einer Region und den Werten derselben Variablen in den benachbarten Regionen. Die Moran’s I-Statistik reicht in der Regel von -1 bis 1. Ein Wert von 0 bedeutet, dass es keine räumliche Korrelation gibt, während Werte, die näher bei 1 oder -1 liegen, auf eine stärkere räumliche Autokorrelation (ähnliche Werte liegen nahe beieinander) bzw. räumliche Streuung (unähnliche Werte liegen nahe beieinander) hinweisen.\nAls Beispiel berechnen wir eine Moran’s I-Statistik, um die räumliche Autokorrelation in den Ebola-Fällen zu quantifizieren, die wir zuvor kartiert haben (zur Erinnerung: Es handelt sich um eine Teilmenge der Fälle der simulierten Epidemie linelist Datenrahmen). Die spdep Paket hat eine Funktion, moran.test, die diese Berechnung für uns durchführen kann:\n\nmoran_i &lt;-spdep::moran.test(sle_adm3_dat$cases,    # numeric vector with variable of interest\n                            listw=sle_listw)       # listw object summarizing neighbor relationships\n\nmoran_i                                            # print results of Moran's I test\n\n\n    Moran I test under randomisation\n\ndata:  sle_adm3_dat$cases  \nweights: sle_listw    \n\nMoran I statistic standard deviate = 1.6618, p-value = 0.04827\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n       0.22604170       -0.12500000        0.04462167 \n\n\nDie Ausgabe der Funktion moran.test() Funktion zeigt uns eine Moran-I-Statistik von round(moran_i$estimate[1],2). Dies deutet auf das Vorhandensein einer räumlichen Autokorrelation in unseren Daten hin - insbesondere darauf, dass Regionen mit einer ähnlichen Anzahl von Ebola-Fällen wahrscheinlich nahe beieinander liegen. Der p-Wert, den die moran.test() wird durch den Vergleich mit dem Erwartungswert bei der Nullhypothese, dass keine räumliche Autokorrelation vorliegt, ermittelt und kann verwendet werden, wenn du die Ergebnisse eines formalen Hypothesentests angeben musst.\nLokaler Moran’s I - Wir können die oben berechnete (globale) Moran’s I-Statistik zerlegen, um zu ermitteln lokalisierte räumliche Autokorrelation zu identifizieren, d.h. um bestimmte Cluster in unseren Daten zu erkennen. Diese Statistik, die manchmal auch als Lokaler Indikator der räumlichen Assoziation (LISA) Statistik genannt wird, fasst das Ausmaß der räumlichen Autokorrelation um jede einzelne Region herum zusammen. Sie kann nützlich sein, um “heiße” und “kalte” Punkte auf der Karte zu finden.\nUm ein Beispiel zu zeigen, können wir die lokale Moran’s I für die oben verwendeten Ebola-Fallzahlen berechnen und kartieren. local_moran() Funktion von spdep:\n\n# calculate local Moran's I\nlocal_moran &lt;- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # variable of interest\n  listw=sle_listw                                  # listw object with neighbor weights\n)\n\n# join results to sf data\nsle_adm3_dat&lt;- cbind(sle_adm3_dat, local_moran)    \n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\nGetis-Ord Gi* - Dies ist eine weitere Statistik, die häufig für die Hotspot-Analyse verwendet wird. Die Beliebtheit dieser Statistik ist zum großen Teil auf ihre Verwendung im Hotspot-Analyse-Tool in ArcGIS zurückzuführen. Sie basiert auf der Annahme, dass der Unterschied im Wert einer Variable zwischen benachbarten Regionen in der Regel einer Normalverteilung folgt. Sie verwendet einen z-Score-Ansatz, um Regionen zu identifizieren, die im Vergleich zu ihren Nachbarn signifikant höhere (Hot Spot) oder niedrigere (Cold Spot) Werte für eine bestimmte Variable aufweisen.\nWir können die Gi*-Statistik berechnen und abbilden, indem wir die localG() Funktion von spdep:\n\n# Perform local G analysis\ngetis_ord &lt;- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# join results to sf data\nsle_adm3_dat$getis_ord &lt;- as.numeric(getis_ord)\n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\nWie du sehen kannst, sieht die Karte von Getis-Ord Gi* etwas anders aus als die Karte von Local Moran’s, die ich zuvor erstellt habe. Das liegt daran, dass die Methoden zur Berechnung dieser beiden Statistiken leicht unterschiedlich sind. Welche du verwenden solltest, hängt von deinem speziellen Anwendungsfall und der Forschungsfrage ab.\nLee’s L-Test - Dies ist ein statistischer Test für bivariate räumliche Korrelationen. Er ermöglicht es dir zu prüfen, ob das räumliche Muster für eine bestimmte Variable x mit dem räumlichen Muster einer anderen Variable übereinstimmt, y von der angenommen wird, dass sie in einem räumlichen Zusammenhang steht mit x.\nAls Beispiel wollen wir prüfen, ob das räumliche Muster der Ebola-Fälle aus der simulierten Epidemie mit dem räumlichen Muster der Bevölkerung korreliert ist. Zu Beginn brauchen wir eine population Variable in unserer sle_adm3 Daten. Wir können die total Variable aus dem sle_adm3_pop Datenrahmen verwenden, den wir zuvor geladen haben.\n\nsle_adm3_dat &lt;- sle_adm3_dat %&gt;% \n  rename(population = total)                          # rename 'total' to 'population'\n\nWir können die räumlichen Muster der beiden Variablen schnell nebeneinander visualisieren, um zu sehen, ob sie ähnlich aussehen:\n\ntmap_mode(\"plot\")\n\ncases_map &lt;- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + tm_layout(main.title=\"Cases\")\npop_map &lt;- tm_shape(sle_adm3_dat) + tm_polygons(\"population\") + tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # arrange into 2x1 facets\n\n\n\n\n\n\n\n\nOptisch scheinen die Muster unähnlich zu sein. Wir können die lee.test() Funktion in spdep um statistisch zu prüfen, ob das Muster der räumlichen Autokorrelation in den beiden Variablen zusammenhängt. Die L-Statistik liegt nahe bei 0, wenn keine Korrelation zwischen den Mustern besteht, nahe bei 1, wenn eine starke positive Korrelation besteht (d. h. die Muster sind ähnlich), und nahe bei -1, wenn eine starke negative Korrelation besteht (d. h. die Muster sind invers).\n\nlee_test &lt;- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # variable 1 to compare\n  y=sle_adm3_dat$population,     # variable 2 to compare\n  listw=sle_listw                # listw object with neighbor weights\n)\n\nlee_test\n\n\n    Lee's L statistic randomisation\n\ndata:  sle_adm3_dat$cases ,  sle_adm3_dat$population \nweights: sle_listw  \n\nLee's L statistic standard deviate = -0.82341, p-value = 0.7949\nalternative hypothesis: greater\nsample estimates:\nLee's L statistic       Expectation          Variance \n      -0.13163315       -0.04013630        0.01234755 \n\n\nDie obige Ausgabe zeigt, dass die Lee’s L-Statistik für unsere beiden Variablen wie folgt lautet round(lee_test$estimate[1],2) ist, was auf eine schwache negative Korrelation hinweist. Dies bestätigt unsere visuelle Einschätzung, dass das Muster der Fälle und die Bevölkerung nicht miteinander zusammenhängen, und liefert den Beweis dafür, dass das räumliche Muster der Fälle nicht ausschließlich auf die Bevölkerungsdichte in Hochrisikogebieten zurückzuführen ist.\nDie Lee-L-Statistik kann nützlich sein, um diese Art von Rückschlüssen auf die Beziehung zwischen räumlich verteilten Variablen zu ziehen, aber auch, um die Art der Beziehung zwischen zwei Variablen genauer zu beschreiben oder um Störfaktoren auszugleichen, räumliche Regression Techniken benötigt. Diese werden im folgenden Abschnitt kurz beschrieben.\n\n\nRäumliche Regression\nVielleicht möchtest du statistische Rückschlüsse auf die Beziehungen zwischen den Variablen in deinen räumlichen Daten ziehen. In diesen Fällen ist es sinnvoll, Folgendes zu berücksichtigen räumliche Regression zu berücksichtigen, d. h. Regressionsansätze, die die räumliche Organisation der Einheiten in deinen Daten explizit berücksichtigen. Einige Gründe, warum du räumliche Regressionsmodelle anstelle von Standardregressionsmodellen wie GLMs in Betracht ziehen solltest, sind:\n\nStandardregressionsmodelle gehen davon aus, dass die Residuen unabhängig voneinander sind. Beim Vorhandensein von starken räumlicher Autokorrelation sind die Residuen eines Standardregressionsmodells wahrscheinlich auch räumlich autokorreliert und verstoßen somit gegen diese Annahme. Dies kann zu Problemen bei der Interpretation der Modellergebnisse führen, so dass ein räumliches Modell vorzuziehen ist.\nRegressionsmodelle gehen in der Regel auch davon aus, dass der Effekt einer Variable x über alle Beobachtungen hinweg konstant ist. Im Fall von räumlicher Heterogenität können die Effekte, die wir schätzen wollen, räumlich variieren, und wir sind daran interessiert, diese Unterschiede zu quantifizieren. In diesem Fall bieten räumliche Regressionsmodelle mehr Flexibilität bei der Schätzung und Interpretation von Effekten.\n\nDie Einzelheiten der räumlichen Regressionsansätze würden den Rahmen dieses Handbuchs sprengen. Dieser Abschnitt gibt stattdessen einen Überblick über die gebräuchlichsten räumlichen Regressionsmodelle und ihre Anwendungen und verweist auf weiterführende Literatur, wenn du dich mit diesem Thema näher befassen möchtest.\nRäumliche Fehlermodelle - Diese Modelle gehen davon aus, dass die Fehlerterme zwischen den räumlichen Einheiten korreliert sind. In diesem Fall würden die Daten die Annahmen eines Standard-OLS-Modells verletzen. Räumliche Fehlermodelle werden manchmal auch bezeichnet als simultane autoregressive (SAR) Modelle. Sie können mit Hilfe der folgenden Methode angepasst werden errorsarlm() Funktion in der spatialreg Paket (räumliche Regressionsfunktionen, die früher ein Teil von spdep).\nSpatial Lag Modelle - Diese Modelle gehen davon aus, dass die abhängige Variable für eine Region i nicht nur von den Werten der unabhängigen Variablen in i beeinflusst, sondern auch von den Werten dieser Variablen in den benachbarten Regionen i. Wie räumliche Fehlermodelle werden auch räumliche Lag-Modelle manchmal beschrieben als simultane autoregressive (SAR) Modelle. Sie können mit Hilfe der folgenden Methode angepasst werden lagsarlm() Funktion in der spatialreg Paket.\nDas spdep Paket enthält mehrere nützliche Diagnosetests, um zwischen Standard-OLS-, Spatial Lag- und Spatial Error-Modellen zu entscheiden. Diese Tests, genannt Lagrange-Multiplikator-Diagnosen genannt, können verwendet werden, um die Art der räumlichen Abhängigkeit in deinen Daten zu ermitteln und das am besten geeignete Modell zu wählen. Die Funktion lm.LMtests() kann verwendet werden, um alle Lagrange-Multiplikator-Tests zu berechnen. Anselin (1988) stellt außerdem ein nützliches Flussdiagramm zur Verfügung, mit dem du anhand der Ergebnisse der Lagrange-Multiplikator-Tests entscheiden kannst, welches räumliche Regressionsmodell du verwenden möchtest:\n\n\n\n\n\n\n\n\n\nBayessche hierarchische Modelle - Bayes’sche Ansätze werden häufig für einige Anwendungen in der räumlichen Analyse verwendet, am häufigsten für Kartierung von Krankheiten. Sie werden bevorzugt, wenn die Falldaten spärlich verteilt sind (z. B. bei einem seltenen Ergebnis) oder statistisch “verrauscht” sind, da sie dazu verwendet werden können, “geglättete” Schätzungen des Krankheitsrisikos zu erstellen, indem sie den zugrunde liegenden latenten räumlichen Prozess berücksichtigen. Dies kann die Qualität der Schätzungen verbessern. Sie ermöglichen es außerdem, komplexe räumliche Korrelationsmuster, die in den Daten vorhanden sein können, im Voraus zu spezifizieren (durch die Wahl des Priors), wodurch räumlich abhängige und nicht abhängige Variationen sowohl in den unabhängigen als auch in den abhängigen Variablen berücksichtigt werden können. In R können Bayes’sche hierarchische Modelle mit der Funktion CARbayes Paket angepasst werden (siehe Vignette) oder R-INLA (siehe Website und Lehrbuch). R kann auch verwendet werden, um externe Software aufzurufen, die Bayes’sche Schätzungen vornimmt, z. B. JAGS oder WinBUGS.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.de.html#ressourcen",
    "href": "new_pages/gis.de.html#ressourcen",
    "title": "28  GIS-Grundlagen",
    "section": "28.12 Ressourcen",
    "text": "28.12 Ressourcen\n\nR Simple Features und sf-Paket Vignette\nR tmap Paket Vignette\nggmap: Räumliche Visualisierung mit ggplot2\nEinführung in die Erstellung von Karten mit R, Überblick über verschiedene Pakete\nRäumliche Daten in R (EarthLab-Kurs)\nAngewandte raumbezogene Datenanalyse in R Lehrbuch\nSpatialEpiApp - a Shiny-App, die als R-Paket heruntergeladen werden kann heruntergeladen werden kann. Damit kannst du deine eigenen Daten bereitstellen und Kartierungen, Clusteranalysen und räumliche Statistiken durchführen.\nEine Einführung in die räumliche Ökonometrie in R Workshop",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS-Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.de.html",
    "href": "new_pages/tables_presentation.de.html",
    "title": "29  Tische für die Präsentation",
    "section": "",
    "text": "29.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tische für die Präsentation</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.de.html#vorbereitung",
    "href": "new_pages/tables_presentation.de.html#vorbereitung",
    "title": "29  Tische für die Präsentation",
    "section": "",
    "text": "Pakete laden\nInstallieren und laden flextable. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst Pakete auch laden mit library() von BasisR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization\n\n\n\nDaten importieren\nZunächst importieren wir die bereinigte Liste der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.\n\n\n\n\n\n\n\n\nTabelle vorbereiten\nVor Beginn der Nutzung flextable musst du erstellendeine Tabelle als Datenrahmen erstellen. Siehe die Seite über [Beschreibende Tabellen] und [Pivotierung von Daten] erfährst du, wie du einen Datenrahmen mit Paketen wieHausmeister und dplyr. Du musst den Inhalt in Zeilen und Spalten so anordnen, wie du ihn anzeigen lassen willst. Anschließend wird der Datenrahmen an flextable übergeben, um ihn mit Farben, Überschriften, Schriftarten usw. anzuzeigen.\nNachfolgend ein Beispiel aus der [Beschreibende Tabellen] Seite für die Umwandlung des Falleslinelist in einen Datenrahmen umwandelt, der die Patientenergebnisse und CT-Werte nach Krankenhaus zusammenfasst und unten eine Summenzeile enthält. Die Ausgabe wird gespeichert als table.\n\ntable &lt;- linelist %&gt;% \n  \n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %&gt;%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %&gt;%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Death columns\n  arrange(N_Known)                                    # Arrange rows from lowest to highest (Total row at bottom)\n\ntable  # print\n\n# A tibble: 7 × 8\n# Groups:   hospital [7]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Missing          1125       514 45.7%                     21     611 54.3%    \n6 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n7 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tische für die Präsentation</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.de.html#basis-flextisch",
    "href": "new_pages/tables_presentation.de.html#basis-flextisch",
    "title": "29  Tische für die Präsentation",
    "section": "29.2 Basis-Flextisch",
    "text": "29.2 Basis-Flextisch\n\nEine Flextabelle erstellen\nSo erstellen und verwalten Sie flextable Objekte zu erstellen und zu verwalten, übergeben wir den Datenrahmen zunächst durch die flextable() Funktion. Wir speichern das Ergebnis als my_table.\n\nmy_table &lt;- flextable(table) \nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nDanach können wir nach und nach die my_table Objekt durch weitere flextable Formatierungsfunktionen.\nAuf dieser Seite werden wir der Übersichtlichkeit halber die Tabelle bei Zwischenschritten als my_table und fügen flextable Funktionen Stück für Stück hinzu. Wenn du sehen willst alle Code von Anfang bis Ende in einem Stück sehen willst, besuche die Alle Codes zusammen Abschnitt unten.\nDie allgemeine Syntax der einzelnen Zeilen von flextable Codes lautet wie folgt:\n\nfunction(table, i = X, j = X, part = \"X\"), wobei:\n\nDie “Funktion” kann eine von vielen verschiedenen Funktionen sein, wie zum Beispiel width() um Spaltenbreiten zu bestimmen, bg() um Hintergrundfarben festzulegen, align() um festzulegen, ob der Text mittig/rechts/links ausgerichtet ist, und so weiter.\ntable = ist der Name des Datenrahmens, muss aber nicht angegeben werden, wenn der Datenrahmen in die Funktion eingefügt wird.\npart = gibt an, auf welchen Teil der Tabelle die Funktion angewendet wird. Z.B. “Kopf”, “Körper” oder “alles”.\ni = legt fest, dass die Zeile auf die die Funktion angewendet werden soll, wobei “X” die Zeilennummer ist. Bei mehreren Zeilen, z. B. der ersten bis dritten Zeile, kann man angeben: i = c(1:3). Wenn du “Körper” auswählst, beginnt die erste Zeile unterhalb des Kopfbereichs.\nj = spezifiziert die Spalte auf die die Funktion angewendet werden soll, wobei “x” die Spaltennummer oder der Spaltenname ist. Bei mehreren Spalten, z. B. der fünften und sechsten, kann man angeben: j = c(5,6).\n\n\nDu findest die vollständige Liste der flextable Formatierungsfunktion hier oder sehen Sie sich die Dokumentation an, indem Sie ?flextable.\n\n\nSpaltenbreite\nWir können die autofit() Funktion verwenden, die die Tabelle so streckt, dass jede Zelle nur eine Zeile Text enthält. Die Funktion qflextable() ist eine praktische Abkürzung für flextable() und autofit().\n\nmy_table %&gt;% autofit()\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nDies ist jedoch nicht immer sinnvoll, vor allem wenn die Zellen sehr lange Werte enthalten und die Tabelle nicht auf die Seite passt.\nStattdessen können wir die Breite mit der Option width() Funktion angeben. Man muss ein bisschen herumspielen, um herauszufinden, welchen Breitenwert man angeben muss. Im folgenden Beispiel geben wir unterschiedliche Breiten für Spalte 1, Spalte 2 und die Spalten 4 bis 8 an.\n\nmy_table &lt;- my_table %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nSpaltenüberschriften\nWir wollen klarere Überschriften, damit der Inhalt der Tabelle leichter zu verstehen ist.\nFür diese Tabelle wollen wir eine zweite Kopfebene hinzufügen, damit Spalten, die dieselben Untergruppen abdecken, gruppiert werden können. Wir tun dies mit der add_header_row() Funktion mit top = TRUE. Wir geben den neuen Namen der einzelnen Spalten an values = und lassen leere Werte \"\" für Spalten, von denen wir wissen, dass wir sie später zusammenführen werden.\nWir benennen auch die Namen der Überschriften in der nun zweiten Überschrift in einer separaten set_header_labels() Befehl.\nUm schließlich bestimmte Spaltenüberschriften in der oberen Kopfzeile zu “kombinieren”, verwenden wir merge_at() um die Spaltenüberschriften in der obersten Kopfzeile zusammenzuführen.\n\nmy_table &lt;- my_table %&gt;% \n  \n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %&gt;% \n    \n  set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Horizontally merge columns 6 to 8 in new header row\n\nmy_table  # print\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nUmrandungen und Hintergrund\nDu kannst die Ränder, inneren Linien usw. mit verschiedenen flextable Funktionen anpassen. Oft ist es einfacher, zunächst alle vorhandenen Ränder mit border_remove().\nDann kannst du Standard-Rahmenmotive anwenden, indem du die Tabelle an theme_box(), theme_booktabs(), oder theme_alafoli().\nDu kannst vertikale und horizontale Linien mit einer Vielzahl von Funktionen hinzufügen. hline() und vline() fügen Linien zu einer bestimmten Zeile bzw. Spalte hinzu. In jeder Funktion musst du die part = entweder als “alle”, “Körper” oder “Kopfzeile” angeben. Für vertikale Zeilen gibst du die Spalte an, die j = und für horizontale Zeilen die Zeile auf i =. Andere Funktionen wie vline_right(), vline_left(), hline_top(), und hline_bottom() füge nur an den Außenseiten Linien hinzu.\nBei all diesen Funktionen muss der eigentliche Linienstil selbst angegeben werden, um border = angegeben werden und muss die Ausgabe eines separaten Befehls sein, der die fp_border() Funktion aus dem Offizier Paket. Mit dieser Funktion kannst du die Breite und Farbe der Linie festlegen. Du kannst dies über die Tabellenbefehle festlegen, wie unten gezeigt.\n\n# define style for border line\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# add border lines to table\nmy_table &lt;- my_table %&gt;% \n\n  # Remove all existing borders\n  border_remove() %&gt;%  \n  \n  # add horizontal lines via a pre-determined theme setting\n  theme_booktabs() %&gt;% \n  \n  # add vertical lines to separate Recovered and Died sections\n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style)       # at column 5\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nSchriftart und Ausrichtung\nWir richten alle Spalten außer der Spalte ganz links mit den Namen der Krankenhäuser mittig aus, indem wir die align() Funktion von flextable.\n\nmy_table &lt;- my_table %&gt;% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nAußerdem können wir die Schriftgröße der Kopfzeile erhöhen und sie fett machen. Wir können auch die gesamte Zeile fett formatieren.\n\nmy_table &lt;-  my_table %&gt;%  \n  fontsize(i = 1, size = 12, part = \"header\") %&gt;%   # adjust font size of header\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;%     # adjust bold face of header\n  bold(i = 7, bold = TRUE, part = \"body\")           # adjust bold face of total row (row 7 of body)\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nWir können sicherstellen, dass die Proportionsspalten nur eine Dezimalstelle anzeigen, indem wir die Funktion colformat_num(). Dies hätte auch bei der Datenverwaltung mit der Funktion round() Funktion.\n\nmy_table &lt;- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nZellen zusammenführen\nGenauso wie wir Zellen in der Kopfzeile horizontal zusammenführen, können wir auch Zellen vertikal zusammenführen, indem wir merge_at() und der Angabe der Zeilen (i) und Spalte (j). Hier fassen wir die Werte “Krankenhaus” und “Fälle mit bekanntem Ausgang insgesamt” vertikal zusammen, um ihnen mehr Platz zu geben.\n\nmy_table &lt;- my_table %&gt;% \n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nHintergrundfarbe\nUm den Inhalt der Tabelle von den Überschriften zu unterscheiden, können wir zusätzliche Formatierungen hinzufügen, z. B. die Hintergrundfarbe ändern. In diesem Beispiel ändern wir den Tabellenkörper in grau.\n\nmy_table &lt;- my_table %&gt;% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tische für die Präsentation</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.de.html#bedingte-formatierung",
    "href": "new_pages/tables_presentation.de.html#bedingte-formatierung",
    "title": "29  Tische für die Präsentation",
    "section": "29.3 Bedingte Formatierung",
    "text": "29.3 Bedingte Formatierung\nWir können alle Werte in einer Spalte hervorheben, die eine bestimmte Regel erfüllen, z.B. wenn mehr als 55% der Fälle gestorben sind. Setze die Kriterien einfach in die i = oder j = Argument, dem eine Tilde vorangestellt ist ~. Verweise auf die Spalte im Datenrahmen, nicht auf die Werte der Anzeigeüberschrift.\n\nmy_table %&gt;% \n  bg(j = 7, i = ~ Pct_Death &gt;= 55, part = \"body\", bg = \"red\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nOder wir können die gesamte Zeile hervorheben, die ein bestimmtes Kriterium erfüllt, z. B. ein Krankenhaus von Interesse. Dazu entfernen wir einfach die Spalte (j), damit die Kriterien für alle Spalten gelten.\n\nmy_table %&gt;% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tische für die Präsentation</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.de.html#alle-codes-zusammen-tbl_pres_all",
    "href": "new_pages/tables_presentation.de.html#alle-codes-zusammen-tbl_pres_all",
    "title": "29  Tische für die Präsentation",
    "section": "29.4 Alle Codes zusammen {#tbl_pres_all}",
    "text": "29.4 Alle Codes zusammen {#tbl_pres_all}\nIm Folgenden zeigen wir den gesamten Code aus den obigen Abschnitten zusammen.\n\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization\n\ntable &lt;- linelist %&gt;% \n\n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %&gt;%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %&gt;%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Death columns\n  arrange(N_Known) %&gt;%                                 # Arrange rows from lowest to highest (Total row at bottom)\n\n  # formatting\n  ############\n  flextable() %&gt;%              # table is piped in from above\n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %&gt;% \n    set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\") %&gt;%  \n  border_remove() %&gt;%  \n  theme_booktabs() %&gt;% \n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style) %&gt;%   # at column 5\n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\") %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1) %&gt;% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %&gt;% \n  bg(., part = \"body\", bg = \"gray95\")  %&gt;% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %&gt;% \n  colformat_num(., j = c(4,7), digits = 1) %&gt;%\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;% \n  bold(i = 7, bold = TRUE, part = \"body\")\n\n`summarise()` has grouped output by 'hospital'. You can override using the\n`.groups` argument.\n\ntable\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tische für die Präsentation</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.de.html#deine-tabelle-speichern",
    "href": "new_pages/tables_presentation.de.html#deine-tabelle-speichern",
    "title": "29  Tische für die Präsentation",
    "section": "29.5 Deine Tabelle speichern",
    "text": "29.5 Deine Tabelle speichern\nEs gibt verschiedene Möglichkeiten, wie die Tabelle in deine Ausgabe integriert werden kann.\n\nEinzelne Tabelle speichern\nDu kannst die Tabellen in Word, PowerPoint oder HTML oder als Bild (PNG) exportieren. Verwende dazu eine der folgenden Funktionen:\n\nsave_as_docx()\nsave_as_pptx()\nsave_as_image()\nsave_as_html()\n\nUnten speichern wir zum Beispiel unsere Tabelle als Word-Dokument. Beachte die Syntax des ersten Arguments - du kannst einfach den Namen deines Flextable-Objekts angeben, z. B. my_table angeben, oder du kannst ihm einen “Namen” geben, wie unten gezeigt (der Name ist “Meine Tabelle”). Wenn du einen Namen angibst, wird dieser als Titel der Tabelle in Word angezeigt. Wir zeigen auch den Code zum Speichern als PNG-Bild.\n\n# Edit the 'my table' as needed for the title of table.  \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\n\nBeachte die Pakete webshot oder webshot2 sind erforderlich, um eine Flextabelle als Bild zu speichern. Die Bilder können einen transparenten Hintergrund haben.\nWenn du dir eine “Live”-Version der flextable Ausgabe im gewünschten Dokumentformat anzeigen lassen möchtest, verwende print() und gib eine der folgenden Optionen an, um preview =. Das Dokument wird auf deinem Computer in dem angegebenen Softwareprogramm “aufpoppen”, aber nicht gespeichert. Das kann nützlich sein, um zu prüfen, ob die Tabelle auf eine Seite/Folie passt oder damit du sie schnell in ein anderes Dokument kopieren kannst, kannst du die Druckmethode verwenden, wobei das Argument Vorschau auf “pptx” oder “docx” eingestellt ist.\n\nprint(my_table, preview = \"docx\") # Word document example\nprint(my_table, preview = \"pptx\") # Powerpoint example\n\n\n\nTabelle in R Markdown drucken\nDiese Tabelle kann in dein automatisiertes Dokument, eine R Markdown-Ausgabe, integriert werden, wenn das Tabellenobjekt innerhalb des R Markdown-Chunks aufgerufen wird. Das bedeutet, dass die Tabelle als Teil eines Berichts aktualisiert werden kann, wenn sich die Daten ändern, sodass die Zahlen aktualisiert werden können.\nDetails dazu findest du in der [Berichte mit R Markdown] Seite dieses Handbuchs.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tische für die Präsentation</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.de.html#ressourcen",
    "href": "new_pages/tables_presentation.de.html#ressourcen",
    "title": "29  Tische für die Präsentation",
    "section": "29.6 Ressourcen",
    "text": "29.6 Ressourcen\nDie vollständige flextable Buch ist hier: https://ardata-fr.github.io/flextable-book/ Die Github-Seite ist hier\nEin Handbuch mit allen flextable Funktionen findest du hier\nEine Galerie mit schönen Beispielen flextable Tabellen mit Code kann aufgerufen werden hier",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tische für die Präsentation</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html",
    "href": "new_pages/ggplot_basics.de.html",
    "title": "30  ggplot Grundlagen",
    "section": "",
    "text": "30.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#vorbereitung",
    "href": "new_pages/ggplot_basics.de.html#vorbereitung",
    "title": "30  ggplot Grundlagen",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other data management tools\n  janitor,        # cleaning and summary tables\n  ggforce,        # ggplot extras\n  rio,            # import/export\n  here,           # file locator\n  stringr         # working with characters   \n)\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt. Wir werden uns auf die kontinuierlichen Variablen konzentrieren age, wt_kg (Gewicht in Kilo), ct_blood (CT-Werte), und days_onset_hosp (Differenz zwischen Eintrittsdatum und Krankenhausaufenthalt).\n\n\n\n\n\n\n\n\nAllgemeine Reinigung\nBei der Aufbereitung der Daten für das Plotten ist es am besten, die Daten an die “ordentliche” Datenstandardsso gut wie möglich einhalten. Wie du das erreichen kannst, wird auf den Seiten zum Datenmanagement in diesem Handbuch näher erläutert, z. B. [Daten und Kernfunktionen bereinigen].\nEinige einfache Möglichkeiten, wie wir unsere Daten aufbereiten können, um sie für die Darstellung besser zu machen, können darin bestehen, den Inhalt der Daten für die Anzeige zu verbessern - was nicht unbedingt gleichbedeutend mit einer besseren Datenmanipulation ist. Ein Beispiel:\n\nErsetze NA Werte in einer Zeichenspalte durch die Zeichenkette “Unbekannt”\nKonvertierung der Spalte in eine Klasse erwägen Faktor damit ihre Werte vorgeschriebene Ordnungsstufen haben\nBereinigen Sie einige Spalten, so dass ihre “datenfreundlichen” Werte mit Unterstrichen usw. in normalen Text oder Großbuchstaben geändert werden (siehe [Zeichen und Zeichenketten])\n\nHier sind einige Beispiele für diese Funktion:\n\n# make display version of columns with more friendly names\nlinelist &lt;- linelist %&gt;%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m to Male \n                            gender == \"f\" ~ \"Female\",      # f to Female,\n                            is.na(gender) ~ \"Unknown\"),    # NA to Unknown\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # replace NA outcome with \"unknown\"\n  )\n\n\n\nLänger schwenken\nIn Bezug auf die Datenstruktur ist es für ggplot2 wollen wir unsere Daten oft auch in längereFormate. Mehr dazu findest du auf der Seite über [Pivotierung von Daten].\n\n\n\n\n\n\n\n\n\nNehmen wir zum Beispiel an, dass wir Daten in einem “breiten” Format darstellen wollen, wie zum Beispiel für jeden Fall in der linelist und ihre Symptome. Im Folgenden erstellen wir eine Mini-Liste namens symptoms_data die nur die case_id und Symptome enthält.\n\nsymptoms_data &lt;- linelist %&gt;% \n  select(c(case_id, fever, chills, cough, aches, vomit))\n\nSo sehen die ersten 50 Zeilen dieser Mini-Liste aus - du siehst, dass sie “breit” formatiert sind und jedes Symptom eine Spalte ist:\n\n\n\n\n\n\nWenn wir die Anzahl der Fälle mit bestimmten Symptomen darstellen wollen, sind wir dadurch eingeschränkt, dass jedes Symptom eine eigene Spalte ist. Wir können jedoch drehen die Spalten mit den Symptomen in ein längeres Format umwandeln, wie hier:\n\nsymptoms_data_long &lt;- symptoms_data %&gt;%    # begin with \"mini\" linelist called symptoms_data\n  \n  pivot_longer(\n    cols = -case_id,                       # pivot all columns except case_id (all the symptoms columns)\n    names_to = \"symptom_name\",             # assign name for new column that holds the symptoms\n    values_to = \"symptom_is_present\") %&gt;%  # assign name for new column that holds the values (yes/no)\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # convert NA to \"unknown\"\n\nHier sind die ersten 50 Zeilen. Beachte, dass der Fall 5 Zeilen hat - eine für jedes mögliche Symptom. Die neuen Spalten symptom_name und symptom_is_present sind das Ergebnis des Pivots. Beachte, dass dieses Format für andere Operationen vielleicht nicht sehr nützlich ist, aber für das Plotten ist es nützlich.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#grundlagen-von-ggplot",
    "href": "new_pages/ggplot_basics.de.html#grundlagen-von-ggplot",
    "title": "30  ggplot Grundlagen",
    "section": "30.2 Grundlagen von ggplot",
    "text": "30.2 Grundlagen von ggplot\n“Grammatik der Grafik” - ggplot2\nPlotten mit ggplot2 basiert auf dem “Hinzufügen” von Plot-Ebenen und Gestaltungselementen übereinander, wobei jeder Befehl mit einem Plus-Symbol zu den vorherigen hinzugefügt wird (+). Das Ergebnis ist ein mehrschichtiges Plotobjekt, das gespeichert, geändert, gedruckt, exportiert usw. werden kann.\nggplot-Objekte können sehr komplex sein, aber die grundlegende Reihenfolge der Ebenen sieht normalerweise so aus:\n\nBeginne mit der Grundlinie ggplot() Befehl - dieser “öffnet” den ggplot und ermöglicht das Hinzufügen weiterer Funktionen mit +. Normalerweise wird in diesem Befehl auch der Datensatz angegeben\nHinzufügen von “geom”-Layern - diese Funktionen visualisieren die Daten als Geometrien (Formen), z. B. als Balkendiagramm, Liniendiagramm, Streudiagramm, Histogramm (oder eine Kombination!). Diese Funktionen beginnen alle mit geom_ als Präfix.\nHinzufügen von Designelementen zum Diagramm wie Achsenbeschriftungen, Titel, Schriftarten, Größen, Farbschemata, Legenden oder Achsendrehung\n\nIm Folgenden findest du ein einfaches Beispiel für einen Skelettcode. Die einzelnen Komponenten werden in den folgenden Abschnitten erklärt.\n\n# plot data from my_data columns as red points\nggplot(data = my_data)+                   # use the dataset \"my_data\"\n  geom_point(                             # add a layer of points (dots)\n    mapping = aes(x = col1, y = col2),    # \"map\" data column to axes\n    color = \"red\")+                       # other specification for the geom\n  labs()+                                 # here you add titles, axes labels, etc.\n  theme()                                 # here you adjust color, font, size etc of non-data plot elements (axes, title, etc.)",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#ggplot",
    "href": "new_pages/ggplot_basics.de.html#ggplot",
    "title": "30  ggplot Grundlagen",
    "section": "30.3 ggplot()",
    "text": "30.3 ggplot()\nDer Eröffnungsbefehl eines jeden ggplot2-Plots lautet ggplot(). Mit diesem Befehl wird einfach eine leere Leinwand erstellt, auf der du Ebenen hinzufügen kannst. Er “öffnet” den Weg für weitere Ebenen, die mit einem + Symbol.\nNormalerweise wird der Befehl ggplot() enthält die data = Argument für den Plot. Damit wird der Standarddatensatz festgelegt, der für die nachfolgenden Ebenen des Plots verwendet wird.\nDieser Befehl endet mit einem + nach der schließenden Klammer. Dadurch bleibt der Befehl “offen”. Der ggplot wird nur ausgeführt/erscheinen, wenn der vollständige Befehl eine letzte Ebene enthält ohne a + am Ende.\n\n# This will create plot that is a blank canvas\nggplot(data = linelist)",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#geoms",
    "href": "new_pages/ggplot_basics.de.html#geoms",
    "title": "30  ggplot Grundlagen",
    "section": "30.4 Geoms",
    "text": "30.4 Geoms\nEine leere Leinwand reicht nicht aus - wir müssen aus unseren Daten Geometrien (Formen) erstellen (z. B. Balkendiagramme, Histogramme, Streudiagramme, Boxplots).\nDazu fügen wir Ebenen “Geoms” zu den ursprünglichen ggplot() Befehl. Es gibt viele ggplot2 Funktionen, die “geoms” erstellen. Jede dieser Funktionen beginnt mit “geom_”, daher bezeichnen wir sie im Folgenden allgemein als geom_XXXX(). Es gibt über 40 Geoms in ggplot2 und viele andere, die von Fans erstellt wurden. Schau sie dir auf der ggplot2-Galerie. Einige gängige Geoms sind unten aufgeführt:\n\nHistogramme - geom_histogram()\nBalkendiagramme - geom_bar() oder geom_col() (siehe Abschnitt “Balkendiagramm”)\nBox Plots - geom_boxplot()\nPunkte (z. B. Streudiagramme) - geom_point()\nLiniendiagramme - geom_line() oder geom_path()\nTrendlinien - geom_smooth()\n\nIn einem Diagramm kannst du ein oder mehrere Geoms anzeigen. Jede wird zur vorherigen hinzugefügt ggplot2 Befehlen mit einem + und sie werden nacheinander geplottet, sodass spätere Geoms über den vorherigen geplottet werden.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#daten-auf-den-plot-abbilden-ggplot_basics_mapping",
    "href": "new_pages/ggplot_basics.de.html#daten-auf-den-plot-abbilden-ggplot_basics_mapping",
    "title": "30  ggplot Grundlagen",
    "section": "30.5 Daten auf den Plot abbilden {#ggplot_basics_mapping}",
    "text": "30.5 Daten auf den Plot abbilden {#ggplot_basics_mapping}\nDen meisten Geom-Funktionen muss mitgeteilt werden was verwendet werden soll um ihre Formen zu erstellen - du musst ihnen also sagen, wie sie Spalten in deinen Daten abbilden (zuordnen) den Komponenten des Plots wie Achsen, Formfarben, Formgrößen usw. zuordnen sollen. Für die meisten Geoms ist die wesentliche Komponenten, die auf Spalten in den Daten abgebildet werden müssen, die x-Achse und (falls nötig) die y-Achse.\nDieses “Mapping” erfolgt mit der mapping = Argument. Die Mappings, die du für mapping übergibst, müssen in die aes() Funktion eingeschlossen werden, du würdest also etwas schreiben wie mapping = aes(x = col1, y = col2) schreiben, wie unten gezeigt.\nUnten, in der ggplot() Befehl werden die Daten als Fall gesetzt linelist. Im mapping = aes() Argument wird die Spalte age auf die x-Achse abgebildet, und die Spalte wt_kg wird auf die y-Achse abgebildet.\nNach einer + werden die Plotting-Befehle fortgesetzt. Eine Form wird mit der Funktion “geom” erstellt geom_point(). Dieses Geom erbt die Mappings aus dem ggplot() Befehl - er kennt die Achsen-Spalten-Zuordnungen und visualisiert diese Beziehungen als Punkte auf der Leinwand.\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\n\n\n\n\n\n\n\n\nAls weiteres Beispiel verwenden die folgenden Befehle dieselben Daten, eine etwas andere Zuordnung und ein anderes Geom. Die geom_histogram() Funktion benötigt nur eine Spalte, die der x-Achse zugeordnet ist, da die y-Achse automatisch erzeugt wird.\n\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\n\n\n\n\n\n\n\n\nÄsthetik des Plots\nIn der ggplot-Terminologie hat die “Ästhetik” eines Plots eine bestimmte Bedeutung. Sie bezieht sich auf eine visuelle Eigenschaft von geplotteten Daten. Beachte, dass “ästhetisch” sich hier auf die Daten in Geometrien/Formen gezeichnet werden - und nicht auf die umgebende Darstellung wie Titel, Achsenbeschriftung oder Hintergrundfarbe, die du vielleicht mit dem Wort “Ästhetik” in Verbindung bringst. In ggplot werden diese Details “Themen” genannt und innerhalb einer theme() Befehl angepasst (siehe diesen Abschnitt).\nDaher ist das Plot-Objekt Ästhetik können Farben, Größen, Transparenzen, Platzierungen usw. sein. der gezeichneten Daten. Nicht alle Geoms haben die gleichen ästhetischen Optionen, aber viele können von den meisten Geoms verwendet werden. Hier sind einige Beispiele:\n\nshape = Einen Punkt anzeigen mit geom_point() als Punkt, Stern, Dreieck oder Quadrat…\nfill = Die Innenfarbe (z. B. eines Balkens oder Boxplots)\ncolor = Die äußere Linie eines Balkens, Boxplots usw. oder die Punktfarbe, wenn du geom_point()\nsize = Größe (z. B. Liniendicke, Punktgröße)\nalpha = Transparenz (1 = undurchsichtig, 0 = unsichtbar)\nbinwidth = Breite der Histogramm-Bins\nwidth = Breite der “Barplot”-Spalten\nlinetype = Linientyp (z. B. durchgezogen, gestrichelt, gepunktet)\n\nDiese Ästhetik des Plotobjekts kann auf zwei Arten zugewiesen werden:\n\nZuweisung eines statischen Wertes (z. B. color = \"blue\"), der für alle gezeichneten Beobachtungen gilt\neiner Spalte der Daten zugewiesen (z. B. color = hospital), so dass die Anzeige jeder Beobachtung von ihrem Wert in dieser Spalte abhängt\n\n\n\n\nAuf einen statischen Wert setzen\nWenn du möchtest, dass die Ästhetik des Plot-Objekts statisch ist, d.h. für jede Beobachtung in den Daten gleich ist, schreibst du seine Zuweisung innerhalb des geom aber außerhalb von jeder mapping = aes() Anweisung. Diese Zuweisungen könnten wie folgt aussehen size = 1 oder color = \"blue\". Hier sind zwei Beispiele:\n\nIm ersten Beispiel wird die mapping = aes() ist in der ggplot() Befehl und die Achsen werden den Spalten Alter und Gewicht in den Daten zugeordnet. Die Ästhetik der Darstellung color =, size =, und alpha = (Transparenz) werden statische Werte zugewiesen. Der Übersichtlichkeit halber wird dies in der geom_point() Funktion, da du später andere Geomodelle hinzufügen kannst, die für die Ästhetik ihrer Darstellung andere Werte benötigen.\nIm zweiten Beispiel muss für das Histogramm nur die x-Achse einer Spalte zugeordnet werden. Das Histogramm binwidth =, color =, fill = (interne Farbe), und alpha = werden im Geom wieder auf statische Werte gesetzt.\n\n\n# scatterplot\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # set data and axes mapping\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # set static point aesthetics\n\n# histogram\nggplot(data = linelist, mapping = aes(x = age))+       # set data and axes\n  geom_histogram(              # display histogram\n    binwidth = 7,                # width of bins\n    color = \"red\",               # bin line color\n    fill = \"blue\",               # bin interior color\n    alpha = 0.1)                 # bin transparency\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkaliert auf Spaltenwerte\nDie Alternative ist, die Ästhetik des Diagrammobjekts anhand der Werte in einer Spalte zu skalieren. Bei diesem Ansatz hängt die Darstellung der Ästhetik vom Wert der Beobachtung in der jeweiligen Datenspalte ab. Wenn die Spaltenwerte kontinuierlich sind, ist auch die Anzeigeskala (Legende) für diese Ästhetik kontinuierlich. Wenn die Spaltenwerte diskret sind, zeigt die Legende jeden Wert an und die gezeichneten Daten erscheinen deutlich “gruppiert” (mehr dazu im Abschnitt Gruppierung Abschnitt auf dieser Seite).\nUm dies zu erreichen, ordnest du die ästhetische Darstellung einem Spaltennamen (nicht in Anführungszeichen). Das muss getan werden innerhalb einer mapping = aes() Funktion (Hinweis: Es gibt mehrere Stellen im Code, an denen du diese Zuordnungen vornehmen kannst, wie besprochen unten).\nZwei Beispiele findest du unten.\n\nIm ersten Beispiel wird die color = Ästhetik (jedes Punktes) auf die Spalte age - und eine Skala ist in einer Legende erschienen! Nimm vorerst nur zur Kenntnis, dass die Skala existiert - wir werden in späteren Abschnitten zeigen, wie du sie ändern kannst.\nIm zweiten Beispiel werden auch zwei neue Plot-Ästhetiken auf Spalten abgebildet (color = und size =), während die Plotästhetik shape = und alpha = auf statische Werte außerhalb der mapping = aes() Funktion.\n\n\n# scatterplot\nggplot(data = linelist,   # set data\n       mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age)\n       )+     # map color to age\n  geom_point()         # display data as points \n\n# scatterplot\nggplot(data = linelist,   # set data\n       mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age,       # map color to age\n         size = age))+      # map size to age\n  geom_point(             # display data as points\n    shape = \"diamond\",      # points display as diamonds\n    alpha = 0.3)            # point transparency at 30%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis: Achsenzuweisungen werden immer den Spalten in den Daten zugewiesen (nicht den statischen Werten), und dies geschieht immer innerhalb der mapping = aes().\nEs ist wichtig, den Überblick über deine Plot-Ebenen und die Ästhetik zu behalten, wenn du komplexere Plots erstellst - zum Beispiel Plots mit mehreren Geomen. Im folgenden Beispiel wird die size = Ästhetik zweimal zugewiesen - einmal für geom_point() und einmal für geom_smooth() - beide Male als statischer Wert.\n\nggplot(data = linelist,\n       mapping = aes(           # map aesthetics to columns\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # add points for each row of data\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # add a trend line \n    method = \"lm\",              # with linear method\n    size = 2)                   # size (width of line) of 2\n\n\n\n\n\n\n\n\n\n\n30.5.1 Wo du Kartierungen vornehmen kannst {#ggplot_basics_map_loc .unnumbered}\nÄsthetische Kartierung innerhalb mapping = aes() kann an mehreren Stellen in deinen Plot-Befehlen geschrieben werden und kann sogar mehr als einmal geschrieben werden. Dies kann im oberen Bereich geschrieben werden ggplot() Befehl und/oder für jedes einzelne darunter liegende Geom geschrieben werden. Zu den Feinheiten gehören:\n\nKartierungszuweisungen, die in der oberen ggplot() Befehl vorgenommenen Zuordnungen werden als Standardwerte an alle darunter liegenden Geometrien vererbt, so wie x = und y = vererbt werden\nMapping-Zuweisungen, die innerhalb eines Geoms vorgenommen werden, gelten nur für dieses Geom\n\nGleiches gilt, data = die in der obersten ggplot() werden standardmäßig auf alle darunter liegenden Geom angewendet, aber du könntest auch Daten für jedes Geom angeben (das ist aber schwieriger).\nSo erstellt jeder der folgenden Befehle denselben Plot:\n\n# These commands will produce the exact same plot\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))\n\n\n\nGruppen\nDu kannst die Daten ganz einfach gruppieren und “nach Gruppen plotten”. Tatsächlich hast du das bereits getan!\nWeisen Sie die Spalte “Gruppierung” der entsprechenden Plot-Ästhetik zu, innerhalb einer mapping = aes(). Oben haben wir dies mit kontinuierlichen Werten demonstriert, als wir den Punkt size = der Spalte age. Das funktioniert aber genauso bei diskreten/kategorialen Spalten.\nWenn du zum Beispiel möchtest, dass die Punkte nach Geschlecht angezeigt werden, musst du mapping = aes(color = gender). Es erscheint automatisch eine Legende. Diese Zuordnung kann innerhalb der mapping = aes() im oberen ggplot() Befehl erfolgen (und an das Geom vererbt werden), oder sie kann in einem separaten mapping = aes() innerhalb des geom. Beide Ansätze werden unten gezeigt:\n\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n# This alternative code produces the same plot\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)\n\nBeachte, dass du je nach Geom unterschiedliche Argumente verwenden musst, um die Daten zu gruppieren. Für geom_point() wirst du höchstwahrscheinlich verwenden color =, shape = oder size =. Für geom_bar() ist es wahrscheinlicher, dass du fill =. Das hängt von der Geometrie ab und davon, wie du die Gruppierungen darstellen willst.\nZu deiner Information: Die grundlegendste Art, die Daten zu gruppieren, ist die Verwendung der group = Argument innerhalb mapping = aes(). Dadurch werden jedoch weder die Farben noch die Füllung oder die Formen geändert. Es wird auch keine Legende erstellt. Die Daten werden jedoch gruppiert, sodass statistische Darstellungen davon betroffen sein können.\nUm die Reihenfolge der Gruppen in einem Diagramm anzupassen, siehe die [ggplot-Tipps] Seite oder die Seite über [Faktoren]. In den folgenden Abschnitten über das Plotten von kontinuierlichen und kategorialen Daten findest du viele Beispiele für gruppierte Diagramme.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#facetten-kleine-vielfache-ggplot_basics_facet",
    "href": "new_pages/ggplot_basics.de.html#facetten-kleine-vielfache-ggplot_basics_facet",
    "title": "30  ggplot Grundlagen",
    "section": "30.6 Facetten / Kleine Vielfache {#ggplot_basics_facet}",
    "text": "30.6 Facetten / Kleine Vielfache {#ggplot_basics_facet}\nFacetten oder “Small-Multiples” werden verwendet, um eine Darstellung in eine Abbildung mit mehreren Feldern aufzuteilen, mit einem Feld (“Facette”) pro Datengruppe. Dieselbe Art von Diagramm wird mehrmals erstellt, wobei jedes Mal eine Untergruppe desselben Datensatzes verwendet wird.\nDie Facettierung ist eine Funktion, die mit ggplot2enthalten ist, sodass die Legenden und Achsen der Facetten-“Panels” automatisch ausgerichtet werden. Es gibt noch weitere Pakete, die in den [ggplot-Tipps] beschriebenen Pakete, die dazu dienen, völlig unterschiedliche Plots zu kombinieren (cowplot und Patchwork) zu einer Figur.\nDie Facettierung wird mit einer der folgenden Methoden durchgeführt ggplot2 Funktionen:\n\nfacet_wrap() Um für jede Ebene eines Projekts ein anderes Panel anzuzeigen einzelnen Variable. Ein Beispiel hierfür wäre die Darstellung einer anderen Epidemiekurve für jedes Krankenhaus in einer Region. Die Facetten sind alphabetisch geordnet, es sei denn, die Variable ist ein Faktor, für den eine andere Reihenfolge festgelegt wurde.\n\n\nDu kannst bestimmte Optionen aufrufen, um das Layout der Facetten zu bestimmen, z.B. nrow = 1 oder ncol = 1 um die Anzahl der Zeilen oder Spalten festzulegen, in denen die Facettenplots angeordnet werden.\n\n\nfacet_grid() Dies wird verwendet, wenn du eine zweite Variable in die Facettenanordnung einbeziehen möchtest. Hier zeigt jedes Feld eines Rasters die Schnittmenge zwischen Werten in zwei Spalten. Zum Beispiel Epidemiekurven für jede Krankenhaus-Altersgruppen-Kombination mit Krankenhäusern an der Spitze (Spalten) und Altersgruppen an den Seiten (Zeilen).\n\n\nnrow und ncol sind nicht relevant, da die Untergruppen in einem Raster dargestellt werden\n\nJede dieser Funktionen akzeptiert eine Formelsyntax, um die Spalte(n) für die Facettierung anzugeben. Beide akzeptieren bis zu zwei Spalten, eine auf jeder Seite einer Tilde ~.\n\nFür facet_wrap() Meistens wirst du nur eine Spalte schreiben, der eine Tilde vorangestellt ist ~ wie facet_wrap(~hospital). Du kannst aber auch zwei Spalten schreiben facet_wrap(outcome ~ hospital) - jede einzigartige Kombination wird in einem separaten Feld angezeigt, aber sie werden nicht in einem Raster angeordnet. In den Überschriften werden kombinierte Begriffe angezeigt, die keiner spezifischen Logik für die Spalten oder Zeilen unterliegen. Wenn du nur eine Facettenvariable angibst, wird ein Punkt . als Platzhalter auf der anderen Seite der Formel verwendet - siehe die Codebeispiele.\nFür facet_grid() kannst du auch eine oder zwei Spalten in der Formel angeben (Gitter rows ~ columns). Wenn du nur eine Spalte angeben willst, kannst du einen Punkt setzen . auf die andere Seite der Tilde setzen, wie facet_grid(. ~ hospital) oder facet_grid(hospital ~ .).\n\nFacetten können schnell eine überwältigende Menge an Informationen enthalten - daher solltest du sicherstellen, dass du nicht zu viele Ebenen für jede Variable hast, nach der du facettieren willst. Hier sind einige schnelle Beispiele mit dem Malaria-Datensatz (siehe [Handbuch und Daten herunterladen]), der die täglichen Malariafälle in den Einrichtungen nach Altersgruppen enthält.\nIm Folgenden importieren wir die Daten und nehmen der Einfachheit halber ein paar schnelle Änderungen vor:\n\n# These data are daily counts of malaria cases, by facility-day\nmalaria_data &lt;- import(here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;%  # import\n  select(-submitted_date, -Province, -newid)                                 # remove unneeded columns\n\nDie ersten 50 Zeilen der Malaria-Daten sind unten zu sehen. Beachte, dass es eine Spalte malaria_tot aber auch Spalten für die Zählungen nach Altersgruppen (diese werden im zweiten Abschnitt verwendet, facet_grid() Beispiel verwendet).\n\n\n\n\n\n\n\nfacet_wrap()\nKonzentrieren wir uns erst einmal auf die Spalten malaria_tot und District. Ignoriere die altersspezifischen Zählspalten vorerst. Wir werden die Epidemiekurven mit geom_col() die für jeden Tag eine Spalte in der angegebenen y-Achsenhöhe erzeugt, die in der Spalte malaria_tot (die Daten sind bereits tägliche Zählungen, also verwenden wir geom_col() - siehe den Abschnitt “Balkendiagramm” unten).\nWenn wir den Befehl facet_wrap() hinzufügen, geben wir eine Tilde und dann die Spalte an, die wir facettieren wollen (District in diesem Fall). Du kannst eine weitere Spalte auf der linken Seite der Tilde platzieren - dann wird eine Facette für jede Kombination erstellt - aber wir empfehlen, dies mit facet_grid() stattdessen. In diesem Anwendungsfall wird eine Facette für jeden eindeutigen Wert von District.\n\n# A plot with facets by district\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # plot the count data as columns\n  theme_minimal()+                              # simplify the background panels\n  labs(                                         # add plot labels, title, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # the facets are created\n\n\n\n\n\n\n\n\n\n\nfacet_grid()\nWir können eine facet_grid() Ansatz verwenden, um zwei Variablen zu kreuzen. Nehmen wir an, wir wollen Folgendes kreuzen District und Alter. Wir müssen einige Datentransformationen an den Altersspalten vornehmen, um diese Daten in das von ggplot bevorzugte “lange” Format zu bringen. Die Altersgruppen haben alle ihre eigenen Spalten - wir wollen sie in einer einzigen Spalte namens age_group und eine weitere namens num_cases. Siehe die Seite über [Pivotierung von Daten] für weitere Informationen zu diesem Prozess.\n\nmalaria_age &lt;- malaria_data %&gt;%\n  select(-malaria_tot) %&gt;% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # choose columns to pivot longer\n    names_to = \"age_group\",      # column names become age group\n    values_to = \"num_cases\"      # values to a single column (num_cases)\n  ) %&gt;%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\n\nJetzt sehen die ersten 50 Datenzeilen so aus:\n\n\n\n\n\n\nWenn du die beiden Variablen an facet_grid() übergibst, ist es am einfachsten, die Formelschreibweise zu verwenden (z. B. x ~ y), wobei x für Zeilen und y für Spalten steht. Hier ist die Darstellung, die facet_grid() um die Diagramme für jede Kombination der Spalten anzuzeigen age_group und District.\n\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district and age group\"\n  ) +\n  facet_grid(District ~ age_group)\n\n\n\n\n\n\n\n\n\n\nFreie oder feste Achsen\nDie Achsenskalen, die beim Facettieren angezeigt werden, sind standardmäßig für alle Facetten gleich (fest). Das ist hilfreich für Quervergleiche, aber nicht immer sinnvoll.\nWenn du facet_wrap() oder facet_grid() können wir hinzufügen scales = \"free_y\" hinzufügen, um die Y-Achsen der Panels zu “befreien” oder freizugeben, damit sie entsprechend ihrer Datenuntermenge skalieren. Das ist besonders nützlich, wenn die tatsächlichen Zählungen für eine der Unterkategorien klein sind und Trends sonst schwer zu erkennen sind. Anstelle von “free_y” können wir auch “free_x” schreiben, um dasselbe für die x-Achse (z. B. für Daten) oder “free” für beide Achsen zu tun. Beachte, dass in facet_grid die y-Skalen für die Facetten in derselben Zeile und die x-Skalen für die Facetten in derselben Spalte gleich sind.\nWenn du facet_grid verwenden, können wir hinzufügen space = \"free_y\" oder space = \"free_x\" hinzufügen, so dass die tatsächliche Höhe oder Breite der Facette mit den Werten der Figur darin gewichtet wird. Das funktioniert nur, wenn scales = \"free\" (y oder x) bereits angewendet wird.\n\n# Free y-axis\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # plot the count data as columns\n  theme_minimal()+                              # simplify the background panels\n  labs(                                         # add plot labels, title, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # the facets are created\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReihenfolge der Faktorebenen in den Facetten\nSiehe dies Beitrag wie du die Faktorstufen neu anordnen kannst innerhalb von Facetten.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#speichern-von-plots",
    "href": "new_pages/ggplot_basics.de.html#speichern-von-plots",
    "title": "30  ggplot Grundlagen",
    "section": "30.7 Speichern von Plots",
    "text": "30.7 Speichern von Plots\n\nSpeichern von Plots\nStandardmäßig werden beim Ausführen einer ggplot() Befehl ausführst, wird der Plot standardmäßig in das RStudio-Fenster “Plots” gedruckt. Du kannst den Plot aber auch als Objekt speichern, indem du den Zuweisungsoperator &lt;- verwendest und ihm einen Namen gibst. Dann wird er nur gedruckt, wenn der Objektname selbst ausgeführt wird. Du kannst ihn auch drucken, indem du den Plotnamen mit print() einschließt, aber das ist nur unter bestimmten Umständen notwendig, z. B. wenn der Plot innerhalb eines anderen Objekts erstellt wird. for-Schleifeverwendet wird, um mehrere Plots auf einmal zu drucken (siehe [Iteration, Schleifen und Listen] Seite).\n\n# define plot\nage_by_wt &lt;- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# print\nage_by_wt    \n\n\n\n\n\n\n\n\n\n\nGespeicherte Diagramme ändern\nEine schöne Sache über ggplot2 ist, dass du einen Plot (wie oben) definieren und ihm dann Ebenen hinzufügen kannst, beginnend mit seinem Namen. Du musst nicht alle Befehle wiederholen, mit denen der ursprüngliche Plot erstellt wurde!\nUm zum Beispiel den Plot zu ändern age_by_wt zu ändern, um eine vertikale Linie bei Alter 50 einzufügen, fügen wir einfach einen + ein und fügen weitere Ebenen zum Diagramm hinzu.\n\nage_by_wt+\n  geom_vline(xintercept = 50)\n\n\n\n\n\n\n\n\n\n\nPlots exportieren\nDas Exportieren von ggplots wird mit der Funktion ggsave() Funktion von ggplot2. Sie kann auf zwei Arten funktionieren, entweder:\n\nDu gibst den Namen des Plot-Objekts an, dann den Dateipfad und den Namen mit der Erweiterung\n\nZum Beispiel: ggsave(my_plot, here(\"plots\", \"my_plot.png\"))\n\nFühre den Befehl nur mit einem Dateipfad aus, um den zuletzt gedruckten Plot zu speichern\n\nZum Beispiel: ggsave(here(\"plots\", \"my_plot.png\"))\n\n\nDu kannst als png, pdf, jpeg, tiff, bmp, svg oder verschiedene andere Dateitypen exportieren, indem du die Dateierweiterung im Dateipfad angibst.\nDu kannst auch die folgenden Argumente angeben width =, height =, und units = (entweder “in”, “cm”, oder “mm”). Du kannst auch angeben dpi = mit einer Zahl für die Plotauflösung angeben (z. B. 300). Sieh dir die Details der Funktion an, indem du ?ggsave eingibst oder die Dokumentation online.\nDenken Sie daran, dass Sie here()Syntax verwenden kannst, um den gewünschten Dateipfad anzugeben. Siehe die [Importieren und Exportieren] Seite für weitere Informationen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#etiketten",
    "href": "new_pages/ggplot_basics.de.html#etiketten",
    "title": "30  ggplot Grundlagen",
    "section": "30.8 Etiketten",
    "text": "30.8 Etiketten\nSicherlich möchtest du die Beschriftungen des Plots hinzufügen oder anpassen. Das kannst du am einfachsten in der labs() Funktion, die dem Plot mit + genauso wie die Geoms.\nInnerhalb von labs() kannst du Zeichenketten für diese Argumente angeben:\n\nx = und y = Die Titel der x- und y-Achse (Beschriftungen)\ntitle = Der Haupttitel der Grafik\nsubtitle = Der Untertitel der Handlung, in kleinerem Text unterhalb des Titels\ncaption = Die Beschriftung des Plots, standardmäßig unten rechts\n\nHier ist ein Diagramm, das wir zuvor erstellt haben, aber mit schöneren Beschriftungen:\n\nage_by_wt &lt;- ggplot(\n  data = linelist,   # set data\n  mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age))+     # map color to age\n  geom_point()+           # display data as points\n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt\n\n\n\n\n\n\n\n\nBeachte, dass wir in der Beschriftungszuweisung Folgendes verwendet haben str_glue() aus dem stringrPaket, um dynamischen R-Code in den String-Text einzubauen. Die Überschrift zeigt das “Daten vom:” an, das das maximale Datum des Krankenhausaufenthalts in der Zeilenliste widerspiegelt. Mehr dazu findest du auf der Seite über [Zeichen und Zeichenketten].\nEin Hinweis zum Festlegen der Legende titel: Es gibt nicht das eine Argument “Legendentitel”, da du mehrere Skalen in deiner Legende haben kannst. Innerhalb von labs() kannst du das Argument für die Plot-Ästhetik schreiben, mit der du die Legende erstellst, und den Titel auf diese Weise angeben. Zum Beispiel haben wir oben color = age um die Legende zu erstellen. Daher geben wir color = an labs() an und vergeben den gewünschten Legendentitel (“Alter” mit großem A). Wenn du die Legende mit aes(fill = COLUMN), dann in labs() würdest du schreiben fill =um den Titel der Legende anzupassen. Der Abschnitt über Farbskalen in den [ggplot-Tipps] Seite enthält weitere Details zur Bearbeitung von Legenden und einen alternativen Ansatz mitscales_() Funktionen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#themen-ggplot_basics_themes",
    "href": "new_pages/ggplot_basics.de.html#themen-ggplot_basics_themes",
    "title": "30  ggplot Grundlagen",
    "section": "30.9 Themen {#ggplot_basics_themes}",
    "text": "30.9 Themen {#ggplot_basics_themes}\nEine der besten Seiten von ggplot2 ist die große Kontrolle, die du über den Plot hast - du kannst alles definieren! Wie bereits erwähnt, ist das Design des Plots, das nicht nicht mit den Daten zusammenhängt, wird innerhalb der theme() Funktion angepasst. Zum Beispiel die Hintergrundfarbe des Plots, das Vorhandensein/Fehlen von Gitternetzlinien und die Schriftart/Größe/Farbe/Ausrichtung von Text (Titel, Untertitel, Beschriftungen, Achsentext…). Diese Anpassungen können auf zwei Arten vorgenommen werden:\n\nHinzufügen eines komplettes Thema theme_() Funktion, um weitreichende Anpassungen vorzunehmen - dazu gehören theme_classic(), theme_minimal(), theme_dark(), theme_light() theme_grey(), theme_bw() u.a.\nPasse jeden winzigen Aspekt des Plots individuell innerhalb theme()\n\n\nVollständige Themen\nDa sie recht einfach sind, werden wir im Folgenden die Funktionen der vollständigen Themen demonstrieren und sie hier nicht weiter beschreiben. Beachte, dass alle Mikroanpassungen mit theme() vorgenommen werden sollten nach der Verwendung eines vollständigen Themas.\nSchreibe sie mit leeren Klammern.\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThema ändern\nDie theme() Funktion kann eine große Anzahl von Argumenten annehmen, von denen jedes einen ganz bestimmten Aspekt des Plots bearbeitet. Wir können unmöglich alle Argumente behandeln, aber wir werden das allgemeine Muster für sie beschreiben und dir zeigen, wie du den Namen des Arguments findest, das du brauchst. Die grundlegende Syntax lautet wie folgt:\n\nInnerhalb von theme() schreibst du den Argumentnamen für das Plot-Element, das du bearbeiten willst, z.B. plot.title =\nErstelle ein element_() Funktion für das Argument\n\n\nAm häufigsten verwenden Sie element_text(), aber auch andere Funktionen wie element_rect() für Leinwand-Hintergrundfarben oder element_blank() zum Entfernen von Plot-Elementen\n\n\nInnerhalb der element_() Funktion schreibst du die Argumente, um die gewünschten Feineinstellungen vorzunehmen\n\nDiese Beschreibung war ziemlich abstrakt, deshalb sind hier ein paar Beispiele.\nDas folgende Diagramm sieht ziemlich albern aus, aber es soll dir zeigen, wie du dein Diagramm anpassen kannst.\n\nWir beginnen mit dem Plot age_by_wt der gerade oben definiert wurde und fügen theme_classic()\nFür feinere Anpassungen fügen wir hinzu theme() und fügen ein Argument für jedes Plot-Element hinzu, das angepasst werden soll\n\nEs kann sinnvoll sein, die Argumente in logischen Abschnitten zu organisieren. Im Folgenden werden nur einige davon beschrieben:\n\nlegend.position = ist einzigartig, weil es einfache Werte wie “unten”, “oben”, “links” und “rechts” akzeptiert. Aber im Allgemeinen erfordern textbezogene Argumente, dass du die Details innerhalb von element_text().\nTitelgröße mit element_text(size = 30)\nDie horizontale Ausrichtung der Überschrift mit element_text(hjust = 0) (von rechts nach links)\nDer Untertitel wird kursiv dargestellt mit element_text(face = \"italic\")\n\n\nage_by_wt + \n  theme_classic()+                                 # pre-defined theme adjustments\n  theme(\n    legend.position = \"bottom\",                    # move legend to bottom\n    \n    plot.title = element_text(size = 30),          # size of title to 30\n    plot.caption = element_text(hjust = 0),        # left-align caption\n    plot.subtitle = element_text(face = \"italic\"), # italicize subtitle\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # adjusts only x-axis text\n    axis.text.y = element_text(size = 15),         # adjusts only y-axis text\n    \n    axis.title = element_text(size = 20)           # adjusts both axes titles\n    )     \n\n\n\n\n\n\n\n\nHier sind einige besonders häufige theme() Argumente. Du wirst einige Muster erkennen, wie zum Beispiel das Anhängen von .x oder .y um die Änderung nur auf eine Achse anzuwenden.\n\n\n\n\n\n\n\ntheme() Argument\nWas es anpasst\n\n\n\n\nplot.title = element_text()\nDer Titel\n\n\nplot.subtitle = element_text()\nDer Untertitel\n\n\nplot.caption = element_text()\nDie Überschrift (Familie, Schriftart, Farbe, Größe, Winkel, vjust, hjust…)\n\n\naxis.title = element_text()\nAchsentitel (sowohl x als auch y) (Größe, Fläche, Winkel, Farbe…)\n\n\naxis.title.x = element_text()\nAchsentitel nur x-Achse (verwende .y nur für die y-Achse)\n\n\naxis.text = element_text()\nAchsentext (sowohl x als auch y)\n\n\naxis.text.x = element_text()\nAchsentext nur x-Achse (verwenden Sie .y nur für die y-Achse)\n\n\naxis.ticks = element_blank()\nAchsenhäkchen entfernen\n\n\naxis.line = element_line()\nAchsenlinien (Farbe, Größe, Linientyp: durchgezogen gestrichelt gepunktet usw.)\n\n\nstrip.text = element_text()\nFacettenstreifentext (Farbe, Fläche, Größe, Winkel…)\n\n\nstrip.background = element_rect()\nFacettenstreifen (Füllung, Farbe, Größe…)\n\n\n\nAber es gibt so viele thematische Argumente! Wie soll ich sie mir alle merken? Keine Sorge - es ist unmöglich, sie sich alle zu merken. Zum Glück gibt es ein paar Hilfsmittel, die dir helfen:\nDie tidyverse Dokumentation auf Ändern des Themas die eine vollständige Liste enthält.\nTIPP: Führe aus. theme_get() von ggplot2 um eine Liste mit allen 90+ theme() Argumente auf der Konsole aus.\nTIPP: Wenn du einmal ein Element eines Plots entfernen möchtest, kannst du das auch über theme(). Gib einfach element_blank() an ein Argument, damit es komplett verschwindet. Für Legenden, setze legend.position = \"none\".",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#farben",
    "href": "new_pages/ggplot_basics.de.html#farben",
    "title": "30  ggplot Grundlagen",
    "section": "30.10 Farben",
    "text": "30.10 Farben\nBitte siehe dies Abschnitt über Farbskalen auf der ggplot Tipps Seite.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#piping-in-ggplot2",
    "href": "new_pages/ggplot_basics.de.html#piping-in-ggplot2",
    "title": "30  ggplot Grundlagen",
    "section": "30.11 Piping in ggplot2",
    "text": "30.11 Piping in ggplot2\nWenn du deine Daten mithilfe von Pipes bereinigst und transformierst, ist es einfach, die transformierten Daten in ggplot().\nDie Pipes, die den Datensatz von Funktion zu Funktion weiterleiten, gehen in + sobald die ggplot() Funktion aufgerufen wird. Beachte, dass es in diesem Fall nicht nötig ist, die data = Argument nicht angegeben werden muss, da es automatisch als Piped-in-Datensatz definiert wird.\nSo könnte das aussehen:\n\nlinelist %&gt;%                                                     # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#kontinuierliche-daten-aufzeichnen",
    "href": "new_pages/ggplot_basics.de.html#kontinuierliche-daten-aufzeichnen",
    "title": "30  ggplot Grundlagen",
    "section": "30.12 Kontinuierliche Daten aufzeichnen",
    "text": "30.12 Kontinuierliche Daten aufzeichnen\nAuf dieser Seite hast du bereits viele Beispiele für das Plotten von kontinuierlichen Daten gesehen. Hier fassen wir sie kurz zusammen und stellen ein paar Varianten vor.\nZu den hier behandelten Visualisierungen gehören:\n\nDiagramme für eine kontinuierliche Variable:\n\nHistogramm Ein Histogramm ist ein klassisches Diagramm zur Darstellung der Verteilung einer kontinuierlichen Variable.\nBoxplot (auch Box und Whisker genannt), um die 25., 50. und 75. Perzentile, die Schwanzenden der Verteilung und Ausreißer zu zeigen (wichtige Einschränkungen).\nJitter-Plot, um alle Werte als Punkte darzustellen, die “gejittert” sind, damit sie (meistens) alle zu sehen sind, auch wenn zwei denselben Wert haben.\nGeigenplot zeigen die Verteilung einer kontinuierlichen Variable anhand der symmetrischen Breite der “Geige”.\nSina-Plot sind eine Kombination aus Jitter- und Violinplots, bei denen einzelne Punkte dargestellt werden, aber in der symmetrischen Form der Verteilung (über ggforce Paket).\n\nStreudiagramm für zwei kontinuierliche Variablen.\nHeat Plotsfür drei kontinuierliche Variablen (verlinkt mit [Wärmebildern] Seite)\n\n\nHistogramme\nHistogramme sehen zwar aus wie Balkendiagramme, unterscheiden sich aber dadurch, dass sie die Verteilung eines kontinuierlichen Variable messen. Es gibt keine Leerzeichen zwischen den “Balken”, und es wird nur eine Spalte für geom_histogram().\nNachfolgend der Code für die Erstellung Histogramme die kontinuierliche Daten in Bereiche gruppieren und in nebeneinander liegenden Balken mit unterschiedlicher Höhe anzeigen. Dies geschieht mit geom_histogram(). Siehe die “Abschnitt”Balkendiagramm der ggplot-Grundlagen-Seite, um den Unterschied zwischen geom_histogram(), geom_bar(), und geom_col().\nWir zeigen die Verteilung des Alters der Fälle. Innerhalb von mapping = aes() gibst du an, für welche Spalte du die Verteilung sehen willst. Du kannst diese Spalte entweder der x- oder der y-Achse zuordnen.\nDie Zeilen werden auf der Grundlage ihres numerischen Alters “Bins” zugewiesen, und diese Bins werden grafisch durch Balken dargestellt. Wenn du eine Anzahl von Bins mit der Option bins = Plot-Ästhetik angibst, werden die Haltepunkte gleichmäßig zwischen den Minimal- und Maximalwerten des Histogramms verteilt. Wenn bins = nicht angegeben ist, wird eine entsprechende Anzahl von Bins geschätzt und diese Meldung nach der Darstellung angezeigt:\n## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nWenn du keine Anzahl von Bins angeben möchtest, um bins = angeben möchtest, kannst du alternativ angeben binwidth = in den Einheiten der Achse angeben. Wir geben ein paar Beispiele für verschiedene Bins und Bin-Breiten:\n\n# A) Regular histogram\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) Fewer bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n\n# D) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUm geglättete Proportionen zu erhalten, kannst du Folgendes verwenden geom_density():\n\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# Stacked frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUm ein “gestapeltes” Histogramm (einer kontinuierlichen Datenspalte) zu erhalten, kannst du eine der folgenden Möglichkeiten nutzen:\n\nVerwende geom_histogram() mit dem fill = Argument innerhalb aes() und der Gruppierungsspalte zugewiesen, oder\nverwenden. geom_freqpoly() was wahrscheinlich einfacher zu lesen ist (du kannst immer noch die binwidth =)\nUm die Proportionen aller Werte zu sehen, setzt du die y = after_stat(density) (verwende genau diese Syntax - nicht für deine Daten geändert). Hinweis: Diese Proportionen werden angezeigt pro Gruppe.\n\nJede Gruppe ist unten abgebildet (*beachte die Verwendung von color = vs. fill = in jedem):\n\n# \"Stacked\" histogram\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# Frequency \nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# Frequency with proportion axis\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWenn du etwas Spaß haben willst, versuche geom_density_ridges von der ggridges Paket (Vignette hier.\nMehr über Histogramme erfährst du im Detail auf der tidyverse Seite zu geom_histogram().\n\n\nBoxplots\nBoxplots sind weit verbreitet, haben aber wichtige Einschränkungen. Sie können die tatsächliche Verteilung verschleiern - z. B. eine bimodale Verteilung. Siehe dies R-Grafik-Galerie und diese data-to-viz Artikel für weitere Details. Sie zeigen jedoch sehr schön den Interquartilsbereich und die Ausreißer an, sodass sie über andere Arten von Diagrammen gelegt werden können, die die Verteilung detaillierter darstellen.\nIm Folgenden werden die verschiedenen Bestandteile eines Boxplots erläutert:\n\n\n\n\n\n\n\n\n\nBei der Verwendung von geom_boxplot() um ein Boxplot zu erstellen, wird normalerweise nur eine Achse (x oder y) innerhalb aes(). Die angegebene Achse bestimmt, ob die Diagramme horizontal oder vertikal sind.\nIn den meisten Geoms erstellst du einen Plot pro Gruppe, indem du eine Ästhetik wie color = oder fill = auf eine Spalte innerhalb aes(). Bei Boxplots erreichst du dies jedoch, indem du die Gruppierungsspalte der nicht zugewiesenen Achse (x oder y) zuordnest. Nachfolgend der Code für einen Boxplot von allen Alterswerte im Datensatz und ein Boxplot für jedes (nicht fehlende) Geschlecht im Datensatz. Beachte, dass NA (fehlende) Werte als separates Boxplot angezeigt werden, wenn sie nicht entfernt werden. In diesem Beispiel setzen wir auch die fill auf die Spalte outcome ein, damit jedes Diagramm eine andere Farbe hat - das ist aber nicht notwendig.\n\n# A) Overall boxplot\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # only y axis mapped (not x)\n  labs(title = \"A) Overall boxplot\")\n\n# B) Box plot by group\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # remove legend (redundant)\n  labs(title = \"B) Boxplot by gender\")      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDen Code zum Hinzufügen eines Box-Plots an den Rändern eines Scatter-Plots (“marginal” Plots) findest du auf der Seite [ggplot-Tipps].\n\n\nGeigen-, Jitter- und Sina-Plots\nNachfolgend findest du den Code zum Erstellen von Geigenplots (geom_violin) und Jitter-Plots (geom_jitter), um Verteilungen darzustellen. Du kannst festlegen, dass die Füllung oder Farbe auch von den Daten bestimmt wird, indem du diese Optionen innerhalb von aes().\n\n# A) Jitter plot by group\nggplot(data = linelist %&gt;% drop_na(outcome),      # remove missing values\n       mapping = aes(y = age,                     # Continuous variable\n           x = outcome,                           # Grouping variable\n           color = outcome))+                     # Color variable\n  geom_jitter()+                                  # Create the violin plot\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# B) Violin plot by group\nggplot(data = linelist %&gt;% drop_na(outcome),       # remove missing values\n       mapping = aes(y = age,                      # Continuous variable\n           x = outcome,                            # Grouping variable\n           fill = outcome))+                       # fill variable (color)\n  geom_violin()+                                   # create the violin plot\n  labs(title = \"B) violin plot by gender\")    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDu kannst beides kombinieren, indem du die geom_sina() Funktion aus dem ggforce Paket. Die Sina zeichnet die Jitter-Punkte in der Form des Violin-Plots auf. Wenn du den Violinplot überlagerst (indem du die Transparenzen anpasst), lässt sich das visuell besser interpretieren.\n\n# A) Sina plot by group\nggplot(\n  data = linelist %&gt;% drop_na(outcome), \n  aes(y = age,           # numeric variable\n      x = outcome)) +    # group variable\n  geom_violin(\n    aes(fill = outcome), # fill (color of violin background)\n    color = \"white\",     # white outline\n    alpha = 0.2)+        # transparency\n  geom_sina(\n    size=1,                # Change the size of the jitter\n    aes(color = outcome))+ # color (color of dots)\n  scale_fill_manual(       # Define fill for violin background by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # Define colours for points by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # Remove the gray background\n  theme(legend.position = \"none\") +                # Remove unnecessary legend\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      \n\n\n\n\n\n\n\n\n\n\nZwei kontinuierliche Variablen\nNach einer ähnlichen Syntax, geom_point() können Sie zwei kontinuierliche Variablen gegeneinander in einer Streudiagramm. Dies ist nützlich, um die tatsächlichen Werte und nicht ihre Verteilungen darzustellen. Ein einfaches Streudiagramm von Alter und Gewicht ist in (A) dargestellt. In (B) verwenden wir wieder facet_grid() um die Beziehung zwischen zwei kontinuierlichen Variablen in der Lineliste darzustellen.\n\n# Basic scatter plot of weight and age\nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Scatter plot of weight and age by gender and Ebola outcome\nggplot(data = linelist %&gt;% drop_na(gender, outcome), # filter retains non-missing gender/outcome\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrei kontinuierliche Variablen\nDu kannst drei kontinuierliche Variablen anzeigen, indem du die fill = Argument verwenden, um eine Wärmediagramm. Die Farbe jeder “Zelle” spiegelt den Wert der dritten kontinuierlichen Datenspalte wider. Siehe die [ggplot-Tipps] Seite und die Seite über [Wärmeplots] für weitere Details und einige Beispiele.\nEs gibt Möglichkeiten, 3D-Diagramme in R zu erstellen, aber für die angewandte Epidemiologie sind diese oft schwer zu interpretieren und daher weniger nützlich für die Entscheidungsfindung.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#kategoriale-daten-plotten",
    "href": "new_pages/ggplot_basics.de.html#kategoriale-daten-plotten",
    "title": "30  ggplot Grundlagen",
    "section": "30.13 Kategoriale Daten plotten",
    "text": "30.13 Kategoriale Daten plotten\nKategoriale Daten können Zeichenwerte, logische Werte (TRUE/FALSE) oder Faktoren sein (siehe die [Faktoren] Seite).\n\nVorbereitung\n\nDatenstruktur\nAls Erstes musst du wissen, ob deine kategorialen Daten in Form von Rohbeobachtungen (z. B. einer Liste von Fällen) oder in Form einer Zusammenfassung oder eines aggregierten Datenrahmens mit Zählungen oder Proportionen vorliegen. Der Zustand deiner Daten wirkt sich darauf aus, welche Diagrammfunktion du verwendest:\n\nWenn es sich bei deinen Daten um Rohbeobachtungen mit einer Zeile pro Beobachtung handelt, wirst du wahrscheinlich die Funktion geom_bar()\nWenn deine Daten bereits zu Zählungen oder Proportionen aggregiert sind, wirst du wahrscheinlich geom_col()\n\n\n\nSpaltenklasse und Reihenfolge der Werte\nAls Nächstes untersuchst du die Klasse der Spalten, die du darstellen willst. Wir sehen uns hospital zuerst mit class() von Basis R, und mit tabyl() von Hausmeister.\n\n# View class of hospital column - we can see it is a character\nclass(linelist$hospital)\n\n[1] \"character\"\n\n# Look at values and proportions within hospital column\nlinelist %&gt;% \n  tabyl(hospital)\n\n                             hospital    n    percent\n                     Central Hospital  454 0.07710598\n                    Military Hospital  896 0.15217391\n                              Missing 1469 0.24949049\n                                Other  885 0.15030571\n                        Port Hospital 1762 0.29925272\n St. Mark's Maternity Hospital (SMMH)  422 0.07167120\n\n\nWir können sehen, dass die Werte darin aus Buchstaben bestehen, da es sich um Krankenhausnamen handelt, und sie sind standardmäßig alphabetisch geordnet. Es gibt auch “andere” und “fehlende” Werte, die wir bei der Darstellung von Aufschlüsselungen lieber als letzte Unterkategorie sehen würden. Deshalb ändern wir diese Spalte in einen Faktor und ordnen sie neu an. Näheres dazu findest du im Abschnitt [Faktoren] Seite.\n\n# Convert to factor and define level order so \"Other\" and \"Missing\" are last\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\n\n\nlevels(linelist$hospital)\n\n[1] \"St. Mark's Maternity Hospital (SMMH)\"\n[2] \"Port Hospital\"                       \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Other\"                               \n[6] \"Missing\"                             \n\n\n\n\n\n30.13.1 geom_bar() {#ggplot_basics_bars .unnumbered}\nverwenden geom_bar() wenn du möchtest, dass die Balkenhöhe (oder die Höhe der gestapelten Balkenkomponenten) die die Anzahl der relevanten Zeilen in den Daten. Diese Balken haben Lücken zwischen ihnen, es sei denn, die width = Ästhetik der Darstellung angepasst wird.\n\nGib nur eine Achsenspaltenzuordnung an (normalerweise die x-Achse). Wenn du x und y angibst, erhältst du Error: stat_count() can only have an x or y aesthetic.\nDu kannst gestapelte Balken erstellen, indem du eine fill = Spaltenzuordnung innerhalb mapping = aes()\nDie gegenüberliegende Achse wird standardmäßig mit “Anzahl” betitelt, weil sie die Anzahl der Zeilen darstellt\n\nUnten haben wir das Ergebnis der y-Achse zugewiesen, aber es könnte genauso gut auf der x-Achse stehen. Wenn du längere Zeichenwerte hast, kann es manchmal besser aussehen, wenn du die Balken zur Seite drehst und die Legende unten anbringst. Das kann Auswirkungen darauf haben, wie deine Faktorstufen angeordnet sind - in diesem Fall kehren wir sie mit fct_rev() um fehlende und andere unten anzuordnen.\n\n# A) Outcomes in all cases\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) Outcomes in all cases by hosptial\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_col()\nVerwende geom_col() wenn du möchtest, dass die Balkenhöhe (oder die Höhe der gestapelten Balkenkomponenten) die vorberechnete Werte die in den Daten vorhanden sind. Oft handelt es sich dabei um zusammengefasste oder “aggregierte” Zählungen oder Proportionen.\nGib Spaltenzuordnungen an für beide Achsen an geom_col(). Normalerweise ist die Spalte der x-Achse diskret und die Spalte der y-Achse ist numerisch.\nNehmen wir an, wir haben diesen Datensatz outcomes:\n\n\n# A tibble: 2 × 3\n  outcome     n proportion\n  &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 Death    1022       56.2\n2 Recover   796       43.8\n\n\nNachfolgend der Code mit geom_col um einfache Balkendiagramme zu erstellen, die die Verteilung der Ergebnisse von Ebola-Patienten zeigen. Bei geom_col müssen sowohl x als auch y angegeben werden. Hier ist x die kategoriale Variable auf der x-Achse und y die Spalte mit den generierten Proportionen proportion.\n\n# Outcomes in all cases\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\n\n\n\n\n\n\n\n\nUm eine Aufschlüsselung nach Krankenhaus vorzunehmen, müsste unsere Tabelle mehr Informationen enthalten und ein “langes” Format haben. Wir erstellen diese Tabelle mit den Häufigkeiten der kombinierten Kategorien outcome und hospital(siehe [Daten gruppieren] Seite für Tipps zur Gruppierung).\n\noutcomes2 &lt;- linelist %&gt;% \n  drop_na(outcome) %&gt;% \n  count(hospital, outcome) %&gt;%  # get counts by hospital and outcome\n  group_by(hospital) %&gt;%        # Group so proportions are out of hospital total\n  mutate(proportion = n/sum(n)*100) # calculate proportions of hospital total\n\nhead(outcomes2) # Preview data\n\n# A tibble: 6 × 4\n# Groups:   hospital [3]\n  hospital                             outcome     n proportion\n  &lt;fct&gt;                                &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n3 Port Hospital                        Death     785       57.6\n4 Port Hospital                        Recover   579       42.4\n5 Central Hospital                     Death     193       53.9\n6 Central Hospital                     Recover   165       46.1\n\n\nDann erstellen wir den ggplot mit einigen zusätzlichen Formatierungen:\n\nAchsenumkehr: Vertausche die Achse mit coord_flip() so dass wir die Namen der Krankenhäuser lesen können.\nSpalten nebeneinander: Hinzugefügt wurde ein position = \"dodge\" hinzugefügt, damit die Balken für Tod und Genesung nebeneinander und nicht gestapelt dargestellt werden. Beachte, dass gestapelte Balken die Standardeinstellung sind.\nSpaltenbreite Spaltenbreite: Festgelegte ‘Breite’, damit die Spalten halb so dünn sind wie die volle mögliche Breite.\nReihenfolge der Spalten Die Reihenfolge der Kategorien auf der y-Achse wurde umgedreht, so dass “Sonstige” und “Fehlende” ganz unten stehen, mit scale_x_discrete(limits=rev). Beachte, dass wir das anstelle von scale_y_discrete weil das Krankenhaus in der x Argument von aes() steht, auch wenn es visuell auf der y-Achse liegt. Wir tun dies, weil Ggplot die Kategorien scheinbar rückwärts darstellt, es sei denn, wir weisen es an, dies nicht zu tun.\nAndere Details: Etiketten/Titel und Farben hinzugefügt labs und scale_fill_color beziehungsweise.\n\n\n# Outcomes in all cases by hospital\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # show pre-calculated proportion values\n      y = fct_rev(hospital),          # reverse level order so missing/other at bottom\n      fill = outcome),                # stacked by outcome\n    width = 0.5)+                    # thinner bars (out of 1)\n  theme_minimal() +                  # Minimal theme \n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # legend title\n       y = \"Count\",                  # y axis title\n       x = \"Hospital of admission\")+ # x axis title\n  scale_fill_manual(                 # adding colors manually\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) \n\n\n\n\n\n\n\n\nBeachte, dass die Proportionen binär sind, also können wir “erholen” weglassen und nur den Anteil der Verstorbenen angeben. Dies dient nur zur Veranschaulichung.\nWenn du geom_col() mit Datumsdaten (z. B. eine Epikurve aus aggregierten Daten) verwendest, musst du die width = Argument anpassen, um die “Lücken” zwischen den Balken zu entfernen. Wenn du einen täglichen Datensatz verwendest width = 1. Wenn wöchentlich, width = 7. Monate sind nicht möglich, da jeder Monat eine andere Anzahl von Tagen hat.\n\n\ngeom_histogram()\nHistogramme sehen zwar wie Balkendiagramme aus, unterscheiden sich aber von diesen, weil sie die Verteilung einer kontinuierlichen Variable messen. Es gibt keine Leerzeichen zwischen den “Balken”, und es wird nur eine Spalte für geom_histogram(). Es gibt spezielle Argumente für Histogramme wie bin_width = und breaks =um anzugeben, wie die Daten gebinnt werden sollen. Im obigen Abschnitt über kontinuierliche Daten und auf der Seite über [Epidemische Kurven] bieten zusätzliche Details.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.de.html#ressourcen",
    "href": "new_pages/ggplot_basics.de.html#ressourcen",
    "title": "30  ggplot Grundlagen",
    "section": "30.14 Ressourcen",
    "text": "30.14 Ressourcen\nEs gibt eine große Menge an Hilfe im Internet, vor allem zu ggplot. Siehe:\n\nggplot2 Spickzettel\nein weiterer Spickzettel\ntidyverse ggplot Grundlagen Seite\nPlotten von kontinuierlichen Variablen\nR für Data Science Seiten auf Datenvisualisierung\nGrafiken für die Kommunikation",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot Grundlagen</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html",
    "href": "new_pages/ggplot_tips.de.html",
    "title": "31  ggplot-Tipps",
    "section": "",
    "text": "31.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#vorbereitung",
    "href": "new_pages/ggplot_tips.de.html#vorbereitung",
    "title": "31  ggplot-Tipps",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other\n  rio,            # import/export\n  here,           # file locator\n  stringr,        # working with characters   \n  scales,         # transform numbers\n  ggrepel,        # smartly-placed labels\n  gghighlight,    # highlight one part of plot\n  RColorBrewer    # color scales\n)\n\n\n\nDaten importieren\nAuf dieser Seite importieren wir den Datensatz der Fälle einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#skalen-für-farbe-füllung-achsen-etc.-ggplot_tips_colors",
    "href": "new_pages/ggplot_tips.de.html#skalen-für-farbe-füllung-achsen-etc.-ggplot_tips_colors",
    "title": "31  ggplot-Tipps",
    "section": "31.2 Skalen für Farbe, Füllung, Achsen, etc. {#ggplot_tips_colors}",
    "text": "31.2 Skalen für Farbe, Füllung, Achsen, etc. {#ggplot_tips_colors}\nIn ggplot2 wenn die Ästhetik der geplotteten Daten (z. B. Größe, Farbe, Form, Füllung, Plot-Achse) auf Spalten in den Daten abgebildet wird, kann die genaue Darstellung mit dem entsprechenden Befehl “scale” angepasst werden. In diesem Abschnitt erklären wir einige gängige Skalenanpassungen.\n\n31.2.1 Farbschemata\nEine Sache, die anfangs schwer zu verstehen sein kann, ist die ggplot2 ist die Steuerung von Farbschemata. In diesem Abschnitt geht es um die Farbe von Plot-Objekten (Geometrien/Formen) wie Punkte, Balken, Linien, Kacheln, etc. Um die Farbe von Zubehörtext, Titeln oder Hintergrundfarbe anzupassen, siehe den ThemenAbschnitt der [ggplot Grundlagen] Seite.\nUm die “Farbe” von Plot-Objekten einzustellen, musst du entweder die color = Ästhetik (die Äußere Farbe) oder die fill = Ästhetik (die Innenraum Farbe). Eine Ausnahme von diesem Muster ist geom_point() wo du wirklich nur die Farbe der color = die die Farbe des Punktes (innen und außen) bestimmt.\nBeim Einstellen von Farbe oder Füllung kannst du von R erkannte Farbnamen verwenden wie \"red\" (siehe vollständige Liste oder eingeben ?colors), oder eine bestimmte Hex-Farbe wie \"#ff0505\".\n\n# histogram - \nggplot(data = linelist, mapping = aes(x = age))+       # set data and axes\n  geom_histogram(              # display histogram\n    binwidth = 7,                # width of bins\n    color = \"red\",               # bin line color\n    fill = \"lightblue\")          # bin interior color (fill) \n\n\n\n\n\n\n\n\nWie in den [ggplot Grundlagen] Abschnitt aufDaten auf den Plot abbilden Ästhetik, wie zum Beispiel fill = und color = können entweder definiert werden außerhalb von einer mapping = aes() Anweisung oder innerhalb von einer Anweisung. Wenn außerhalb der aes() ist, sollte der zugewiesene Wert statisch sein (z. B. color = \"blue\") und gilt für alle Daten, die mit dem Geom gezeichnet werden. Wenn innerhalb steht, sollte die Ästhetik auf eine Spalte abgebildet werden, wie color = hospital und der Ausdruck wird durch den Wert für diese Zeile in den Daten verändert. Ein paar Beispiele:\n\n# Static color for points and for line\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# Color mapped to continuous column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# Color mapped to discrete column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# bar plot, fill to discrete column, color to static value\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n31.2.2 Skalen {#ggplot_tips_scales .unnumbered}\nSobald du eine Spalte einem ästhetischen Plot zuordnest (z.B. x =, y =, fill =, color =…), erhält dein Diagramm eine Skala/Legende. Wie du oben siehst, kann die Skala je nach Klasse der zugewiesenen Spalte kontinuierlich, diskret, datumsbezogen usw. sein. Wenn du den Spalten mehrere Ästhetiken zugewiesen hast, hat dein Diagramm mehrere Skalen.\nDu kannst die Skalen mit den entsprechenden scales_() Funktion steuern. Die Skalenfunktionen von ggplot() haben 3 Teile, die wie folgt geschrieben sind: scale_AESTHETIC_METHOD().\n\nDer erste Teil, scale_(), ist fest.\nDer zweite Teil, die ÄSTHETIK, sollte die Ästhetik sein, für die du den Maßstab anpassen willst (_fill_, _shape_, _color_, _size_, _alpha_…) - Die Optionen hier umfassen auch _x_ und _y_.\nDer dritte Teil, die METHODE, wird entweder _discrete(), continuous(), _date(), _gradient(), oder _manual() abhängig von der Klasse der Spalte und wie du sie steuern willst. Es gibt noch weitere, aber diese sind die am häufigsten verwendeten.\n\nAchte darauf, dass du die richtige Funktion für die Skala verwendest! Sonst scheint dein Skalenbefehl nichts zu verändern. Wenn du mehrere Skalen hast, kannst du mehrere Skalenfunktionen verwenden, um sie anzupassen! Zum Beispiel:\n\n\nSkalenargumente\nJede Art von Skala hat ihre eigenen Argumente, obwohl es einige Überschneidungen gibt. Abfrage der Funktion wie ?scale_color_discrete in der R-Konsole ab, um die Dokumentation der Funktionsargumente zu sehen.\nFür kontinuierliche Skalen, verwende breaks = um eine Folge von Werten mit seq() (nimm to =, from =, und by = wie im folgenden Beispiel gezeigt. einstellen expand = c(0,0) ein, um den Füllraum um die Achsen zu eliminieren (dies kann bei jedem _x_ oder _y_ Skala.\nBei diskreten Skalen kannst du die Reihenfolge der Darstellung der Ebenen mit breaks = und wie die Werte angezeigt werden, mit der labels = Argument. Gib für jedes dieser Argumente einen Zeichenvektor an (siehe Beispiel unten). Du kannst auch NA einfach durch Setzen von na.translate = FALSE.\nDie Feinheiten der Datumsskalen werden ausführlicher im Abschnitt [Epidemie-Kurven] Seite.\n\n\nManuelle Anpassungen\nEiner der nützlichsten Tricks ist die Verwendung von “manuellen” Skalierungsfunktionen, um Farben explizit nach deinen Wünschen zuzuweisen. Das sind Funktionen mit der Syntax scale_xxx_manual() (z.B.. scale_colour_manual() oder scale_fill_manual()). Jedes der unten genannten Argumente wird im folgenden Codebeispiel demonstriert.\n\nWeisen Sie den Datenwerten Farben zu mit dem values = Argument\nFestlegen einer Farbe für NA mit na.value =\nÄndern Sie, wie die Werte sind geschrieben werden in der Legende mit der Option labels = Argument\nÄndere den Titel der Legende mit name =\n\nIm Folgenden erstellen wir ein Balkendiagramm und zeigen, wie es standardmäßig aussieht und dann mit drei angepassten Skalen - der kontinuierlichen y-Achsenskala, der diskreten x-Achsenskala und der manuellen Anpassung der Füllung (innere Balkenfarbe).\n\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n\n\n\n\n\n\n# SCALES ADJUSTED\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # simplify background\n  \n  scale_y_continuous(                # continuous scale for y-axis (counts)\n    expand = c(0,0),                 # no padding\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # discrete scale for x-axis (gender)\n    expand = c(0,0),                  # no padding\n    drop = FALSE,                     # show all factor levels (even if not in data)\n    na.translate = FALSE,             # remove NA outcomes from plot\n    labels = c(\"Died\", \"Recovered\"))+ # Change display of values\n    \n  \n  scale_fill_manual(                  # Manually specify fill (bar interior color)\n    values = c(\"m\" = \"violetred\",     # reference values in data to assign colors\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          # re-label the legend (use \"=\" assignment to avoid mistakes)\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # title of legend\n    na.value = \"grey\"                 # assign a color for missing values\n  )+\n  labs(title = \"Adjustment of scales\") # Adjust the title of the fill legend\n\n\n\n\n\n\n\n\n\n\nKontinuierliche Achsenskalen\nWenn die Daten den Achsen zugeordnet werden, können auch diese mit Skalenbefehlen angepasst werden. Ein gängiges Beispiel ist die Anpassung der Anzeige einer Achse (z. B. der y-Achse), die auf eine Spalte mit kontinuierlichen Daten abgebildet wird.\nWir können die Brüche oder die Anzeige der Werte im ggplot anpassen, indem wir scale_y_continuous(). Wie oben erwähnt, verwende das Argument breaks = eine Reihe von Werten an, die als “Unterbrechungen” entlang der Skala dienen sollen. Das sind die Werte, bei denen die Zahlen angezeigt werden. Zu diesem Argument kannst du eine c() Vektor angeben, der die gewünschten Unterbrechungswerte enthält, oder du kannst eine reguläre Zahlenfolge angeben, indem du die Basis R-Funktion seq(). Diese seq() Funktion akzeptiert to =, from =, und by =.\n\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProzente anzeigen\nWenn deine ursprünglichen Datenwerte Proportionen sind, kannst du sie ganz einfach als Prozentwerte mit “%” anzeigen, indem du labels = scales::percent in deinem Skalenbefehl einfügst, wie unten gezeigt.\nEine Alternative wäre, die Werte in Zeichen umzuwandeln und am Ende ein “%”-Zeichen hinzuzufügen. Dieser Ansatz führt jedoch zu Komplikationen, weil deine Daten dann keine kontinuierlichen numerischen Werte mehr sind.\n\n# Original y-axis proportions\n#############################\nlinelist %&gt;%                                   # start with linelist\n  group_by(hospital) %&gt;%                       # group data by hospital\n  summarise(                                   # create summary columns\n    n = n(),                                     # total number of rows in group\n    deaths = sum(outcome == \"Death\", na.rm=T),   # number of deaths in group\n    prop_death = deaths/n) %&gt;%                   # proportion deaths in group\n  ggplot(                                      # begin plotting\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# Display y-axis proportions as percents\n########################################\nlinelist %&gt;%         \n  group_by(hospital) %&gt;% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %&gt;% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # display proportions as percents\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLog-Skala\nUm eine kontinuierliche Achse in eine logarithmische Skala umzuwandeln, füge trans = \"log2\" an den Befehl scale an. Für das Beispiel erstellen wir einen Datenrahmen mit Regionen und ihren jeweiligen preparedness_index und kumulativen Fallwerten.\n\nplot_data &lt;- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data\n\n  region preparedness_index cases_cumulative\n1      A                8.8               15\n2      B                7.5               45\n3      C                3.4               80\n4      D                3.6               20\n5      E                2.1               21\n6      F                7.9                7\n7      G                7.0               51\n8      H                5.6               30\n9      I                1.0             1442\n\n\nDie kumulierten Fälle in der Region “I” sind dramatisch höher als in allen anderen Regionen. In solchen Fällen kannst du die y-Achse mit einer logarithmischen Skala darstellen, damit der Leser die Unterschiede zwischen den Regionen mit weniger kumulativen Fällen erkennen kann.\n\n# Original y-axis\npreparedness_plot &lt;- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # points for each region \n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # add text labels\n  theme_minimal()\n\npreparedness_plot                  # print original plot\n\n\n# print with y-axis transformed\npreparedness_plot+                   # begin with plot saved above\n  scale_y_continuous(trans = \"log2\") # add transformation for y-axis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSteigungsskalen\nDie Skalierung von Füllverläufen kann zusätzliche Nuancen enthalten. Die Standardeinstellungen sind in der Regel recht ansprechend, aber vielleicht möchtest du die Werte, Abgrenzungen usw. anpassen.\nUm zu zeigen, wie man eine kontinuierliche Farbskala anpasst, verwenden wir einen Datensatz aus der [Kontaktverfolgung] Seite, der das Alter der Fälle und ihrer Ausgangsfälle enthält.\n\ncase_source_relationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_age, target_age) \n\nIm Folgenden erstellen wir ein “Raster” für die Wärmekacheldichte. Wir erklären nicht, wie das geht (siehe den Link im Absatz oben), sondern konzentrieren uns darauf, wie wir die Farbskala anpassen können. Lies mehr über die stat_density2d() ggplot2 Funktion hier. Beachte, wie die fill Skala ist kontinuierlich.\n\ntrans_matrix &lt;- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\n\nJetzt zeigen wir einige Variationen der Füllskala:\n\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJetzt zeigen wir einige Beispiele, wie du die Haltepunkte der Skala anpassen kannst:\n\nscale_fill_gradient() nimmt zwei Farben an (hoch/niedrig)\nscale_fill_gradientn() akzeptiert einen Vektor beliebiger Länge von Farben zu values = (Zwischenwerte werden interpoliert)\nverwenden scales::rescale() kannst du einstellen, wie die Farben entlang des Farbverlaufs positioniert werden; der Vektor der Positionen wird so skaliert, dass er zwischen 0 und 1 liegt.\n\n\ntrans_matrix + \n  scale_fill_gradient(     # 2-sided gradient scale\n    low = \"aquamarine\",    # low value\n    high = \"purple\",       # high value\n    na.value = \"grey\",     # value for NA\n    name = \"Density\")+     # Legend title\n  labs(title = \"Manually specify high/low colors\")\n\n# 3+ colors to scale\ntrans_matrix + \n  scale_fill_gradientn(    # 3-color scale (low/mid/high)\n    colors = c(\"blue\", \"yellow\",\"red\") # provide colors in vector\n  )+\n  labs(title = \"3-color scale\")\n\n# Use of rescale() to adjust placement of colors along scale\ntrans_matrix + \n  scale_fill_gradientn(    # provide any number of colors\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # positions for colors are rescaled between 0 and 1\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# use of limits to cut-off values that get fill color\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaletten\n\nColorbrewer und Viridis\nWenn du generell vordefinierte Paletten möchtest, kannst du die scale_xxx_brewer oder scale_xxx_viridis_y Funktionen verwenden.\nDie “Brauer”-Funktionen können aus colorbrewer.org Paletten beziehen.\nDie “viridis”-Funktionen basieren auf den viridis-Paletten (farbenblind), die “Farbkarten bieten, die sowohl in Farbe als auch in Schwarz-Weiß einheitlich wahrgenommen werden. Sie sind so konzipiert, dass sie auch von Menschen mit Farbenblindheit wahrgenommen werden können.” (mehr dazu hier und hier). Lege fest, ob die Palette diskret, kontinuierlich oder gebündelt ist, indem du dies am Ende der Funktion angibst (z. B. ist diskret scale_xxx_viridis_d).\nEs ist ratsam, dass du deinen Plot auf diese Weise testest Farbenblindheitssimulator. Wenn du ein rot/grünes Farbschema hast, versuche stattdessen ein “heiß-kaltes” (rot-blaues) Schema, wie beschrieben hier\nHier ist ein Beispiel aus den [ggplot Grundlagen] Seite, das verschiedene Farbschemata verwendet.\n\nsymp_plot &lt;- linelist %&gt;%                                         # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  # print with default colors\n\n#################################\n# print with manually-specified colors\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # explicitly define colours\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # order the factors correctly\n    name = \"\"                           # set legend to no title\n\n  ) \n\n#################################\n# print with viridis discrete colors\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#reihenfolge-der-diskreten-variablen-ändern",
    "href": "new_pages/ggplot_tips.de.html#reihenfolge-der-diskreten-variablen-ändern",
    "title": "31  ggplot-Tipps",
    "section": "31.3 Reihenfolge der diskreten Variablen ändern",
    "text": "31.3 Reihenfolge der diskreten Variablen ändern\nDie Reihenfolge der diskreten Variablen zu ändern, ist für Menschen, die sich noch nicht so gut auskennen, oft schwer zu verstehen. ggplot2 Graphen. Dabei ist es ganz einfach zu verstehen, wie man das macht, wenn man weiß, wie ggplot2 diskrete Variablen unter der Haube behandelt. Wenn eine diskrete Variable verwendet wird, wird sie im Allgemeinen automatisch in eine factor Typ umgewandelt, der die Faktoren standardmäßig in alphabetischer Reihenfolge anordnet. Um dies zu ändern, musst du die Faktoren einfach in der Reihenfolge anordnen, in der sie im Diagramm erscheinen sollen. Ausführlichere Informationen über die Neuordnung factor Objekten findest du im Abschnitt über die Faktoren in diesem Leitfaden.\nWir können ein gängiges Beispiel mit Altersgruppen betrachten - standardmäßig wird die Altersgruppe 5-9 in der Mitte der Altersgruppen platziert (in alphanumerischer Reihenfolge), aber wir können sie hinter die Altersgruppe 0-4 des Diagramms verschieben, indem wir die Faktoren neu ordnen.\n\nggplot(\n  data = linelist %&gt;% drop_na(age_cat5),                         # remove rows where age_cat5 is missing\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # relevel factor\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n31.3.0.1 ggthemr\nErwäge auch die Verwendung der ggthemr Paket zu verwenden. Du kannst dieses Paket von Github herunterladen, indem du die Anweisungen befolgst hier. Es bietet Paletten, die ästhetisch sehr ansprechend sind, aber sei dir bewusst, dass diese in der Regel eine maximale Anzahl von Werten haben, die dich einschränken können, wenn du mehr als 7 oder 8 Farben möchtest.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#konturlinien",
    "href": "new_pages/ggplot_tips.de.html#konturlinien",
    "title": "31  ggplot-Tipps",
    "section": "31.4 Konturlinien",
    "text": "31.4 Konturlinien\nKonturdiagramme sind hilfreich, wenn du viele Punkte hast, die sich gegenseitig überdecken könnten (“Overplotting”). Die oben verwendeten Fallquellendaten werden wieder geplottet, aber einfacher mit stat_density2d() und stat_density2d_filled() um diskrete Konturenebenen zu erzeugen - wie bei einer topografischen Karte. Lies mehr über die Statistiken hier.\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#marginale-verteilungen",
    "href": "new_pages/ggplot_tips.de.html#marginale-verteilungen",
    "title": "31  ggplot-Tipps",
    "section": "31.5 Marginale Verteilungen",
    "text": "31.5 Marginale Verteilungen\nUm die Verteilungen an den Rändern eines geom_point() Streudiagramms anzuzeigen, kannst du die ggExtra Paket und seine Funktion ggMarginal(). Speichere deinen ursprünglichen ggplot als Objekt und übergebe es dann an ggMarginal() wie unten gezeigt. Hier sind die wichtigsten Argumente:\n\nDu musst die type = entweder als “Histogramm”, “Dichte” “Boxplot”, “Geige” oder “Densigramm” angeben.\nStandardmäßig werden Randdiagramme für beide Achsen angezeigt. Du kannst einstellen margins = auf “x” oder “y” einstellen, wenn du nur eine Achse möchtest.\nAndere optionale Argumente sind fill = (Balkenfarbe), color = (Linienfarbe), size = (Plotgröße relativ zur Randgröße, d.h. eine größere Zahl macht den Randplot kleiner).\nDu kannst weitere achsenspezifische Argumente an xparams = und yparams =. Du kannst zum Beispiel verschiedene Histogramm-Bin-Größen angeben, wie unten gezeigt.\n\nDie Randdiagramme können Gruppen widerspiegeln (Spalten, die zu color = in deinem ggplot() kartierten Ästhetik). Wenn dies der Fall ist, setze die ggMarginal() Argument groupColour = oder groupFill = an TRUE, wie unten gezeigt.\nLies mehr unter diese Vignette, im R Graph Galerie oder in der R-Dokumentation der Funktion ?ggMarginal.\n\n# Install/load ggExtra\npacman::p_load(ggExtra)\n\n# Basic scatter plot of weight and age\nscatter_plot &lt;- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n\nUm marginale Histogramme hinzuzufügen, verwenden Sie type = \"histogram\". Sie können optional einstellen groupFill = TRUE setzen, um gestapelte Histogramme zu erhalten.\n\n# with histograms\nggMarginal(\n  scatter_plot,                     # add marginal histograms\n  type = \"histogram\",               # specify histograms\n  fill = \"lightblue\",               # bar fill\n  xparams = list(binwidth = 10),    # other parameters for x-axis marginal\n  yparams = list(binwidth = 5))     # other parameters for y-axis marginal\n\n\n\n\n\n\n\n\nMarginaler Dichteplot mit gruppierten/gefärbten Werten:\n\n# Scatter plot, colored by outcome\n# Outcome column is assigned as color in ggplot. groupFill in ggMarginal set to TRUE\nscatter_plot_color &lt;- ggplot(data = linelist %&gt;% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n\n\n\n\n\n\n\n\nStellen Sie die size = ein, um die relative Größe der Randdarstellung anzupassen. Je kleiner die Zahl, desto größer die Randdarstellung. Du stellst auch color =. Unten siehst du einen marginalen Boxplot, mit einer Demonstration der margins = Argument, damit es nur auf einer Achse erscheint:\n\n# with boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # only show x-axis marginal plot\n  type = \"boxplot\")",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#intelligente-beschriftung",
    "href": "new_pages/ggplot_tips.de.html#intelligente-beschriftung",
    "title": "31  ggplot-Tipps",
    "section": "31.6 Intelligente Beschriftung",
    "text": "31.6 Intelligente Beschriftung\nUnter ggplot2 ist es auch möglich, Plots mit Text zu versehen. Dies hat jedoch den Nachteil, dass die Textbeschriftungen oft mit den Datenpunkten in einem Diagramm kollidieren und dadurch unübersichtlich oder schwer zu lesen sind. Im Basispaket gibt es keine ideale Lösung für dieses Problem, aber es gibt eine ggplot2 Add-on, bekannt als ggrepel das den Umgang mit diesem Problem sehr einfach macht!\nDie ggrepel Paket bietet zwei neue Funktionen, geom_label_repel() und geom_text_repel(), die ersetzen geom_label() und geom_text(). Verwende diese Funktionen einfach anstelle der Basisfunktionen, um saubere Beschriftungen zu erzeugen. Bilde innerhalb der Funktion die Ästhetik ab aes() wie immer, aber füge das Argument label = ein, das du mit einem Spaltennamen versiehst, der die Werte enthält, die du anzeigen möchtest (z. B. Patienten-ID oder Name usw.). Du kannst auch komplexere Beschriftungen erstellen, indem du Spalten und Zeilenumbrüche kombinierst (\\n) innerhalb von str_glue() wie unten gezeigt.\nEin paar Tipps:\n\nVerwende min.segment.length = 0 um immer Liniensegmente zu zeichnen, oder min.segment.length = Inf um sie nie zu zeichnen\nverwenden size = außerhalb von aes() um die Textgröße einzustellen\nverwenden force = änderst du den Grad der Abstoßung zwischen Beschriftungen und ihren jeweiligen Punkten (Standard ist 1).\neinbeziehen fill = innerhalb von aes() um das Etikett nach dem Wert zu färben\n\nEin Buchstabe “a” kann in der Legende erscheinen - hinzufügen guides(fill = guide_legend(override.aes = aes(color = NA)))+ um ihn zu entfernen\n\n\nSiehst du, das ist sehr detailliert Tutorium für mehr.\n\npacman::p_load(ggrepel)\n\nlinelist %&gt;%                                               # start with linelist\n  group_by(hospital) %&gt;%                                   # group by hospital\n  summarise(                                               # create new dataset with summary values per hospital\n    n_cases = n(),                                           # number of cases per hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # mean delay per hospital\n  ) %&gt;% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # send data frame to ggplot\n  geom_point(size = 2)+                                    # add points\n  geom_label_repel(                                        # add point labels\n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # how label displays\n      ), \n    size = 3,                                              # text size in labels\n    min.segment.length = 0)+                               # show all line segments                \n  labs(                                                    # add axes labels\n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\n\n\n\n\n\n\n\n\nDu kannst nur eine Teilmenge der Datenpunkte beschriften - indem du Standard ggplot() Syntax verschiedene data = für jeden geom Ebene des Plots zu verwenden. Unten sind alle Fälle aufgezeichnet, aber nur einige wenige sind beschriftet.\n\nggplot()+\n  # All points in grey\n  geom_point(\n    data = linelist,                                   # all data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # grey and semi-transparent\n  \n  # Few points in black\n  geom_point(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # filtered data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # default black and not transparent\n  \n  # point labels for few points\n  geom_label_repel(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # filter the data for the labels\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # label color by outcome\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # label created with str_glue()\n    min.segment.length = 0) +                                  # show line segments for all\n  \n  # remove letter \"a\" from inside legend boxes\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # axis labels\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#zeit-achsen",
    "href": "new_pages/ggplot_tips.de.html#zeit-achsen",
    "title": "31  ggplot-Tipps",
    "section": "31.7 Zeit-Achsen",
    "text": "31.7 Zeit-Achsen\nDie Arbeit mit Zeitachsen in ggplot kann entmutigend erscheinen, ist aber mit ein paar Schlüsselfunktionen sehr einfach. Denke daran, dass du bei der Arbeit mit Zeit oder Datum sicherstellen solltest, dass die richtigen Variablen als Datums- oder Datetime-Klasse formatiert sind - siehe die [Arbeiten mit Daten] Seite für weitere Informationen dazu, oder [Epidemische Kurven] Seite (Abschnitt ggplot) für Beispiele.\nDer nützlichste Satz von Funktionen für die Arbeit mit Daten in ggplot2 sind die Skalierungsfunktionen (scale_x_date(), scale_x_datetime() und ihre verwandten Funktionen für die y-Achse). Mit diesen Funktionen kannst du festlegen, wie oft du Achsenbeschriftungen haben willst und wie du die Achsenbeschriftungen formatieren willst. Wie du Daten formatieren kannst, erfährst du in der Arbeiten mit Datumsangaben noch einmal nach! Du kannst die date_breaks und date_labels Argumente verwenden, um festzulegen, wie die Daten aussehen sollen:\n\ndate_breaks Ermöglicht es dir, festzulegen, wie oft Achsenbrüche auftreten - du kannst hier eine Zeichenkette übergeben (z. B. \"3 months\", oder “2 days\")\ndate_labels kannst du festlegen, in welchem Format das Datum angezeigt werden soll. Du kannst diesen Argumenten einen Datumsformat-String übergeben (z. B. \"%b-%d-%Y\"):\n\n\n# make epi curve by date of onset when available\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # 1 break every 1 month\n    date_breaks = \"1 months\",\n    # labels should show month then date\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\nEine einfache Lösung für effiziente Datumsbeschriftungen auf der x-Achse ist die Zuweisung des labels = Argument in scale_x_date() an die Funktion label_date_short() aus dem Paket skaliert. Diese Funktion konstruiert automatisch effiziente Datumsetiketten (mehr dazu hier). Ein zusätzlicher Vorteil dieser Funktion ist, dass sich die Beschriftungen automatisch anpassen, wenn deine Daten im Laufe der Zeit wachsen - von Tagen über Wochen bis hin zu Monaten und Jahren.\nEin vollständiges Beispiel findest du auf der Epicurves-Seite unter mehrstufige Datumsetiketten aber ein kurzes Beispiel ist unten als Referenz dargestellt:\n\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    labels = scales::label_date_short()  # automatically efficient date labels\n  )+\n  theme_classic()",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#hervorhebung",
    "href": "new_pages/ggplot_tips.de.html#hervorhebung",
    "title": "31  ggplot-Tipps",
    "section": "31.8 Hervorhebung",
    "text": "31.8 Hervorhebung\nDas Hervorheben bestimmter Elemente in einem Diagramm ist eine nützliche Methode, um die Aufmerksamkeit auf ein bestimmtes Beispiel einer Variable zu lenken und gleichzeitig Informationen über die Streuung des gesamten Datensatzes zu liefern. In der Basisversion ist dies nicht so einfach möglich ggplot2 möglich ist, gibt es ein externes Paket, das dabei helfen kann, nämlich gghighlight. Es ist einfach in der ggplot-Syntax zu verwenden.\nDie gghighlight Paket verwendet die gghighlight() Funktion, um diesen Effekt zu erzielen. Um diese Funktion zu nutzen, übergibst du eine logische Anweisung an die Funktion - das kann ziemlich flexible Ergebnisse haben, aber hier zeigen wir ein Beispiel für die Altersverteilung der Fälle in unserer Zeilenliste und heben sie nach Ergebnis hervor.\n\n# load gghighlight\nlibrary(gghighlight)\n\n# replace NA values with unknown in the outcome variable\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produce a histogram of all cases by age\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # highlight instances where the patient has died.\n\n\n\n\n\n\n\n\nDas funktioniert auch gut mit Facettenfunktionen - so kann der Nutzer Facettenplots erstellen, bei denen die Hintergrunddaten hervorgehoben werden, die nicht auf die Facette zutreffen! Unten zählen wir die Fälle nach Woche und stellen die Epidemiekurven nach Krankenhaus dar (color = und facet_wrap() gesetzt auf hospital Spalte).\n\n# produce a histogram of all cases by age\nlinelist %&gt;% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %&gt;% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # highlight instances where the patient has died\n  facet_wrap(~hospital)                              # make facets by outcome",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#plotten-mehrerer-datensätze",
    "href": "new_pages/ggplot_tips.de.html#plotten-mehrerer-datensätze",
    "title": "31  ggplot-Tipps",
    "section": "31.9 Plotten mehrerer Datensätze",
    "text": "31.9 Plotten mehrerer Datensätze\nBeachte, dass es schwierig sein kann, die Achsen von mehreren Datensätzen in einem Diagramm richtig auszurichten. Ziehe eine der folgenden Strategien in Betracht:\n\nFühre die Daten vor dem Plotten zusammen und konvertiere sie in das “lange” Format mit einer Spalte, die den Datensatz widerspiegelt.\nVerwende cowplot oder ein ähnliches Paket, um zwei Plots zu kombinieren (siehe unten)",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#plots-kombinieren",
    "href": "new_pages/ggplot_tips.de.html#plots-kombinieren",
    "title": "31  ggplot-Tipps",
    "section": "31.10 Plots kombinieren",
    "text": "31.10 Plots kombinieren\nZwei Pakete, die für die Kombination von Plots sehr nützlich sind, sind cowplot und Patchwork. Auf dieser Seite werden wir uns hauptsächlich auf Folgendes konzentrieren Cowplot mit gelegentlicher Verwendung von Patchwork.\nHier ist die Online Einführung in Cowplot. Du kannst die ausführlichere Dokumentation für jede Funktion online lesen hier. Im Folgenden gehen wir auf einige der häufigsten Anwendungsfälle und Funktionen ein.\nDie cowplot Paket arbeitet zusammen mit ggplot2 - Im Wesentlichen verwendest du es, um ggplots und ihre Legenden zu zusammengesetzten Zahlen anzuordnen und zu kombinieren. Es kann auch Basis R-Grafiken.\n\npacman::p_load(\n  tidyverse,      # data manipulation and visualisation\n  cowplot,        # combine plots\n  patchwork       # combine plots\n)\n\nWährend die Facettierung (beschrieben in den [ggplot Grundlagen] Seite beschrieben) ist zwar ein praktischer Ansatz zum Plotten, aber manchmal ist es nicht möglich, mit diesem relativ restriktiven Ansatz die gewünschten Ergebnisse zu erzielen. In diesem Fall kannst du Plots kombinieren, indem du sie zu einem größeren Plot zusammenfügst. Es gibt drei bekannte Pakete, die sich dafür hervorragend eignen -cowplot, gridExtra und Patchwork. Diese Pakete tun jedoch weitgehend dasselbe, daher konzentrieren wir uns auf cowplot für diesen Abschnitt.\n\nplot_grid()\nDie Kuhplot Paket hat eine ziemlich große Bandbreite an Funktionen, aber am einfachsten lässt es sich durch die Verwendung von plot_grid(). Damit kannst du vordefinierte Diagramme in einem Raster anordnen. Wir können ein weiteres Beispiel mit dem Malaria-Datensatz durcharbeiten - hier können wir die Gesamtzahl der Fälle nach Bezirken darstellen und auch die Epidemiekurve im Zeitverlauf zeigen.\n\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# bar chart of total cases by district\np1 &lt;- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# epidemic curve over time\np2 &lt;- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 column and two rows - stacked on top of each other\n                   ncol = 1,\n                   nrow = 2,\n                   # top plot is 2/3 as tall as second\n                   rel_heights = c(2, 3))\n\n\n\n\n\n\n\n\n\n\nKombiniere Legenden\nWenn deine Plots die gleiche Legende haben, ist es relativ einfach, sie zu kombinieren. Verwende einfach die cowplot um die Plots zu kombinieren, aber entferne die Legende von einem der Plots (de-duplicate).\nWenn deine Plots unterschiedliche Legenden haben, musst du einen anderen Ansatz wählen:\n\nErstelle und speichere deine Plots ohne Legenden mit theme(legend.position = \"none\")\nExtrahiere die Legenden aus jedem Plot mit get_legend() wie unten gezeigt - aber extrahiere die Legenden aus den geänderten Plots, um die Legende tatsächlich anzuzeigen\nKombiniere die Legenden in einem Legenden-Panel\nKombiniere die Plots und das Legenden-Panel\n\nZur Veranschaulichung zeigen wir die beiden Diagramme getrennt und dann in einem Raster mit ihren eigenen Legenden angeordnet (hässliche und ineffiziente Platznutzung):\n\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\n\nSo sehen die beiden Diagramme aus, wenn sie mit plot_grid() ohne ihre Legenden zu kombinieren:\n\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n\n\n\n\n\n\n\n\nUnd jetzt zeigen wir, wie wir die Legenden kombinieren. Im Wesentlichen definieren wir jeden Plot wie folgt ohne seine Legende (theme(legend.position = \"none\"), und dann definieren wir die Legende für jeden Plot separat unter Verwendung der get_legend() Funktion von cowplot. Wenn wir die Legende aus dem gespeicherten Plot extrahieren, müssen wir Folgendes hinzufügen + die Legende wieder einfügen, einschließlich der Angabe der Platzierung (“rechts”) und kleinerer Anpassungen für die Ausrichtung der Legenden und ihrer Titel. Dann fügen wir die Legenden vertikal zusammen und kombinieren dann die beiden Plots mit den neu kombinierten Legenden. Voila!\n\n# Define plot 1 without legend\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# Define plot 2 without legend\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# extract legend from p1 (from p1 + legend)\nleg_p1 &lt;- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # extract vertical legend\n                                      legend.justification = c(0,0.5))+ # so legends  align\n                                labs(fill = \"Outcome\"))                 # title of legend\n# extract legend from p2 (from p2 + legend)\nleg_p2 &lt;- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # extract vertical legend   \n                                      legend.justification = c(0,0.5))+  # so legends align\n                                labs(fill = \"Age Category\"))             # title of legend\n\n# create a blank plot for legend alignment\n#blank_p &lt;- patchwork::plot_spacer() + theme_void()\n\n# create legends panel, can be one on top of the other (or use spacer commented above)\nlegends &lt;- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# combine two plots and the combined legends panel\ncombined &lt;- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # print\n\n\n\n\n\n\n\n\nDiese Lösung wurde gelernt von diesem Beitrag mit einer kleinen Korrektur zum Ausrichten von Legenden aus diesem Beitrag.\nTIPP: Lustige Anmerkung - die “Kuh” in Kuhplot kommt vom Namen des Erfinders - Claus O. Wilke.\n\n\nInset Plots\nDu kannst einen Plot in einen anderen einfügen, indem du cowplot. Hier sind einige Dinge, die du beachten solltest:\n\nDefiniere die Haupthandlung mit theme_half_open() von Kuhplot Es ist vielleicht am besten, wenn die Legende entweder oben oder unten steht.\nDefiniere den Insetplot. Am besten ist es, wenn du einen Plot hast, für den du keine Legende brauchst. Du kannst Plot-Themelemente entfernen mit element_blank() wie unten gezeigt.\nKombiniere sie durch Anwendung von ggdraw() auf den Hauptplot anwendet und dann draw_plot() auf den Inset-Plot anwenden und die Koordinaten (x und y der linken unteren Ecke), die Höhe und die Breite als Anteil des gesamten Hauptplots angeben.\n\n\n# Define main plot\nmain_plot &lt;- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# Define inset plot\ninset_plot &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# Combine main with inset\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)\n\n\n\n\n\n\n\n\nDiese Technik wird in diesen beiden Vignetten näher erläutert:\nWilke Labor\ndraw_plot() Dokumentation",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#zwei-achsen",
    "href": "new_pages/ggplot_tips.de.html#zwei-achsen",
    "title": "31  ggplot-Tipps",
    "section": "31.11 Zwei Achsen",
    "text": "31.11 Zwei Achsen\nEine sekundäre y-Achse ist oft eine gewünschte Ergänzung zu einer ggplot2 Diagramm. Obwohl es in der Datenvisualisierungs-Community eine heftige Debatte über die Sinnhaftigkeit solcher Diagramme gibt und sie oft nicht empfohlen werden, kann es sein, dass dein Manager sie trotzdem haben möchte. Im Folgenden stellen wir eine Methode vor, um sie zu erreichen: mit der cowplot Paket, um zwei separate Diagramme zu kombinieren.\nBei diesem Ansatz werden zwei separate Diagramme erstellt - eines mit einer y-Achse auf der linken und eines mit einer y-Achse auf der rechten Seite. Beide verwenden eine bestimmte theme_cowplot() und müssen die gleiche x-Achse haben. In einem dritten Befehl werden die beiden Diagramme dann ausgerichtet und übereinander gelegt. Die Funktionalitäten von cowplot, von denen dies nur eine ist, werden in diesem Artikel ausführlich beschrieben Seite.\nUm diese Technik zu demonstrieren, werden wir die Epidemiekurve mit einer Linie überlagern, die den wöchentlichen Prozentsatz der Patienten darstellt, die gestorben sind. Wir verwenden dieses Beispiel, weil die Ausrichtung der Daten auf der X-Achse komplexer ist als z. B. die Ausrichtung eines Balkendiagramms mit einer anderen Darstellung. Einige Dinge sind zu beachten:\n\nDie Epikurve und die Linie werden vor der Darstellung in Wochen aggregiert und die date_breaks und date_labels identisch sind - wir tun dies, damit die x-Achsen der beiden Diagramme gleich sind, wenn sie übereinander gelegt werden.\nDie y-Achse wird für Diagramm 2 mit der Taste position = Argument von scale_y_continuous().\nBeide Diagramme verwenden die theme_cowplot()\n\nEs gibt ein weiteres Beispiel für diese Technik in der [Epidemie-Kurven] Seite - das Überlagern der kumulativen Inzidenz mit der Epikurve.\nPlot 1 erstellen\nDies ist im Wesentlichen die Epikurve. Wir verwenden geom_area() nur zur Veranschaulichung der Anwendung (Fläche unter einer Linie, standardmäßig)\n\npacman::p_load(cowplot)            # load/install cowplot\n\np1 &lt;- linelist %&gt;%                 # save plot as object\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # view plot \n\n\n\n\n\n\n\n\nPlot 2 erstellen\nErstelle das zweite Diagramm, das den wöchentlichen Prozentsatz der verstorbenen Fälle darstellt.\n\np2 &lt;- linelist %&gt;%         # save plot as object\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %&gt;% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # view plot\n\n\n\n\n\n\n\n\nJetzt richten wir den Plot mit der Funktion align_plots() und geben dabei die horizontale und vertikale Ausrichtung an (“hv”, kann auch “h”, “v”, “none” sein). Mit “tblr” legen wir auch die Ausrichtung aller Achsen fest (oben, unten, links und rechts). Die Ausgabe ist eine Liste der Klasse (2 Elemente).\nDann zeichnen wir die beiden Diagramme zusammen mit ggdraw() (aus Kuhplot) und referenzieren die beiden Teile der aligned_plots Objekts.\n\naligned_plots &lt;- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # align the two plots and save them as list\naligned_plotted &lt;- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # overlay them and save the visual plot\naligned_plotted                                                                # print the overlayed plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#pakete-die-dir-helfen",
    "href": "new_pages/ggplot_tips.de.html#pakete-die-dir-helfen",
    "title": "31  ggplot-Tipps",
    "section": "31.12 Pakete, die dir helfen",
    "text": "31.12 Pakete, die dir helfen\nEs gibt einige wirklich tolle R-Pakete, die speziell dafür entwickelt wurden, dir bei der Navigation zu helfen ggplot2:\n\nZeigen-und-Klicken ggplot2 mit equisse\n“Mit diesem Addin kannst du deine Daten interaktiv erkunden, indem du sie mit dem ggplot2-Paket visualisierst. Es ermöglicht dir, Balkenplots, Kurven, Streudiagramme, Histogramme, Boxplots und sf-Objekte zu zeichnen und dann die Grafik zu exportieren oder den Code abzurufen, um die Grafik zu reproduzieren.”\nInstalliere das Addin und starte es dann über das RStudio-Menü oder mit esquisse::esquisser().\nSiehe die Github-Seite\nDokumentation",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#sonstiges",
    "href": "new_pages/ggplot_tips.de.html#sonstiges",
    "title": "31  ggplot-Tipps",
    "section": "31.13 Sonstiges",
    "text": "31.13 Sonstiges\n\nNumerische Anzeige\nDu kannst die wissenschaftliche Notation deaktivieren, indem du diesen Befehl vor dem Plotten ausführst.\n\noptions(scipen=999)\n\nOder wende number_format() aus dem Waage Paket auf einen bestimmten Wert oder eine bestimmte Spalte, wie unten gezeigt.\nFunktionen aus dem Paket verwenden skaliert um die Darstellung von Zahlen einfach anzupassen. Sie können auf die Spalten in deinem Datenrahmen angewendet werden, werden aber in diesem Beispiel nur für einzelne Zahlen angezeigt.\n\nscales::number(6.2e5)\n\n[1] \"620 000\"\n\nscales::number(1506800.62,  accuracy = 0.1,)\n\n[1] \"1 506 800.6\"\n\nscales::comma(1506800.62, accuracy = 0.01)\n\n[1] \"1,506,800.62\"\n\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")\n\n[1] \"1.506.800,62\"\n\nscales::percent(0.1)\n\n[1] \"10%\"\n\nscales::dollar(56)\n\n[1] \"$56\"\n\nscales::scientific(100000)\n\n[1] \"1e+05\"",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.de.html#ressourcen",
    "href": "new_pages/ggplot_tips.de.html#ressourcen",
    "title": "31  ggplot-Tipps",
    "section": "31.14 Ressourcen",
    "text": "31.14 Ressourcen\nInspiration ggplot Diagramm-Galerie\nPräsentation von Daten Europäisches Zentrum für die Prävention und die Kontrolle von Krankheiten Leitlinien für die Präsentation von Überwachungsdaten\nFacetten und Etikettierer Verwendung von Etikettierern für Facettenstreifen Etikettierer\nBestellung mit Faktoren anpassen fct_reorder\nfct_inorder\nWie man einen Boxplot neu anordnet\nEine Variable in ggplot2 neu anordnen\nR für Datenwissenschaft - Faktoren\nLegenden\nReihenfolge der Legenden anpassen\nBeschriftungen Ausrichtung der Beschriftung\nBeschriftungen\nggrepel\nCheatsheets\nSchönes Plotten mit ggplot2",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplot-Tipps</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html",
    "href": "new_pages/epicurves.de.html",
    "title": "32  Epidemische Kurven",
    "section": "",
    "text": "32.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html#vorbereitung",
    "href": "new_pages/epicurves.de.html#vorbereitung",
    "title": "32  Epidemische Kurven",
    "section": "",
    "text": "Pakete\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,          # file import/export\n  here,         # relative filepaths \n  lubridate,    # working with dates/epiweeks\n  aweek,        # alternative package for working with dates/epiweeks\n  incidence2,   # epicurves of linelist data\n  i2extras,     # supplement to incidence2\n  stringr,      # search and manipulate character strings\n  forcats,      # working with factors\n  RColorBrewer, # Color palettes from colorbrewer2.org\n  tidyverse     # data management + ggplot2 graphics\n) \n\n\n\nDaten importieren\nIn diesem Abschnitt werden zwei Beispieldatensätze verwendet:\n\nEine Liste von Einzelfällen aus einer simulierten Epidemie\nAggregierte Zählungen nach Krankenhaus aus der gleichen simulierten Epidemie\n\nDie Datensätze werden mit der Methode import() Funktion aus der rioPaket. Siehe die Seite über [Import und Export] für verschiedene Möglichkeiten, Daten zu importieren.\nFall-Lineliste\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du die Daten herunterladen möchtest, um Schritt für Schritt vorzugehen, lies die Anleitung im [Handbuch und Daten herunterladen] Seite. Wir gehen davon aus, dass sich die Datei im Arbeitsverzeichnis befindet, also werden in diesem Dateipfad keine Unterordner angegeben.\n\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nDie ersten 50 Zeilen werden unten angezeigt.\n\n\n\n\n\n\nFallzahlen aggregiert nach Krankenhaus\nFür die Zwecke des Handbuchs wird der Datensatz der wöchentlich aggregierten Fallzahlen nach Krankenhaus aus den linelist mit dem folgenden Code erstellt.\n\n# import the counts data into R\ncount_data &lt;- linelist %&gt;% \n  group_by(hospital, date_hospitalisation) %&gt;% \n  summarize(n_cases = dplyr::n()) %&gt;% \n  filter(date_hospitalisation &gt; as.Date(\"2013-06-01\")) %&gt;% \n  ungroup()\n\nDie ersten 50 Zeilen werden unten angezeigt:\n\n\n\n\n\n\n\n\nParameter einstellen\nFür die Erstellung eines Berichts möchtest du vielleicht bearbeitbare Parameter wie das Datum, für das die Daten aktuell sind (das “Datumsdatum”), festlegen. Du kannst dann auf das Objekt data_date in deinem Code referenzieren, wenn du Filter oder dynamische Beschriftungen anwendest.\n\n## set the report date for the report\n## note: can be set to Sys.Date() for the current date\ndata_date &lt;- as.Date(\"2015-05-15\")\n\n\n\nDaten überprüfen\nÜberprüfe, ob jede relevante Datumsspalte der Klasse Datum angehört und einen geeigneten Wertebereich hat. Du kannst dies einfach mit hist() für Histogramme, oder range() mit na.rm=TRUE, oder mit ggplot() wie unten.\n\n# check range of onset dates\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html#epikurven-mit-ggplot2",
    "href": "new_pages/epicurves.de.html#epikurven-mit-ggplot2",
    "title": "32  Epidemische Kurven",
    "section": "32.2 Epikurven mit ggplot2",
    "text": "32.2 Epikurven mit ggplot2\nverwenden ggplot() um deine Epikurve zu erstellen, bietet Flexibilität und Anpassungsmöglichkeiten, erfordert aber mehr Aufwand und Verständnis dafür, wie ggplot() funktioniert.\nDu musst manuell die Aggregation der Fälle nach Zeit (in Wochen, Monaten usw.) steuern und die Abstände der Beschriftungen auf der Datumsachse. Dies muss sorgfältig gesteuert werden.\nDiese Beispiele verwenden eine Teilmenge der linelist Datensatzes - nur die Fälle aus dem Zentralkrankenhaus.\n\ncentral_data &lt;- linelist %&gt;% \n  filter(hospital == \"Central Hospital\")\n\nZur Erstellung einer Epikurve mit ggplot() zu erstellen, gibt es drei Hauptelemente:\n\nEin Histogramm, in dem die Fälle der Linienliste in “Bins” zusammengefasst werden, die sich durch bestimmte “Break”-Punkte unterscheiden\nSkalen für die Achsen und ihre Beschriftungen\nThemen für das Erscheinungsbild des Plots, einschließlich Titel, Beschriftungen, Beschriftungen usw.\n\n\nFallkästen festlegen\nHier zeigen wir dir, wie du die Fälle in Histogramm-Bins (“Balken”) zusammenfasst. Es ist wichtig zu wissen, dass die Aggregation von Fällen in Histogramm-Bins nicht nicht unbedingt die gleichen Intervalle sind wie die Daten, die auf der x-Achse erscheinen.\nIm Folgenden findest du den vielleicht einfachsten Code, um tägliche und wöchentliche Epikurven zu erstellen.\nIn der übergreifenden ggplot() Befehl wird der Datensatz an data =. Auf dieser Grundlage wird die Geometrie eines Histogramms mit einem +. Innerhalb der geom_histogram() bilden wir die Ästhetik so ab, dass die Spalte date_onset auf die x-Achse abgebildet wird. Auch innerhalb der geom_histogram() aber nicht innerhalb aes() setzen wir die binwidth = der Histogramm-Bins, in Tagen. Wenn diese ggplot2Syntax verwirrend ist, lies die Seite über [ggplot-Grundlagen].\nVORSICHT! Das Plotten wöchentlicher Fälle mit Hilfe von binwidth = 7 beginnt der erste 7-Tage-Bin mit dem ersten Fall, der ein beliebiger Wochentag sein kann! Um bestimmte Wochen zu erstellen, siehe Abschnitt unten.\n\n# daily \nggplot(data = central_data) +          # set data\n  geom_histogram(                      # add histogram\n    mapping = aes(x = date_onset),     # map date column to x-axis\n    binwidth = 1)+                     # cases binned by 1 day \n  labs(title = \"Central Hospital - Daily\")                # title\n\n# weekly\nggplot(data = central_data) +          # set data \n  geom_histogram(                      # add histogram\n      mapping = aes(x = date_onset),   # map date column to x-axis\n      binwidth = 7)+                   # cases binned every 7 days, starting from first case (!) \n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # title\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer erste Fall in diesem Datensatz des Zentralkrankenhauses hat seine Symptome am ersten Tag gezeigt:\n\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")\n\n[1] \"Thursday 01 May, 2014\"\n\n\nUm die Histogramm-Bin-Breaks manuell festzulegen, tippe auf nicht verwenden Sie die binwidth = Argument und übergibt stattdessen einen Vektor von Daten an breaks =.\nErstelle den Datumsvektor mit der Option Basis R-Funktion seq.Date(). Diese Funktion erwartet Argumente to =, from =, und by =. Der folgende Befehl liefert zum Beispiel monatliche Daten, die am 15. Januar beginnen und am 28. Juni enden.\n\nmonthly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks   # print\n\n [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\"\n [6] \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\"\n[11] \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\"\n[16] \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n\n\nDieser Vektor kann geliefert werden an geom_histogram() als breaks =:\n\n# monthly \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # provide the pre-defined vector of breaks                    \n  labs(title = \"Monthly case bins\")   # title\n\n\n\n\n\n\n\n\nEine einfache wöchentliche Datumsfolge kann zurückgegeben werden, indem man by = \"week\". Zum Beispiel:\n\nweekly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n\nEine Alternative zur Angabe eines bestimmten Start- und Enddatums ist es, zu schreiben dynamischen Code so zu schreiben, dass die wöchentlichen Bins beginnen der Montag vor dem ersten Fall. Wir werden diese Datumsvektoren in den folgenden Beispielen verwenden.\n\n# Sequence of weekly Monday dates for CENTRAL HOSPITAL\nweekly_breaks_central &lt;- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")\n\nPacken wir den ziemlich entmutigenden Code oben aus:\n\nDer “von”-Wert (frühestes Datum der Sequenz) wird wie folgt erstellt: Der minimale Datumswert (min() mit na.rm=TRUE) in der Spalte date_onset wird gefüttert mit floor_date() von der lubridate Paket. floor_date() auf “Woche” gesetzt, gibt das Startdatum der “Woche” dieses Falls zurück, da der Starttag jeder Woche ein Montag ist (week_start = 1).\nEbenso wird der “bis”-Wert (Enddatum der Folge) mit der umgekehrten Funktion erstellt ceiling_date() erstellt, um den Montag zurückzugeben nach dem letzten Fall.\nDas “by”-Argument von seq.Date() kann auf eine beliebige Anzahl von Tagen, Wochen oder Monaten gesetzt werden.\nverwenden week_start = 7 für Sonntagswochen\n\nDa wir diese Datumsvektoren auf dieser Seite durchgängig verwenden werden, definieren wir auch einen für den gesamten Ausbruch (der obige ist nur für das Central Hospital).\n\n# Sequence for the entire outbreak\nweekly_breaks_all &lt;- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")\n\nDiese seq.Date() Ausgaben können verwendet werden, um Histogramm-Bin-Breaks zu erstellen, aber auch die Breaks für die Datumsbeschriftungen, die unabhängig von den Bins sein können. Mehr über die Datumsbeschriftungen erfährst du in späteren Abschnitten.\nTIPP: Für eine einfachere ggplot() Befehl zu verwenden, speichere die Bin-Breaks und die Datumslabel-Breaks im Voraus als benannte Vektoren und gib ihre Namen einfach an breaks =.\n\n\nWöchentliches Epikurvenbeispiel\nIm Folgenden findest du einen detaillierten Beispielcode, um wöchentliche Epikurven für Montagswochen zu erstellen, mit ausgerichteten Balken, Datumsbeschriftungen und vertikalen Gitternetzlinien. Dieser Abschnitt ist für Nutzer gedacht, die den Code schnell brauchen. Um die einzelnen Aspekte (Themen, Datumsbeschriftungen usw.) im Detail zu verstehen, lies die folgenden Abschnitte. Zu beachten:\n\nDie Histogramm-Bin-Breaks sind definiert mit seq.Date() wie oben erklärt, um am Montag vor dem frühesten Fall zu beginnen und am Montag nach dem letzten Fall zu enden\nDas Intervall von Datumsangaben wird festgelegt durch date_breaks = innerhalb von scale_x_date()\nDer Abstand der kleinen vertikalen Rasterlinien zwischen den Datumsbeschriftungen wird festgelegt auf date_minor_breaks =\nWir verwenden closed = \"left\" in der geom_histogram() um sicherzustellen, dass die Daten in den richtigen Behältern gezählt werden\nexpand = c(0,0) in der x- und y-Skala entfernt überschüssigen Platz auf jeder Seite der Achsen, wodurch auch sichergestellt wird, dass die Datumsbeschriftungen mit dem ersten Balken beginnen.\n\n\n# TOTAL MONDAY WEEK ALIGNMENT\n#############################\n# Define sequence of weekly breaks\nweekly_breaks_central &lt;- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # Monday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # Monday after last case\n      by   = \"week\")    # bins are 7-days \n\n\nggplot(data = central_data) + \n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    \n    # mapping aesthetics\n    mapping = aes(x = date_onset),  # date column mapped to x-axis\n    \n    # histogram bin breaks\n    breaks = weekly_breaks_central, # histogram bin breaks defined previously\n      \n    closed = \"left\",  # count cases from start of breakpoint\n    \n    # bars\n    color = \"darkblue\",     # color of lines around bars\n    fill = \"lightblue\"      # color of fill within bars\n  )+ \n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"4 weeks\",        # date labels and major vertical gridlines appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # minor vertical lines appear every Monday week\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+             # remove excess y-axis space below 0 (align histogram flush with x-axis)\n  \n  # aesthetic themes\n  theme_minimal()+                # simplify plot background\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # caption on left side\n                                face = \"italic\"), # caption in italics\n    axis.title = element_text(face = \"bold\"))+    # axis titles in bold\n  \n  # labels including dynamic caption\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\n\nSonntagswochen\nUm die obige Darstellung für Sonntagswochen zu erreichen, sind ein paar Änderungen erforderlich, denn die date_breaks = \"weeks\" nur für Montagswochen funktionieren.\n\nDie Haltepunkte der Histogramm-Bins müssen auf Sonntage gesetzt werden (week_start = 7)\nInnerhalb von scale_x_date() sollten die ähnlichen Datumsunterbrechungen zur Verfügung gestellt werden breaks = und minor_breaks = um sicherzustellen, dass die Datumsbeschriftungen und vertikalen Rasterlinien an Sonntagen ausgerichtet sind.\n\nZum Beispiel kann die scale_x_date() Befehl für Sonntagswochen könnte zum Beispiel so aussehen:\n\nscale_x_date(\n    expand = c(0,0),\n    \n    # specify interval of date labels and major vertical gridlines\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"4 weeks\"),\n    \n    # specify interval of minor vertical gridline \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"week\"),\n   \n    # date label format\n    #date_labels = \"%a\\n%d %b\\n%Y\")+         # day, above month abbrev., above 2-digit year\n    label = scales::label_date_short())+ # automatic label formatting\n\n\n\n\nGruppieren/Färben nach Wert\nDie Histogrammbalken können nach Gruppen gefärbt und “gestapelt” werden. Um die Gruppierungsspalte zu bestimmen, nimmst du die folgenden Änderungen vor. Siehe die [ggplot Grundlagen] Seite für Details.\n\nInnerhalb der ästhetischen Histogramm-Zuordnung aes() ordnen Sie den Spaltennamen dem group = und fill = Argumente\nEntfernen Sie alle fill = Argument außerhalb von von aes() da sie diejenige innerhalb von\nArgumente innen aes() wird angewendet nach Gruppen, während jede außerhalb für alle Balken gelten (z.B. kannst du immer noch color = außen, damit jeder Balken den gleichen Rand hat)\n\nHier ist, was die aes() Befehl aussehen würde, um die Balken nach Geschlecht zu gruppieren und einzufärben:\n\naes(x = date_onset, group = gender, fill = gender)\n\nHier wird sie angewendet:\n\nggplot(data = linelist) +     # begin with linelist (many hospitals)\n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # set data to be grouped by hospital\n      fill = hospital),       # bar fill (inside color) by hospital\n    \n    # bin breaks are Monday weeks\n    breaks = weekly_breaks_all,   # sequence of weekly Monday bin breaks for whole outbreak, defined in previous code       \n    \n    closed = \"left\",          # count cases from start of breakpoint\n\n    # Color around bars\n    color = \"black\")\n\n\n\n\n\n\n\n\n\n\nFarben anpassen\n\nZu manuell die Füllung für jede Gruppe einzustellen, verwendest du scale_fill_manual() (beachte: scale_color_manual() ist unterschiedlich!).\n\nVerwende die values = Argument, um einen Vektor von Farben anzuwenden.\nverwenden na.value = um eine Farbe anzugeben für NA Werte.\nVerwende die labels = Argument, um den Text der Legendenelemente zu ändern. Um sicher zu gehen, solltest du einen benannten Vektor angeben, wie c(\"old\" = \"new\", \"old\" = \"new\") oder passe die Werte in den Daten selbst an.\nVerwende name = um der Legende einen passenden Titel zu geben\n\nWeitere Tipps zu Farbskalen und Paletten findest du auf der Seite über [ggplot-Grundlagen].\n\n\nggplot(data = linelist)+           # begin with linelist (many hospitals)\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # cases grouped by hospital\n        fill = hospital),          # bar fill by hospital\n    \n    # bin breaks\n    breaks = weekly_breaks_all,    # sequence of weekly Monday bin breaks, defined in previous code\n    \n    closed = \"left\",               # count cases from start of breakpoint\n\n    # Color around bars\n    color = \"black\")+              # border color of each bar\n  \n  # manual specification of colors\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\") # specify fill colors (\"values\") - attention to order!\n\n\n\n\n\n\n\n\n\n\nReihenfolge der Ebenen anpassen\nDie Reihenfolge, in der gruppierte Balken gestapelt werden, lässt sich am besten anpassen, indem du die Gruppierungsspalte als Klasse Faktor klassifizierst. Dann kannst du die Reihenfolge der Faktorebenen (und ihre Beschriftung) festlegen. Siehe die Seite über [Faktoren] oder [ggplot-Tipps] für Details.\nBevor du den Plot erstellst, verwende die fct_relevel() Funktion von forcatsPaket, um die Gruppierungsspalte in einen Klassenfaktor umzuwandeln und die Reihenfolge der Ebenen manuell anzupassen, wie auf der Seite über [Faktoren].\n\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Define new dataset with hospital as factor\nplot_data &lt;- linelist %&gt;% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convert to factor and set \"Missing\" and \"Other\" as top levels to appear on epicurve top\n\nlevels(plot_data$hospital) # print levels in order\n\n[1] \"Missing\"                             \n[2] \"Other\"                               \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\nIm folgenden Diagramm unterscheidet sich nur die Spalte hospital wie oben konsolidiert wurde, und wir verwenden guides() um die Reihenfolge der Legende umzukehren, so dass “Missing” unten in der Legende steht.\n\nggplot(plot_data) +                     # Use NEW dataset with hospital as re-ordered factor\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # cases grouped by hospital\n        fill = hospital),               # bar fill (color) by hospital\n    \n    breaks = weekly_breaks_all,         # sequence of weekly Monday bin breaks for whole outbreak, defined at top of ggplot section\n    \n    closed = \"left\",                    # count cases from start of breakpoint\n\n    color = \"black\")+                   # border color around each bar\n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"3 weeks\",        # labels appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # vertical lines appear every Monday week\n    label = scales::label_date_short()) + # efficient label formatting\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+                   # remove excess y-axis space below 0\n  \n  # manual specification of colors, ! attention to order\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\")+ \n  \n  # aesthetic themes\n  theme_minimal()+                      # simplify plot background\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # caption on left side in italics\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # axis titles in bold\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\")\n\n\n\n\n\n\n\n\nTIPP: Um nur die Reihenfolge der Legende umzukehren, füge Folgendes hinzu ggplot2 Befehl hinzu: guides(fill = guide_legend(reverse = TRUE)).\n\n\nLegende anpassen\nMehr über Legenden und Skalen findest du in den [ggplot-Tipps] Seite. Hier sind ein paar Highlights:\n\nBearbeite den Titel der Legende entweder in der Skalenfunktion oder mit labs(fill = \"Legend title\") (wenn du die Funktion color = Ästhetik verwendest, dann verwende labs(color = \"\"))\ntheme(legend.title = element_blank()) keinen Legendentitel zu haben\ntheme(legend.position = \"top\") (“unten”, “links”, “rechts”, oder “keine”, um die Legende zu entfernen)\ntheme(legend.direction = \"horizontal\") horizontale Legende\nguides(fill = guide_legend(reverse = TRUE)) um die Reihenfolge der Legende umzukehren\n\n\n\nBalken nebeneinander\nDie nebeneinander liegende Anzeige von Gruppenleisten (im Gegensatz zur gestapelten Anzeige) wird in geom_histogram() mit position = \"dodge\" außerhalb von aes().\nWenn es mehr als zwei Wertegruppen gibt, kann es schwierig werden, diese zu lesen. Erwäge stattdessen eine facettierte Darstellung (kleine Vielfache). Um die Lesbarkeit in diesem Beispiel zu verbessern, wurden fehlende Geschlechterwerte entfernt.\n\nggplot(central_data %&gt;% drop_na(gender))+   # begin with Central Hospital cases dropping missing gender\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # cases grouped by gender\n          fill = gender),         # bars filled by gender\n        \n        # histogram bin breaks\n        breaks = weekly_breaks_central,   # sequence of weekly dates for Central outbreak - defined at top of ggplot section\n        \n        closed = \"left\",          # count cases from start of breakpoint\n        \n        color = \"black\",          # bar edge color\n        \n        position = \"dodge\")+      # SIDE-BY-SIDE bars\n                      \n  \n  # The labels on the x-axis\n  scale_x_date(expand            = c(0,0),          # remove excess x-axis space below and after case bars\n               date_breaks       = \"3 weeks\",       # labels appear every 3 Monday weeks\n               date_minor_breaks = \"week\",          # vertical lines appear every Monday week\n               label = scales::label_date_short())+ # efficient date labels\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+             # removes excess y-axis space between bottom of bars and the labels\n  \n  #scale of colors and legend labels\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # specify fill colors (\"values\") - attention to order!\n                    na.value = \"grey\" )+     \n\n  # aesthetic themes\n  theme_minimal()+                                               # a set of themes to simplify plot\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n        axis.title = element_text(face = \"bold\"))+               # axis titles in bold\n  \n  # labels\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")\n\n\n\n\n\n\n\n\n\n\nAchsengrenzen\nEs gibt zwei Möglichkeiten, den Umfang der Achsenwerte zu begrenzen.\nDie bevorzugte Methode ist die Verwendung des Befehls coord_cartesian() zu verwenden, der akzeptiert xlim = c(min, max) und ylim = c(min, max) (wobei du die Mindest- und Höchstwerte angibst). Dies wirkt wie ein “Zoom”, ohne tatsächlich Daten zu entfernen, was für Statistiken und zusammenfassende Maße wichtig ist.\nAlternativ kannst du maximale und minimale Datumswerte festlegen, indem du limits = c() in scale_x_date(). Zum Beispiel:\n\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # sets a minimum date but leaves the maximum open.  \n\nWenn du möchtest, dass die x-Achse bis zu einem bestimmten Datum reicht (z. B. dem aktuellen Datum), auch wenn keine neuen Fälle gemeldet wurden, kannst du das verwenden:\n\nscale_x_date(limits = c(NA, Sys.Date()) # ensures date axis will extend until current date  \n\nGEFAHR! Sei vorsichtig, wenn du die Skalenbrüche oder Grenzen der y-Achse einstellst (z.B. 0 bis 30 mal 5: seq(0, 30, 5)). Solche statischen Zahlen können deinen Plot zu kurz abschneiden, wenn sich die Daten ändern und die Grenze überschreiten!\n\n\nDatumsachsenbeschriftungen/Gitterlinien\nTIPP: Denke daran, dass die Datums-Achse Beschriftungen unabhängig von der Aggregation der Daten zu Balken sind, aber visuell kann es wichtig sein, die Bins, die Datumsbeschriftungen und die vertikalen Gitterlinien auszurichten.\nAn die Datumsbeschriftungen und Gitterlinien zu ändern verwenden Sie scale_x_date() auf eine der folgenden Arten:\n\nWenn deine Histogramm-Bins Tage, Montagswochen, Monate oder Jahre sind:\n\nVerwende date_breaks = um das Intervall der Beschriftungen und der Hauptgitterlinien anzugeben (z.B. “Tag”, “Woche”, “3 Wochen”, “Monat” oder “Jahr”)\nverwenden date_minor_breaks = um den Abstand der kleinen vertikalen Gitternetzlinien (zwischen den Datumsbeschriftungen) festzulegen\nhinzufügen expand = c(0,0) um die Beschriftungen am ersten Balken zu beginnen\nverwenden date_labels = um das Format der Datumsbeschriftungen festzulegen - siehe die Seite Datumsangaben für Tipps (mit \\n für eine neue Zeile)\n\nWenn deine Histogramm-Bins Sonntagswochen sind:\n\nVerwende breaks = und minor_breaks = indem du eine Folge von Datumsumbrüchen für jede\nDu kannst trotzdem verwenden date_labels = und expand = für die Formatierung verwenden, wie oben beschrieben\n\n\nEinige Anmerkungen:\n\nIm Abschnitt über die Eröffnung von ggplot findest du Anweisungen, wie du eine Datumsfolge mit seq.Date().\nSiehe diese Seiteoder die [Arbeiten mit Datumsangaben] Seite für Tipps zum Erstellen von Datumsetiketten.\n\n\nVorführungen\nNachfolgend findest du eine Demonstration von Plots, bei denen die Bins und die Plotbeschriftungen/Gitterlinien ausgerichtet und nicht ausgerichtet sind:\n\n# 7-day bins + Monday labels\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # 7-day bins with start at first case\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",             # Monday every 3 weeks\n    date_minor_breaks = \"week\",          # Monday weeks\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # remove excess space under x-axis, make flush\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# 7-day bins + Months\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",              # 1st of month\n    date_minor_breaks = \"week\",          # Monday weeks\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                 # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# TOTAL MONDAY ALIGNMENT: specify manual bin breaks to be mondays\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    closed = \"left\",                   # count cases from start of breakpoint\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"4 weeks\",             # Monday every 4 weeks\n    date_minor_breaks = \"week\",          # Monday weeks \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                  # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# TOTAL MONDAY ALIGNMENT WITH MONTHS LABELS:\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    closed = \"left\",                   # count cases from start of breakpoint\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",              # Monday every 4 weeks\n    date_minor_breaks = \"week\",          # Monday weeks \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                  # remove excess space under x-axis, make flush \n  \n  theme(panel.grid.major = element_blank())+  # Remove major gridlines (fall on 1st of month)\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# TOTAL SUNDAY ALIGNMENT: specify manual bin breaks AND labels to be Sundays\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"7 days\"),\n    \n    closed = \"left\",                    # count cases from start of breakpoint\n\n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # date label breaks and major gridlines set to every 3 weeks beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"3 weeks\"),\n    \n    # minor gridlines set to weekly beginning Sunday before first case\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by   = \"7 days\"),\n    \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAggregierte Daten\nOftmals beginnt man mit aggregierten Zählungen von Einrichtungen, Bezirken usw., anstatt mit einer Linienliste. Du kannst eine Epikurve erstellen mit ggplot() erstellen, aber der Code wird etwas anders aussehen. In diesem Abschnitt wird die count_data Datensatz, der zuvor im Abschnitt Datenvorbereitung importiert wurde. Dieser Datensatz ist der linelist auf die Anzahl der Tageskrankenhäuser aggregiert. Die ersten 50 Zeilen werden unten angezeigt.\n\n\n\n\n\n\n\nTägliche Zählungen aufzeichnen\nWir können eine tägliche Epikurve aus diesen täglichen Zählungen. Hier sind die Unterschiede zum Code:\n\nInnerhalb des ästhetischen Mappings aes() gibst du an y = als Zählspalte an (in diesem Fall lautet der Spaltenname n_cases)\nFüge das Argument stat = \"identity\" innerhalb von geom_histogram() ein, das angibt, dass die Balkenhöhe die y = Wert sein soll und nicht die Anzahl der Zeilen, wie es der Standard ist\nFüge das Argument width = hinzu, um vertikale weiße Linien zwischen den Balken zu vermeiden. Setze für tägliche Daten den Wert 1. Für wöchentliche Zähldaten setze den Wert auf 7. Bei monatlichen Zähldaten sind weiße Linien ein Problem (jeder Monat hat eine unterschiedliche Anzahl von Tagen) - überlege dir, ob du die x-Achse in einen kategorialen geordneten Faktor (Monate) umwandeln und mit geom_col().\n\n\nggplot(data = count_data)+\n  geom_histogram(\n   mapping = aes(x = date_hospitalisation, y = n_cases),\n   stat = \"identity\",\n   width = 1)+                # for daily counts, set width = 1 to avoid white space between bars\n  labs(\n    x = \"Date of report\", \n    y = \"Number of cases\",\n    title = \"Daily case incidence, from daily count data\")\n\n\n\n\n\n\n\n\n\n\nWöchentliche Zählungen aufzeichnen\nWenn deine Daten bereits Fallzahlen nach Wochen sind, könnten sie wie dieser Datensatz aussehen (genannt count_data_weekly):\nDie ersten 50 Zeilen der count_data_weekly werden unten angezeigt. Du kannst sehen, dass die Zählungen zu Wochen zusammengefasst wurden. Jede Woche wird nach dem ersten Tag der Woche (standardmäßig Montag) angezeigt.\n\n\n\n\n\n\nStelle nun so dar, dass x = die Spalte epiweek. Denke daran, hinzuzufügen y = die Zählungsspalte zum ästhetischen Mapping hinzuzufügen, und füge stat = \"identity\" wie oben erklärt.\n\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # x-axis is epiweek (as class Date)\n      y = n_cases_weekly,    # y-axis height in the weekly case counts\n      group = hospital,      # we are grouping the bars and coloring by hospital\n      fill = hospital),\n    stat = \"identity\")+      # this is also required when plotting count data\n     \n  # labels for x-axis\n  scale_x_date(\n    date_breaks = \"2 months\",      # labels every 2 months \n    date_minor_breaks = \"1 month\", # gridlines every month\n    label = scales::label_date_short())+ # label formatting\n     \n  # Choose color palette (uses RColorBrewer package)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")\n\n\n\n\n\n\n\n\n\n\n\nGleitende Durchschnitte\nSiehe die Seite über Gleitende Durchschnitte für eine detaillierte Beschreibung und verschiedene Optionen. Im Folgenden findest du eine Option für die Berechnung gleitender Durchschnitte mit dem PaketSchieber. Bei diesem Ansatz, wird der gleitende Durchschnitt im Datensatz berechnet, bevor er gezeichnet wird:\n\nAggregiere die Daten je nach Bedarf zu Zählungen (täglich, wöchentlich usw.) (siehe [Daten gruppieren] Seite)\nErstelle eine neue Spalte, die den gleitenden Durchschnitt enthält, der mit slide_index() von Schieber Paket\nZeichne den gleitenden Durchschnitt als geom_line() über (nach) dem Epikurvenhistogramm\n\nSiehe das hilfreiche Online Vignette für die Slider Paket\n\n# load package\npacman::p_load(slider)  # slider used to calculate rolling averages\n\n# make dataset of daily counts and 7-day moving average\n#######################################################\nll_counts_7day &lt;- linelist %&gt;%    # begin with linelist\n  \n  ## count cases by date\n  count(date_onset, name = \"new_cases\") %&gt;%   # name new column with counts as \"new_cases\"\n  drop_na(date_onset) %&gt;%                     # remove cases with missing date_onset\n  \n  ## calculate the average number of cases in 7-day window\n  mutate(\n    avg_7day = slider::slide_index(    # create new column\n      new_cases,                       # calculate based on value in new_cases column\n      .i = date_onset,                 # index is date_onset col, so non-present dates are included in window \n      .f = ~mean(.x, na.rm = TRUE),    # function is mean() with missing values removed\n      .before = 6,                     # window is the day and 6-days before\n      .complete = FALSE),              # must be FALSE for unlist() to work in next step\n    avg_7day = unlist(avg_7day))       # convert class list to class numeric\n\n\n# plot\n######\nggplot(data = ll_counts_7day) +  # begin with new dataset defined above \n    geom_histogram(              # create epicurve histogram\n      mapping = aes(\n        x = date_onset,          # date column as x-axis\n        y = new_cases),          # height is number of daily new cases\n        stat = \"identity\",       # height is y value\n        fill=\"#92a8d1\",          # cool color for bars\n        colour = \"#92a8d1\",      # same color for bar border\n        )+ \n    geom_line(                   # make line for rolling average\n      mapping = aes(\n        x = date_onset,          # date column for x-axis\n        y = avg_7day,            # y-value set to rolling average column\n        lty = \"7-day \\nrolling avg\"), # name of line in legend\n      color=\"red\",               # color of line\n      size = 1) +                # width of line\n    scale_x_date(                # date scale\n      date_breaks = \"1 month\",\n      label = scales::label_date_short(), # label formatting\n      expand = c(0,0)) +\n    scale_y_continuous(          # y-axis scale\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # removes title of legend\n\n\n\n\n\n\n\n\n\n\nFacettieren/Klein-Multiplikatoren\nWie bei anderen ggplots kannst du facettierte Plots (“kleine Vielfache”) erstellen. Wie in den [ggplot-Tipps] Seite dieses Handbuchs erklärt, kannst du entwederfacet_wrap() oder facet_grid(). Hier demonstrieren wir mit facet_wrap(). Für Epikurven, facet_wrap() ist in der Regel einfacher, da du wahrscheinlich nur eine Spalte facettieren musst.\nDie allgemeine Syntax lautet facet_wrap(rows ~ cols) wobei links von der Tilde (~) der Name einer Spalte steht, die auf die “Zeilen” der facettierten Darstellung verteilt werden soll, und rechts von der Tilde der Name einer Spalte, die auf die “Spalten” der facettierten Darstellung verteilt werden soll. Am einfachsten ist es, nur einen Spaltennamen rechts von der Tilde zu verwenden: facet_wrap(~age_cat).\nFreie Achsen\nDu musst entscheiden, ob die Skalen der Achsen für jede Facette auf die gleichen Dimensionen “fixiert” (Standard) oder “frei” (d. h. sie ändern sich je nach den Daten innerhalb der Facette) sind. Dies tust du mit der Option scales = Argument innerhalb von facet_wrap() indem du “free_x” oder “free_y” oder “free” angibst.\nAnzahl der Spalten und Zeilen der Facetten\nDies kann angegeben werden mit ncol = und nrow = innerhalb von facet_wrap().\nReihenfolge der Paneele\nUm die Reihenfolge des Erscheinungsbildes zu ändern, änderst du die zugrunde liegende Reihenfolge der Ebenen der Faktorsäule, die zur Erstellung der Facetten verwendet wird.\nÄsthetik\nSchriftgröße und -art, Streifenfarbe usw. können über theme() mit Argumenten wie:\n\nstrip.text = element_text() (Größe, Farbe, Gesicht, Winkel…)\nstrip.background = element_rect() (z. B. element_rect(fill=“grey”))\nstrip.position = (Position des Streifens “unten”, “oben”, “links”, oder “rechts”)\n\nStreifenbeschriftungen\nDie Beschriftungen der Facettenplots können über die “Beschriftungen” der Spalte als Faktor oder durch die Verwendung eines “Beschriftungsgeräts” geändert werden.\nErstelle einen Beschrifter wie diesen, indem du die Funktion as_labeller() von ggplot2. Dann gib den Labeller an die labeller = Argument von facet_wrap() wie unten gezeigt.\n\nmy_labels &lt;- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n\nEin Beispiel für eine facettierte Darstellung - facettiert nach Spalte age_cat.\n\n# make plot\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # arguments inside aes() apply by group\n      \n    color = \"black\",      # arguments outside aes() apply to all data\n        \n    # histogram breaks\n    breaks = weekly_breaks_central, # pre-defined date vector (see earlier in this page)\n    closed = \"left\" # count cases from start of breakpoint\n    )+  \n                      \n  # The labels on the x-axis\n  scale_x_date(\n    expand            = c(0,0),          # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",      # labels appear every 2 months\n    date_minor_breaks = \"1 month\",       # vertical lines appear every 1 month \n    label = scales::label_date_short())+ # label formatting\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+                       # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\nSiehe dies Link für weitere Informationen über Etikettierer.\n\nGesamtepidemie im Facettenhintergrund\nUm die Gesamtzahl der Epidemien im Hintergrund der einzelnen Facetten anzuzeigen, füge die Funktion gghighlight() mit leeren Klammern zum ggplot hinzu. Diese ist aus dem Paket gghighlight. Beachte, dass das Maximum der y-Achse in allen Facetten jetzt auf dem Höhepunkt der gesamten Epidemie basiert. Weitere Beispiele für dieses Paket findest du in den [ggplot Tipps] Seite.\n\nggplot(central_data) + \n  \n  # epicurves by group\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # arguments inside aes() apply by group\n    \n    color = \"black\",    # arguments outside aes() apply to all data\n    \n    # histogram breaks\n    breaks = weekly_breaks_central, # pre-defined date vector (see earlier in this page)\n    \n    closed = \"left\", # count cases from start of breakpoint\n    )+     # pre-defined date vector (see top of ggplot section)                \n  \n  # add grey epidemic in background to each facet\n  gghighlight::gghighlight()+\n  \n  # labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),          # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",      # labels appear every 2 months\n    date_minor_breaks = \"1 month\",       # vertical lines appear every 1 month \n    label = scales::label_date_short())+ # label formatting\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space below 0\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,                          # each plot is one value of age_cat\n    ncol = 4,                          # number of columns\n    strip.position = \"top\",            # position of the facet title/strip\n    labeller = my_labels)+             # labeller defines above\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\n\n\nEine Facette mit Daten\nWenn du ein einziges Facettenfeld haben möchtest, das alle Daten enthält, duplizierst du den gesamten Datensatz und behandelst die Duplikate als einen Facettenwert. Eine “Helfer”-Funktion CreateAllFacet() unten kann dir dabei helfen (dank dieser Blogbeitrag). Wenn sie ausgeführt wird, verdoppelt sich die Anzahl der Zeilen und es gibt eine neue Spalte namens facet in der die duplizierten Zeilen den Wert “alle” haben und die ursprünglichen Zeilen den Wert der Facettenspalte. Jetzt musst du nur noch die Facettierung der facet Spalte.\nHier ist die Hilfsfunktion. Führe sie aus, damit sie für dich verfügbar ist.\n\n# Define helper function\nCreateAllFacet &lt;- function(df, col){\n     df$facet &lt;- df[[col]]\n     temp &lt;- df\n     temp$facet &lt;- \"all\"\n     merged &lt;-rbind(temp, df)\n     \n     # ensure the facet value is a factor\n     merged[[col]] &lt;- as.factor(merged[[col]])\n     \n     return(merged)\n}\n\nWende nun die Hilfsfunktion auf den Datensatz an, und zwar auf die Spalte age_cat:\n\n# Create dataset that is duplicated and with new column \"facet\" to show \"all\" age categories as another facet level\ncentral_data2 &lt;- CreateAllFacet(central_data, col = \"age_cat\") %&gt;%\n  \n  # set factor levels\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `facet = fct_relevel(...)`.\nCaused by warning:\n! 1 unknown level in `f`: 70+\n\n# check levels\ntable(central_data2$facet, useNA = \"always\")\n\n\n  all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  &lt;NA&gt; \n  454    84    84    82    58    73    57     7     9 \n\n\nBemerkenswerte Änderungen an der ggplot() Befehls sind:\n\nDie verwendeten Daten sind jetzt central_data2 (doppelte Anzahl von Zeilen, mit neuer Spalte “facet”)\nDer Labeller muss aktualisiert werden, falls er verwendet wird\nOptional: Um vertikal gestapelte Facetten zu erhalten, wird die Facettenspalte auf die Zeilenseite der Gleichung verschoben und auf der rechten Seite durch “.” ersetzt (facet_wrap(facet~.)), und ncol = 1. Möglicherweise musst du auch die Breite und Höhe des gespeicherten png-Plotbildes anpassen (siehe ggsave()in [ggplot-Tipps]).\n\n\nggplot(central_data2) + \n  \n  # actual epicurves by group\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # arguments inside aes() apply by group\n        color = \"black\",    # arguments outside aes() apply to all data\n        \n        # histogram breaks\n        breaks = weekly_breaks_central, # pre-defined date vector (see earlier in this page)\n        \n        closed = \"left\", # count cases from start of breakpoint\n        )+    # pre-defined date vector (see top of ggplot section)\n                     \n  # Labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),          # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",      # labels appear every 2 months\n    date_minor_breaks = \"1 month\",       # vertical lines appear every 1 month \n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # create facets\n  facet_wrap(facet~. ,                            # each plot is one value of facet\n             ncol = 1)+            \n\n  # labels\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html#vorläufige-daten",
    "href": "new_pages/epicurves.de.html#vorläufige-daten",
    "title": "32  Epidemische Kurven",
    "section": "32.3 Vorläufige Daten",
    "text": "32.3 Vorläufige Daten\nDie aktuellsten Daten in den Epikurven sollten oft als vorläufig gekennzeichnet werden oder unterliegen Verzögerungen bei der Berichterstattung. Dies kann durch Hinzufügen einer vertikalen Linie und/oder eines Rechtecks über eine bestimmte Anzahl von Tagen geschehen. Hier sind zwei Optionen:\n\nVerwende annotate():\n\n\nFür eine Linie verwenden annotate(geom = \"segment\"). zur Verfügung stellen. x, xend, y, und yend. Größe und Linientyp anpassen (lty) und die Farbe an.\nFür ein Rechteck verwende annotate(geom = \"rect\"). Gib xmin/xmax/ymin/ymax an. Passe Farbe und Alpha an.\n\n\nGruppiere die Daten nach vorläufigem Status und färbe diese Balken unterschiedlich\n\nVORSICHT! Du könntest versuchen geom_rect() ein Rechteck zu zeichnen, aber das Einstellen der Transparenz funktioniert nicht im Kontext einer Linienliste. Diese Funktion überlagert ein Rechteck für jede Beobachtung/Zeile! Verwende entweder einen sehr niedrigen Alphawert (z.B. 0,01) oder einen anderen Ansatz. \n\nverwenden annotate()\n\nUnter annotate(geom = \"rect\"), die xmin und xmax Argumente müssen Eingaben der Klasse Date erhalten.\nDa diese Daten in wöchentlichen Balken aggregiert werden und der letzte Balken bis zum Montag nach dem letzten Datenpunkt reicht, kann der schattierte Bereich 4 Wochen umfassen\nHier ist ein annotate() Online-Beispiel\n\n\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    \n    closed = \"left\", # count cases from start of breakpoint\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"1 month\",             # 1st of month\n    date_minor_breaks = \"1 month\",       # 1st of month\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # labels and theme\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # add semi-transparent red rectangle to tentative data\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # note must be wrapped in as.Date()\n    xmax  = as.Date(Inf),                                          # note must be wrapped in as.Date()\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # alpha easy and intuitive to adjust using annotate()\n    fill  = \"red\")+\n  \n  # add black vertical line on top of other layers\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 days before last data\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # line begins at y = 0\n    yend  = Inf,       # line to top of plot\n    size  = 2,         # line size\n    color = \"black\",\n    lty   = \"solid\")+   # linetype e.g. \"solid\", \"dashed\"\n\n  # add text in rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\n\n\n\n\n\n\n\n\nDie gleiche schwarze vertikale Linie kann mit dem folgenden Code erreicht werden, allerdings mit geom_vline() verlierst du jedoch die Möglichkeit, die Höhe zu kontrollieren:\n\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")\n\n\n\nFarbe der Balken\nEin alternativer Ansatz könnte darin bestehen, die Farbe oder Darstellung der vorläufigen Datenbalken selbst anzupassen. Du könntest in der Phase der Datenvorbereitung eine neue Spalte erstellen und die Daten darin gruppieren, so dass die aes(fill = ) der vorläufigen Daten eine andere Farbe oder einen anderen Alphawert haben kann als die anderen Balken.\n\n# add column\n############\nplot_data &lt;- central_data %&gt;% \n  mutate(tentative = case_when(\n    date_onset &gt;= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative if in last 7 days\n    TRUE                                       ~ \"Reliable\")) # all else reliable\n\n# plot\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogram\n  geom_histogram(\n    breaks = weekly_breaks_central,   # pre-defined data vector, see top of ggplot page\n    closed = \"left\", # count cases from start of breakpoint\n    color = \"black\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",             # Monday every 3 weeks\n    date_minor_breaks = \"week\",          # Monday weeks \n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # labels and theme\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # remove title of legend",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html#mehrstufige-datumsbeschriftungen",
    "href": "new_pages/epicurves.de.html#mehrstufige-datumsbeschriftungen",
    "title": "32  Epidemische Kurven",
    "section": "32.4 Mehrstufige Datumsbeschriftungen",
    "text": "32.4 Mehrstufige Datumsbeschriftungen\nWenn du mehrstufige Datumsbeschriftungen möchtest (z.B. Monat und Jahr) ohne die unteren Beschriftungsebenen zu duplizieren möchtest, ziehe eine der folgenden Methoden in Betracht:\nDenke daran - du kannst Tools wie \\n innerhalb von der date_labels oder labels Argumente, um Teile jedes Etiketts in eine neue Zeile darunter zu setzen. Die folgenden Codes helfen dir jedoch dabei, Jahre oder Monate (zum Beispiel) in eine untere Zeile zu setzen und nur einmal.\nDie einfachste Methode ist, die labels = Argument in scale_x_date() an die Funktion label_date_short() aus dem Paket skaliert (Hinweis: Vergiss nicht, leere Klammern () zu setzen, wie unten gezeigt). Diese Funktion konstruiert automatisch effiziente Datumsbeschriftungen (mehr dazu hier). Ein zusätzlicher Vorteil dieser Funktion ist, dass sich die Beschriftungen automatisch anpassen, wenn sich deine Daten im Laufe der Zeit erweitern: von Tagen über Wochen und Monate bis hin zu Jahren.\n\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    closed = \"left\",                  # count cases from start of breakpoint\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n\n  # y-axis scale as before \n  scale_y_continuous(expand = c(0,0))+\n  \n  # x-axis scale sets efficient date labels\n  scale_x_date(\n    expand = c(0,0),                      # remove excess x-axis space below and after case bars\n    labels = scales::label_date_short())+ # auto efficient date labels\n  \n  # labels and theme\n  labs(\n    title = \"Using label_date_short()\\nTo make automatic and efficient date labels\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()\n\n\n\n\n\n\n\n\nEine zweite Möglichkeit ist die Verwendung von Facetten. Unten:\n\nDie Fallzahlen werden aus ästhetischen Gründen zu Wochen zusammengefasst. Weitere Informationen findest du auf der Seite Epicurves (Registerkarte Aggregierte Daten).\nA geom_area() Linie wird anstelle eines Histogramms verwendet, da der unten beschriebene Facettenansatz nicht gut mit Histogrammen funktioniert.\n\nAggregieren zu wöchentlichen Zählungen\n\n# Create dataset of case counts by week\n#######################################\ncentral_weekly &lt;- linelist %&gt;%\n  filter(hospital == \"Central Hospital\") %&gt;%   # filter linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %&gt;%  \n  count(week) %&gt;%                              # summarize weekly case counts\n  drop_na(week) %&gt;%                            # remove cases with missing onset_date\n  complete(                                    # fill-in all weeks with no cases reported\n    week = seq.Date(\n      from = min(week),   \n      to   = max(week),\n      by   = \"week\"),\n    fill = list(n = 0))                        # convert new NA values to 0 counts\n\nPlots erstellen\n\n# plot with no facet box border\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # establish x and y for entire plot\n  geom_line(stat = \"identity\",              # make line, line height is count number\n            color = \"#69b3a2\") +            # line color\n  geom_point(size=1, color=\"#69b3a2\") +     # make points at the weekly data points\n  geom_area(fill = \"#69b3a2\",               # fill area below line\n            alpha = 0.4)+                   # fill transparency\n  scale_x_date(date_labels=\"%b\",            # date label format show month \n               date_breaks=\"month\",         # date labels on 1st of each month\n               expand=c(0,0)) +             # remove excess space\n  scale_y_continuous(\n    expand  = c(0,0))+                      # remove excess space below x-axis\n  facet_grid(~lubridate::year(week),        # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",               # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                  # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",                  # facet label placement\n          strip.background = element_blank(),         # no facet lable background\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_blank(),             # no border for facet panel\n          panel.spacing=unit(0,\"cm\"))+                # No space between facet panels\n  labs(title = \"Nested year labels - points, shaded, no label border\")\n\n\n\n\n\n\n\n\nDie obige Technik zum Facettieren wurde angepasst von dieser und dies Beitrag auf stackoverflow.com.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html#dual-axis",
    "href": "new_pages/epicurves.de.html#dual-axis",
    "title": "32  Epidemische Kurven",
    "section": "32.5 Dual-axis",
    "text": "32.5 Dual-axis\nObwohl es in der Datenvisualisierungs-Community heftige Diskussionen über die Sinnhaftigkeit von zwei Achsen gibt, wollen viele Epi-Betreuer/innen immer noch eine Epikurve oder ein ähnliches Diagramm mit einem Prozentwert sehen, der von einer zweiten Achse überlagert wird. Dies wird ausführlicher in den [ggplot-Tipps] Seite näher erläutert, aber ein Beispiel, das diecowplot Methode wird unten gezeigt:\n\nEs werden zwei verschiedene Plots erstellt, die dann mit Kuhplot Paket kombiniert.\nDie Diagramme müssen genau die gleiche x-Achse haben (Grenzen setzen), sonst stimmen die Daten und Beschriftungen nicht überein\nJeder verwendet theme_cowplot() und bei einer wurde die y-Achse auf die rechte Seite der Grafik verschoben\n\n\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\n#######################################\nplot_cases &lt;- linelist %&gt;% \n  \n  # plot cases per week\n  ggplot()+\n  \n  # create histogram  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks every week beginning monday before first case, going to monday after last case\n    breaks = weekly_breaks_all)+  # pre-defined vector of weekly dates (see top of ggplot section)\n        \n  # specify beginning and end of date axis to align with other plot\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  # labels\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# make second plot of percent died per week\n###########################################\nplot_deaths &lt;- linelist %&gt;%                        # begin with linelist\n  group_by(week = floor_date(date_onset, \"week\")) %&gt;%  # create week column\n  \n  # summarise to get weekly percent of cases who died\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %&gt;% \n  \n  # begin plot\n  ggplot()+\n  \n  # line of weekly percent who died\n  geom_line(                                # create line of percent died\n    mapping = aes(x = week, y = pct_died),  # specify y-height as pct_died column\n    stat = \"identity\",                      # set line height to the value in pct_death column, not the number of rows (which is default)\n    size = 2,\n    color = \"black\")+\n  \n  # Same date-axis limits as the other plot - perfect alignment\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  \n  # y-axis adjustments\n  scale_y_continuous(                # adjust y-axis\n    breaks = seq(0,100, 10),         # set break intervals of percent axis\n    limits = c(0, 100),              # set extent of percent axis\n    position = \"right\")+             # move percent axis to the right\n  \n  # Y-axis label, no x-axis label\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # percent axis label\n  \n  theme_cowplot()                   # add this to make the two plots merge together nicely\n\nJetzt benutzen Kuhplot um die beiden Diagramme zu überlagern. Es wurde auf die Ausrichtung der x-Achse, die Seite der y-Achse und die Verwendung von theme_cowplot().\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html#kumulative-inzidenz",
    "href": "new_pages/epicurves.de.html#kumulative-inzidenz",
    "title": "32  Epidemische Kurven",
    "section": "32.6 Kumulative Inzidenz",
    "text": "32.6 Kumulative Inzidenz\nWenn du mit einer Fallliste beginnst, erstelle eine neue Spalte, die die kumulative Anzahl der Fälle pro Tag eines Ausbruchs enthält, indem du cumsum() von Basis R:\n\ncumulative_case_counts &lt;- linelist %&gt;% \n  count(date_onset) %&gt;%                # count of rows per day (returned in column \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n)       # new column of the cumulative number of rows at each date\n    )\n\nDie ersten 10 Zeilen werden unten angezeigt:\n\n\n\n\n\n\nDiese kumulative Spalte kann dann gegen folgende Werte aufgetragen werden date_onset dargestellt werden, indem geom_line():\n\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n\n\n\n\n\n\n\n\nSie kann auch über die Epikurve gelegt werden, mit zwei Achsen unter Verwendung der KuhplotMethode, die oben und in den [ggplot-Tipps] Seite:\n\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\nplot_cases &lt;- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# make second plot of cumulative cases line\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\n\nBenutze jetzt Kuhplot um die beiden Diagramme zu überlagern. Es wurde auf die Ausrichtung der x-Achse, die Seite der y-Achse und die Verwendung von theme_cowplot().\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.de.html#ressourcen",
    "href": "new_pages/epicurves.de.html#ressourcen",
    "title": "32  Epidemische Kurven",
    "section": "32.7 Ressourcen",
    "text": "32.7 Ressourcen",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Epidemische Kurven</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.de.html",
    "href": "new_pages/age_pyramid.de.html",
    "title": "33  Demografische Pyramiden und Likert-Skalen",
    "section": "",
    "text": "33.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Demografische Pyramiden und Likert-Skalen</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.de.html#vorbereitung",
    "href": "new_pages/age_pyramid.de.html#vorbereitung",
    "title": "33  Demografische Pyramiden und Likert-Skalen",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(rio,       # to import data\n               here,      # to locate files\n               tidyverse, # to clean, handle, and plot the data (includes ggplot2 package)\n               apyramid,  # a package dedicated to creating age pyramids\n               janitor,   # tables and cleaning data\n               stringr)   # working with strings for titles, captions, etc.\n\n\n\nDaten importieren\nZu Beginn importieren wir die bereinigte Liste der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import case linelist \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.\n\n\n\n\n\n\n\n\nReinigung\nUm eine traditionelle demografische Alters-/Geschlechtspyramide zu erstellen, müssen die Daten zunächst wie folgt bereinigt werden:\n\nDie Spalte Geschlecht muss bereinigt werden.\nJe nach deiner Methode sollte das Alter entweder als numerische Zahl oder in einer Alterskategorie Spalte gespeichert werden.\n\nWenn du Alterskategorien verwendest, sollten die Spaltenwerte korrigiert werden, entweder standardmäßig alphanumerisch oder absichtlich durch Konvertierung in einen Klassenfaktor.\nIm Folgenden verwenden wir tabyl() von Hausmeister um die Säulen zu inspizieren gender und age_cat5.\n\nlinelist %&gt;% \n  tabyl(age_cat5, gender)\n\n age_cat5   f   m NA_\n      0-4 640 416  39\n      5-9 641 412  42\n    10-14 518 383  40\n    15-19 359 364  20\n    20-24 305 316  17\n    25-29 163 259  13\n    30-34 104 213   9\n    35-39  42 157   3\n    40-44  25 107   1\n    45-49   8  80   5\n    50-54   2  37   1\n    55-59   0  30   0\n    60-64   0  12   0\n    65-69   0  12   1\n    70-74   0   4   0\n    75-79   0   0   1\n    80-84   0   1   0\n      85+   0   0   0\n     &lt;NA&gt;   0   0  86\n\n\nWir führen auch ein schnelles Histogramm für die age Spalte, um sicherzustellen, dass sie sauber und richtig klassifiziert ist:\n\nhist(linelist$age)",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Demografische Pyramiden und Likert-Skalen</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.de.html#apyramide-paket",
    "href": "new_pages/age_pyramid.de.html#apyramide-paket",
    "title": "33  Demografische Pyramiden und Likert-Skalen",
    "section": "33.2 Apyramide Paket",
    "text": "33.2 Apyramide Paket\nDas Paket apyramid ist ein Produkt der R4Epis Projekts. Du kannst mehr über dieses Paket lesen hier. Es ermöglicht dir, schnell eine Alterspyramide zu erstellen. Für differenziertere Situationen, siehe den folgenden Abschnitt verwenden ggplot(). Du kannst mehr über die Apyramide Paket kannst du auf der Hilfeseite nachlesen, indem du ?age_pyramid in deiner R-Konsole eingibst.\n\nLinelist-Daten\nVerwendung der bereinigten linelist Datensatzes können wir eine Alterspyramide mit einem einfachen age_pyramid() Befehl erstellen. In diesem Befehl:\n\nDie data = Argument wird als linelist Datenrahmen\nDie age_group = Argument (für die y-Achse) wird auf den Namen der kategorialen Altersspalte (in Anführungszeichen) gesetzt\nDie split_by = Argument (für die x-Achse) wird auf die Spalte Geschlecht gesetzt\n\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\n\n\n\n\n\n\n\n\nDie Pyramide kann mit dem Prozentsatz aller Fälle auf der x-Achse angezeigt werden, anstatt mit der Anzahl, indem du proportional = TRUE.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\n\n\n\n\n\n\n\n\nWenn du agepyramid Paket, wenn die split_by Spalte binär ist (z. B. männlich/weiblich oder ja/nein), dann wird das Ergebnis als Pyramide angezeigt. Gibt es jedoch mehr als zwei Werte in der split_by Spalte (ohne NA), erscheint die Pyramide als facettiertes Balkendiagramm mit grauen Balken im “Hintergrund”, die den Bereich der nicht facettierten Daten für diese Altersgruppe anzeigen. In diesem Fall sind Werte von split_by = als Beschriftungen am oberen Rand jedes Facettenfelds angezeigt. Das folgende Beispiel zeigt, was passiert, wenn die split_by = die Spalte zugewiesen wird hospital.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  \n\n\n\n\n\n\n\n\n\nFehlende Werte\nZeilen, die NA fehlende Werte in der split_by = oder age_group = Spalten, wenn sie kodiert sind als NA codiert sind, wird die oben gezeigte Facettierung nicht ausgelöst. Standardmäßig werden diese Zeilen nicht angezeigt. Du kannst jedoch festlegen, dass sie in einem angrenzenden Balkendiagramm und als separate Altersgruppe am oberen Rand angezeigt werden, indem du angibst na.rm = FALSE.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # show patients missing age or gender\n\n\n\n\n\n\n\n\n\n\nProportionen, Farben & Ästhetik\nIn der Standardeinstellung zeigen die Balken die Anzahl (nicht den Prozentsatz), eine gestrichelte Mittellinie für jede Gruppe und die Farben grün/lila an. Jeder dieser Parameter kann, wie unten gezeigt, angepasst werden:\nDu kannst auch zusätzliche ggplot() Befehle zum Plot hinzufügen, indem du die Standard ggplot() “+”-Syntax zusätzliche Befehle hinzufügen, z. B. ästhetische Themen und Beschriftungsanpassungen:\n\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # show percents, not counts\n  show_midpoint = FALSE,            # remove bar mid-point line\n  #pal = c(\"orange\", \"purple\")      # can specify alt. colors here (but not labels)\n  )+                 \n  \n  # additional ggplot commands\n  theme_minimal()+                               # simplfy background\n  scale_fill_manual(                             # specify colors AND labels\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # note x and y labs are switched\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # legend to bottom\n    axis.text = element_text(size = 10, face = \"bold\"),  # fonts/sizes\n    axis.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nAggregierte Daten\nIn den obigen Beispielen wird davon ausgegangen, dass deine Daten in einem Zeilenformat vorliegen, mit einer Zeile pro Beobachtung. Wenn deine Daten bereits in Zählungen nach Alterskategorie aggregiert sind, kannst du trotzdem die apyramid Paket verwenden, wie unten gezeigt.\nZur Veranschaulichung fassen wir die Daten der Linienliste nach Alterskategorie und Geschlecht in einem “breiten” Format zusammen. So wird simuliert, als ob deine Daten von Anfang an in Zählungen vorliegen würden. Erfahre mehr über [Daten gruppieren] und [Pivotieren von Daten] auf den entsprechenden Seiten.\n\ndemo_agg &lt;- linelist %&gt;% \n  count(age_cat5, gender, name = \"cases\") %&gt;% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %&gt;% \n  rename(`missing_gender` = `NA`)\n\n…dann sieht der Datensatz wie folgt aus: mit Spalten für die Alterskategorie, männlichen und weiblichen Zahlen und fehlenden Zahlen.\n\n\n\n\n\n\nUm diese Daten für die Alterspyramide einzurichten, schwenken wir die Daten mit der Option “lang”. pivot_longer() Funktion von dplyr. Der Grund dafür ist ggplot() generell “lange” Daten bevorzugt und apyramid verwendet ggplot().\n\n# pivot the aggregated data into long format\ndemo_agg_long &lt;- demo_agg %&gt;% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # cols to elongate\n    names_to = \"gender\",                # name for new col of categories\n    values_to = \"counts\") %&gt;%           # name for new col of counts\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # convert \"missing_gender\" to NA\n\n\n\n\n\n\n\nDann benutze die split_by = und count = Argumente von age_pyramid() um die jeweiligen Spalten in den Daten anzugeben:\n\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# column name for age category\n                      split_by = \"gender\",   # column name for gender\n                      count = \"counts\")      # column name for case counts\n\n\n\n\n\n\n\n\nBeachte in der obigen Abbildung, dass die Reihenfolge der Faktoren “m” und “f” unterschiedlich ist (Pyramide umgedreht). Um die Reihenfolge anzupassen, musst du das Geschlecht in den aggregierten Daten als Faktor neu definieren und die Ebenen wie gewünscht anordnen. Siehe die [Faktoren] Seite.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Demografische Pyramiden und Likert-Skalen</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.de.html#ggplot-demo_pyr_gg",
    "href": "new_pages/age_pyramid.de.html#ggplot-demo_pyr_gg",
    "title": "33  Demografische Pyramiden und Likert-Skalen",
    "section": "33.3 ggplot() {#demo_pyr_gg}",
    "text": "33.3 ggplot() {#demo_pyr_gg}\nverwenden ggplot() um deine Alterspyramide aufzubauen, bietet mehr Flexibilität, erfordert aber auch mehr Aufwand und Verständnis dafür, wie ggplot() funktioniert. Außerdem ist es einfacher, aus Versehen Fehler zu machen.\nZur Verwendung ggplot() um demografische Pyramiden zu erstellen, erstellst du zwei Balkendiagramme (eines für jedes Geschlecht), konvertierst die Werte in einem Diagramm ins Negative und drehst schließlich die x- und y-Achse, um die Balkendiagramme vertikal darzustellen, sodass sich ihre Basen in der Mitte des Diagramms treffen.\n\nVorbereitung\nDieser Ansatz verwendet die numerische Altersspalte, nicht die kategorische Spalte von age_cat5. Wir prüfen also, ob die Klasse dieser Spalte tatsächlich numerisch ist.\n\nclass(linelist$age)\n\n[1] \"numeric\"\n\n\nDu könntest dieselbe Logik anwenden, um eine Pyramide aus kategorialen Daten zu erstellen, indem du geom_col() anstelle von geom_histogram().\n\n\n\nKonstruieren des Plots\nZunächst musst du verstehen, dass du eine solche Pyramide mit Hilfe von ggplot() folgendermaßen vorgeht:\n\nInnerhalb der ggplot() erstellen zwei Histogramme unter Verwendung der numerischen Altersspalte. Erstelle eines für jeden der beiden Gruppierungswerte (in diesem Fall die Geschlechter männlich und weiblich). Dazu werden die Daten für jedes Histogramm in ihren jeweiligen geom_histogram() Befehlen angegeben, wobei die jeweiligen Filter auf linelist.\nEin Diagramm enthält positive Zählwerte, während die Zählwerte des anderen in negative Werte umgewandelt werden - so entsteht die “Pyramide” mit den 0 Wert in der Mitte des Diagramms. Die negativen Werte werden mit einer speziellen ggplot2 Term ..count.. und multipliziert mit -1.\nDer Befehl coord_flip() tauscht die X- und Y-Achse, wodurch die Graphen vertikal werden und die Pyramide entsteht.\nSchließlich müssen die Beschriftungen der Werte auf der Zählachse geändert werden, damit sie auf beiden Seiten der Pyramide als “positive” Werte erscheinen (obwohl die zugrunde liegenden Werte auf einer Seite negativ sind).\n\nA einfache Version dieser Methode, die geom_histogram() ist unten zu sehen:\n\n  # begin ggplot\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # female histogram\n  geom_histogram(data = linelist %&gt;% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # male histogram (values converted to negative)\n  geom_histogram(data = linelist %&gt;% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # flip the X and Y axes\n  coord_flip() +\n  \n  # adjust counts-axis scale\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n\n\n\n\n\n\n\n\nGEFAHR! Wenn die Grenzen deiner Zählachse zu niedrig eingestellt sind und ein Zählbalken sie überschreitet, verschwindet der Balken ganz oder wird künstlich verkürzt! Achte darauf, wenn du Daten analysierst, die routinemäßig aktualisiert werden. Verhindere dies, indem du die Grenzen der Zählachse automatisch an deine Daten anpasst (siehe unten).\nEs gibt viele Dinge, die du an dieser einfachen Version ändern/hinzufügen kannst, zum Beispiel:\n\nAutomatische Anpassung der Skala der Zählachse an deine Daten (um Fehler zu vermeiden, siehe Warnung unten)\nManuelles Festlegen von Farben und Beschriftungen\n\nZählungen in Prozente umrechnen\nUm Zählungen in Prozentwerte (der Gesamtzahl) umzuwandeln, musst du dies in deinen Daten tun, bevor du sie aufzeichnest. Nachfolgend werden die Zählungen nach Alter und Geschlecht ermittelt, dann ungroup() und dann mutate() um neue Prozentspalten zu erstellen. Wenn du die Prozente nach Geschlecht aufschlüsseln willst, überspringst du den Schritt “Gruppierung aufheben”.\n\n# create dataset with proportion of total\npyramid_data &lt;- linelist %&gt;%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %&gt;% \n  ungroup() %&gt;%                 # ungroup so percents are not by group\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,     # convert male to negative\n            TRUE          ~ NA_real_))    # NA val must by numeric as well\n\nWichtig ist, dass wir die Höchst- und Mindestwerte speichern, damit wir wissen, wo die Grenzen der Skala liegen sollen. Diese werden in der ggplot() Befehl unten verwendet.\n\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nmax_per\n\n[1] 10.9\n\nmin_per\n\n[1] -7.1\n\n\nZum Schluss machen wir die ggplot() auf die Prozentdaten. Wir geben an scale_y_continuous() um die vordefinierten Längen in jede Richtung (positiv und “negativ”) zu verlängern. Wir verwenden floor() und ceiling() um Dezimalzahlen in die entsprechende Richtung (abwärts oder aufwärts) für die Seite der Achse zu runden.\n\n# begin ggplot\n  ggplot()+  # default x-axis is age in years;\n\n  # case data graph\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # white around each bar\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n\n  # adjust the axes scales\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # sequence of values, by 2s\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # sequence of absolute values, by 2s, with \"%\"\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # label values (remember X and Y flipped now)\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # display themes\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )\n\n\n\n\n\n\n\n\n\n\n\nMit der Basislinie vergleichen\nMit der Flexibilität von ggplot() kannst du eine zweite Ebene mit Balken im Hintergrund einblenden, die die “wahre” Bevölkerungspyramide oder die “Basislinie” darstellen. So kannst du die beobachteten Werte mit der Basislinie vergleichen.\nImportieren und Anzeigen der Bevölkerungsdaten (siehe [Handbuch und Daten herunterladen] Seite):\n\n# import the population demographics data\npop &lt;- rio::import(\"country_demographics.csv\")\n\n\n\n\n\n\n\nZunächst einige Schritte zur Datenverwaltung:\nHier legen wir die Reihenfolge der Alterskategorien fest, die erscheinen sollen. Aufgrund einiger Macken in der Art, wie die ggplot() implementiert ist, ist es in diesem speziellen Szenario am einfachsten, diese als Zeichenvektor zu speichern und sie später in der Plotting-Funktion zu verwenden.\n\n# record correct age cat levels\nage_levels &lt;- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n\nKombiniere die Bevölkerungs- und Falldaten mit der Funktion dplyr Funktion bind_rows():\n\nStellen Sie zunächst sicher, dass sie die genau dasselbe Spaltennamen, Werte der Alterskategorien und des Geschlechts\nSorge dafür, dass sie die gleiche Datenstruktur haben: Spalten für Alterskategorie, Geschlecht, Anzahl und Prozent der Gesamtzahl\nVerbinde sie miteinander, eine über der anderen (bind_rows())\n\n\n# create/transform populaton data, with percent of total\n########################################################\npop_data &lt;- pop %&gt;% \n  pivot_longer(      # pivot gender columns longer\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %&gt;% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % of total\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent,               # if male, convert % to negative\n     TRUE          ~ NA_real_))\n\nÜberprüfe den geänderten Bevölkerungsdatensatz\n\n\n\n\n\n\nFühre nun das Gleiche für die Fallliste durch. Sie unterscheidet sich ein wenig, weil sie mit Fallzeilen und nicht mit Zählungen beginnt.\n\n# create case data by age/gender, with percent of total\n#######################################################\ncase_data &lt;- linelist %&gt;%\n  count(age_cat5, gender, name = \"counts\") %&gt;%  # counts by age-gender groups\n  ungroup() %&gt;% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculate % of total for age-gender groups\n    percent = case_when(                                     # convert % to negative if male\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent,\n      TRUE          ~ NA_real_))\n\nÜberprüfe den geänderten Falldatensatz\n\n\n\n\n\n\nJetzt sind die beiden Datenrahmen kombiniert, einer über dem anderen (sie haben die gleichen Spaltennamen). Wir können jeden der Datenrahmen “benennen” und die .id = Argument eine neue Spalte “data_source” erstellen, die angibt, aus welchem Datenrahmen die einzelnen Zeilen stammen. Diese Spalte können wir zum Filtern in der ggplot().\n\n# combine case and population data (same column names, age_cat values, and gender values)\npyramid_data &lt;- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n\nSpeichere die maximalen und minimalen Prozentwerte, die in der Plot-Funktion verwendet werden, um den Umfang des Plots zu definieren (und keine Balken abzuschneiden!)\n\n# Define extent of percent axis, used for plot limits\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nJetzt wird die Handlung mit ggplot():\n\nEin Balkendiagramm der Bevölkerungsdaten (breitere, transparentere Balken)\nEin Balkendiagramm der Falldaten (kleine, festere Balken)\n\n\n# begin ggplot\n##############\nggplot()+  # default x-axis is age in years;\n\n  # population data graph\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # black color around bars\n    alpha = 0.2,                                    # more transparent\n    width = 1)+                                     # full width\n  \n  # case data graph\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # age categories as original X axis\n      y = percent,                                # % as original Y-axis\n      fill = gender),                             # fill of bars by gender\n    colour = \"black\",                               # black color around bars\n    alpha = 1,                                      # not transparent \n    width = 0.3)+                                   # half width\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n  # manually ensure that age-axis is ordered correctly\n  scale_x_discrete(limits = age_levels)+     # defined in chunk above\n  \n  # set percent-axis \n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # min and max defined above\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # from min% to max% by 2 \n    labels = paste0(                                                       # for the labels, paste together... \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # assign colors to values in the data\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # change labels that appear in legend, note order\n  ) +\n\n  # plot labels, titles, caption    \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # optional aesthetic themes\n  theme(\n    legend.position = \"bottom\",                             # move legend to bottom\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Demografische Pyramiden und Likert-Skalen</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.de.html#likert-skala",
    "href": "new_pages/age_pyramid.de.html#likert-skala",
    "title": "33  Demografische Pyramiden und Likert-Skalen",
    "section": "33.4 Likert-Skala",
    "text": "33.4 Likert-Skala\nDie Techniken, die zur Erstellung einer Bevölkerungspyramide mit ggplot() verwendet wird, kann auch für die Darstellung von Umfragedaten auf der Likert-Skala verwendet werden.\nImportiere die Daten (siehe [Handbuch und Daten herunterladen] Seite, falls gewünscht).\n\n# import the likert survey response data\nlikert_data &lt;- rio::import(\"likert_data.csv\")\n\nBeginne mit Daten, die wie folgt aussehen, mit einer kategorialen Klassifizierung jedes Befragten (status) und deren Antworten auf 8 Fragen auf einer 4-stufigen Likert-Skala (“Sehr schlecht”, “Schlecht”, “Gut”, “Sehr gut”).\n\n\n\n\n\n\nZunächst einige Schritte zur Datenverwaltung:\n\nPivotiere die Daten länger\nNeue Spalte erstellen direction je nachdem, ob die Antwort generell “positiv” oder “negativ” war\nLege die Reihenfolge der Faktorebenen für die status Spalte und die Response Spalte\nSpeichere den maximalen Zählwert, damit die Grenzen der Darstellung angemessen sind\n\n\nmelted &lt;- likert_data %&gt;% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %&gt;% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # must reverse 'Very Poor' and 'Poor' for ordering to work\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# get largest value for scale limits\nmelted_max &lt;- melted %&gt;% \n  count(status, Question) %&gt;% # get counts\n  pull(n) %&gt;%                 # column 'n'\n  max(na.rm=T)                # get max\n\nErstelle nun das Diagramm. Wie bei den Alterspyramiden oben erstellen wir zwei Balkendiagramme und invertieren die Werte eines von ihnen ins Negative.\nWir verwenden geom_bar() weil es sich bei unseren Daten um eine Zeile pro Beobachtung und nicht um aggregierte Zahlen handelt. Wir verwenden die spezielle ggplot2 Term ..count.. in einem der Balkendiagramme, um die Werte negativ zu invertieren (*-1), und wir setzen position = \"stack\" damit die Werte übereinander gestapelt werden.\n\n# make plot\nggplot()+\n     \n  # bar graph of the \"negative\" responses \n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # counts inverted to negative\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # bar graph of the \"positive responses\n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # flip the X and Y axes\n     coord_flip()+\n  \n     # Black vertical line at 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # convert labels to all positive numbers\n    scale_y_continuous(\n      \n      # limits of the x-axis scale\n      limits = c(-ceiling(melted_max/10)*11,    # seq from neg to pos by 10, edges rounded outward to nearest 5\n                 ceiling(melted_max/10)*10),   \n      \n      # values of the x-axis scale\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # labels of the x-axis scale\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # color scales manually assigned \n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # assigns colors\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # orders the legend\n     \n    \n     \n    # facet the entire plot so each question is a sub-plot\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # labels, titles, caption\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # display adjustments \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # facet sub-titles\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # black box around each facet",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Demografische Pyramiden und Likert-Skalen</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.de.html#ressourcen",
    "href": "new_pages/age_pyramid.de.html#ressourcen",
    "title": "33  Demografische Pyramiden und Likert-Skalen",
    "section": "33.5 Ressourcen",
    "text": "33.5 Ressourcen\nApyramide Dokumentation",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Demografische Pyramiden und Likert-Skalen</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.de.html",
    "href": "new_pages/heatmaps.de.html",
    "title": "34  Wärmebilanzen",
    "section": "",
    "text": "34.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Wärmebilanzen</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.de.html#vorbereitung",
    "href": "new_pages/heatmaps.de.html#vorbereitung",
    "title": "34  Wärmebilanzen",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  tidyverse,       # data manipulation and visualization\n  rio,             # importing data \n  lubridate        # working with dates\n  )\n\nDatensätze\nDiese Seite verwendet die Fallliste eines simulierten Ausbruchs für den Abschnitt Übertragungsmatrix und einen separaten Datensatz mit den täglichen Malariafallzahlen nach Einrichtungen für den Abschnitt zur Verfolgung von Kennzahlen. Sie werden in den einzelnen Abschnitten geladen und bereinigt.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Wärmebilanzen</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.de.html#übertragungsmatrix",
    "href": "new_pages/heatmaps.de.html#übertragungsmatrix",
    "title": "34  Wärmebilanzen",
    "section": "34.2 Übertragungsmatrix",
    "text": "34.2 Übertragungsmatrix\nWärmekacheln können nützlich sein, um Matrizen zu visualisieren. Ein Beispiel ist die Anzeige von “Wer hat wen infiziert” bei einem Ausbruch. Dies setzt voraus, dass du Informationen über Übertragungsereignisse hast.\nBeachte, dass die [Kontaktverfolgung] Seite ein weiteres Beispiel für die Erstellung einer Kontaktmatrix mit Wärmekacheln enthält, bei dem ein anderer (vielleicht einfacher) Datensatz verwendet wird, bei dem das Alter der Fälle und ihre Quellen sauber in derselben Zeile des Datenrahmens angeordnet sind. Dieselben Daten werden verwendet, um eineDichteKarte in den [ggplot-Tipps] Seite. Das folgende Beispiel geht von einer Fallliste aus und erfordert daher eine erhebliche Datenmanipulation, bevor ein plottfähiger Datenrahmen entsteht. Es gibt also viele Szenarien, aus denen du wählen kannst…\nWir beginnen mit der Fall-Liste einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen (als .rds-Datei). Importiere deine Daten mit der import() Funktion aus der rioPaket (sie akzeptiert viele Dateitypen wie .xlsx, .rds, .csv - siehe die [Import und Export] Seite für Details).\nZur Veranschaulichung werden unten die ersten 50 Zeilen der Linienliste angezeigt:\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nIn dieser Zeilenliste:\n\nEs gibt eine Zeile pro Fall, gekennzeichnet durch case_id\nEs gibt eine weitere Spalte infector die die case_id der Ansteckers der auch ein Fall in der Linienliste ist\n\n\n\n\n\n\n\n\nDatenaufbereitung\nZielsetzung Wir müssen einen “langen” Datenrahmen erstellen, der eine Zeile pro möglichem Übertragungsweg von Alter zu Alter enthält, mit einer numerischen Spalte, die den Anteil dieser Zeile an allen beobachteten Übertragungsereignissen in der Zeilenliste enthält.\nUm dies zu erreichen, sind mehrere Schritte der Datenmanipulation erforderlich:\n\nFälle erstellen Datenrahmen\nZu Beginn erstellen wir einen Datenrahmen mit den Fällen, ihrem Alter und ihren Infektoren - wir nennen den Datenrahmen case_ages. Die ersten 50 Zeilen werden unten angezeigt.\n\ncase_ages &lt;- linelist %&gt;% \n  select(case_id, infector, age_cat) %&gt;% \n  rename(\"case_age_cat\" = \"age_cat\")\n\n\n\n\n\n\n\n\n\nInfektoren-Datenrahmen erstellen\nAls Nächstes erstellen wir einen Datenrahmen mit den Infektoren - im Moment besteht er aus einer einzigen Spalte. Das sind die IDs der Infektoren aus der Linienliste. Nicht jeder Fall hat einen bekannten Infektor, also entfernen wir die fehlenden Werte. Die ersten 50 Zeilen werden unten angezeigt.\n\ninfectors &lt;- linelist %&gt;% \n  select(infector) %&gt;% \n  drop_na(infector)\n\n\n\n\n\n\n\nAls Nächstes verwenden wir Joins, um das Alter der Infizierten zu ermitteln. Das ist nicht einfach, denn in der linelist die Altersangaben der Infizierten nicht als solche aufgeführt sind. Wir erreichen dieses Ergebnis, indem wir den Fall linelist mit den Ansteckern verbinden. Wir beginnen mit den Ansteckern, und left_join() (fügen) den Fall hinzu linelist so, dass die infector id-Spalte auf der linken Seite des “Baseline”-Datenrahmens mit dem case_id Spalte auf der rechten Seite linelist Datenrahmens.\nSo werden die Daten aus dem Falldatensatz des Ansteckers in der Zeilenliste (einschließlich des Alters) zur Ansteckerzeile hinzugefügt. Die ersten 50 Zeilen werden unten angezeigt.\n\ninfector_ages &lt;- infectors %&gt;%             # begin with infectors\n  left_join(                               # add the linelist data to each infector  \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %&gt;%    # match infector to their information as a case\n  select(infector, age_cat) %&gt;%            # keep only columns of interest\n  rename(\"infector_age_cat\" = \"age_cat\")   # rename for clarity\n\n\n\n\n\n\n\nDann kombinieren wir die Fälle und ihr Alter mit den Ansteckern und ihrem Alter. Jeder dieser Datenrahmen hat die Spalte infector und wird daher für die Verknüpfung verwendet. Die ersten Zeilen werden unten angezeigt:\n\nages_complete &lt;- case_ages %&gt;%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %&gt;%        # each has the column infector\n  drop_na()                     # drop rows with any missing data\n\nWarning in left_join(., infector_ages, by = \"infector\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 6 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\nUnten eine einfache Kreuztabellierung der Zählungen zwischen den Altersgruppen der Fälle und der Infizierten. Zur besseren Übersichtlichkeit wurden Beschriftungen hinzugefügt.\n\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)\n\n       infectors\ncases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n  0-4   105 156   105   114   143   117    13   0\n  5-9   102 132   110   102   117    96    12   5\n  10-14 104 109    91    79   120    80    12   4\n  15-19  85 105    82    39    75    69     7   5\n  20-29 101 127   109    80   143   107    22   4\n  30-49  72  97    56    54    98    61     4   5\n  50-69   5   6    15     9     7     5     2   0\n  70+     1   0     2     0     0     0     0   0\n\n\nWir können diese Tabelle in einen Datenrahmen umwandeln mit data.frame() von Basis R, das sie auch automatisch in das “lange” Format konvertiert, das für die ggplot(). Die ersten Zeilen werden unten angezeigt.\n\nlong_counts &lt;- data.frame(table(\n    cases     = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\n\n\n\n\n\n\n\nJetzt machen wir das Gleiche, aber wenden prop.table() von Basis R in die Tabelle ein, sodass wir anstelle von Zählungen Anteile an der Gesamtsumme erhalten. Die ersten 50 Zeilen werden unten angezeigt.\n\nlong_prop &lt;- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))\n\n\n\n\n\n\n\n\n\n\nHeatplot erstellen\nJetzt können wir endlich den Heatplot erstellen mit ggplot2 Paket erstellen, indem wir die geom_tile()Funktion. Siehe die [ggplot-Tipps] Seite, um mehr über Farb-/Füllskalen zu erfahren, insbesondere über diescale_fill_gradient() Funktion.\n\nIn der Ästhetik aes() von geom_tile() setze die x und y als Alter des Falles und Alter des Infizierten\nAuch in aes() setzen Sie das Argument fill = auf die Freq Spalte - das ist der Wert, der in eine Kachelfarbe umgewandelt wird\nLege eine Skalenfarbe mit scale_fill_gradient() - kannst du die hohen/niedrigen Farben festlegen\n\nBeachte, dass scale_color_gradient() anders ist! In diesem Fall willst du die Füllung\n\nDa die Farbe über “Füllen” gemacht wird, kannst du die fill = Argument in labs() verwenden, um den Titel der Legende zu ändern\n\n\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = cases,         # x-axis is case age\n      y = infectors,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  labs(                         # labels\n    x = \"Case age\",\n    y = \"Infector age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Wärmebilanzen</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.de.html#berichterstattung-über-metriken-im-laufe-der-zeit",
    "href": "new_pages/heatmaps.de.html#berichterstattung-über-metriken-im-laufe-der-zeit",
    "title": "34  Wärmebilanzen",
    "section": "34.3 Berichterstattung über Metriken im Laufe der Zeit",
    "text": "34.3 Berichterstattung über Metriken im Laufe der Zeit\nIm öffentlichen Gesundheitswesen geht es oft darum, Trends im Zeitverlauf für viele Einheiten (Einrichtungen, Gerichtsbarkeiten usw.) zu bewerten. Eine Möglichkeit, solche Trends im Laufe der Zeit zu visualisieren, ist ein Wärmediagramm, bei dem die x-Achse die Zeit und die y-Achse die vielen Einrichtungen darstellt.\n\nDatenaufbereitung\nZunächst importieren wir einen Datensatz mit täglichen Malariameldungen aus vielen Einrichtungen. Die Berichte enthalten ein Datum, eine Provinz, einen Bezirk und die Anzahl der Malariafälle. Siehe die Seite zum [Handbuch und Daten herunterladen] findest du Informationen darüber, wie du diese Daten herunterladen kannst. Im Folgenden findest du die ersten 30 Zeilen:\n\nfacility_count_data &lt;- import(\"malaria_facility_count_data.rds\")\n\n\n\n\n\n\n\n\nAggregieren und zusammenfassen\nDas Ziel in diesem Beispiel ist die Umwandlung der täglichen Einrichtung gesamt Malariafallzahlen (siehe vorherige Registerkarte) in wöchentlich zusammenfassende Statistiken über die Meldeleistung der Einrichtungen - in diesem Fall der Anteil der Tage pro Woche, an denen die Einrichtung Daten gemeldet hat. In diesem Beispiel zeigen wir nur die Daten für Bezirk Frühling.\nUm dies zu erreichen, werden wir die folgenden Schritte zur Datenverwaltung durchführen:\n\nFiltere die Daten nach Bedarf (nach Ort, Datum)\nErstelle eine Wochenspalte mit floor_date() aus dem Paket lubridate\n\n\nDiese Funktion gibt das Startdatum der Woche eines bestimmten Datums zurück, wobei ein bestimmtes Startdatum jeder Woche (z.B. “montags”) verwendet wird.\n\n\nDie Daten werden nach den Spalten “Ort” und “Woche” gruppiert, um die Analyseeinheiten “Einrichtung-Woche” zu bilden\nDie Funktion summarise() erstellt neue Spalten, um die zusammenfassenden Statistiken für jede Betriebswochengruppe wiederzugeben:\n\n\nAnzahl der Tage pro Woche (7 - ein statischer Wert)\nAnzahl der von der Einrichtung erhaltenen Berichte - Woche (kann mehr als 7 sein!)\nSumme der von der Einrichtung gemeldeten Malariafälle (nur aus Interesse)\nAnzahl der einzigartiger Tage in der Betriebswoche, für die Daten gemeldet wurden\nProzentsatz der 7 Tage pro Betriebswoche, für die Daten gemeldet wurden\n\n\nDer Datenrahmen wird verbunden mit right_join() zu einer umfassenden Liste aller möglichen Betriebswochen-Kombinationen verbunden, um den Datensatz zu vervollständigen. Die Matrix mit allen möglichen Kombinationen wird erstellt, indem man expand() auf die beiden Spalten des Datenrahmens anwendet, wie sie sich zu diesem Zeitpunkt in der Rohrkette befinden (dargestellt durch .). Da eine right_join() verwendet wird, werden alle Zeilen im expand() Datenrahmen beibehalten und zu agg_weeks wenn nötig. Diese neuen Zeilen erscheinen mit NA (fehlenden) zusammengefassten Werten.\n\nIm Folgenden demonstrieren wir Schritt für Schritt:\n\n# Create weekly summary dataset\nagg_weeks &lt;- facility_count_data %&gt;% \n  \n  # filter the data as appropriate\n  filter(\n    District == \"Spring\",\n    data_date &lt; as.Date(\"2020-08-01\")) \n\nJetzt hat der Datensatz nrow(agg_weeks) Zeilen, während er vorher nrow(facility_count_data).\nAls nächstes erstellen wir eine week Spalte, die das Startdatum der Woche für jeden Datensatz wiedergibt. Dies geschieht mit der lubridate Paket und der Funktion floor_date() die auf “Woche” eingestellt ist und dafür sorgt, dass die Wochen montags beginnen (Tag 1 der Woche - sonntags wäre es 7). Die oberen Zeilen werden unten angezeigt.\n\nagg_weeks &lt;- agg_weeks %&gt;% \n  # Create week column from data_date\n  mutate(\n    week = lubridate::floor_date(                     # create new column of weeks\n      data_date,                                      # date column\n      unit = \"week\",                                  # give start of the week\n      week_start = 1))                                # weeks to start on Mondays \n\nDie neue Wochenspalte ist ganz rechts im Datenrahmen zu sehen\n\n\n\n\n\n\nJetzt gruppieren wir die Daten in Betriebswochen und fassen sie zusammen, um Statistiken pro Betriebswoche zu erstellen. Siehe die Seite über [Deskriptive Tabellen] für Tipps. Die Gruppierung selbst ändert nicht den Datenrahmen, aber sie hat Auswirkungen darauf, wie die nachfolgenden zusammenfassenden Statistiken berechnet werden.\nDie obersten Zeilen sind unten abgebildet. Beachte, dass sich die Spalten komplett verändert haben, um die gewünschten zusammenfassenden Statistiken wiederzugeben. Jede Zeile steht für eine Betriebswoche.\n\nagg_weeks &lt;- agg_weeks %&gt;%   \n\n  # Group into facility-weeks\n  group_by(location_name, week) %&gt;%\n  \n  # Create summary statistics columns on the grouped data\n  summarize(\n    n_days          = 7,                                          # 7 days per week           \n    n_reports       = dplyr::n(),                                 # number of reports received per week (could be &gt;7)\n    malaria_tot     = sum(malaria_tot, na.rm = T),                # total malaria cases reported\n    n_days_reported = length(unique(data_date)),                  # number of unique days reporting per week\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;%  # percent of days reporting\n\n  ungroup(location_name, week)                                    # ungroup so expand() works in next step\n\n\n\n\n\n\n\nZum Schluss führen wir den folgenden Befehl aus, um sicherzustellen, dass ALLE möglichen Betriebswochen in den Daten enthalten sind, auch wenn sie vorher fehlten.\nWir verwenden eine right_join() auf sich selbst (der Datensatz wird durch “.” dargestellt), wurde aber erweitert, um alle möglichen Kombinationen der Spalten einzuschließen week und location_name. Siehe Dokumentation über die expand()Funktion auf der Seite über [Pivotieren]. Bevor dieser Code ausgeführt wird, enthält der Datensatznrow(agg_weeks) Zeilen.\n\n# Create data frame of every possible facility-week\nexpanded_weeks &lt;- agg_weeks %&gt;% \n  tidyr::expand(location_name, week)  # expand data frame to include all possible facility-week combinations\n\nHier ist expanded_weeks, mit 180 Zeilen:\n\n\n\n\n\n\nBevor du diesen Code ausführst, agg_weeks enthält 107 Zeilen.\n\n# Use a right-join with the expanded facility-week list to fill-in the missing gaps in the data\nagg_weeks &lt;- agg_weeks %&gt;%      \n  right_join(expanded_weeks) %&gt;%                            # Ensure every possible facility-week combination appears in the data\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # convert missing values to 0                           \n\nJoining with `by = join_by(location_name, week)`\n\n\nNachdem du diesen Code ausgeführt hast, agg_weeks enthält nrow(agg_weeks) Zeilen.\n\n\n\n\nHeatplot erstellen\nDie ggplot() wird mit geom_tile() aus dem ggplot2 Paket:\n\nDie Wochen auf der x-Achse werden in Daten umgewandelt, so dass die Verwendung von scale_x_date()\nlocation_name Auf der y-Achse werden alle Namen der Einrichtungen angezeigt.\nDie fill ist p_days_reported die Leistung für diese Anlage-Woche (numerisch)\nscale_fill_gradient() wird für die numerische Füllung verwendet, wobei die Farben für hoch, niedrig und NA\nscale_x_date() wird auf der x-Achse verwendet, um die Beschriftungen alle 2 Wochen und ihr Format festzulegen\nAnzeigethemen und Beschriftungen können nach Bedarf angepasst werden\n\n\n\n\nBasic\nIm Folgenden wird ein einfacher Wärmeplan mit den Standardfarben, -skalen usw. erstellt. Wie oben erklärt, können Sie innerhalb der aes() für geom_tile() eine Spalte für die x-Achse und eine Spalte für die y-Achse angeben, und eine Spalte für die fill =. Die Füllung ist der numerische Wert, der als Kachelfarbe dargestellt wird.\n\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))\n\n\n\n\n\n\n\n\n\n\nGereinigte Fläche\nWir können diesen Plot besser aussehen lassen, indem wir zusätzliche ggplot2Funktionen hinzufügen, wie unten gezeigt. Siehe die Seite über [ggplot-Tipps] für Details.\n\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\n\n\n\n\n\n\n\n\n\n\nGeordnete y-Achse\nDerzeit sind die Einrichtungen “alphanumerisch” von unten nach oben geordnet. Wenn du die Reihenfolge der Einrichtungen auf der y-Achse anpassen möchtest, wandle sie in Klassenfaktoren um und gib die Reihenfolge an. Siehe die Seite über [Faktoren] für Tipps.\nDa es viele Einrichtungen gibt und wir sie nicht alle aufschreiben wollen, versuchen wir es mit einem anderen Ansatz: Wir ordnen die Einrichtungen in einem Datenrahmen und verwenden die daraus resultierende Spalte mit den Namen als Reihenfolge der Faktoren. Unten wird die Spalte location_name in einen Faktor umgewandelt und die Reihenfolge der Ebenen anhand der Gesamtzahl der von der Einrichtung über die gesamte Zeitspanne eingereichten Berichtstage festgelegt.\nZu diesem Zweck erstellen wir einen Datenrahmen, der die Gesamtzahl der Meldungen pro Betrieb in aufsteigender Reihenfolge darstellt. Anhand dieses Vektors können wir die Faktorstufen in der Grafik anordnen.\n\nfacility_order &lt;- agg_weeks %&gt;% \n  group_by(location_name) %&gt;% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %&gt;% \n  arrange(tot_reports) # ascending order\n\nSiehe den Datenrahmen unten:\n\n\n\n\n\n\nVerwenden Sie nun eine Spalte aus dem obigen Datenrahmen (facility_order$location_name), um die Reihenfolge der Faktorstufen von location_name im Datenrahmen agg_weeks:\n\n# load package \npacman::p_load(forcats)\n\n# create factor and define levels manually\nagg_weeks &lt;- agg_weeks %&gt;% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\n\nUnd jetzt werden die Daten neu gezeichnet, wobei der Ortsname ein geordneter Faktor ist:\n\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\n\n\n\n\n\n\n\n\n\n\nWerte anzeigen\nDu kannst eine geom_text() Ebene über die Kacheln legen, um die tatsächlichen Zahlen der einzelnen Kacheln anzuzeigen. Sei dir bewusst, dass dies nicht schön aussieht, wenn du viele kleine Kacheln hast!\nDer folgende Code wurde hinzugefügt: geom_text(aes(label = p_days_reported)). Dies fügt Text zu jeder Kachel hinzu. Der angezeigte Text ist der Wert, der dem Argument label = zugewiesen wurde, der in diesem Fall auf die gleiche numerische Spalte gesetzt wurde p_days_reported gesetzt wurde, die auch zum Erstellen des Farbverlaufs verwendet wird.\n\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  # text\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+      # add text on top of tile\n  \n  # fill scale\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                    # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Wärmebilanzen</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.de.html#ressourcen",
    "href": "new_pages/heatmaps.de.html#ressourcen",
    "title": "34  Wärmebilanzen",
    "section": "34.4 Ressourcen",
    "text": "34.4 Ressourcen\nscale_fill_gradient()\nR-Grafik-Galerie - Heatmap",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Wärmebilanzen</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.de.html",
    "href": "new_pages/diagrams.de.html",
    "title": "35  Diagramme und Tabellen",
    "section": "",
    "text": "35.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramme und Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.de.html#vorbereitung",
    "href": "new_pages/diagrams.de.html#vorbereitung",
    "title": "35  Diagramme und Tabellen",
    "section": "",
    "text": "Pakete laden\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  DiagrammeR,     # for flow diagrams\n  networkD3,      # For alluvial/Sankey diagrams\n  tidyverse)      # data management and visualization\n\n\n\nDaten importieren\nFür die meisten Inhalte auf dieser Seite wird kein Datensatz benötigt. Im Abschnitt über das Sankey-Diagramm werden wir jedoch die Fallliste einer simulierten Ebola-Epidemie verwenden. Wenn du bei diesem Teil mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere die Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramme und Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.de.html#flussdiagramme",
    "href": "new_pages/diagrams.de.html#flussdiagramme",
    "title": "35  Diagramme und Tabellen",
    "section": "35.2 Flussdiagramme",
    "text": "35.2 Flussdiagramme\nMan kann das R-Paket verwenden DiagrammeR verwenden, um Diagramme/Flussdiagramme zu erstellen. Sie können statisch sein oder sich dynamisch an Änderungen in einem Datensatz anpassen.\nWerkzeuge\nDie Funktion grViz() wird verwendet, um ein “Graphviz”-Diagramm zu erstellen. Diese Funktion akzeptiert eine Zeichenketteneingabe mit Anweisungen für die Erstellung des Diagramms enthält. Innerhalb dieser Zeichenkette werden die Anweisungen in einer anderen Sprache geschrieben, die DOT - Es ist ganz einfach, die Grundlagen zu lernen.\nGrundlegende Struktur\n\nÖffne die Anleitung grViz(\"\nGib die Richtung und den Namen des Diagramms an und öffne die Klammern, z. B. digraph my_flow_chart {\nGraph-Anweisung (Layout, Rangrichtung)\nKnoten-Anweisungen (Knoten erstellen)\nEdges-Anweisungen (geben Verbindungen zwischen Knoten)\nSchließen Sie die Anweisungen }\")\n\n\nEinfache Beispiele\nIm Folgenden sind zwei einfache Beispiele aufgeführt\nEin sehr minimales Beispiel:\n\n# A minimal plot\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -&gt; b -&gt; c\n}\")\n\n\n\n\n\nEin Beispiel, das vielleicht ein bisschen mehr Bezug zum öffentlichen Gesundheitswesen hat:\n\ngrViz(\"                           # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  # nodes\n  #######\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]               # width of circles\n  \n  Primary                         # names of nodes\n  Secondary\n  Tertiary\n\n  # edges\n  #######\n  Primary   -&gt; Secondary [label = ' case transfer']\n  Secondary -&gt; Tertiary [label = ' case transfer']\n}\n\")\n\n\n\n\n\n\n\nSyntax\nGrundlegende Syntax\nKnotennamen oder Kantenanweisungen können durch Leerzeichen, Semikolons oder Zeilenumbrüche getrennt werden.\nRangrichtung\nEin Plot kann so ausgerichtet werden, dass er sich von links nach rechts bewegt, indem du die rankdir Argument in der Diagramm-Anweisung angepasst wird. Die Standardeinstellung ist TB (von oben nach unten), aber es kann auch LR (von links nach rechts), RL oder BT sein.\nKnotennamen\nKnotennamen können aus einzelnen Wörtern bestehen, wie in dem einfachen Beispiel oben. Wenn du Namen mit mehreren Wörtern oder Sonderzeichen (z. B. Klammern, Bindestriche) verwenden willst, setze den Knotennamen in einfache Anführungszeichen (’ ’). Es kann einfacher sein, einen kurzen Knotennamen zu haben und einen Bezeichnungzu vergeben, wie unten in Klammern gezeigt []. Wenn du einen Zeilenumbruch im Namen des Knotens haben möchtest, musst du dies über ein Label tun - verwende\\n in der Knotenbezeichnung in einfachen Anführungszeichen, wie unten gezeigt.\nUntergruppen\nInnerhalb von Randanweisungen können Untergruppen auf beiden Seiten des Randes mit geschweiften Klammern ({ }). Die Kante gilt dann für alle Knoten in der Klammer - das ist eine Kurzform.\nLayouts\n\nPunkt (setzen rankdir entweder auf TB, LR, RL, BT, )\nschön\ntwopi\ncirco\n\nKnoten - bearbeitbare Attribute\n\nlabel (Text, in einfachen Anführungszeichen, wenn es sich um mehrere Wörter handelt)\nfillcolor (viele mögliche Farben)\nfontcolor\nalpha (Transparenz 0-1)\nshape (Ellipse, Oval, Raute, Ei, Klartext, Punkt, Quadrat, Dreieck)\nstyle\nsides\nperipheries\nfixedsize (h x b)\nheight\nwidth\ndistortion\npenwidth (Breite des Formrandes)\nx (Verschiebung links/rechts)\ny (Verschiebung nach oben/unten)\nfontname\nfontsize\nicon\n\nKanten - bearbeitbare Attribute\n\narrowsize\narrowhead (normal, Kasten, Krähe, Kurve, Raute, Punkt, inv, keine, T-Stück, V-Stück)\narrowtail\ndir (Richtung, )\nstyle (gestrichelt, …)\ncolor\nalpha\nheadport (Text vor der Pfeilspitze)\ntailport (Text hinter der Pfeilspitze)\nfontname\nfontsize\nfontcolor\npenwidth (Breite des Pfeils)\nminlen (Mindestlänge)\n\nFarbnamen: Hexadezimalwerte oder “X11”-Farbnamen, siehe hier für X11-Details\n\n\nKomplexe Beispiele\nDas folgende Beispiel erweitert das surveillance_diagram und fügt komplexe Knotennamen, gruppierte Kanten, Farben und Styling hinzu\nDiagrammeR::grViz(\"               # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            # layout top-to-bottom\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary   [label = 'Primary\\nFacility'] \n  Secondary [label = 'Secondary\\nFacility'] \n  Tertiary  [label = 'Tertiary\\nFacility'] \n  SC        [label = 'Surveillance\\nCoordination',\n             fontcolor = darkgreen] \n  \n  # edges\n  #######\n  Primary   -&gt; Secondary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  Secondary -&gt; Tertiary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  \n  # grouped edge\n  {Primary Secondary Tertiary} -&gt; SC [label = 'case reporting',\n                                      fontcolor = darkgreen,\n                                      color = darkgreen,\n                                      style = dashed]\n}\n\")\n\n\n\n\n\n\nUntergraphen-Cluster\nUm Knoten in Box-Cluster zu gruppieren, musst du sie innerhalb desselben benannten Teilgraphen platzieren (subgraph name {}). Um jeden Untergraphen innerhalb eines Begrenzungsrahmens zu identifizieren, beginnst du den Namen des Untergraphen mit “cluster”, wie in den 4 Kästchen unten gezeigt.\nDiagrammeR::grViz(\"             # All instructions are within a large character string\ndigraph surveillance_diagram {  # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,                  # shape = circle\n       fixedsize = true\n       width = 1.3]                      # width of circles\n  \n  subgraph cluster_passive {\n    Primary   [label = 'Primary\\nFacility'] \n    Secondary [label = 'Secondary\\nFacility'] \n    Tertiary  [label = 'Tertiary\\nFacility'] \n    SC        [label = 'Surveillance\\nCoordination',\n               fontcolor = darkgreen] \n  }\n  \n  # nodes (boxes)\n  ###############\n  node [shape = box,                     # node shape\n        fontname = Helvetica]            # text font in node\n  \n  subgraph cluster_active {\n    Active [label = 'Active\\nSurveillance'] \n    HCF_active [label = 'HCF\\nActive Search']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'Event-Based\\nSurveillance (EBS)'] \n    'Social Media'\n    Radio\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = 'Community-Based\\nSurveillance (CBS)']\n    RECOs\n  }\n\n  \n  # edges\n  #######\n  {Primary Secondary Tertiary} -&gt; SC [label = 'case reporting']\n\n  Primary   -&gt; Secondary [label = 'case transfer',\n                          fontcolor = red]\n  Secondary -&gt; Tertiary [label = 'case transfer',\n                          fontcolor = red]\n  \n  HCF_active -&gt; Active\n  \n  {'Social Media' Radio} -&gt; EBS\n  \n  RECOs -&gt; CBS\n}\n\")\n\n\n\n\n\n\n\nKnotenformen\nDas folgende Beispiel stammt aus diesem Tutorial zeigt die angewandten Knotenformen und eine Kurzform für serielle Kantenverbindungen\n\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n# define the global styles of the nodes. We can override these in box if we wish\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataset 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataset 2', shape = folder, fillcolor = Beige]\nprocess [label =  'Process \\n Data']\nstatistical [label = 'Statistical \\n Analysis']\nresults [label= 'Results']\n\n# edge definitions with the node IDs\n{data1 data2}  -&gt; process -&gt; statistical -&gt; results\n}\")\n\n\n\n\n\n\n\nAusgänge\nWie man Ausgaben behandelt und speichert\n\nDie Ausgaben werden im RStudio-Viewer-Fenster angezeigt, standardmäßig unten rechts neben Dateien, Plots, Paketen und Hilfe.\nZum Exportieren kannst du im Ansichtsfenster “Als Bild speichern” oder “In die Zwischenablage kopieren” wählen. Die Grafik wird an die angegebene Größe angepasst.\n\n\n\nParametrisierte Zahlen\nHier ist ein Zitat aus diesem Tutorial https://mikeyharper.uk/flowcharts-in-r-using-diagrammer/\n” Parametrisierte Zahlen: Ein großer Vorteil beim Entwerfen von Zahlen in R ist, dass wir die Zahlen direkt mit unserer Analyse verbinden können, indem wir R-Werte direkt in unsere Flussdiagramme einlesen. Angenommen, du hast einen Filterprozess erstellt, bei dem nach jeder Stufe eines Prozesses Werte entfernt werden, dann kannst du in einer Abbildung die Anzahl der Werte anzeigen lassen, die nach jeder Stufe deines Prozesses noch im Datensatz vorhanden sind. Dazu kannst du das @@ X-Symbol direkt in der Abbildung verwenden und dann in der Fußzeile des Diagramms darauf verweisen, indem du [X]:, wobei X ein eindeutiger numerischer Index ist.”\nWenn du dich für die Parametrisierung interessierst, empfehlen wir dir, dieses Tutorial zu lesen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramme und Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.de.html#alluvialsankey-diagramme",
    "href": "new_pages/diagrams.de.html#alluvialsankey-diagramme",
    "title": "35  Diagramme und Tabellen",
    "section": "35.3 Alluvial/Sankey Diagramme",
    "text": "35.3 Alluvial/Sankey Diagramme\n\nPakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\nWir laden die NetzwerkD3 Paket, um das Diagramm zu erstellen, und auch tidyverse für die Datenaufbereitung.\n\npacman::p_load(\n  networkD3,\n  tidyverse)\n\n\n\nPlotten aus dem Datensatz\nPlotten der Verbindungen in einem Datensatz. Nachfolgend demonstrieren wir die Verwendung dieses Pakets an dem Fall linelist. Hier ist eine Online-Tutorial.\nWir beginnen damit, die Fallzahlen für jede einzelne Kombination aus Alterskategorie und Krankenhaus zu ermitteln. Werte mit fehlender Alterskategorie haben wir aus Gründen der Übersichtlichkeit entfernt. Außerdem kennzeichnen wir die hospital und age_cat Spalten als source und target bezeichnen. Dies sind die beiden Seiten des Anschwemmungsdiagramms.\n\n# counts by hospital and age category\nlinks &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = hospital,\n         target = age_cat)\n\nDer Datensatz sieht nun wie folgt aus:\n\n\n\n\n\n\nJetzt erstellen wir einen Datenrahmen mit allen Diagrammknoten, unter der Spalte name. Dieser besteht aus allen Werten für hospital und age_cat. Beachte, dass wir sicherstellen, dass sie alle Klassenzeichen sind, bevor wir sie kombinieren. und passe die ID-Spalten so an, dass sie Zahlen statt Bezeichnungen sind:\n\n# The unique node names\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\nnodes  # print\n\n                                   name\n1                      Central Hospital\n2                     Military Hospital\n3                               Missing\n4                                 Other\n5                         Port Hospital\n6  St. Mark's Maternity Hospital (SMMH)\n7                                   0-4\n8                                   5-9\n9                                 10-14\n10                                15-19\n11                                20-29\n12                                30-49\n13                                50-69\n14                                  70+\n\n\nWir bearbeiten die links Datenrahmen, den wir oben mit count(). Wir fügen zwei numerische Spalten hinzu IDsource und IDtarget hinzu, die die Verbindungen zwischen den Knoten wiedergeben/erstellen. Diese Spalten enthalten die Rownummern (Position) der Quell- und Zielknoten. 1 wird abgezogen, damit diese Positionsnummern bei 0 (nicht 1) beginnen.\n\n# match to numbers, not names\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\nDer Links-Datensatz sieht nun wie folgt aus:\n\n\n\n\n\n\nZeichne nun das Sankey-Diagramm mit sankeyNetwork(). Du kannst mehr über jedes Argument lesen, indem du ?sankeyNetwork in der Konsole aufrufst. Beachte, dass du, wenn du die iterations = 0 gesetzt hast, ist die Reihenfolge der Knoten möglicherweise nicht wie erwartet.\n\n# plot\n######\np &lt;- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0)        # ensure node order is as in data\np\n\n\n\n\n\nHier ist ein Beispiel, in dem auch der Patient Outcome enthalten ist. Beachte, dass wir bei der Datenaufbereitung die Anzahl der Fälle zwischen Alter und Krankenhaus und separat zwischen Krankenhaus und Ergebnis berechnen müssen. bind_rows().\n\n# counts by hospital and age category\nage_hosp_links &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = age_cat,          # re-name\n         target = hospital)\n\nhosp_out_links &lt;- linelist %&gt;% \n    drop_na(age_cat) %&gt;% \n    select(hospital, outcome) %&gt;% \n    count(hospital, outcome) %&gt;% \n    rename(source = hospital,       # re-name\n           target = outcome)\n\n# combine links\nlinks &lt;- bind_rows(age_hosp_links, hosp_out_links)\n\n# The unique node names\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\n# Create id numbers\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\n# plot\n######\np &lt;- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np\n\n\n\n\n\nhttps://www.displayr.com/sankey-diagrams-r/",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramme und Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.de.html#zeitleisten-der-ereignisse",
    "href": "new_pages/diagrams.de.html#zeitleisten-der-ereignisse",
    "title": "35  Diagramme und Tabellen",
    "section": "35.4 Zeitleisten der Ereignisse",
    "text": "35.4 Zeitleisten der Ereignisse\nUm eine Zeitleiste mit bestimmten Ereignissen zu erstellen, kannst du die vistime Paket.\nSiehe dies Vignette\n\n# load package\npacman::p_load(vistime,  # make the timeline\n               plotly    # for interactive visualization\n               )\n\nHier ist der Ereignisdatensatz, mit dem wir beginnen:\n\n\n\n\n\n\n\np &lt;- vistime(data)    # apply vistime\n\nlibrary(plotly)\n\n# step 1: transform into a list\npp &lt;- plotly_build(p)\n\n# step 2: Marker size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size &lt;- 10\n}\n\n# step 3: text size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size &lt;- 10\n}\n\n\n# step 4: text position\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition &lt;- \"right\"\n}\n\n#print\npp",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramme und Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.de.html#dags",
    "href": "new_pages/diagrams.de.html#dags",
    "title": "35  Diagramme und Tabellen",
    "section": "35.5 DAGs",
    "text": "35.5 DAGs\nDu kannst eine DAG manuell erstellen, indem du die DiagammeR Paket und der DOT-Sprache wie oben beschrieben erstellen.\nAlternativ dazu gibt es Pakete wie ggdag und daggity\nEinführung in DAGs ggdag Vignette\nKausale Inferenz mit DAGs in R",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramme und Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.de.html#ressourcen",
    "href": "new_pages/diagrams.de.html#ressourcen",
    "title": "35  Diagramme und Tabellen",
    "section": "35.6 Ressourcen",
    "text": "35.6 Ressourcen\nVieles von dem, was oben über die DOT-Sprache steht, stammt aus dem Tutorial auf dieser Seite\nEine andere, ausführlichere Tutorium über DiagammeR\nDiese Seite auf Sankey-Diagramme",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramme und Tabellen</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.de.html",
    "href": "new_pages/combination_analysis.de.html",
    "title": "36  Analyse der Kombinationen",
    "section": "",
    "text": "36.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse der Kombinationen</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.de.html#vorbereitung",
    "href": "new_pages/combination_analysis.de.html#vorbereitung",
    "title": "36  Analyse der Kombinationen",
    "section": "",
    "text": "Pakete laden\nDieser Codechunk zeigt das Laden der Pakete, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  tidyverse,     # data management and visualization\n  UpSetR,        # special package for combination plots\n  ggupset)       # special package for combination plots\n\n\n\n\nDaten importieren\nZunächst importieren wir die bereinigte Liste der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import case linelist \nlinelist_sym &lt;- import(\"linelist_cleaned.rds\")\n\nDiese Liste enthält fünf “Ja/Nein”-Variablen zu den gemeldeten Symptomen. Wir müssen diese Variablen ein wenig umformen, um die ggupset Paket für unser Diagramm zu verwenden. Sieh dir die Daten an (scrolle nach rechts, um die Symptomvariablen zu sehen).\n\n\n\n\n\n\n\n\n\nWerte neu formatieren\nZur Anpassung an das Format, das von ggupset zu entsprechen, konvertieren wir die “Ja” und “Nein” in den tatsächlichen Symptomnamen, indem wir case_when() von dplyr. Wenn “nein”, setzen wir den Wert als leer, so dass die Werte entweder NA oder das Symptom.\n\n# create column with the symptoms named, separated by semicolons\nlinelist_sym_1 &lt;- linelist_sym %&gt;% \n\n  # convert the \"yes\" and \"no\" values into the symptom name itself\n  # if old value is \"yes\", new value is \"fever\", otherwise set to missing (NA)\nmutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n       chills = ifelse(chills == \"yes\", \"chills\", NA),\n       cough = ifelse(cough == \"yes\", \"cough\", NA),\n       aches = ifelse(aches == \"yes\", \"aches\", NA),\n       vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\n\nJetzt erstellen wir zwei letzte Spalten:\n\nDie Verkettung (das Zusammenkleben) aller Symptome des Patienten (eine Zeichenspalte)\nDie obige Spalte in eine Klasse umwandeln Liste um, damit sie von ggupset akzeptiert wird, um den Plot\n\nSiehe die Seite über [Charaktere und Strings] erfährst du mehr über dieunite() Funktion von stringr\n\nlinelist_sym_1 &lt;- linelist_sym_1 %&gt;% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \"; \",\n        remove = TRUE,\n        na.rm = TRUE) %&gt;% \n  mutate(\n    # make a copy of all_symptoms column, but of class \"list\" (which is required to use ggupset() in next step)\n    all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n    )\n\nSieh dir die neuen Daten an. Beachte die beiden Spalten am rechten Ende - die eingefügten kombinierten Werte und die Liste",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse der Kombinationen</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.de.html#ggupset",
    "href": "new_pages/combination_analysis.de.html#ggupset",
    "title": "36  Analyse der Kombinationen",
    "section": "36.2 ggupset",
    "text": "36.2 ggupset\nLade das Paket\n\npacman::p_load(ggupset)\n\nErstelle den Plot. Wir beginnen mit einer ggplot() und geom_bar() an, aber dann fügen wir die spezielle Funktion scale_x_upset() von der ggupset.\n\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signs & symptoms\",\n  subtitle = \"10 most frequent combinations of signs and symptoms\",\n  caption = \"Caption here.\",\n  x = \"Symptom combination\",\n  y = \"Frequency in dataset\")\n\n\n\n\n\n\n\n\nMehr Informationen über ggupset können gefunden werden online oder offline in der Paketdokumentation in deinem RStudio-Hilfetab ?ggupset.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse der Kombinationen</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.de.html#upsetr",
    "href": "new_pages/combination_analysis.de.html#upsetr",
    "title": "36  Analyse der Kombinationen",
    "section": "36.3 UpSetR",
    "text": "36.3 UpSetR\nDie UpSetR Paket ermöglicht mehr Anpassungen des Plots, aber es kann schwieriger auszuführen sein:\nPaket laden\n\npacman::p_load(UpSetR)\n\nDatenbereinigung\nWir müssen die linelist Werte der Symptome in 1 / 0 umwandeln.\n\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n     # convert the \"yes\" and \"no\" values into 1s and 0s\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n\nWenn du an einem effizienteren Befehl interessiert bist, kannst du die Vorteile der +() Funktion nutzen, die auf der Grundlage einer logischen Aussage in 1en und 0en umwandelt. Dieser Befehl nutzt die across() Funktion, um mehrere Spalten auf einmal zu ändern (mehr dazu in Daten bereinigen und Kernfunktionen).\n\n# Efficiently convert \"yes\" to 1 and 0\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n  \n  # convert the \"yes\" and \"no\" values into 1s and 0s\n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n\nErstelle nun den Plot mit der benutzerdefinierten Funktion upset() - nur mit den Symptomspalten. Du musst angeben, welche “Sets” verglichen werden sollen (die Namen der Symptomspalten). Alternativ kannst du auch nsets = und order.by = \"freq\" um nur die obersten X Kombinationen anzuzeigen.\n\n# Make the plot\nlinelist_sym_2 %&gt;% \n  UpSetR::upset(\n       sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n       order.by = \"freq\",\n       sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n       empty.intersections = \"on\",\n       # nsets = 3,\n       number.angles = 0,\n       point.size = 3.5,\n       line.size = 2, \n       mainbar.y.label = \"Symptoms Combinations\",\n       sets.x.label = \"Patients with Symptom\")",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse der Kombinationen</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.de.html#ressourcen",
    "href": "new_pages/combination_analysis.de.html#ressourcen",
    "title": "36  Analyse der Kombinationen",
    "section": "36.4 Ressourcen",
    "text": "36.4 Ressourcen\nDie Github-Seite zu UpSetR\nEine Shiny App Version - du kannst deine eigenen Daten hochladen\n*Dokumentation - schwer zu interpretieren",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse der Kombinationen</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.de.html",
    "href": "new_pages/transmission_chains.de.html",
    "title": "37  Übertragungsketten",
    "section": "",
    "text": "37.1 Übersicht\nDas wichtigste Werkzeug zur Handhabung, Analyse und Visualisierung von Übertragungsketten und Kontakten Kontaktverfolgungsdaten ist das Paket epicontacts, entwickelt von den Leuten bei RECON. Probiere die interaktive Grafik unten aus, indem du mit dem Mauszeiger über die Knotenpunkte fährst. Informationen, ziehst sie, um sie zu verschieben, und klickst sie an, um nachgelagerte Fälle zu markieren.\nWarning in epicontacts::make_epicontacts(linelist = linelist, contacts =\ncontacts, : Cycle(s) detected in the contact network: this may be unwanted",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Übertragungsketten</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.de.html#vorbereitung",
    "href": "new_pages/transmission_chains.de.html#vorbereitung",
    "title": "37  Übertragungsketten",
    "section": "37.2 Vorbereitung",
    "text": "37.2 Vorbereitung\n\nPakete laden\nLade zunächst die Standardpakete, die du für den Datenimport und die Datenmanipulation benötigst. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und es zur Verwendung lädt. Du kannst Pakete auch laden mit library() von BasisR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   remotes       # Package installation from github\n)\n\nDu benötigst die Entwicklungsversion von epicontacts, die Sie von Github installiert werden kann, indem die p_install_github() Funktion von pacman. Du musst nur diesen Befehl ausführen unten nur einmal ausführen, nicht jedes Mal, wenn du das Paket verwendest (danach kannst du p_load() wie gewohnt).\n\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du die Daten herunterladen möchtest, um Schritt für Schritt vorzugehen, lies die Anweisungen im [Handbuch und Daten herunterladen] Seite. Der Datensatz wird importiert, indem dieimport() Funktion aus dem rioPaket. Siehe die Seite über [Import und Export] für verschiedene Möglichkeiten, Daten zu importieren.\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nDie ersten 50 Zeilen der Zeilenliste werden unten angezeigt. Von besonderem Interesse sind die Spalten case_id, generation, infector, und source.\n\n\n\n\n\n\n\n\nEin epicontacts Objekt erstellen\nAnschließend müssen wir ein epicontacts Objekt erstellen, das zwei Typen von Daten:\n\neine Zeilenliste, die Fälle dokumentiert, wobei die Spalten Variablen sind und die Zeilen eindeutigen Fällen entsprechen\neine Liste von Kanten, die Verbindungen zwischen Fällen auf der Grundlage ihrer eindeutigen IDs definieren (dies können Kontakte sein, Übertragungsereignisse, etc.)\n\nDa wir bereits eine Linienliste haben, müssen wir nur noch eine Liste von Kanten zwischen Fällen erstellen, genauer gesagt zwischen ihren IDs. Wir können die Übertragungsverbindungen aus der Lineliste extrahieren, indem wir die infector Spalte mit der case_id Spalte. An dieser Stelle können wir auch “edge” hinzufügen Eigenschaften” hinzufügen, womit wir jede Variable meinen, die die Verbindung zwischen den beiden Fällen beschreibt, nicht die Fälle selbst. Zur Veranschaulichung fügen wir eine location Variable, die den Ort des Übertragungsereignisses beschreibt, und eine Dauer die die Dauer des Kontakts in Tagen angibt.\nIn dem folgenden Code wird die dplyr Funktion transmute ist ähnlich wie die mutate mit dem Unterschied, dass sie nur die die Spalten, die wir in der Funktion angegeben haben. Die drop_na Funktion wird alle Zeilen herausfiltern, in denen die angegebenen Spalten ein NA Wert haben; in diesem Fall wollen wir nur die Zeilen behalten, in denen der Infektor bekannt ist.\n\n## generate contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %&gt;%\n  drop_na(infector)\n\nWir können nun die epicontacts Objekt mit Hilfe der make_epicontacts Funktion. Wir müssen angeben, welche Spalte in der Lineliste auf den eindeutigen Fall verweist Identifikator verweist, und welche Spalten in den Kontakten auf die eindeutigen Identifikatoren der Fälle, die an jeder Verbindung beteiligt sind. Diese Verknüpfungen sind richtungsweisend in die Infektion geht von dem Ansteckenden zu den Fall, also müssen wir angeben die from und to Argumente entsprechend. Wir setzen daher auch die directed Argument auf TRUE ein, was sich auf zukünftige Operationen auswirkt.\n\n## generate epicontacts object\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n\nWarning in make_epicontacts(linelist = linelist, contacts = contacts, id =\n\"case_id\", : Cycle(s) detected in the contact network: this may be unwanted\n\n\nNach der Untersuchung der epicontacts Objekte können wir sehen, dass die case_id Spalte in der Linelist umbenannt wurde in id und die case_id und infector Spalten in den Kontakten wurden umbenannt in from und to. Dies gewährleistet Konsistenz bei der anschließenden Bearbeitung, Visualisierung und Analyse.\n\n## view epicontacts object\nepic\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 5,888 cases in linelist; 3,800 contacts; directed \n\n  // linelist\n\n# A tibble: 5,888 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 8689b7          4 NA             2014-05-13 2014-05-14           2014-05-18  \n 3 11f8ea          2 NA             2014-05-16 2014-05-18           2014-05-30  \n 4 b8812a          3 2014-05-04     2014-05-18 2014-05-20           NA          \n 5 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 be99c8          3 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 07e3e8          4 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 369449          4 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 f393b4          4 NA             2014-06-05 2014-06-06           2014-06-18  \n10 1389ca          4 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 3,800 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f547d6 5fe599 Community         2\n 2 f90f5f b8812a Nosocomial        7\n 3 11f8ea 893f25 Nosocomial        3\n 4 aec8ec be99c8 Nosocomial        3\n 5 893f25 07e3e8 Nosocomial        7\n 6 133ee7 369449 Community         6\n 7 996f3a 2978ac Nosocomial        2\n 8 133ee7 57a565 Nosocomial        9\n 9 37a6f6 fc15ef Nosocomial        1\n10 9f6884 2eaa9a Nosocomial        7\n# ℹ 3,790 more rows",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Übertragungsketten</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.de.html#handhabung",
    "href": "new_pages/transmission_chains.de.html#handhabung",
    "title": "37  Übertragungsketten",
    "section": "37.3 Handhabung",
    "text": "37.3 Handhabung\n\nTeilmenge\nDie subset() Methode für epicontacts Objekte ermöglicht unter anderem, das Filtern von Netzwerken anhand von Eigenschaften der Lineliste (“Knotenattribute”) und der Kontakte Datenbank (“Kantenattribute”). Diese Werte müssen als benannte Listen an die jeweiligen Argument übergeben werden. Im folgenden Code behalten wir zum Beispiel nur die männlichen Fälle in der Liste, die ein Infektionsdatum zwischen April und Juli 2014 haben (die Daten sind als Bereiche angegeben), und Übertragungsverbindungen, die im Krankenhaus.\n\nsub_attributes &lt;- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 69 cases in linelist; 1,911 contacts; directed \n\n  // linelist\n\n# A tibble: 69 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 3 2978ac          4 2014-05-30     2014-06-06 2014-06-08           2014-06-15  \n 4 57a565          4 2014-05-28     2014-06-13 2014-06-15           NA          \n 5 fc15ef          6 2014-06-14     2014-06-16 2014-06-17           2014-07-09  \n 6 99e8fa          7 2014-06-24     2014-06-28 2014-06-29           2014-07-09  \n 7 f327be          6 2014-06-14     2014-07-12 2014-07-13           2014-07-14  \n 8 90e5fe          5 2014-06-18     2014-07-13 2014-07-14           2014-07-16  \n 9 a47529          5 2014-06-13     2014-07-17 2014-07-18           2014-07-26  \n10 da8ecb          5 2014-06-20     2014-07-18 2014-07-20           2014-08-01  \n# ℹ 59 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 1,911 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f90f5f b8812a Nosocomial        7\n 2 11f8ea 893f25 Nosocomial        3\n 3 aec8ec be99c8 Nosocomial        3\n 4 893f25 07e3e8 Nosocomial        7\n 5 996f3a 2978ac Nosocomial        2\n 6 133ee7 57a565 Nosocomial        9\n 7 37a6f6 fc15ef Nosocomial        1\n 8 9f6884 2eaa9a Nosocomial        7\n 9 ab634e 99e8fa Nosocomial        2\n10 b799eb bc2adf Nosocomial        6\n# ℹ 1,901 more rows\n\n\nWir können die thin Funktion können wir entweder die Zeilenliste filtern, um Fälle einzuschließen die in den Kontakten gefunden werden, indem wir das Argument what = \"linelist\", oder die Kontakte so filtern, dass sie nur die Fälle enthalten, die in der Linienliste gefunden werden, indem du das Argument das Argument what = \"contacts\". Im folgenden Code filtern wir zusätzlich die epicontacts-Objekt weiter, um nur die Übermittlungslinks zu behalten, die die männlichen Fälle betreffen die zwischen April und Juli infiziert wurden und nach denen wir oben gefiltert haben. Wir können sehen, dass nur zwei bekannte Übertragungswege auf diese Spezifikation passen.\n\nsub_attributes &lt;- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)\n\n[1] 4\n\n\nZusätzlich zur Unterteilung nach Knoten- und Kantenattributen können die Netze nach folgenden Kriterien unterteilt werden um nur Komponenten zu berücksichtigen, die mit bestimmten Knoten verbunden sind. Die cluster_id Argument nimmt einen Vektor von Fall-IDs und gibt die Liste der Individuen zurück, die die direkt oder indirekt mit diesen IDs verknüpft sind. Im folgenden Code sehen wir dass insgesamt 13 Fälle in den Clustern enthalten sind, die in der Lineliste 2ae019 und 71577a.\n\nsub_id &lt;- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)\n\n[1] 13\n\n\nDie subset() Methode für epicontacts Objekte erlaubt auch das Filtern nach Clustern Größe zu filtern, indem die cs, cs_min und cs_max Argumente. Im folgenden Code sind wir nur die Fälle, die mit Clustern von 10 oder mehr Fällen verknüpft sind, und wir sehen, dass 271 Fälle in der Linienliste mit solchen Clustern verbunden sind.\n\nsub_cs &lt;- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)\n\n[1] 271\n\n\n\n\nZugriff auf IDs\nDie get_id() Funktion ruft Informationen über Fall-IDs in der Datensatz ab und kann wie folgt parametrisiert werden:\n\nlinelist: IDs in den Daten der Linienliste\nKontakte: IDs im Kontaktdatensatz (“von” und “bis” kombiniert)\nvon: IDs in der Spalte “von” des Kontaktdatensatzes\nan IDs in der Spalte “bis” des Kontaktdatensatzes\nalle: IDs, die irgendwo in einem der beiden Datensätze erscheinen\ngemeinsame: IDs, die sowohl im Kontaktdatensatz als auch in der Zeilenliste erscheinen\n\nWas sind zum Beispiel die ersten zehn IDs im Datensatz “Kontakte”?\n\ncontacts_ids &lt;- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)\n\n [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\"\n [9] \"9f6884\" \"4802b1\"\n\n\nWie viele IDs finden sich sowohl in der Linienliste als auch in den Kontakten?\n\nlength(get_id(epic, \"common\"))\n\n[1] 4352",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Übertragungsketten</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.de.html#visualisierung",
    "href": "new_pages/transmission_chains.de.html#visualisierung",
    "title": "37  Übertragungsketten",
    "section": "37.4 Visualisierung",
    "text": "37.4 Visualisierung\n\nBasic Plotting\nAlle Visualisierungen von epicontacts Objekten werden von der plot Funktion behandelt. Wir filtern zunächst die epicontacts Objekt so, dass es nur die Fälle mit Eintrittsdatum im Juni 2014 mit der subset Funktion, und nur die mit diesen Fällen verknüpften Kontakte mit der Funktion thin Funktion.\n\n## subset epicontacts object\nsub &lt;- epic %&gt;%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %&gt;%\n thin(\"contacts\")\n\nDann können wir den grundlegenden, interaktiven Plot ganz einfach wie folgt erstellen:\n\n## plot epicontacts object\nplot(\n  sub,\n  width = 700,\n  height = 700\n)\n\n\n\n\n\nDu kannst die Knoten verschieben, indem du sie ziehst, und mit dem Mauszeiger über sie fahren, um mehr Informationen und klicke sie an, um zusammenhängende Fälle zu markieren.\nEs gibt eine Vielzahl von Argumenten, um diese Darstellung weiter zu verändern. Wir werden behandeln die wichtigsten, aber sieh dir auch die Dokumentation unter ?vis_epicontacts (die Funktion, die bei der Verwendung von plot auf eine epicontacts Objekt), um eine vollständige Beschreibung der Funktionsargumente zu erhalten.\n\nVisualisierung von Knotenattributen\nKnotenfarbe, Knotenform und Knotengröße können einer bestimmten Spalte in der Linienliste zugeordnet werden mit Hilfe der node_color, node_shape und node_size Argumente. Das ist ähnlich dem aes Syntax, die du vielleicht von ggplot2.\nDie spezifischen Farben, Formen und Größen der Knotenpunkte können wie folgt festgelegt werden:\n\nFarben über die col_pal Argument, entweder durch die Angabe einer Namensliste für manuelle die manuelle Angabe jeder Farbe, wie unten beschrieben, oder durch die Angabe einer Farbpalette Funktion wie colorRampPalette(c(\"black\", \"red\", \"orange\")), die einen Farbverlauf zwischen den angegebenen Farben erzeugt.\nFormen durch Übergabe einer benannten Liste an die shapes Argument, das eine Form angibt für jedes eindeutige Element in der Spalte der Zeilenliste, die durch die node_shape Argument angegeben ist. Siehe codeawesome für verfügbare Formen.\nGröße durch Übergabe eines Größenbereichs der Knoten an die size_range Argument übergeben.\n\nHier ein Beispiel, bei dem die Farbe das Ergebnis, die Form das Geschlecht und die Größe darstellt das Alter:\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nVisualisierung von Kantenattributen\nKantenfarbe, Breite und Linientyp können einer bestimmten Spalte in den Kontakten zugeordnet werden Datenrahmen zugeordnet werden, indem die edge_color, edge_width und edge_linetype Argumente. Die spezifischen Farben und Breiten der Kanten können wie folgt festgelegt werden:\n\nFarben über die edge_col_pal Argument, auf die gleiche Art und Weise, wie für col_pal.\nWeiten durch die Übergabe eines Größenbereichs der Knoten an die width_range Argument übergeben.\n\nHier ein Beispiel:\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\n\nZeitliche Achse\nWir können das Netzwerk auch entlang einer zeitlichen Achse visualisieren, indem wir die x_axis Argument auf eine Spalte in der Linelist abbildet. Im folgenden Beispiel wird die x-Achse das Datum des Auftretens der Symptome dar. Wir haben auch die arrow_size Argument, um sicherzustellen, dass die Pfeile nicht zu groß sind, und setzen label = FALSE um die die Abbildung weniger unübersichtlich zu machen.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nEs gibt eine große Anzahl zusätzlicher Argumente, um genauer festzulegen, wie diese Netzwerk entlang der Zeitachse visualisiert wird, die du dir ansehen kannst über ?vis_temporal_interactive (die Funktion, die bei der Verwendung von plot auf einer epicontacts Objekt mit x_axis angegeben). Wir gehen durch einige unten durch.\n\nFestlegen der Form des Übertragungsbaums\nEs gibt zwei Hauptformen, die der Übertragungsbaum annehmen kann, die mit die network_shape Argument angegeben wird. Die erste ist ein branching Form, wie oben gezeigt, bei der eine gerade Kante zwei beliebige Knotenpunkte verbindet. Dies ist die intuitivste Darstellung, kann aber in einem dicht vernetzten System zu überlappenden Kanten führen. Netzwerk führen. Die zweite Form ist rectangle, die einen Baum erzeugt, der einem Phylogenie. Zum Beispiel:\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nJedem Fallknoten kann eine eindeutige vertikale Position zugewiesen werden, indem du die position_dodge Argument. Die Position von unverbundenen Fällen (d. h. ohne gemeldeten Kontakten) wird mit dem Argument unlinked_pos Argument angegeben.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nDie Position des übergeordneten Knotens im Verhältnis zu den untergeordneten Knoten kann angegeben werden, indem die parent_pos Argument angegeben werden. Die Standardoption ist, dass der Elternknoten in der Mitte zu platzieren, er kann aber auch am unteren Rand platziert werden (parent_pos = 'bottom') oder an der Spitze (parent_pos = 'top').\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nSpeichern von Plots und Zahlen\nDu kannst einen Plot als interaktive, in sich geschlossene Html-Datei speichern, indem du die visSave Funktion aus dem VisNetwork Paket:\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %&gt;%\n  visNetwork::visSave(\"network.html\")\n\nDas Speichern dieser Netzwerkausgaben als Bild ist leider nicht so einfach und erfordert Du musst die Datei als html speichern und dann einen Screenshot von dieser Datei machen, indem du der webshot Paket. Im folgenden Code konvertieren wir die gespeicherte html-Datei oben in ein PNG um:\n\nwebshot(url = \"network.html\", file = \"network.png\")\n\n\n\n\nZeitleisten\nDu kannst dem Netzwerk auch Zeitleisten zuordnen, die auf der x-Achse dargestellt werden eines jeden Falls dargestellt werden. Damit kannst du z. B. die Standorte der Fälle oder die Zeit visualisieren. zum Ergebnis. Um eine Zeitleiste zu erstellen, müssen wir einen data.frame mit mindestens drei Spalten erstellen, die die Fall-ID, das Startdatum des “Ereignisses” und das Enddatum des “Ereignisses”. Du kannst auch eine beliebige Anzahl anderer Spalten hinzufügen, die die dann auf Knoten- und Kanteneigenschaften der Zeitleiste abgebildet werden können. Im folgenden Code, erstellen wir eine Zeitleiste, die vom Datum des Symptombeginns bis zum Datum der und behalten die Ergebnis- und Krankenhausvariablen bei, die wir verwenden, um die Form und Farbe des Knotens definieren. Beachte, dass du mehr als eine Zeile/Ereignis in der Zeitleiste haben kannst pro Fall haben kannst, zum Beispiel wenn ein Fall zwischen mehreren Krankenhäusern verlegt wird.\n\n## generate timeline\ntimeline &lt;- linelist %&gt;%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n\nAnschließend übergeben wir das Zeitleistenelement an die timeline Argument. Wir können abbilden Timeline-Attribute den Farben, Formen und Größen der Timeline-Knoten auf die gleiche Weise zuordnen wie in den vorangegangenen Abschnitten beschrieben, nur dass wir zwei Knoten: den Start- und den Endknoten Knoten jeder Zeitleiste, die getrennte Argumente haben. Zum Beispiel, tl_start_node_color definiert, welche Spalte der Zeitleiste auf die Farbe von des Startknotens zugeordnet wird, während tl_end_node_shape definiert, welche Spalte der Zeitleiste auf die Form des Endknotens abgebildet wird. Wir können auch Farbe, Breite, Linientyp und Beschriftungen auf die Zeitleiste Kante über die tl_edge_* Argumente.\nSiehe ?vis_temporal_interactive (die Funktion, die beim Plotten einer epicontacts-Objekts aufgerufen wird) für eine detaillierte Dokumentation der Argumente. Jedes Argument wird auch im folgenden Code kommentiert:\n\n## define shapes\nshapes &lt;- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## define colours\ncolours &lt;- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## make plot\nplot(\n  sub,\n  ## max x coordinate to date of onset\n  x_axis = \"date_onset\",\n  ## use rectangular network shape\n  network_shape = \"rectangle\",\n  ## mape case node shapes to gender column\n  node_shape = \"gender\",\n  ## we don't want to map node colour to any columns - this is important as the\n  ## default value is to map to node id, which will mess up the colour scheme\n  node_color = NULL,\n  ## set case node size to 30 (as this is not a character, node_size is not\n  ## mapped to a column but instead interpreted as the actual node size)\n  node_size = 30,\n  ## set transmission link width to 4 (as this is not a character, edge_width is\n  ## not mapped to a column but instead interpreted as the actual edge width)\n  edge_width = 4,\n  ## provide the timeline object\n  timeline = timeline,\n  ## map the shape of the end node to the outcome column in the timeline object\n  tl_end_node_shape = \"outcome\",\n  ## set the size of the end node to 15 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## node size)\n  tl_end_node_size = 15,\n  ## map the colour of the timeline edge to the hospital column\n  tl_edge_color = \"hospital\",\n  ## set the width of the timeline edge to 2 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## edge width)\n  tl_edge_width = 2,\n  ## map edge labels to the hospital variable\n  tl_edge_label = \"hospital\",\n  ## specify the shape for everyone node attribute (defined above)\n  shapes = shapes,\n  ## specify the colour palette (defined above)\n  col_pal = colours,\n  ## set the size of the arrow to 0.5\n  arrow_size = 0.5,\n  ## use two columns in the legend\n  legend_ncol = 2,\n  ## set font size\n  font_size = 15,\n  ## define formatting for dates\n  date_labels = c(\"%d %b %Y\"),\n  ## don't plot the ID labels below nodes\n  label = FALSE,\n  ## specify height\n  height = 1000,\n  ## specify width\n  width = 1200,\n  ## ensure each case node has a unique y-coordinate - this is very important\n  ## when using timelines, otherwise you will have overlapping timelines from\n  ## different cases\n  position_dodge = TRUE\n)\n\nWarning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed\nas ID not found in linelist or start/end date is NA",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Übertragungsketten</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.de.html#analyse",
    "href": "new_pages/transmission_chains.de.html#analyse",
    "title": "37  Übertragungsketten",
    "section": "37.5 Analyse",
    "text": "37.5 Analyse\n\nZusammenfassend\nWir können uns einen Überblick über einige der Netzwerkeigenschaften verschaffen, indem wir die summary Funktion.\n\n## summarise epicontacts object\nsummary(epic)\n\n\n/// Overview //\n  // number of unique IDs in linelist: 5888\n  // number of unique IDs in contacts: 5511\n  // number of unique IDs in both: 4352\n  // number of contacts: 3800\n  // contacts with both cases in linelist: 56.868 %\n\n/// Degrees of the network //\n  // in-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n\n  // out-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n\n  // in and out degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   1.000   1.078   1.000   7.000 \n\n/// Attributes //\n  // attributes in linelist:\n generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n\n  // attributes in contacts:\n location duration\n\n\nWir können zum Beispiel sehen, dass nur 57 % der Kontakte beide Fälle in der Das bedeutet, dass wir keine Daten für eine signifikante Anzahl von Kontakten in der Linienliste haben. Anzahl von Fällen, die an diesen Übertragungsketten beteiligt sind.\n\n\nPaarweise Merkmale\nDie get_pairwise() Funktion ermöglicht die Bearbeitung von Variablen in der Zeilenliste entsprechend den einzelnen Paaren im Kontaktdatensatz. Im folgenden Beispiel wird das Datum des Ausbruchs der Krankheit aus der Zeilenliste extrahiert, um die Differenz zwischen dem Datum des Ausbruchs der Krankheit für jedes Paar zu berechnen. Der Wert, der aus diesem Vergleich ergibt, stellt die Serienintervall (si).\n\nsi &lt;- get_pairwise(epic, \"date_onset\")   \nsummary(si)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    5.00    9.00   11.01   15.00   99.00    1820 \n\ntibble(si = si) %&gt;%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1820 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nDie get_pairwise() wird die Klasse der Spalte interpretieren, die für Vergleich verwendet wird, und passt seine Methode zum Vergleichen der Werte entsprechend an. Für Zahlen und Daten (wie die si Beispiel oben), wird die Funktion subtrahieren die Werte. Bei der Anwendung auf Spalten, die Zeichen oder kategorisch sind, get_pairwise() die Werte zusammenfügen. Da die Funktion auch erlaubt eine beliebige Verarbeitung zulässt (siehe Argument “f”), können diese diskreten Kombinationen leicht tabellarisch dargestellt und analysiert werden.\n\nhead(get_pairwise(epic, \"gender\"), n = 10)\n\n [1] \"f -&gt; m\" NA       \"m -&gt; m\" NA       \"m -&gt; f\" \"f -&gt; f\" NA       \"f -&gt; m\"\n [9] NA       \"m -&gt; f\"\n\nget_pairwise(epic, \"gender\", f = table)\n\n           values.to\nvalues.from   f   m\n          f 464 516\n          m 510 468\n\nfisher.test(get_pairwise(epic, \"gender\", f = table))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  get_pairwise(epic, \"gender\", f = table)\np-value = 0.03758\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6882761 0.9892811\nsample estimates:\nodds ratio \n 0.8252575 \n\n\nHier sehen wir einen signifikanten Zusammenhang zwischen Übertragungswegen und Geschlecht.\n\n\nIdentifizierung von Clustern\nDie get_clusters() Funktion kann verwendet werden, um verbundene Komponenten zu identifizieren in einer epicontacts Objekt zu identifizieren. Zunächst verwenden wir sie, um eine data.frame das die Cluster-Informationen enthält:\n\nclust &lt;- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)\n\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42 \n\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\n\nWir wollen uns die größten Cluster ansehen. Dazu fügen wir die Clusterinformationen zu den epicontacts Objekt hinzu und unterteilen es dann, um nur die größten Cluster zu behalten:\n\nepic &lt;- get_clusters(epic)\nmax_size &lt;- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))\n\n\n\n\n\n\n\nBerechnung der Grade\nDer Grad eines Knotens entspricht der Anzahl seiner Kanten oder Verbindungen zu anderen Knoten. get_degree() bietet eine einfache Methode zur Berechnung dieses Wertes für epicontacts Netzwerke. Ein hoher Grad bedeutet in diesem Zusammenhang, dass eine Person der mit vielen anderen in Kontakt war. Die type Argument zeigt, dass wir sowohl den In-Grad als auch den Out-Grad zählen wollen, die only_linelist Argument gibt an, dass wir nur den Grad für die Fälle in der Linienliste berechnen wollen.\n\ndeg_both &lt;- get_degree(epic, type = \"both\", only_linelist = TRUE)\n\nWelche Personen haben die zehn meisten Kontakte?\n\nhead(sort(deg_both, decreasing = TRUE), 10)\n\n916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n     7      6      6      6      5      5      5      5      5      5 \n\n\nWie hoch ist die durchschnittliche Anzahl der Kontakte?\n\nmean(deg_both)\n\n[1] 1.078473",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Übertragungsketten</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.de.html#ressourcen",
    "href": "new_pages/transmission_chains.de.html#ressourcen",
    "title": "37  Übertragungsketten",
    "section": "37.6 Ressourcen",
    "text": "37.6 Ressourcen\nDie epicontacts Seite gibt einen Überblick über die Funktionen des Pakets und enthält einige vertiefende Vignetten.\nDie github-Seite kann genutzt werden, um die Probleme zu melden und Funktionen anzufordern.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Übertragungsketten</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.de.html",
    "href": "new_pages/phylogenetic_trees.de.html",
    "title": "38  Phylogenetische Bäume",
    "section": "",
    "text": "38.1 Übersicht\nPhylogenetische Bäume werden verwendet, um die Verwandtschaft und Evolution von Organismen anhand der Sequenz ihres genetischen Codes zu visualisieren und zu beschreiben.\nSie können aus genetischen Sequenzen mit Hilfe von entfernungsbasierten Methoden (z. B. der neighbor-joining-Methode) oder charakterbasierten Methoden (z. B. der Maximum-Likelihood- und der Bayes’schen Markov-Chain-Monte-Carlo-Methode) erstellt werden. Die Sequenzierung der nächsten Generation (Next Generation Sequencing, NGS) ist erschwinglicher geworden und wird im öffentlichen Gesundheitswesen immer häufiger eingesetzt, um Erreger von Infektionskrankheiten zu beschreiben. Tragbare Sequenziergeräte verkürzen die Durchlaufzeit und versprechen, Daten zur Unterstützung der Untersuchung von Krankheitsausbrüchen in Echtzeit zur Verfügung zu stellen. NGS-Daten können verwendet werden, um den Ursprung oder die Quelle eines Erregerstammes und seine Ausbreitung zu identifizieren und das Vorhandensein von Genen für antimikrobielle Resistenz zu bestimmen. Um die genetische Verwandtschaft zwischen Proben zu visualisieren, wird ein phylogenetischer Baum erstellt.\nAuf dieser Seite lernen wir, wie man den ggtree Paket, das eine kombinierte Visualisierung von phylogenetischen Bäumen mit zusätzlichen Beispieldaten in Form eines Datenrahmens ermöglicht. So können wir Muster beobachten und die Ausbruchsdynamik besser verstehen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Phylogenetische Bäume</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.de.html#vorbereitung",
    "href": "new_pages/phylogenetic_trees.de.html#vorbereitung",
    "title": "38  Phylogenetische Bäume",
    "section": "38.2 Vorbereitung",
    "text": "38.2 Vorbereitung\n\nPakete laden\nDieser Codeausschnitt zeigt das Laden der benötigten Pakete. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,             # import/export\n  here,            # relative file paths\n  tidyverse,       # general data management and visualization\n  ape,             # to import and export phylogenetic files\n  ggtree,          # to visualize phylogenetic files\n  treeio,          # to visualize phylogenetic files\n  ggnewscale)      # to add additional layers of color schemes\n\n\n\nDaten importieren\nDie Daten für diese Seite können mit den Anweisungen auf der Seite [Handbuch und Daten herunterladen] Seite herunterladen.\nEs gibt verschiedene Formate, in denen ein phylogenetischer Baum gespeichert werden kann (z. B. Newick, NEXUS, Phylip). Ein gängiges Format ist das Newick-Dateiformat (.nwk), das der Standard für die Darstellung von Bäumen in computerlesbarer Form ist. Das bedeutet, dass ein ganzer Baum in einem String-Format wie “((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59);” ausgedrückt werden kann, in dem alle Knoten und Spitzen und ihre Beziehung (Zweiglänge) zueinander aufgeführt sind.\nHinweis: Es ist wichtig zu verstehen, dass die phylogenetische Baumdatei an sich keine Sequenzierungsdaten enthält, sondern lediglich das Ergebnis der genetischen Abstände zwischen den Sequenzen ist. Wir können daher keine Sequenzierungsdaten aus einer Baumdatei extrahieren.\nZunächst verwenden wir die read.tree() Funktion von ape Paket, um eine Newick-Baumdatei im .txt-Format zu importieren und sie in einem Listenobjekt der Klasse “phylo” zu speichern. Falls nötig, verwende die here() Funktion aus dem hier Paket, um den relativen Dateipfad anzugeben.\nHinweis: In diesem Fall wird der newick-Baum zur einfacheren Handhabung und zum Herunterladen von Github als .txt-Datei gespeichert.\n\ntree &lt;- ape::read.tree(\"Shigella_tree.txt\")\n\nWir untersuchen unser Baumobjekt und sehen, dass es 299 Spitzen (oder Proben) und 236 Knoten enthält.\n\ntree\n\n\nPhylogenetic tree with 299 tips and 236 internal nodes.\n\nTip labels:\n  SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\nNode labels:\n  17, 29, 100, 67, 100, 100, ...\n\nRooted; includes branch lengths.\n\n\nZweitens importieren wir eine Tabelle, die als .csv-Datei gespeichert ist, mit zusätzlichen Informationen für jede sequenzierte Probe, wie z. B. Geschlecht, Herkunftsland und Attribute für antimikrobielle Resistenz, indem wir die import() Funktion aus der rio Paket:\n\nsample_data &lt;- import(\"sample_data_Shigella_tree.csv\")\n\nUnten sind die ersten 50 Zeilen der Daten:\n\n\n\n\n\n\n\n\nBereinigen und prüfen\nWir bereinigen und prüfen unsere Daten: Um die richtigen Beispieldaten dem phylogenetischen Baum zuzuordnen, müssen die Werte in der Spalte Sample_ID in der sample_data Datenrahmen mit den tip.labels Werte in der tree Datei übereinstimmen:\nWir überprüfen die Formatierung der tip.labels in der tree Datei, indem wir uns die ersten 6 Einträge ansehen, indem wir mit head() von Basis R.\n\nhead(tree$tip.label) \n\n[1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\"\n[6] \"S17BD05939\"\n\n\nWir stellen auch sicher, dass die erste Spalte in unserer sample_data Datenrahmen ist Sample_ID. Wir sehen uns die Spaltennamen unseres Datenrahmens mit colnames() von Basis R.\n\ncolnames(sample_data)   \n\n [1] \"Sample_ID\"                  \"serotype\"                  \n [3] \"Country\"                    \"Continent\"                 \n [5] \"Travel_history\"             \"Year\"                      \n [7] \"Belgium\"                    \"Source\"                    \n [9] \"Gender\"                     \"gyrA_mutations\"            \n[11] \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n[13] \"MIC_CIP\"                   \n\n\nWir schauen uns die Sample_IDs im Datenrahmen an, um sicherzustellen, dass die Formatierung die gleiche ist wie in der tip.label (z. B. Buchstaben in Großbuchstaben, keine zusätzlichen Unterstriche _ zwischen Buchstaben und Zahlen, usw.)\n\nhead(sample_data$Sample_ID) # we again inspect only the first 6 using head()\n\n[1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\"\n[6] \"S18BD02657\"\n\n\nWir können auch vergleichen, ob alle Muster in der tree Datei enthalten sind und umgekehrt, indem wir einen logischen Vektor von TRUE oder FALSE erzeugen, wenn sie übereinstimmen oder nicht. Diese werden hier der Einfachheit halber nicht ausgedruckt.\n\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\n\nWir können diese Vektoren verwenden, um alle Proben-IDs anzuzeigen, die sich nicht im Baum befinden (es gibt keine).\n\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]\n\ncharacter(0)\n\n\nBei näherer Betrachtung können wir feststellen, dass das Format der Sample_ID im Datenrahmen dem Format der Probennamen in der tip.labels. Diese müssen nicht in der gleichen Reihenfolge sortiert sein, um übereinstimmen zu können.\nWir sind bereit zu gehen!",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Phylogenetische Bäume</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.de.html#einfache-baumvisualisierung",
    "href": "new_pages/phylogenetic_trees.de.html#einfache-baumvisualisierung",
    "title": "38  Phylogenetische Bäume",
    "section": "38.3 Einfache Baumvisualisierung",
    "text": "38.3 Einfache Baumvisualisierung\n\nVerschiedene Baum-Layouts\nggtree bietet viele verschiedene Layout-Formate an, von denen einige für deinen speziellen Zweck besser geeignet sind als andere. Unten findest du ein paar Beispiele. Für andere Optionen siehe dies Online-Buch.\nHier sind einige Beispiele für die Gestaltung von Bäumen:\n\nggtree(tree)                                            # simple linear tree\nggtree(tree,  branch.length = \"none\")                   # simple linear tree with all tips aligned\nggtree(tree, layout=\"circular\")                         # simple circular tree\nggtree(tree, layout=\"circular\", branch.length = \"none\") # simple circular tree with all tips aligned\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEinfacher Baum plus Beispieldaten\nDie %&lt;+% Operator wird verwendet, um die sample_data Datenrahmen mit dem tree Datei zu verbinden. Die einfachste Annotation deines Baums ist das Hinzufügen der Probennamen an den Spitzen sowie das Einfärben der Spitzenpunkte und, falls gewünscht, der Äste:\nHier ist ein Beispiel für einen kreisförmigen Baum:\n\nggtree(tree, layout = \"circular\", branch.length = 'none') %&lt;+% sample_data + # %&lt;+% adds dataframe with sample data to tree\n  aes(color = I(Belgium))+                       # color the branches according to a variable in your dataframe\n  scale_color_manual(\n    name = \"Sample Origin\",                      # name of your color scheme (will show up in the legend like this)\n    breaks = c(\"Yes\", \"No\"),                     # the different options in your variable\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # how you want the different options named in your legend, allows for formatting\n    values = c(\"blue\", \"black\"),                  # the color you want to assign to the variable \n    na.value = \"black\") +                        # color NA values in black as well\n  new_scale_color()+                             # allows to add an additional color scheme for another variable\n    geom_tippoint(\n      mapping = aes(color = Continent),          # tip color by continent. You may change shape adding \"shape = \"\n      size = 1.5)+                               # define the size of the point at the tip\n  scale_color_brewer(\n    name = \"Continent\",                    # name of your color scheme (will show up in the legend like this)\n    palette = \"Set1\",                      # we choose a set of colors coming with the brewer package\n    na.value = \"grey\") +                    # for the NA values we choose the color grey\n  geom_tiplab(                             # adds name of sample to tip of its branch \n    color = 'black',                       # (add as many text lines as you wish with + , but you may need to adjust offset value to place them next to each other)\n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    align = TRUE)+    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # title of your graph\n  theme(\n    axis.title.x = element_blank(), # removes x-axis title\n    axis.title.y = element_blank(), # removes y-axis title\n    legend.title = element_text(    # defines font size and format of the legend title\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # defines font size and format of the legend text\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # defines font size and format of the plot title\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # defines placement of the legend\n    legend.box = \"vertical\",        # defines placement of the legend\n    legend.margin = margin())   \n\n\n\n\n\n\n\n\nDu kannst deinen Baumplot exportieren mit ggsave() wie jedes andere ggplot-Objekt exportieren. Auf diese Weise geschrieben, ggsave() speichert das zuletzt erzeugte Bild in dem von dir angegebenen Dateipfad. Vergiss nicht, dass du die here() und relative Dateipfade verwenden kannst, um einfach in Unterordnern etc. zu speichern.\n\nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Phylogenetische Bäume</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.de.html#baummanipulation",
    "href": "new_pages/phylogenetic_trees.de.html#baummanipulation",
    "title": "38  Phylogenetische Bäume",
    "section": "38.4 Baummanipulation",
    "text": "38.4 Baummanipulation\nManchmal hast du einen sehr großen phylogenetischen Baum und bist nur an einem Teil des Baums interessiert. Zum Beispiel, wenn du einen Baum mit historischen oder internationalen Proben erstellt hast, um einen Überblick darüber zu bekommen, wo dein Datensatz in das Gesamtbild passt. Um deine Daten näher zu betrachten, möchtest du aber nur diesen Teil des großen Baums untersuchen.\nDa die phylogenetische Baumdatei nur das Ergebnis der Sequenzierdatenanalyse ist, können wir die Reihenfolge der Knoten und Äste in der Datei selbst nicht verändern. Diese wurden bereits in früheren Analysen aus den NGS-Rohdaten bestimmt. Wir können jedoch in Teile hineinzoomen, Teile ausblenden und sogar Teile des Baums unterteilen.\n\nHeranzoomen\nWenn du deinen Baum nicht “zerschneiden”, sondern nur einen Teil davon genauer untersuchen willst, kannst du einen bestimmten Teil heranzoomen, um ihn zu betrachten.\nZunächst zeichnen wir den gesamten Baum linear auf und fügen jedem Knoten im Baum numerische Beschriftungen hinzu.\n\np &lt;- ggtree(tree,) %&lt;+% sample_data +\n  geom_tiplab(size = 1.5) +                # labels the tips of all branches with the sample name in the tree file\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # labels all the nodes in the tree\n\np  # print\n\n\n\n\n\n\n\n\nUm auf einen bestimmten Zweig (der nach rechts herausragt) zu zoomen, benutze viewClade() auf das ggtree-Objekt p und gib die Knotennummer an, um einen genaueren Blick darauf zu werfen:\n\nviewClade(p, node = 452)\n\n\n\n\n\n\n\n\n\n\nZusammenbrechende Zweige\nWenn wir diesen Zweig jedoch ignorieren wollen, können wir ihn an demselben Knoten (Knoten Nr. 452) zusammenbrechen, indem wir collapse(). Dieser Baum ist definiert als p_collapsed.\n\np_collapsed &lt;- collapse(p, node = 452)\np_collapsed\n\n\n\n\n\n\n\n\nZur Verdeutlichung: Wenn wir drucken p_collapsed drucken, fügen wir ein geom_point2() (eine blaue Raute) an den Knoten des zusammengebrochenen Zweigs.\n\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # we assign a symbol to the collapsed node\n            size = 5,                     # define the size of the symbol\n            shape = 23,                   # define the shape of the symbol\n            fill = \"steelblue\")           # define the color of the symbol\n\n\n\n\n\n\n\n\n\n\nEinen Baum unterteilen\nWenn wir eine dauerhafte Änderung vornehmen und einen neuen, reduzierten Baum erstellen wollen, können wir einen Teil des Baums mit tree_subset(). Dann kannst du ihn als neue Baumdatei oder .txt-Datei speichern.\nZuerst inspizieren wir die Baumknoten und Tip-Labels, um zu entscheiden, was wir unterteilen wollen.\n\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %&lt;+% sample_data +               # we add the asmple data using the %&lt;+% operator\n  geom_tiplab(size = 1)+                                # label tips of all branches with sample name in tree file\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # labels all the nodes in the tree\n theme(\n   legend.position = \"none\",                            # removes the legend all together\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\n\n\n\n\n\n\n\n\nAngenommen, wir haben uns entschieden, den Baum am Knoten 528 zu unterteilen (nur die Spitzen innerhalb dieses Zweigs nach dem Knoten 528 zu behalten) und speichern dies als neue sub_tree1 Objekt:\n\nsub_tree1 &lt;- tree_subset(\n  tree,\n  node = 528)                                            # we subset the tree at node 528\n\nWerfen wir einen Blick auf den untergeordneten Baum 1:\n\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\n\n\n\n\n\n\n\n\nDu kannst auch auf der Grundlage einer bestimmten Stichprobe ein Subset erstellen, indem du angibst, wie viele Knoten du “rückwärts” einbeziehen möchtest. Wir unterteilen denselben Teil des Baums auf der Grundlage einer Stichprobe, in diesem Fall S17BD07692, und gehen 9 Knoten zurück. sub_tree2 Objekt:\n\nsub_tree2 &lt;- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels back defines how many nodes backwards from the sample tip you want to go\n\nWerfen wir einen Blick auf den Untergruppenbaum 2:\n\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n\n\n\n\n\n\n\n\nDu kannst deinen neuen Baum auch entweder als Newick-Typ oder sogar als Textdatei speichern, indem du die write.tree() Funktion von ape Paket:\n\n# to save in .nwk format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# to save in .txt format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')\n\n\n\nRotierende Knoten in einem Baum\nWie bereits erwähnt, können wir die Reihenfolge der Spitzen oder Knoten im Baum nicht ändern, da diese auf ihrer genetischen Verwandtschaft basiert und nicht visuell manipuliert werden kann. Aber wir können Zweige um die Knoten herum ausrotten, wenn das die Visualisierung erleichtert.\nZunächst zeichnen wir unseren neuen Teilbaum 2 mit Knotenbeschriftungen, um den Knoten auszuwählen, den wir bearbeiten wollen, und speichern ihn in einem ggtree-Plotobjekt p.\n\np &lt;- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # labels all the nodes in the tree\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\n\n\n\n\n\n\n\n\nDann können wir die Knoten bearbeiten, indem wir ggtree::rotate() oder ggtree::flip(): Hinweis: Um zu verdeutlichen, welche Knoten wir manipulieren, wenden wir zunächst die geom_hilight() Funktion aus ggtree um die Stichproben in den Knoten zu markieren, an denen wir interessiert sind, und das ggtree-Plot-Objekt in einem neuen Objekt zu speichern p1.\n\np1 &lt;- p + geom_hilight(  # highlights node 39 in blue, \"extend =\" allows us to define the length of the color block\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # highlights the node 37 in yellow\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # print\n\n\n\n\n\n\n\n\nJetzt können wir den Knoten 37 im Objekt drehen p1 drehen, so dass die Proben am Knoten 38 nach oben wandern. Wir speichern den gedrehten Baum in einem neuen Objekt p2.\n\np2 &lt;- ggtree::rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # print\n\n\n\n\n\n\n\n\nOder wir können den Befehl flip verwenden, um den Knoten 36 im Objekt zu drehen p1 und den Knoten 37 nach oben und den Knoten 39 nach unten verschieben. Wir speichern den umgedrehten Baum in einem neuen Objekt p3.\n\np3 &lt;-  flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # print\n\n\n\n\n\n\n\n\n\n\nBeispiel Teilbaum mit Beispieldaten-Anmerkung\nNehmen wir an, wir untersuchen den Cluster von Fällen mit klonaler Expansion, die 2017 und 2018 bei Knoten 39 in unserem Teilbaum aufgetreten sind. Wir fügen das Jahr der Stammisolierung sowie die Reisegeschichte hinzu und färben nach Land, um die Herkunft anderer eng verwandter Stämme zu sehen:\n\nggtree(sub_tree2) %&lt;+% sample_data +     # we use th %&lt;+% operator to link to the sample_data\n  geom_tiplab(                          # labels the tips of all branches with the sample name in the tree file\n    size = 2.5,\n    offset = 0.001,\n    align = TRUE) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # set the x-axis limits of our tree\n  geom_tippoint(aes(color=Country),     # color the tip point by continent\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                          # add isolation year as a text label at the tips\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    align = TRUE)+ \n  geom_tiplab(                          # add travel history as a text label at the tips, in red color\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    align = TRUE)+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # add plot title\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                    # add a label to the x-axis \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\nUnsere Beobachtung deutet auf ein Importereignis von Stämmen aus Asien hin, die dann im Laufe der Jahre in Belgien zirkulierten und unseren jüngsten Ausbruch verursacht zu haben scheinen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Phylogenetische Bäume</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.de.html#komplexere-bäume-hinzufügen-von-heatmaps-der-beispieldaten",
    "href": "new_pages/phylogenetic_trees.de.html#komplexere-bäume-hinzufügen-von-heatmaps-der-beispieldaten",
    "title": "38  Phylogenetische Bäume",
    "section": "Komplexere Bäume: Hinzufügen von Heatmaps der Beispieldaten",
    "text": "Komplexere Bäume: Hinzufügen von Heatmaps der Beispieldaten\nWir können komplexere Informationen wie das kategorische Vorhandensein antimikrobieller Resistenzgene und numerische Werte für die tatsächlich gemessene Resistenz gegen antimikrobielle Mittel in Form einer Heatmap hinzufügen, indem wir die ggtree::gheatmap() Funktion.\nZuerst müssen wir unseren Baum plotten (dies kann entweder linear oder kreisförmig sein) und ihn in einem neuen ggtree-Plot-Objekt speichern p: Wir werden den sub_tree aus Teil 3 verwenden).\n\np &lt;- ggtree(sub_tree2, branch.length='none', layout='circular') %&lt;+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\n\n\n\n\n\n\n\n\nZweitens bereiten wir unsere Daten vor. Um verschiedene Variablen mit neuen Farbschemata zu visualisieren, unterteilen wir unseren Datenrahmen auf die gewünschte Variable. Es ist wichtig, die Sample_ID als Rownamen hinzufügen, sonst können die Daten nicht dem Baum zugeordnet werden. tip.labels:\nIn unserem Beispiel wollen wir uns das Geschlecht und die Mutationen ansehen, die eine Resistenz gegen Ciprofloxacin, ein wichtiges Antibiotikum der ersten Wahl zur Behandlung von Shigella-Infektionen, verleihen könnten.\nWir erstellen einen Datenrahmen für das Geschlecht:\n\ngender &lt;- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) &lt;- sample_data$Sample_ID\n\nWir erstellen einen Datenrahmen für Mutationen im gyrA-Gen, die eine Ciprofloxacin-Resistenz verleihen:\n\ncipR &lt;- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) &lt;- sample_data$Sample_ID\n\nWir erstellen einen Datenrahmen für die gemessene minimale Hemmkonzentration (MIC) für Ciprofloxacin aus dem Labor:\n\nMIC_Cip &lt;- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) &lt;- sample_data$Sample_ID\n\nWir erstellen einen ersten Plot, indem wir eine binäre Heatmap für das Geschlecht zum phylogenetischen Baum hinzufügen und in einem neuen ggtree-Plot-Objekt speichern h1:\n\nh1 &lt;-  gheatmap(p, gender,                                 # we add a heatmap layer of the gender dataframe to our tree plot\n                offset = 10,                               # offset shifts the heatmap to the right,\n                width = 0.10,                              # width defines the width of the heatmap column,\n                color = NULL,                              # color defines the boarder of the heatmap columns\n         colnames = FALSE) +                               # hides column names for the heatmap\n  scale_fill_manual(name = \"Gender\",                       # define the coloring scheme and legend for gender\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nDann fügen wir Informationen über Mutationen im gyrA-Gen hinzu, die eine Resistenz gegen Ciprofloxacin verleihen:\nHinweis: Das Vorhandensein von chromosomalen Punktmutationen in WGS-Daten wurde zuvor mit dem von Zankari et al. entwickelten PointFinder-Tool bestimmt (siehe Referenz im Abschnitt “Zusätzliche Referenzen”).\nZunächst weisen wir unserem bestehenden Plot-Objekt ein neues Farbschema zu h1 zu und speichern es in einem neuen Objekt h2. So können wir die Farben für unsere zweite Variable in der Heatmap festlegen und ändern.\n\nh2 &lt;- h1 + new_scale_fill() \n\nDann fügen wir die zweite Heatmap-Ebene zu h2 und speichern die kombinierten Diagramme in einem neuen Objekt h3:\n\nh3 &lt;- gheatmap(h2, cipR,         # adds the second row of heatmap describing Ciprofloxacin resistance mutations\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh3\n\n\n\n\n\n\n\n\nWir wiederholen den obigen Vorgang, indem wir zunächst eine neue Farbskala-Ebene zu unserem bestehenden Objekt hinzufügen h3 und fügen dann die kontinuierlichen Daten über die minimale Hemmkonzentration (MHK) von Ciprofloxacin für jeden Stamm zu dem resultierenden Objekt hinzu h4 um das endgültige Objekt zu erstellen h5:\n\n# First we add the new coloring scheme:\nh4 &lt;- h3 + new_scale_fill()\n\n# then we combine the two into a new plot:\nh5 &lt;- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # here we define a gradient color scheme for the continuous variable of MIC\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5\n\n\n\n\n\n\n\n\nWir können die gleiche Übung für einen linearen Baum machen:\n\np &lt;- ggtree(sub_tree2) %&lt;+% sample_data +\n  geom_tiplab(size = 3) + # labels the tips\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\n\n\n\n\n\n\n\n\nZuerst fügen wir das Geschlecht hinzu:\n\nh1 &lt;-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nDann fügen wir Ciprofloxacin-Resistenzmutationen hinzu, nachdem wir eine weitere Farbschema-Ebene hinzugefügt haben:\n\nh2 &lt;- h1 + new_scale_fill()\nh3 &lt;- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n h3\n\n\n\n\n\n\n\n\nDann fügen wir die vom Labor ermittelte minimale Hemmstoffkonzentration (MIC) hinzu:\n\nh4 &lt;- h3 + new_scale_fill()\nh5 &lt;- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Phylogenetische Bäume</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.de.html#ressourcen",
    "href": "new_pages/phylogenetic_trees.de.html#ressourcen",
    "title": "38  Phylogenetische Bäume",
    "section": "38.5 Ressourcen",
    "text": "38.5 Ressourcen\nhttp://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Klade_Farben https://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html https://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\nEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: a novel web tool for WGS-based detection of antimicrobial resistance associated with chromosomal point mutations in bacterial pathogens, Journal of Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764-2768, https://doi.org/10.1093/jac/dkx217",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Phylogenetische Bäume</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.de.html",
    "href": "new_pages/interactive_plots.de.html",
    "title": "39  Interaktive Diagramme",
    "section": "",
    "text": "39.1 Vorbereitung",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Interaktive Diagramme</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.de.html#vorbereitung",
    "href": "new_pages/interactive_plots.de.html#vorbereitung",
    "title": "39  Interaktive Diagramme",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,       # import/export\n  here,      # filepaths\n  lubridate, # working with dates\n  plotly,    # interactive plots\n  scales,    # quick percents\n  tidyverse  # data management and visualization\n  ) \n\n\n\nBeginne mit einer ggplot()\nAuf dieser Seite gehen wir davon aus, dass du mit einer ggplot() Diagramm beginnst, das du in ein interaktives Diagramm umwandeln möchtest. Wir werden auf dieser Seite mehrere dieser Diagramme erstellen, indem wir den Fall linelist der auf vielen Seiten dieses Handbuchs verwendet wird.\n\n\nDaten importieren\nZunächst importieren wir die bereinigte Liste der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Liste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import case linelist \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Interaktive Diagramme</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.de.html#plot-mit-ggplotly",
    "href": "new_pages/interactive_plots.de.html#plot-mit-ggplotly",
    "title": "39  Interaktive Diagramme",
    "section": "39.2 Plot mit ggplotly()",
    "text": "39.2 Plot mit ggplotly()\nDie Funktion ggplotly() aus dem plotly Paket macht es einfach, eine ggplot() interaktiv zu machen. Speichere einfach deine ggplot() und leite es dann über die Pipe an die ggplotly() Funktion.\nUnten stellen wir eine einfache Linie dar, die den Anteil der Fälle zeigt, die in einer bestimmten Woche gestorben sind:\nZunächst erstellen wir einen zusammenfassenden Datensatz für jede epidemiologische Woche und den Prozentsatz der Fälle mit bekanntem Ausgang, die gestorben sind.\n\nweekly_deaths &lt;- linelist %&gt;%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %&gt;%  # create and group data by epiweek column\n  summarise(                                              # create new summary data frame:\n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # number of cases per group with known outcome\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # number of cases per group who died\n    pct_death = 100*(n_death / n_known_outcome)           # percent of cases with known outcome who died\n  )\n\nHier sind die ersten 50 Zeilen des weekly_deaths Datensatzes.\n\n\n\n\n\n\nDann erstellen wir das Diagramm mit ggplot2 und verwenden geom_line().\n\ndeaths_plot &lt;- ggplot(data = weekly_deaths)+            # begin with weekly deaths data\n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # make line \n\ndeaths_plot   # print\n\n\n\n\n\n\n\n\nWir können dies interaktiv machen, indem wir diesen Plot einfach an ggplotly() übergeben, wie unten gezeigt. Bewege deine Maus über die Linie, um die x- und y-Werte anzuzeigen. Du kannst das Diagramm zoomen und es verschieben. Außerdem siehst du oben rechts im Diagramm Symbole. Mit ihnen kannst du in der Reihenfolge:\n\nDie aktuelle Ansicht als PNG-Bild herunterladen\nVergrößern mit einer Auswahlbox\n“Schwenken” oder Bewegen über das Diagramm durch Klicken und Ziehen des Diagramms\nVergrößern, verkleinern oder zum Standardzoom zurückkehren\nAchsen auf Standardwerte zurücksetzen\n“Spike-Linien” ein-/ausschalten, d.h. gepunktete Linien, die sich vom interaktiven Punkt bis zur x- und y-Achse erstrecken\nEinstellen, ob Daten angezeigt werden, wenn du den Mauszeiger nicht über die Linie bewegst\n\n\ndeaths_plot %&gt;% plotly::ggplotly()\n\n\n\n\n\nGruppierte Daten arbeiten mit ggplotly() ebenfalls. Unten wird eine wöchentliche Epikurve erstellt, die nach Ergebnissen gruppiert ist. Die gestapelten Balken sind interaktiv. Versuche, auf die verschiedenen Elemente in der Legende zu klicken (sie erscheinen/verschwinden dann).\n\n# Make epidemic curve with incidence2 pacakge\np &lt;- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %&gt;% plot(fill = outcome)\n\n\n# Plot interactively  \np %&gt;% plotly::ggplotly()",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Interaktive Diagramme</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.de.html#änderungen",
    "href": "new_pages/interactive_plots.de.html#änderungen",
    "title": "39  Interaktive Diagramme",
    "section": "39.3 Änderungen",
    "text": "39.3 Änderungen\n\nDateigröße\nBeim Export in ein von R Markdown generiertes HTML (wie in diesem Buch!) möchtest du die Datengröße des Plots so gering wie möglich halten (in den meisten Fällen ohne negative Nebeneffekte). Dazu leitest du den interaktiven Plot einfach nach partial_bundle(), auch von plotly.\n\np &lt;- p %&gt;% \n  plotly::ggplotly() %&gt;%\n  plotly::partial_bundle()\n\n\n\nButtons\nEinige der Schaltflächen in einem Standard-Plotly sind überflüssig und können ablenken, deshalb kannst du sie entfernen. Das kannst du ganz einfach tun, indem du die Ausgabe in config() von plotly und geben an, welche Schaltflächen entfernt werden sollen. Im folgenden Beispiel geben wir im Voraus die Namen der zu entfernenden Schaltflächen an und übergeben sie an das Argument modeBarButtonsToRemove =. Wir setzen auch displaylogo = FALSE um das Plotly-Logo zu entfernen.\n\n## these buttons are distracting and we want to remove them\nplotly_buttons_remove &lt;- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np &lt;- p %&gt;%          # re-define interactive plot without these buttons\n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Interaktive Diagramme</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.de.html#wärmekacheln",
    "href": "new_pages/interactive_plots.de.html#wärmekacheln",
    "title": "39  Interaktive Diagramme",
    "section": "39.4 Wärmekacheln",
    "text": "39.4 Wärmekacheln\nDu kannst fast jede ggplot()Plot interaktiv machen, einschließlich Wärmekacheln. Auf der Seite über [Wärmeplots] kannst du nachlesen, wie du die folgende Grafik erstellst, die den Anteil der Tage pro Woche anzeigt, an denen bestimmte Einrichtungen Daten an ihre Provinz gemeldet haben.\nHier ist der Code, den wir an dieser Stelle nicht näher beschreiben werden.\n\n# import data\nfacility_count_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# aggregate data into Weeks for Spring district\nagg_weeks &lt;- facility_count_data %&gt;% \n  filter(District == \"Spring\",\n         data_date &lt; as.Date(\"2020-08-01\")) %&gt;% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %&gt;% \n  group_by(location_name, week, .drop = F) %&gt;%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;% \n  ungroup(location_name, week) %&gt;% \n  right_join(tidyr::expand(., week, location_name)) %&gt;% \n  mutate(week = aweek::week2date(week))\n\n# create plot\nmetrics_plot &lt;- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\nmetrics_plot # print\n\n\n\n\n\n\n\n\nIm Folgenden machen wir ihn interaktiv und passen ihn für einfache Schaltflächen und die Dateigröße an.\n\nmetrics_plot %&gt;% \n  plotly::ggplotly() %&gt;% \n  plotly::partial_bundle() %&gt;% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Interaktive Diagramme</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.de.html#ressourcen",
    "href": "new_pages/interactive_plots.de.html#ressourcen",
    "title": "39  Interaktive Diagramme",
    "section": "39.5 Ressourcen",
    "text": "39.5 Ressourcen\nPlotly ist nicht nur für R geeignet, sondern funktioniert auch gut mit Python (und eigentlich mit jeder anderen Data-Science-Sprache, da es in JavaScript geschrieben ist). Du kannst mehr darüber auf der Plotly-Website",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Interaktive Diagramme</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html",
    "href": "new_pages/rmarkdown.de.html",
    "title": "40  Berichte mit R Markdown",
    "section": "",
    "text": "40.1 Vorbereitung\nHintergrund zu R Markdown\nUm einige der Konzepte und Pakete zu erklären:\nZusammenfassend lässt sich sagen, dass der Prozess, der passiert im Hintergrund (du musst nicht alle diese Schritte kennen!) besteht darin, die .Rmd-Datei an knitr ein, das die R-Code-Bausteine ausführt und eine neue .md-Datei (Markdown) erstellt, die den R-Code und die gerenderte Ausgabe enthält. Die .md-Datei wird dann von pandoc verarbeitet, um das fertige Produkt zu erstellen: ein Microsoft Word-Dokument, eine HTML-Datei, ein Powerpoint-Dokument, ein PDF usw.\n(Quelle: https://rmarkdown.rstudio.com/authoring_quick_tour.html):\nInstallation\nUm eine R Markdown-Ausgabe zu erstellen, musst du Folgendes installiert haben:\npacman::p_load(tinytex)     # install tinytex package\ntinytex::install_tinytex()  # R command to install TinyTeX software",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#vorbereitung",
    "href": "new_pages/rmarkdown.de.html#vorbereitung",
    "title": "40  Berichte mit R Markdown",
    "section": "",
    "text": "Markdown ist eine “Sprache”, die es dir ermöglicht, ein Dokument in einfachem Text zu schreiben, das in HTML und andere Formate umgewandelt werden kann. Sie ist nicht spezifisch für R. Dateien, die in Markdown geschrieben sind, haben die Endung “.md”.\nR Markdown: ist eine Variante von Markdown, die spezifisch für R ist - Sie ermöglicht es dir, ein Dokument mit Markdown zu schreiben, um Text zu erzeugen und R-Code einzubetten und dessen Ausgaben anzuzeigen. R Markdown-Dateien haben die Erweiterung “.Rmd”.\nrmarkdown - das Paket rmarkdown: Dieses Paket wird von R verwendet, um die .Rmd-Datei in die gewünschte Ausgabe zu verwandeln. Der Schwerpunkt liegt auf der Umwandlung der Markdown (Text)-Syntax, daher brauchen wir auch…\nknitr Dieses R-Paket liest die Code-Bausteine, führt sie aus und fügt sie wieder in das Dokument ein. So werden neben dem Text auch Tabellen und Diagramme eingefügt.\nPandoc Schließlich konvertiert Pandoc die Ausgabe in Word/Pdf/Powerpoint usw. Es ist eine von R getrennte Software, wird aber automatisch mit RStudio installiert.\n\n\n\n\n\n\n\nDie rmarkdown Paket (knitr wird ebenfalls automatisch installiert)\nPandoc, das mit RStudio installiert werden sollte. Wenn du RStudio nicht verwendest, kannst du Pandoc hier herunterladen: http://pandoc.org.\nWenn du eine PDF-Ausgabe erzeugen möchtest (was etwas schwieriger ist), musst du LaTeX installieren. Für R Markdown-Benutzer, die LaTeX noch nicht installiert haben, empfehlen wir die Installation von TinyTeX (https://yihui.name/tinytex/). Du kannst die folgenden Befehle verwenden:",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#erste-schritte",
    "href": "new_pages/rmarkdown.de.html#erste-schritte",
    "title": "40  Berichte mit R Markdown",
    "section": "40.2 Erste Schritte",
    "text": "40.2 Erste Schritte\n\nInstalliere das R-Paket rmarkdown\nInstalliere das rmarkdown R-Paket. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(rmarkdown)\n\n\n\nStarten einer neuen Rmd-Datei\nÖffne in RStudio eine neue R-Markdown-Datei. Beginne mit “Datei”, dann “Neue Datei” und “R-Markdown…”.\n\n\n\n\n\n\n\n\n\nR Studio bietet dir einige Ausgabeoptionen zur Auswahl an. Im folgenden Beispiel wählen wir “HTML”, weil wir ein HTML-Dokument erstellen wollen. Der Titel und die Autorennamen sind nicht wichtig. Wenn der gewünschte Ausgabedokumenttyp nicht dabei ist, ist das kein Problem - du kannst einfach einen beliebigen Typ auswählen und ihn später im Skript ändern.\n\n\n\n\n\n\n\n\n\nDadurch wird ein neues .Rmd-Skript geöffnet.\n\n\nWichtig zu wissen\nDas Arbeitsverzeichnis\nDas Arbeitsverzeichnis einer Markdown-Datei befindet sich dort, wo die Rmd-Datei selbst gespeichert ist. Wenn sich das R-Projekt zum Beispiel im ~/Documents/projectX und die Rmd-Datei selbst befindet sich in einem Unterordner ~/Documents/projectX/markdownfiles/markdown.Rmd befindet, wird der Code read.csv(\"data.csv\") im Markdown nach einer csv-Datei im Ordner markdownfiles Ordner und nicht im Stammordner des Projekts, in dem Skripte innerhalb von Projekten normalerweise automatisch suchen würden.\nUm auf Dateien an anderer Stelle zu verweisen, musst du entweder den vollständigen Dateipfad angeben oder die hier Paket. Die hierPaket setzt das Arbeitsverzeichnis auf den Stammordner des R-Projekts und wird im Detail in der [R-Projekte] und erklärt. [Import und Export] Seiten dieses Handbuchs erklärt. Um zum Beispiel eine Datei namens “data.csv” aus dem PaketprojectX Ordner zu importieren, würde der Code lauten import(here(\"data.csv\")).\nBeachte, dass die Verwendung von setwd() in R Markdown-Skripten nicht empfohlen wird - sie gilt nur für den Codechunk, in dem sie geschrieben ist.\nArbeiten auf einem Laufwerk statt auf deinem Computer\nDa es bei R Markdown zu Problemen mit Pandoc kommen kann, wenn es auf einem freigegebenen Netzlaufwerk ausgeführt wird, wird empfohlen, den Ordner auf deinem lokalen Rechner zu erstellen, z. B. in einem Projekt unter “Eigene Dateien”. Wenn du Git verwendest (sehr empfehlenswert!), wirst du damit vertraut sein. Weitere Informationen findest du auf den Handbuchseiten zu [R auf Netzlaufwerken] und [Fehler und Hilfe].",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#r-markdown-komponenten",
    "href": "new_pages/rmarkdown.de.html#r-markdown-komponenten",
    "title": "40  Berichte mit R Markdown",
    "section": "40.3 R Markdown Komponenten",
    "text": "40.3 R Markdown Komponenten\nEin R Markdown-Dokument kann in RStudio genauso bearbeitet werden wie ein Standard-R-Skript. Wenn du ein neues R Markdown-Skript startest, versucht RStudio dir zu helfen, indem es eine Vorlage anzeigt, die die verschiedenen Abschnitte eines R Markdown-Skripts erklärt.\nDas folgende Bild wird angezeigt, wenn du ein neues Rmd-Skript startest, das eine HTML-Ausgabe erzeugen soll (wie im vorherigen Abschnitt).\n\n\n\n\n\n\n\n\n\nWie du sehen kannst, besteht eine Rmd-Datei aus drei grundlegenden Komponenten: YAML, Markdown-Text und R-Code-Bausteine.\nDiese werden erstellt und werden zu deiner Dokumentenausgabe. Siehe das Diagramm unten:\n\n\n\n\n\n\n\n\n\n\nYAML-Metadaten\nDie so genannten “YAML-Metadaten” oder einfach nur “YAML” befinden sich am Anfang des R Markdown-Dokuments. In diesem Abschnitt des Skripts wird deiner Rmd-Datei mitgeteilt, welche Art von Ausgabe erzeugt werden soll, welche Formatierung gewünscht wird und welche anderen Metadaten wie Titel, Autor und Datum des Dokuments angegeben werden sollen. Es gibt noch weitere Verwendungszwecke, die hier nicht erwähnt werden (aber im Abschnitt “Eine Ausgabe erzeugen”). Beachte, dass die Einrückung wichtig ist; Tabulatoren werden nicht akzeptiert, Leerzeichen hingegen schon.\nDieser Abschnitt muss mit einer Zeile beginnen, die nur drei Bindestriche enthält --- und muss mit einer Zeile mit drei Bindestrichen enden ---. YAML-Parameter kommen in key:value Paaren. Die Platzierung von Doppelpunkten in YAML ist wichtig - die key:value Paare werden durch Doppelpunkte getrennt (nicht durch Gleichheitszeichen!).\nDie YAML sollte mit den Metadaten für das Dokument beginnen. Die Reihenfolge dieser primären YAML-Parameter (nicht eingerückt) spielt keine Rolle. Zum Beispiel:\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"2024-02-21\"\nDu kannst R-Code in YAML-Werten verwenden, indem du ihn als Inline-Code schreibst (mit vorangestelltem r innerhalb von Back-Ticks), aber auch innerhalb von Anführungszeichen (siehe obiges Beispiel für date:).\nIn der obigen Abbildung sehen wir, dass die YAML-Datei Folgendes enthält, weil wir angeklickt haben, dass die Standardausgabe eine HTML-Datei sein soll output: html_document. Wir können dies aber auch ändern und sagen powerpoint_presentation oder word_document oder sogar pdf_document.\n\n\nText\nDies ist der Text deines Dokuments, einschließlich der Titel und Überschriften. Er ist in der Sprache “Markdown” geschrieben, die in vielen verschiedenen Programmen verwendet wird.\nIm Folgenden findest du die wichtigsten Methoden, um diesen Text zu schreiben. Eine ausführlichere Dokumentation findest du im R Markdown “Cheatsheet” auf der RStudio-Website.\n\nNeue Zeilen\nEinzigartig in R Markdown: Um eine neue Zeile zu beginnen, gibst du ein zwei Leerzeichen* am Ende der vorherigen Zeile und dann Enter/Return.\n\n\nFall\nUmfasse deinen normalen Text mit diesen Zeichen, um zu ändern, wie er in der Ausgabe erscheint.\n\nUnterstriche (_text_) oder einzelne Sternchen (*text*) zu kursiv zu setzen\nDoppelte Sternchen (**text**) für fetten Text\nRückwärtshaken (text), um Text als Code anzuzeigen\n\nDas tatsächliche Aussehen der Schriftart kann durch die Verwendung bestimmter Vorlagen (die in den YAML-Metadaten angegeben werden; siehe Beispieltabs) festgelegt werden.\n\n\nFarbe\nEs gibt keinen einfachen Mechanismus, um die Farbe von Text in R Markdown zu ändern. Ein Workaround, WENN deine Ausgabe eine HTML-Datei ist ist es, eine HTML-Zeile in den Markdown-Text einzufügen. Der folgende HTML-Code druckt eine Textzeile in fetter roter Schrift.\n&lt;span style=\"color: red;\"&gt;**_DANGER:_** This is a warning.&lt;/span&gt;  \nGEFAHR! Dies ist eine Warnung.\n\n\nTitel und Überschriften\nEin Rautensymbol in einem Textteil eines R Markdown-Skripts erzeugt eine Überschrift. Das ist etwas anderes als in einem Stück R-Code im Skript, in dem ein Raute-Symbol ein Mechanismus zum Kommentieren/Annotieren/Deaktivieren ist, wie in einem normalen R-Skript.\nVerschiedene Überschriftenebenen werden mit einer unterschiedlichen Anzahl von Rautensymbolen am Anfang einer neuen Zeile festgelegt. Ein Rautensymbol ist ein Titel oder eine erste Überschrift. Zwei Rautensymbole sind eine Überschrift der zweiten Ebene. Überschriften der dritten und vierten Ebene können mit immer mehr Rautensymbolen erstellt werden.\n# First-level heading / title\n\n## Second level heading  \n\n### Third-level heading\n\n\nAufzählungszeichen und Nummerierung\nVerwende Sternchen (*), um eine Aufzählungsliste zu erstellen. Beende den vorherigen Satz, gib zwei Leerzeichen ein, Enter/Return zweimal und beginne dann deine Aufzählungspunkte. Füge ein Leerzeichen zwischen dem Sternchen und deinem Aufzählungstext ein. Nach jedem Aufzählungszeichen gibst du zwei Leerzeichen ein und dann Enter/Return. Unteraufzählungen funktionieren genauso, werden aber eingerückt. Zahlen funktionieren genauso, aber statt eines Sternchens schreibst du 1), 2), usw. So könnte der Text deines R Markdown-Skripts aussehen.\nHere are my bullets (there are two spaces after this colon):  \n\n* Bullet 1 (followed by two spaces and Enter/Return)  \n* Bullet 2 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 1 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 2 (followed by two spaces and Enter/Return)  \n  \n\n\nText auskommentieren\nDu kannst R Markdown-Text auskommentieren, genauso wie du das “#” verwenden kannst, um eine Zeile R-Code in einem R Chunk auszukommentieren. Markiere einfach den Text und drücke Strg+Umschalt+c (Cmd+Umschalt+c für Mac). Der Text ist dann von Pfeilen umgeben und wird grün. Er wird nicht in deiner Ausgabe erscheinen.\n\n\n\n\n\n\n\n\n\n\n\n\nCode-Blöcke\nDie Abschnitte des Skripts, in denen der R-Code ausgeführt wird, werden “Chunks” genannt. Hier kannst du Pakete laden, Daten importieren und die eigentliche Datenverwaltung und Visualisierung durchführen. Da es viele Code-Chunks geben kann, können sie dir helfen, deinen R-Code in Teile zu gliedern, die vielleicht mit Text durchsetzt sind. Zu beachten: Diese “Chunks” haben eine etwas andere Hintergrundfarbe als der erzählende Teil des Dokuments.\nJeder Chunk wird mit einer Zeile eröffnet, die mit drei Back-Ticks beginnt, und geschweiften Klammern, die Parameter für den Chunk enthalten ({ }). Der Chunk endet mit drei weiteren Back-Ticks.\nDu kannst einen neuen Chunk erstellen, indem du ihn selbst eintippst, die Tastenkombination “Strg + Alt + i” (bzw. Cmd + Shift + r beim Mac) verwendest oder auf das grüne Symbol “Neuen Codechunk einfügen” oben in deinem Skripteditor klickst.\nEinige Hinweise zum Inhalt der geschweiften Klammern { }:\n\nSie beginnen mit “r”, um anzuzeigen, dass der Sprachname innerhalb des Chunks R ist.\nNach dem “r” kannst du optional einen “Namen” für den Chunk schreiben - das ist nicht notwendig, kann dir aber helfen, deine Arbeit zu organisieren. Wenn du deine Chunks benennst, solltest du IMMER eindeutige Namen verwenden, sonst beschwert sich R, wenn du versuchst zu rendern.\nDie geschweiften Klammern können auch andere Optionen enthalten, z. B. tag=value geschrieben werden, wie zum Beispiel:\neval = FALSE um den R-Code nicht auszuführen\necho = FALSE um den R-Quellcode des Chunks nicht im Ausgabedokument zu drucken\nwarning = FALSE um Warnungen, die durch den R-Code erzeugt werden, nicht zu drucken\nmessage = FALSE um keine vom R-Code erzeugten Meldungen zu drucken\ninclude = entweder TRUE/FALSE, ob Chunk-Ausgaben (z. B. Plots) in das Dokument aufgenommen werden sollen\nout.width = und out.height = - bieten mit Stil out.width = \"75%\"\nfig.align = \"center\" anpassen, wie eine Abbildung auf der Seite ausgerichtet ist\nfig.show='hold' wenn dein Stück mehrere Zahlen druckt und du willst, dass sie nebeneinander gedruckt werden (Paar mit out.width = c(\"33%\", \"67%\"). Kann auch gesetzt werden als fig.show='asis' setzen, um sie unterhalb des Codes anzuzeigen, der sie erzeugt, 'hide' zu verbergen, oder 'animate' mehrere zu einer Animation zu verketten.\nEin Chunk-Header muss in einer Zeile\nVersuche, Punkte, Unterstriche und Leerzeichen zu vermeiden. Verwende stattdessen Bindestriche ( - ), wenn du ein Trennzeichen brauchst.\n\nLies ausführlicher über die knitr Optionen hier.\nEinige der oben genannten Optionen kannst du per Mausklick über die Einstellungsschaltflächen oben rechts im Chunk konfigurieren. Hier kannst du angeben, welche Teile des Chunks das gerenderte Dokument enthalten soll, nämlich den Code, die Ausgaben und die Warnungen. Die Einstellungen werden in den geschweiften Klammern angegeben, z. B. echo=FALSE wenn du angibst, dass du “nur die Ausgaben anzeigen” möchtest.\n\n\n\n\n\n\n\n\n\nAußerdem gibt es oben rechts in jedem Chunk zwei Pfeile, mit denen du den Code innerhalb eines Chunks oder den gesamten Code in den vorherigen Chunks ausführen kannst. Fahre mit dem Mauszeiger über sie, um zu sehen, was sie bewirken.\nDamit globale Optionen auf alle Chunks im Skript angewendet werden, kannst du sie in deinem allerersten R-Code-Chunk im Skript einrichten. Damit zum Beispiel nur die Ausgaben für jeden Codechunk angezeigt werden und nicht der Code selbst, kannst du diesen Befehl in den R-Codechunk einfügen:\n\nknitr::opts_chunk$set(echo = FALSE) \n\n\nR-Code im Text\nDu kannst auch minimalen R-Code in Backticks einfügen. Innerhalb der Back-Ticks beginnst du den Code mit “r” und einem Leerzeichen, damit RStudio weiß, dass es sich um R-Code handelt. Siehe das Beispiel unten.\nDas folgende Beispiel zeigt mehrere Überschriftenebenen, Aufzählungszeichen und verwendet R-Code für das aktuelle Datum (Sys.Date()) in ein gedrucktes Datum umgewandelt.\n\n\n\n\n\n\n\n\n\nDas obige Beispiel ist einfach (Anzeige des aktuellen Datums), aber mit der gleichen Syntax kannst du auch Werte anzeigen, die durch komplexeren R-Code erzeugt wurden (z. B. zur Berechnung von Minimum, Median und Maximum einer Spalte). Du kannst auch R-Objekte oder Werte einbinden, die zuvor in R-Code-Blöcken erstellt wurden.\nDas folgende Skript berechnet zum Beispiel den Anteil der Fälle, die jünger als 18 Jahre sind, indem es tidyverse Funktionen, und erstellt die Objekte less18, total, und less18prop. Dieser dynamische Wert wird in den nachfolgenden Text eingefügt. Wir sehen, wie es aussieht, wenn es in einem Word-Dokument gestrickt ist.\n\n\n\n\n\n\n\n\n\n\n\n\nBilder\nDu kannst Bilder auf zwei Arten in dein R Markdown einfügen:\n\n![](\"path/to/image.png\")  \n\nWenn das oben genannte nicht funktioniert, versuche es mit knitr::include_graphics()\n\nknitr::include_graphics(\"path/to/image.png\")\n\n(denk daran, dass dein Dateipfad mit der Option hier Paket)\n\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))\n\n\n\nTische\nErstelle eine Tabelle mit Bindestrichen ( -) und Balken ( |). Die Anzahl der Bindestriche vor/zwischen den Balken bestimmt die Anzahl der Leerzeichen in der Zelle, bevor der Text umbrochen wird.\nColumn 1 |Column  2 |Column 3\n---------|----------|--------\nCell A   |Cell B    |Cell C\nCell D   |Cell E    |Cell F\nDer obige Code erzeugt die unten stehende Tabelle:\n\n\n\nSpalte 1\nSpalte 2\nSpalte 3\n\n\n\n\nZelle A\nZelle B\nZelle C\n\n\nZelle D\nZelle E\nZelle F\n\n\n\n\n\nTabellierte Abschnitte\nFür HTML-Ausgaben kannst du die Abschnitte in “Registerkarten” anordnen. Füge einfach .tabset in die geschweiften Klammern { } die gesetzt werden nach einer Überschrift. Alle Unterüberschriften unter dieser Überschrift (bis zu einer weiteren Überschrift der gleichen Ebene) werden als Registerkarten angezeigt, durch die der Benutzer klicken kann. Mehr lesen hier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDu kannst eine zusätzliche Option hinzufügen .tabset-pills nach .tabset hinzufügen, um den Tabs selbst ein “geflochtenes” Aussehen zu geben. Beachte, dass die Strg+f-Suchfunktion bei der Anzeige der HTML-Ausgabe mit Registerkarten nur die “aktiven” Registerkarten durchsucht, nicht die versteckten Registerkarten.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#dateistruktur",
    "href": "new_pages/rmarkdown.de.html#dateistruktur",
    "title": "40  Berichte mit R Markdown",
    "section": "40.4 Dateistruktur",
    "text": "40.4 Dateistruktur\nEs gibt verschiedene Möglichkeiten, dein R Markdown und die dazugehörigen R Skripte zu strukturieren. Jede hat Vor- und Nachteile:\n\nEigenständiger R Markdown - alles, was für den Bericht benötigt wird, wird in den R Markdown importiert oder erstellt\n\nAndere Dateien als Quelle - Du kannst externe R-Skripte mit der source() Befehl ausführen und ihre Ausgaben in der Rmd-Datei verwenden.\nChild-Skripte - ein alternativer Mechanismus für source()\n\neine “runfile” zu verwenden - Befehle in einem R-Skript auszuführen vor der vor dem Rendern des R Markdowns\n\n\nEigenständiges Rmd\nFür einen relativ einfachen Bericht kannst du dein R Markdown-Skript so organisieren, dass es “in sich geschlossen” ist und keine externen Skripte einbezieht.\nAlles, was du zum Ausführen des R Markdown-Skripts brauchst, wird in die Rmd-Datei importiert oder erstellt, einschließlich aller Code-Bausteine und des Ladens von Paketen. Dieser “in sich geschlossene” Ansatz eignet sich, wenn du nicht viele Daten verarbeiten musst (z. B. wenn du eine saubere oder halbwegs saubere Datendatei einbringst) und das Rendern des R Markdowns nicht zu lange dauert.\nIn diesem Szenario könnte ein logischer Aufbau des R Markdown-Skripts so aussehen:\n\nGlobal setzen knitr Optionen\nPakete laden\nDaten importieren\nDaten verarbeiten\nAusgaben produzieren (Tabellen, Diagramme usw.)\nSpeichern der Ergebnisse, falls zutreffend (.csv, .png, etc.)\n\n\nQuelle andere Dateien\nEine Variante des “in sich geschlossenen” Ansatzes besteht darin, dass R Markdown-Codeabschnitte andere R-Skripte “quellen” (ausführen) lassen. Dadurch wird dein R Markdown-Skript weniger unübersichtlich, einfacher und leichter zu organisieren. Es kann auch hilfreich sein, wenn du die endgültigen Zahlen am Anfang des Berichts anzeigen möchtest. Bei diesem Ansatz fasst das endgültige R Markdown-Skript einfach die vorverarbeiteten Ausgaben in einem Dokument zusammen.\nEine Möglichkeit, dies zu tun, besteht darin, die R-Skripte (Dateipfad und -name mit Erweiterung) an den Basis R-Befehl source().\n\nsource(\"your-script.R\", local = knitr::knit_global())\n# or sys.source(\"your-script.R\", envir = knitr::knit_global())\n\nBeachten Sie, dass bei der Verwendung von source() innerhalb von der R Markdown, werden die externen Dateien trotzdem ausgeführt während des Renderns deiner Rmd-Datei. Jedes Skript wird also jedes Mal ausgeführt, wenn du den Bericht renderst. Daher ist es wichtig, dass diese source() Befehle innerhalb von R Markdown zu verwenden, beschleunigt die Laufzeit nicht und hilft auch nicht bei der Fehlersuche, da beim Erstellen des R Markdowns immer noch Fehler ausgegeben werden.\nEine Alternative ist die Verwendung der child = knitr Option. MEHR ZU TUN ERKLÄREN\nDu musst dir über verschiedene R Umgebungen. Objekte, die in einer Umgebung erstellt werden, stehen nicht unbedingt in der Umgebung zur Verfügung, die von R Markdown verwendet wird.\n\n\n\nRunfile\nBei diesem Ansatz wird das R-Skript verwendet, das die render() Befehl(e) enthält, um Objekte vorzubearbeiten, die in den R-Markdown einfließen.\nDu kannst zum Beispiel die Pakete laden, die Daten laden und bereinigen und sogar die gewünschten Diagramme erstellen, bevor du render(). Diese Schritte können im R-Skript oder in anderen Skripten ausgeführt werden, die als Quelle dienen. Solange diese Befehle in der gleichen RStudio-Sitzung ausgeführt und die Objekte in der Umgebung gespeichert werden, können die Objekte innerhalb des Rmd-Inhalts aufgerufen werden. Der R-Markdown selbst wird dann nur noch für den letzten Schritt verwendet - um die Ausgabe mit allen vorverarbeiteten Objekten zu erzeugen. So ist es viel einfacher, Fehler zu beheben, wenn etwas schief geht.\nDieser Ansatz ist aus den folgenden Gründen hilfreich:\n\nInformativere Fehlermeldungen - diese Meldungen werden aus dem R-Skript generiert, nicht aus dem R-Markdown. R Markdown-Fehlermeldungen sagen dir in der Regel, bei welchem Chunk ein Problem aufgetreten ist, aber nicht, bei welcher Zeile.\nFalls zutreffend, kannst du lange Verarbeitungsschritte vor dem render() Befehls ausführen - sie werden dann nur einmal ausgeführt.\n\nIn dem folgenden Beispiel haben wir ein separates R-Skript, in dem wir eine Vorverarbeitung data Objekt in die R-Umgebung einfügen und dann die “create_output.Rmd” mit render().\n\ndata &lt;- import(\"datafile.csv\") %&gt;%       # Load data and save to environment\n  select(age, hospital, weight)          # Select limited columns\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Create Rmd file\n\n\n\nOrdnerstruktur\nDer Workflow betrifft auch die allgemeine Ordnerstruktur, z. B. einen “Output”-Ordner für erstellte Dokumente und Zahlen und “Data”- oder “Input”-Ordner für bereinigte Daten. Wir gehen hier nicht weiter ins Detail, aber sieh dir die [Organisieren von Routineberichten] Seite.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#das-dokument-erstellen",
    "href": "new_pages/rmarkdown.de.html#das-dokument-erstellen",
    "title": "40  Berichte mit R Markdown",
    "section": "40.5 Das Dokument erstellen",
    "text": "40.5 Das Dokument erstellen\nDu kannst das Dokument auf die folgenden Arten erstellen:\n\nManuell durch Drücken der Schaltfläche “Stricken” oben im RStudio-Skripteditor (schnell und einfach)\nFühre die render() Befehl (wird außerhalb des R Markdown-Skripts ausgeführt)\n\n\nOption 1: Schaltfläche “Stricken\nWenn du die Rmd-Datei geöffnet hast, drückst du auf das Symbol/den Button “Stricken” oben in der Datei.\nR Studio zeigt den Fortschritt in einer Registerkarte “R Markdown” neben deiner R-Konsole an. Das Dokument wird automatisch geöffnet, wenn es fertig ist.\nDas Dokument wird im selben Ordner wie dein R Markdown-Skript und unter demselben Dateinamen (abgesehen von der Erweiterung) gespeichert. Das ist natürlich nicht ideal für die Versionskontrolle (es wird bei jedem Stricken überschrieben, es sei denn, du verschiebst es manuell), da du die Datei dann eventuell selbst umbenennen musst (z. B. um ein Datum hinzuzufügen).\nDas ist die RStudio-Verknüpfungstaste für die render() Funktion von rmarkdown. Dieser Ansatz ist nur mit einem in sich geschlossenen R-Markdown kompatibel, bei dem alle benötigten Komponenten in der Datei vorhanden sind oder von dort bezogen werden.\n\n\n\n\n\n\n\n\n\n\n\nOption 2: render() Befehl\nEine andere Möglichkeit, deine R Markdown-Ausgabe zu erzeugen, ist die Ausführung des render() Funktion (aus dem rmarkdown Paket). Du musst diesen Befehl ausführen außerhalb von dem R Markdown-Skript ausführen - also entweder in einem separaten R-Skript (oft “run file” genannt) oder als eigenständiger Befehl in der R-Konsole.\n\nrmarkdown::render(input = \"my_report.Rmd\")\n\nWie bei “knit” speichern die Standardeinstellungen die Rmd-Ausgabe im gleichen Ordner wie das Rmd-Skript und mit dem gleichen Dateinamen (außer der Dateierweiterung). Wenn du zum Beispiel “mein_bericht.rmd” strickst, wird daraus “mein_bericht.docx”, wenn du in ein Word-Dokument strickst. Wenn du jedoch render() hast du die Möglichkeit, andere Einstellungen zu verwenden. render() kann unter anderem folgende Argumente akzeptieren:\n\noutput_format = Das ist das Ausgabeformat, in das konvertiert werden soll (z. B. \"html_document\", \"pdf_document\", \"word_document\", oder \"all\"). Du kannst dies auch in der YAML innerhalb des R Markdown-Skripts angeben.\noutput_file = Dies ist der Name der Ausgabedatei (und der Dateipfad). Diese kann über R-Funktionen wie here() oder erstellt werden. str_glue() wie unten gezeigt.\noutput_dir = Dies ist ein Ausgabeverzeichnis (Ordner) zum Speichern der Datei. So kannst du ein anderes Verzeichnis wählen als das, in dem die Rmd-Datei gespeichert wird.\noutput_options = Du kannst eine Liste von Optionen angeben, die die Optionen in der Skript-YAML überschreiben (z.B. )\noutput_yaml = Du kannst den Pfad zu einer .yml-Datei angeben, die YAML-Spezifikationen enthält\nparams = Siehe den Abschnitt über Parameter weiter unten\nSiehe die vollständige Liste hier\n\nUm die Versionskontrolle zu verbessern, speichert der folgende Befehl zum Beispiel die Ausgabedatei in einem Unterordner “outputs” mit dem aktuellen Datum im Dateinamen. Um den Dateinamen zu erstellen, muss die Funktion str_glue() aus dem stringrPaket wird verwendet, um statische Strings (einfach geschrieben) mit dynamischem R-Code (in geschweiften Klammern geschrieben) zu verbinden. Wenn heute zum Beispiel der 10. April 2021 ist, lautet der Dateiname “Report_2021-04-10.docx”. Siehe die Seite über [Zeichen und Zeichenketten] für weitere Details überstr_glue().\n\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) \n\nWährend die Datei gerendert wird, zeigt dir die RStudio-Konsole den Rendering-Fortschritt bis zu 100 % und eine abschließende Meldung an, dass das Rendering abgeschlossen ist.\n\n\nOptionen 3: reportfactory Paket\nDas R-Paket reportfactory bietet eine alternative Methode zum Organisieren und Kompilieren von R Markdown-Berichten für Szenarien, in denen du routinemäßig Berichte erstellst (z.B. täglich, wöchentlich…). Es erleichtert die Kompilierung mehrerer R Markdown-Dateien und die Organisation ihrer Ergebnisse. Im Wesentlichen stellt es eine “Fabrik” zur Verfügung, von der aus du die R Markdown-Berichte ausführen kannst. Du erhältst automatisch Ordner mit Datums- und Zeitstempeln für die Ausgaben und hast eine “leichte” Versionskontrolle.\nMehr über diesen Arbeitsablauf erfährst du auf der Seite über [Organisieren von Routineberichten].",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#parametrisierte-berichte",
    "href": "new_pages/rmarkdown.de.html#parametrisierte-berichte",
    "title": "40  Berichte mit R Markdown",
    "section": "40.6 Parametrisierte Berichte",
    "text": "40.6 Parametrisierte Berichte\nMit Hilfe von Parametern kannst du einen Bericht dynamisch gestalten, so dass er mit bestimmten Einstellungen ausgeführt werden kann (z. B. mit einem bestimmten Datum oder Ort oder mit bestimmten Strickoptionen). Im Folgenden konzentrieren wir uns auf die Grundlagen, aber es gibt noch mehr Details online über parametrisierte Berichte.\nNehmen wir die Ebola-Lineliste als Beispiel und sagen wir, wir wollen jeden Tag einen Standard-Überwachungsbericht für jedes Krankenhaus erstellen. Wir zeigen, wie man dies mit Hilfe von Parametern erreichen kann.\nWichtig: Dynamische Berichte sind auch ohne die formale Parameterstruktur möglich (ohne params:), indem du einfache R-Objekte in einem angrenzenden R-Skript verwendest. Dies wird am Ende dieses Abschnitts erklärt.\n\nParameter setzen\nDu hast mehrere Möglichkeiten, um Parameterwerte für deine R Markdown-Ausgabe festzulegen.\n\nOption 1: Parameter innerhalb von YAML festlegen\nBearbeite die YAML und füge eine params: mit eingerückten Anweisungen für jeden Parameter, den du definieren willst. In diesem Beispiel erstellen wir Parameter date und hospital an, für die wir Werte festlegen. Diese Werte können sich jedes Mal ändern, wenn der Bericht ausgeführt wird. Wenn du die Schaltfläche “Stricken” verwendest, um die Ausgabe zu erstellen, haben die Parameter diese Standardwerte. Ebenso, wenn du die Schaltfläche render() verwendest, haben die Parameter diese Standardwerte, es sei denn, du hast in der render() Befehl angegeben.\n---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Central Hospital\n---\nIm Hintergrund sind diese Parameterwerte in einer Nur-Lese-Liste namens params. So kannst du die Parameterwerte in den R-Code einfügen, wie du ein anderes R-Objekt/einen anderen Wert in deiner Umgebung einfügen würdest. Gib einfach ein params$ gefolgt von dem Parameternamen ein. Zum Beispiel params$hospital für den Namen des Krankenhauses (standardmäßig “Zentralkrankenhaus”).\nBeachte, dass Parameter auch Werte enthalten können true oder false enthalten können, und daher können diese in deine knitr Optionen für einen R-Chunk enthalten. Du kannst zum Beispiel festlegen {r, eval=params$run} anstelle von {r, eval=FALSE} setzen, und nun hängt es vom Wert eines Parameters ab, ob der Chunk läuft oder nicht run:.\nBeachte, dass Parameter, die Datumsangaben sind, als String eingegeben werden. Also für params$date im R-Code interpretiert werden kann, muss er wahrscheinlich mit as.Date() oder einer ähnlichen Funktion in die Klasse Date umgewandelt werden.\n\n\nOption 2: Parameter innerhalb von render()\nWie bereits erwähnt, können Sie alternativ zum Drücken der Schaltfläche “Stricken” die Ausgabe mit dem Befehl render() Funktion in einem separaten Skript auszuführen. Im letzteren Fall kannst du die Parameter, die in diesem Rendering verwendet werden sollen, in der params = Argument von render().\nBeachten Sie, dass alle hier angegebenen Parameterwerte überschreiben ihre Standardwerte, wenn sie in die YAML geschrieben werden. Wir schreiben die Werte in Anführungszeichen, da sie in diesem Fall als Zeichen/String-Werte definiert werden sollten.\nDer folgende Befehl rendert “surveillance_report.Rmd”, gibt einen dynamischen Ausgabedateinamen und -ordner an und stellt eine list() von zwei Parametern und deren Werten an das Argument params =.\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))\n\n\n\nOption 3: Parameter über eine grafische Benutzeroberfläche festlegen\nWenn du ein interaktiveres Gefühl haben möchtest, kannst du auch die grafische Benutzeroberfläche (GUI) verwenden, um manuell Werte für Parameter auszuwählen. Dazu klickst du auf das Dropdown-Menü neben der Schaltfläche “Stricken” und wählst “Mit Parametern stricken”.\nEs erscheint ein Pop-up-Fenster, in das du die Werte für die Parameter eingeben kannst, die in der YAML des Dokuments festgelegt sind.\n\n\n\n\n\n\n\n\n\nDas Gleiche kannst du mit einer render() Befehl erreichen, indem du params = \"ask\" wie unten gezeigt.\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = \"ask\")\n\nBei der Eingabe von Werten in dieses Pop-up-Fenster können jedoch Fehler und Rechtschreibfehler auftreten. Vielleicht möchtest du die Werte, die über Dropdown-Menüs eingegeben werden können, einschränken. Das kannst du tun, indem du in der YAML mehrere Spezifikationen für jeden params: Eintrag hinzufügst.\n\nlabel: ist wie der Titel für dieses bestimmte Dropdown-Menü\nvalue: ist der Standardwert (Startwert)\ninput: eingestellt auf select für das Dropdown-Menü\nchoices: Gib die in Frage kommenden Werte in das Dropdown-Menü ein\n\nIm Folgenden werden diese Angaben für die hospital Parameter.\n---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: \"Town:\"\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---\nBeim Stricken (entweder über die Schaltfläche “Stricken mit Parametern” oder durch render()), enthält das Pop-up-Fenster Dropdown-Optionen, aus denen du auswählen kannst.\n\n\n\n\n\n\n\n\n\n\n\n\nParametrisiertes Beispiel\nDer folgende Code erstellt Parameter für date und hospital die in R Markdown als Parameter verwendet werden params$date und params$hospital verwendet werden.\nIn der resultierenden Berichtsausgabe siehst du, wie die Daten nach dem spezifischen Krankenhaus gefiltert werden und der Titel der Grafik auf das richtige Krankenhaus und Datum verweist. Wir verwenden hier die Datei “linelist_cleaned.rds”, aber es wäre besonders sinnvoll, wenn die Lineliste selbst auch einen Datumsstempel enthielte, um sie an das parametrisierte Datum anzupassen.\n\n\n\n\n\n\n\n\n\nWenn du das strickst, erhältst du die endgültige Ausgabe mit der Standardschriftart und dem Standardlayout.\n\n\n\n\n\n\n\n\n\n\n\nParametrisierung ohne params\nWenn du eine R Markdown-Datei mit render() aus einem separaten Skript wiedergibst, kannst du die Auswirkungen der Parametrisierung auch ohne die Verwendung der params: Funktionalität.\nZum Beispiel kann in der R-Skript das die render() Befehl enthält, kannst du einfach definieren hospital und date als zwei R-Objekte (Werte) vor dem render() Befehl. Im R Markdown müsstest du nicht mit einem params: Abschnitt in der YAML zu haben, und wir würden uns auf die date Objekt verweisen, anstatt params$date und hospital statt params$hospital.\n\n# This is a R script that is separate from the R Markdown\n\n# define R objects\nhospital &lt;- \"Central Hospital\"\ndate &lt;- \"2021-04-10\"\n\n# Render the R markdown\nrmarkdown::render(input = \"create_output.Rmd\") \n\nWenn du diesen Ansatz verfolgst, kannst du nicht “mit Parametern stricken”, die GUI verwenden oder Strickoptionen in die Parameter aufnehmen. Allerdings ermöglicht es einen einfacheren Code, was von Vorteil sein kann.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#schleifenberichte",
    "href": "new_pages/rmarkdown.de.html#schleifenberichte",
    "title": "40  Berichte mit R Markdown",
    "section": "40.7 Schleifenberichte",
    "text": "40.7 Schleifenberichte\nEs kann sein, dass wir einen Bericht mehrmals ausführen und dabei die Eingabeparameter variieren möchten, um einen Bericht für jede Gerichtsbarkeit/Einheit zu erstellen. Dies kann mit den Tools für Iterationdie auf der Seite über Iteration ausführlich erklärt werden . [Iteration, Schleifen und Listen]. Zu den Optionen gehören diepurrr Paket, oder die Verwendung eines for-Schleife wie unten erklärt.\nIm Folgenden verwenden wir eine einfache for-Schleife um einen Überwachungsbericht für alle Krankenhäuser von Interesse zu erstellen. Dies geschieht mit einem einzigen Befehl (anstatt die Krankenhausparameter manuell einzeln zu ändern). Der Befehl zum Erstellen der Berichte muss in einem separaten Skript enthalten sein außerhalb von dem Bericht Rmd. Dieses Skript enthält auch definierte Objekte zum “Durchschleifen” - das heutige Datum und einen Vektor von Krankenhausnamen zum Durchschleifen.\n\nhospitals &lt;- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \n\nDiese Werte geben wir dann einzeln in die render() eine Schleife ein, die den Befehl für jeden Wert in der Liste einmal ausführt hospitals Vektor. Der Buchstabe i steht für die Indexposition (1 bis 4) des Krankenhauses, das gerade in dieser Iteration verwendet wird, so dass hospital_list[1] wäre “Zentralkrankenhaus”. Diese Information wird an zwei Stellen in der render() Befehl:\n\nAn den Dateinamen, so dass der Dateiname der ersten Iteration, wenn sie am 10. April 2021 erstellt wird, “Bericht_Zentralkrankenhaus_2021-04-10.docx” wäre und im Unterordner “output” des Arbeitsverzeichnisses gespeichert würde.\nAn params = so dass die Rmd den Krankenhausnamen intern verwendet, wenn die params$hospital Wert aufgerufen wird (z. B. um den Datensatz nur auf ein bestimmtes Krankenhaus zu filtern). In diesem Beispiel würden vier Dateien erstellt werden - eine für jedes Krankenhaus.\n\n\nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#vorlagen",
    "href": "new_pages/rmarkdown.de.html#vorlagen",
    "title": "40  Berichte mit R Markdown",
    "section": "40.8 Vorlagen",
    "text": "40.8 Vorlagen\nMit Hilfe einer Dokumentvorlage, die alle gewünschten Formatierungen enthält, kannst du das Aussehen der Rmd-Ausgabe anpassen. Du kannst zum Beispiel eine MS Word- oder Powerpoint-Datei erstellen, die Seiten/Folien mit den gewünschten Abmessungen, Wasserzeichen, Hintergründen und Schriftarten enthält.\n\nWord-Dokumente\nUm eine Vorlage zu erstellen, fängst du ein neues Word-Dokument an (oder verwendest eine bestehende Ausgabe mit der für dich passenden Formatierung) und bearbeitest die Schriftarten, indem du die Stile definierst. Unter Stil verweisen die Überschriften 1, 2 und 3 auf die verschiedenen Markdown-Kopfebenen (# Header 1, ## Header 2 und ### Header 3 bzw.). Klicke mit der rechten Maustaste auf die Formatvorlage und klicke auf “Ändern”, um die Formatierung der Schrift und des Absatzes zu ändern (z. B. kannst du vor bestimmten Formatvorlagen Seitenumbrüche einfügen, um die Abstände zu verbessern). Andere Aspekte des Word-Dokuments wie Ränder, Seitengröße, Überschriften usw. können wie in einem normalen Word-Dokument geändert werden, in dem du direkt arbeitest.\n\n\n\n\n\n\n\n\n\n\n\nPowerpoint-Dokumente\nErstelle wie oben einen neuen Foliensatz oder verwende eine vorhandene PowerPoint-Datei mit der gewünschten Formatierung. Zur weiteren Bearbeitung klickst du auf “Ansicht” und “Folienmaster”. Hier kannst du das Aussehen der “Master”-Folie ändern, indem du die Textformatierung in den Textfeldern sowie die Hintergrund- und Seitenabmessungen für die gesamte Seite bearbeitest.\n\n\n\n\n\n\n\n\n\nLeider ist die Bearbeitung von Powerpoint-Dateien etwas weniger flexibel:\n\nEine Überschrift der ersten Ebene (# Header 1) wird automatisch zum Titel einer neuen Folie,\nA ## Header 2 Text wird nicht als Untertitel, sondern als Text im Haupttextfeld der Folie angezeigt (es sei denn, du findest eine Möglichkeit, die Masteransicht zu ändern).\nAusgegebene Diagramme und Tabellen werden automatisch in neue Folien eingefügt. Du musst sie kombinieren, z. B. mit dem Patchwork Funktion verwenden, um ggplots zu kombinieren, damit sie auf der gleichen Seite angezeigt werden. Siehe dies Blogbeitrag über die Verwendung der Patchwork Paket, um mehrere Bilder auf einer Folie zu platzieren.\n\nSiehe die Offizier Paket für ein Tool, mit dem du tiefergehend mit Powerpoint-Präsentationen arbeiten kannst.\n\n\nVorlagen in die YAML einbinden\nSobald eine Vorlage erstellt wurde, können die Details dazu in der YAML des Rmd unter der Zeile “Ausgabe” und unter der Angabe des Dokumententyps (der in einer eigenen Zeile steht) hinzugefügt werden. Hinweis reference_doc kann für Powerpoint-Folienvorlagen verwendet werden.\nAm einfachsten ist es, die Vorlage in demselben Ordner zu speichern, in dem sich auch die Rmd-Datei befindet (wie im Beispiel unten), oder in einem Unterordner darin.\n---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---\n\n\nFormatieren von HTML-Dateien\nHTML-Dateien verwenden keine Vorlagen, aber die Stile können in der YAML konfiguriert werden. HTML-Dateien sind interaktive Dokumente, die besonders flexibel sind. Wir behandeln hier einige grundlegende Optionen.\n\nInhaltsverzeichnisse: Wir können ein Inhaltsverzeichnis einfügen mit toc: true hinzufügen und außerdem festlegen, dass es beim Scrollen sichtbar bleibt (“schwebt”), mit toc_float: true.\nThemes: Wir können auf einige vorgefertigte Themes zurückgreifen, die aus der Bootswatch-Themenbibliothek stammen. Im folgenden Beispiel verwenden wir cerulean. Weitere Optionen sind: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex und yeti.\nHervorheben: Mit dieser Einstellung wird das Aussehen von hervorgehobenem Text (z. B. Code innerhalb von angezeigten Abschnitten) geändert. Unterstützt werden die Stile default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark und textmate.\n\nHier ist ein Beispiel dafür, wie du die oben genannten Optionen in die YAML integrieren kannst.\n---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---\nUnten findest du zwei Beispiele für HTML-Ausgaben, die beide ein fließendes Inhaltsverzeichnis haben, aber unterschiedliche Themen- und Hervorhebungsstile auswählen:",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#dynamischer-inhalt",
    "href": "new_pages/rmarkdown.de.html#dynamischer-inhalt",
    "title": "40  Berichte mit R Markdown",
    "section": "40.9 Dynamischer Inhalt",
    "text": "40.9 Dynamischer Inhalt\nIn einer HTML-Ausgabe kann der Inhalt deines Berichts dynamisch sein. Im Folgenden findest du einige Beispiele:\n\nTabellen\nIn einem HTML-Bericht kannst du Datenrahmen / Tibbles so ausgeben, dass der Inhalt dynamisch ist, mit Filtern und Bildlaufleisten. Es gibt mehrere Pakete, die diese Möglichkeit bieten.\nUm dies zu tun mit dem DT Paket, wie es in diesem Handbuch verwendet wird, kannst du einen Codeabschnitt wie den folgenden einfügen:\n\n\n\n\n\n\n\n\n\nDie Funktion datatable() gibt den angegebenen Datenrahmen als dynamische Tabelle für den Leser aus. Du kannst die rownames = FALSE setzen, um die ganz linke Seite der Tabelle zu vereinfachen. filter = \"top\" bietet einen Filter über jede Spalte. In der option() Argument gibst du eine Liste mit anderen Spezifikationen an. Im Folgenden geben wir zwei an: pageLength = 5 die Anzahl der angezeigten Zeilen auf 5 festlegen (die restlichen Zeilen können durch Blättern mit Pfeilen angezeigt werden), und scrollX=TRUE aktiviert eine Bildlaufleiste am unteren Rand der Tabelle (für Spalten, die zu weit nach rechts reichen).\nWenn dein Datensatz sehr groß ist, solltest du nur die obersten X Zeilen anzeigen, indem du den Datenrahmen in head().\n\n\nHTML-Widgets\nHTML Widgets für R sind eine spezielle Klasse von R-Paketen, die durch die Verwendung von JavaScript-Bibliotheken mehr Interaktivität ermöglichen. Du kannst sie in HTML-R-Markdown-Ausgaben einbetten.\nEinige gängige Beispiele für diese Widgets sind:\n\nPlotly (wird auf dieser Handbuchseite und in der [Interaktive Plots] Seite)\nvisNetwork (verwendet in den [Übertragungsketten] Seite dieses Handbuchs)\nMerkblatt (verwendet in den [GIS-Grundlagen] Seite dieses Handbuchs)\ndygraphs (nützlich für die interaktive Darstellung von Zeitreihendaten)\nDT (datatable()) (um dynamische Tabellen mit Filter, Sortierung usw. anzuzeigen)\n\nDie ggplotly() Funktion von plotlyist besonders einfach zu benutzen. Siehe die [Interaktive Plots] Seite.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.de.html#ressourcen",
    "href": "new_pages/rmarkdown.de.html#ressourcen",
    "title": "40  Berichte mit R Markdown",
    "section": "40.10 Ressourcen",
    "text": "40.10 Ressourcen\nWeitere Informationen erhältst du über:\n\nhttps://bookdown.org/yihui/rmarkdown/\nhttps://rmarkdown.rstudio.com/articles_intro.html\n\nEine gute Erklärung von Markdown vs. Knitr vs. Rmarkdown findest du hier: https://stackoverflow.com/questions/40563479/relationship-between-r-markdown-knitr-pandoc-and-bookdown",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Berichte mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html",
    "href": "new_pages/reportfactory.de.html",
    "title": "41  Organisieren von Routineberichten",
    "section": "",
    "text": "41.1 Vorbereitung",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html#vorbereitung",
    "href": "new_pages/reportfactory.de.html#vorbereitung",
    "title": "41  Organisieren von Routineberichten",
    "section": "",
    "text": "Pakete laden\nInstallieren Sie in RStudio die neueste Version der reportfactory Paket von Github.\nDu kannst dies über die pacman Paket mit p_load_current_gh() was die Installation der neuesten Version von Github erzwingt. Gib die Zeichenkette “reconverse/reportfactory” ein, die die Github-Organisation (reconverse) und das Repository (reportfactory) angibt. Du kannst auch verwenden install_github() aus dem remotes Paket, als eine Alternative.\n\n# Install and load the latest version of the package from Github\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # alternative",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html#neue-fabrik",
    "href": "new_pages/reportfactory.de.html#neue-fabrik",
    "title": "41  Organisieren von Routineberichten",
    "section": "41.2 Neue Fabrik",
    "text": "41.2 Neue Fabrik\nUm eine neue Fabrik zu erstellen, führen Sie die Funktion new_factory(). Dadurch wird ein neuer, in sich geschlossener R-Projektordner erstellt. Standardmäßig:\n\nDie Factory wird zu deinem Arbeitsverzeichnis hinzugefügt\nDer Name des R-Projekts der Fabrik wird “new_factory.Rproj” heißen.\nDeine RStudio-Sitzung wird in dieses R-Projekt “einziehen”.\n\n\n# This will create the factory in the working directory\nnew_factory()\n\nWenn du dir die Factory ansiehst, kannst du sehen, dass Unterordner und einige Dateien automatisch erstellt wurden.\n\n\n\n\n\n\n\n\n\n\nDie report_sources werden deine R Markdown-Skripte gespeichert, die deine Berichte erstellen\nDer Ausgaben werden die Berichtsausgaben gespeichert (z.B. HTML, Word, PDF, etc.)\nDie Skripte kann verwendet werden, um andere R-Skripte zu speichern (z.B. solche, die von deinen Rmd-Skripten stammen)\nDer Daten kann für deine Daten verwendet werden (Unterordner “raw” und “clean” sind enthalten)\nA .hier Datei, damit du die hierPaket verwenden, um Dateien in Unterordnern über ihre Beziehung zu diesem Stammordner aufzurufen (siehe [R-Projekte] Seite für Details)\nA gitignoreDatei wurde erstellt, falls du dieses R-Projekt mit einem Github-Repository verknüpfst (siehe [Versionskontrolle und Zusammenarbeit mit Github])\nEine leere README-Datei, für den Fall, dass du ein Github-Repository verwendest\n\nVORSICHT! Je nach Einstellung deines Computers können Dateien wie “.here” zwar existieren, aber unsichtbar sein.\nIm Folgenden sind einige der Standardeinstellungen aufgeführt, die du vielleicht innerhalb der new_factory() Befehl:\n\nfactory = - Gib einen Namen für den Werksordner an (Standard ist “new_factory”)\npath = - Gib einen Dateipfad für die neue Fabrik an (Standard ist das Arbeitsverzeichnis)\nreport_sources = Gib einen alternativen Namen für den Unterordner an, der die R Markdown-Skripte enthält (Standard ist “report_sources”)\noutputs = Gib einen alternativen Namen für den Ordner an, der die Berichtsausgaben enthält (Standard ist “outputs”)\n\nSiehe ?new_factory für eine vollständige Liste der Argumente.\nWenn du die neue Factory erstellst, wird deine R-Sitzung in das neue R-Projekt übertragen, daher solltest du erneut die reportfactory Paket laden.\n\npacman::p_load(reportfactory)\n\nJetzt kannst du die factory_overview() Befehl ausführen, um die interne Struktur (alle Ordner und Dateien) in der Fabrik zu sehen.\n\nfactory_overview()            # print overview of the factory to console\n\nDer folgende “Baum” mit den Ordnern und Dateien der Fabrik wird auf der R-Konsole ausgegeben. Beachte, dass es im Ordner “data” Unterordner für “raw” und “clean” Daten sowie für Beispiel-CSV-Daten gibt. Außerdem gibt es im Ordner “report_sources” die Datei “example_report.Rmd”.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html#einen-bericht-erstellen",
    "href": "new_pages/reportfactory.de.html#einen-bericht-erstellen",
    "title": "41  Organisieren von Routineberichten",
    "section": "41.3 Einen Bericht erstellen",
    "text": "41.3 Einen Bericht erstellen\nErstelle im R-Fabrikprojekt einen R-Markdown-Bericht, wie du es normalerweise tun würdest, und speichere ihn im Ordner “report_sources”. Siehe die [R Markdown][Berichte mit R Markdown] Seite für Anweisungen. Für das Beispiel haben wir der Factory Folgendes hinzugefügt:\n\nEin neues R-Markdown-Skript mit dem Titel “daily_sitrep.Rmd”, das im Ordner “report_sources” gespeichert ist\nDaten für den Bericht (“linelist_cleaned.rds”), die im Unterordner “clean” im Ordner “data” gespeichert werden\n\nWir können sehen, dass die factory_overview() unser R Markdown im Ordner “report_sources” und die Datendatei im Ordner “clean” data (hervorgehoben):\n\n\n\n\n\n\n\n\n\nUnten siehst du einen Screenshot vom Anfang des R Markdowns “daily_sitrep.Rmd”. Du kannst sehen, dass das Ausgabeformat über den YAML-Header auf HTML eingestellt ist output: html_document.\n\n\n\n\n\n\n\n\n\nIn diesem einfachen Skript gibt es Befehle für:\n\ndie notwendigen Pakete zu laden\nImportiere die Linelist-Daten mit einem Dateipfad aus dem hierPaket (mehr dazu auf der Seite über [Import und Export])\n\n\nlinelist &lt;- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\n\n\nDrucke eine Übersichtstabelle der Fälle und exportiere sie mit export() als .csv-Datei\nDrucke eine Epikurve und exportiere sie mit ggsave() als .png-Datei\n\nMit diesem Befehl kannst du nur die Liste der R Markdown-Berichte im Ordner “report_sources” überprüfen:\n\nlist_reports()",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html#kompilieren",
    "href": "new_pages/reportfactory.de.html#kompilieren",
    "title": "41  Organisieren von Routineberichten",
    "section": "41.4 Kompilieren",
    "text": "41.4 Kompilieren\nIn einer Report Factory bedeutet das “Kompilieren” eines R Markdown-Berichts, dass das .Rmd-Skript ausgeführt und die Ausgabe erzeugt wird (wie im Skript YAML angegeben, z. B. als HTML, Word, PDF usw.).\nDie Factory erstellt automatisch einen mit Datum und Zeitstempel versehenen Ordner für die Ausgaben im Ordner “outputs”.\nDer Bericht selbst und alle vom Skript erstellten Exportdateien (z. B. csv, png, xlsx) werden in diesem Ordner gespeichert. Außerdem wird das Rmd-Skript selbst in diesem Ordner gespeichert, damit du eine Aufzeichnung dieser Version des Skripts hast.\nDies steht im Gegensatz zum normalen Verhalten eines “gestrickten” R Markdown, bei dem die Ausgaben am Ort des Rmd-Skripts gespeichert werden. Dieses Standardverhalten kann zu überfüllten, unordentlichen Ordnern führen. Die Factory soll die Organisation verbessern, wenn man Berichte häufig ausführen muss.\n\nNach Namen kompilieren\nDu kannst einen bestimmten Bericht kompilieren, indem du compile_reports() und den Namen des Rmd-Skripts (ohne .Rmd-Erweiterung) an reports =. Der Einfachheit halber kannst du die reports = weglassen und einfach den R Markdown-Namen in Anführungszeichen schreiben, wie unten.\n\n\n\n\n\n\n\n\n\nDieser Befehl kompiliert nur den Bericht “daily_sitrep.Rmd” und speichert den HTML-Bericht sowie die .csv-Tabelle und die .png-Epikurven-Exporte in einem mit Datum und Zeitstempel versehenen Unterordner im Ordner “outputs”.\nWenn du die Endung .Rmd angibst, musst du die Endung so schreiben, wie sie im Dateinamen gespeichert ist (.rmd vs. .Rmd).\nBeachte auch, dass beim Kompilieren vorübergehend mehrere Dateien im Ordner “report_sources” erscheinen können - sie werden aber bald verschwinden, wenn sie in den richtigen Ordner “outputs” übertragen werden.\n\n\nKompilieren nach Nummer\nDu kannst das zu kompilierende Rmd-Skript auch angeben, indem du eine Zahl oder einen Vektor von Zahlen an reports =. Die Nummern müssen mit der Reihenfolge übereinstimmen, in der die Berichte erscheinen, wenn du die list_reports().\n\n# Compile the second and fourth Rmds in the \"report_sources\" folder\ncompile_reports(reports = c(2, 4))\n\n\n\nKompiliere alle\nDu kannst kompilieren alle R Markdown-Berichte im Ordner “report_sources” zusammenstellen, indem du die reports = Argument auf TRUE setzt.\n\n\n\n\n\n\n\n\n\n\n\nKompilieren aus Unterordner\nDu kannst Unterordner zum Ordner “report_sources” hinzufügen. Um einen R Markdown-Bericht aus einem Unterordner auszuführen, gib einfach den Namen des Ordners an subfolder =. Im Folgenden findest du ein Beispiel für einen Rmd-Bericht, der sich in einem Unterordner von “report_sources” befindet.\n\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\n\nDu kannst alle Rmd-Berichte innerhalb eines Unterordners kompilieren, indem du den Namen des Unterordners an reports = mit einem Schrägstrich am Ende, wie unten.\n\ncompile_reports(reports = \"for_partners/\")\n\n\n\nParametrisierung\nWie bereits auf der Seite über [Berichte mit R Markdown] beschrieben, kannst du Berichte mit bestimmten Parametern ausführen. Du kannst diese Parameter als Liste ancompile_reports() über die params = Argument übergeben. In diesem fiktiven Bericht gibt es zum Beispiel drei Parameter, die den R Markdown-Berichten übergeben werden.\n\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)\n\n\n\nVerwendung einer “run-file”\nWenn du mehrere Berichte auszuführen hast, solltest du ein R-Skript erstellen, das alle Berichte enthält. compile_reports() Befehle enthält. Ein Benutzer kann einfach alle Befehle in diesem R-Skript ausführen und alle Berichte werden kompiliert. Du kannst diese “Run-Datei” im Ordner “Scripts” speichern.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html#ausgaben",
    "href": "new_pages/reportfactory.de.html#ausgaben",
    "title": "41  Organisieren von Routineberichten",
    "section": "41.5 Ausgaben",
    "text": "41.5 Ausgaben\nNachdem wir die Berichte ein paar Mal zusammengestellt haben, könnte der “Outputs”-Ordner wie folgt aussehen (Hervorhebungen zur Verdeutlichung hinzugefügt):\n\n\n\n\n\n\n\n\n\n\nInnerhalb von “outputs” wurden für jeden Rmd-Bericht Unterordner erstellt\nInnerhalb dieser Ordner wurden weitere Unterordner für jede einzelne Kompilierung erstellt\n\nDiese sind mit einem Datums- und Zeitstempel versehen (“2021-04-23_T11-07-36” bedeutet 23. April 2021 um 11:07:36)\nDu kannst das Format des Datums-/Zeitstempels bearbeiten. Siehe ?compile_reports\n\nIn jedem Datums-/Zeitstempel-Ordner wird die Berichtsausgabe (z. B. HTML, PDF, Word) zusammen mit dem Rmd-Skript (Versionskontrolle!) und allen anderen exportierten Dateien (z. B. table.csv, epidemic_curve.png) gespeichert\n\nHier ist ein Blick in einen der Ordner mit Datums- und Zeitstempel für den Bericht “daily_sitrep”. Der Dateipfad ist zur Verdeutlichung gelb hervorgehoben.\n\n\n\n\n\n\n\n\n\nZum Schluss folgt ein Screenshot der HTML-Berichtsausgabe.\n\n\n\n\n\n\n\n\n\nDu kannst list_outputs() um eine Liste der Ausgaben zu sehen.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html#sonstiges",
    "href": "new_pages/reportfactory.de.html#sonstiges",
    "title": "41  Organisieren von Routineberichten",
    "section": "41.6 Sonstiges",
    "text": "41.6 Sonstiges\n\nStricken\nDu kannst einen deiner R Markdown-Berichte immer noch “stricken”, indem du auf die Schaltfläche “Stricken” drückst, wenn du möchtest. Wenn du dies tust, erscheinen die Ausgaben standardmäßig in dem Ordner, in dem die Rmd gespeichert ist - dem Ordner “report_sources”. In früheren Versionen von reportfactory wurde die Kompilierung verhindert, wenn sich im Ordner “report_sources” Dateien befanden, die keine Rmd-Dateien waren, aber das ist jetzt nicht mehr der Fall. Du kannst compile_reports() ausführen und es wird kein Fehler auftreten.\n\n\nSkripte\nWir empfehlen dir, den Ordner “scripts” zu verwenden, um “runfiles” oder .R-Skripte zu speichern, die von deinen .Rmd-Skripten stammen. Siehe die Seite über [R Markdown][Berichte mit R Markdown] findest du Tipps, wie du deinen Code über mehrere Dateien hinweg strukturieren kannst.\n\n\nExtras\n\nMit reportfactory kannst du die Funktion list_deps() verwenden, um alle Pakete aufzulisten, die für alle Berichte in der gesamten Fabrik benötigt werden.\nIn der Entwicklung befindet sich ein Begleitpaket namens rfextras das weitere Hilfsfunktionen bietet, die dich bei der Erstellung von Berichten unterstützen, wie z. B:\n\nload_scripts() - sources/loadet alle .R-Skripte in einem bestimmten Ordner (standardmäßig der Ordner “scripts”)\nfind_latest() - findet die neueste Version einer Datei (z. B. den neuesten Datensatz)",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.de.html#ressourcen",
    "href": "new_pages/reportfactory.de.html#ressourcen",
    "title": "41  Organisieren von Routineberichten",
    "section": "41.7 Ressourcen",
    "text": "41.7 Ressourcen\nSiehe die reportfactory des Pakets Github-Seite\nSiehe die rfextras des Pakets Github-Seite",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisieren von Routineberichten</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html",
    "href": "new_pages/flexdashboard.de.html",
    "title": "42  Dashboards mit R Markdown",
    "section": "",
    "text": "42.1 Vorbereitung",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#vorbereitung",
    "href": "new_pages/flexdashboard.de.html#vorbereitung",
    "title": "42  Dashboards mit R Markdown",
    "section": "",
    "text": "Pakete laden\nIn diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\npacman::p_load(\n  rio,             # data import/export     \n  here,            # locate files\n  tidyverse,       # data management and visualization\n  flexdashboard,   # dashboard versions of R Markdown reports\n  shiny,           # interactive figures\n  plotly           # interactive figures\n)\n\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du mitmachen willst, klicke, um die “saubere” Linienliste herunterzuladen (als .rds-Datei). Importiere Daten mit dem import() Funktion aus der rioPaket (sie verarbeitet viele Dateitypen wie .xlsx, .csv, .rds - siehe die [Import und Export] Seite für Details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDie ersten 50 Zeilen der Linienliste werden unten angezeigt.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#neues-r-markdown-erstellen",
    "href": "new_pages/flexdashboard.de.html#neues-r-markdown-erstellen",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.2 Neues R Markdown erstellen",
    "text": "42.2 Neues R Markdown erstellen\nNachdem du das Paket installiert hast, erstelle eine neue R Markdown-Datei, indem du dich zu Datei &gt; Neue Datei &gt; R Markd.\n\n\n\n\n\n\n\n\n\nIn dem sich öffnenden Fenster wählst du “Aus Vorlage” und wählst die Vorlage “Flex Dashboard”. Du wirst dann aufgefordert, das Dokument zu benennen. Im Beispiel auf dieser Seite nennen wir unser R Markdown “outbreak_dashboard.Rmd”.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#das-skript",
    "href": "new_pages/flexdashboard.de.html#das-skript",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.3 Das Skript",
    "text": "42.3 Das Skript\nDas Skript ist ein R Markdown-Skript und hat daher die gleichen Komponenten und den gleichen Aufbau wie auf der Seite über [Berichte mit R Markdown]. Wir gehen noch einmal kurz darauf ein und zeigen die Unterschiede zu anderen R Markdown-Ausgabeformaten auf.\n\nYAML\nAm Anfang des Skripts steht der “YAML”-Kopf. Dieser muss mit drei Bindestrichen beginnen --- und muss mit drei Bindestrichen enden ---. YAML-Parameter kommen in key:value Paaren. Die Einrückung und Platzierung von Doppelpunkten in YAML ist wichtig - die key:value Paare werden durch Doppelpunkte getrennt (nicht durch Gleichheitszeichen!).\nDie YAML sollte mit den Metadaten für das Dokument beginnen. Die Reihenfolge dieser primären YAML-Parameter (nicht eingerückt) spielt keine Rolle. Zum Beispiel:\n\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\n\nDu kannst R-Code in YAML-Werten verwenden, indem du ihn wie Inline-Code einfügst (vor dem r innerhalb von Backticks), aber auch innerhalb von Anführungszeichen (siehe oben für Datum).\nEin erforderlicher YAML-Parameter ist output: der den Typ der zu erstellenden Datei angibt (z. B. html_document, pdf_document, word_document, oder powerpoint_presentation). Für flexdashboard ist dieser Parameterwert ein wenig verwirrend - er muss als output:flexdashboard::flex_dashboard. Beachte die einfachen und doppelten Doppelpunkte und den Unterstrich. Dieser YAML-Ausgabeparameter wird oft gefolgt von einem zusätzlichen Doppelpunkt und eingerückten Unterparametern (siehe orientation: und vertical_layout: Parameter unten).\n\ntitle: \"My dashboard\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll\n\nWie oben dargestellt, werden Einrückungen (2 Leerzeichen) für Unterparameter verwendet. Vergiss in diesem Fall nicht, einen zusätzlichen Doppelpunkt nach dem Hauptparameter zu setzen, wie key:value:.\nLogische Werte sollten in YAML gegebenenfalls in Kleinbuchstaben angegeben werden (true, false, null). Wenn ein Doppelpunkt Teil deines Wertes ist (z. B. im Titel), setze den Wert in Anführungszeichen. Siehe die Beispiele in den folgenden Abschnitten.\n\n\nCode-Blöcke\nEin R Markdown-Skript kann mehrere Code-“Chunks” enthalten - das sind Bereiche des Skripts, in denen du mehrzeiligen R-Code schreiben kannst und die wie Mini-R-Skripte funktionieren.\nCode Chunks werden mit drei Backticks und geschweiften Klammern mit einem kleinen “r” darin erstellt. Der Chunk wird mit drei Backticks geschlossen. Du kannst einen neuen Chunk erstellen, indem du ihn selbst eintippst, die Tastenkombination “Strg + Alt + i” (oder Cmd + Shift + r beim Mac) verwendest oder auf das grüne Symbol “Neuen Codechunk einfügen” oben in deinem Skripteditor klickst. Viele Beispiele findest du weiter unten.\n\n\nErzählender Text\nAußerhalb eines R-Code-“Chunks” kannst du erzählenden Text schreiben. Wie auf der Seite über [Berichte mit R Markdown] beschrieben, kannst du Text kursiv machen, indem du ihn mit einem Sternchen (*) umrandest, oder fett, indem du ihn mit zwei Sternchen (**) umrandest. Erinnere dich daran, dass Aufzählungszeichen und Nummerierungsschemata auf Zeilenumbrüche, Einrückungen und den Abschluss einer Zeile mit zwei Leerzeichen reagieren.\nDu kannst auch Inline-R-Code in den Text einfügen, wie im Abschnitt [Berichte mit R Markdown] Seite beschrieben, indem du den Code mit Backticks umschließt und den Befehl mit “r” beginnst :1+1(siehe Beispiel mit Datum oben).\n\n\nÜberschriften\nVerschiedene Überschriftsebenen werden mit einer unterschiedlichen Anzahl von Hash-Symbolen erstellt, wie in der [Berichte mit R Markdown] Seite beschrieben wird.\nIn flexdashboard erstellt eine primäre Überschrift (#) eine “Seite” des Dashboards. Überschriften der zweiten Ebene (##) erstellen eine Spalte oder eine Zeile, je nach orientation: Parameter (siehe Details unten). Überschriften der dritten Ebene (###) erstellen Felder für Diagramme, Tabellen, Text usw.\n# First-level heading (page)\n\n## Second level heading (row or column)  \n\n### Third-level heading (pane for plot, chart, etc.)",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#abschnitt-attribute",
    "href": "new_pages/flexdashboard.de.html#abschnitt-attribute",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.4 Abschnitt-Attribute",
    "text": "42.4 Abschnitt-Attribute\nWie in einem normalen R-Markdown kannst du Attribute angeben, die auf Teile deines Dashboards angewendet werden, indem du key=value Optionen nach einer Überschrift in geschweiften Klammern { }. In einem typischen HTML-R-Markdown-Bericht könntest du zum Beispiel Unterüberschriften in Tabs organisieren mit ## My heading {.tabset}.\nBeachte, dass diese Attribute nach einem Überschrift in einem Textteil des Skripts stehen. Sie sind anders als die knitr Optionen, die am Anfang von R-Code-Blöcken eingefügt werden, wie z. B. out.height =.\nSpezifische Abschnittsattribute für flexdashboard include:\n\n{data-orientation=} Festgelegt auf entweder rows oder columns. Wenn dein Dashboard mehrere Seiten hat, füge dieses Attribut zu jeder Seite hinzu, um die Ausrichtung anzugeben (weitere Informationen findest du unter Abschnitt Layout).\n{data-width=} und {data-height=} die relative Größe von Diagrammen, Spalten und Zeilen festlegen, die in derselben Dimension (horizontal oder vertikal) angeordnet sind. Absolute Größen werden so angepasst, dass sie den Platz auf jedem Anzeigegerät optimal ausfüllen, dank der flexbox Engine.\n\nDie Höhe der Diagramme hängt auch davon ab, ob du den YAML-Parameter vertical_layout: fill oder vertical_layout: scroll. Bei der Einstellung “Scrollen” wird die Höhe der Grafik der traditionellen fig.height = Option in dem R-Codechunk.\nDie vollständige Dokumentation zur Größe findest du in der flexdashboard-Website\n\n{.hidden} Benutze dies, um eine bestimmte Seite aus der Navigationsleiste auszuschließen\n{data-navbar=} Verwende dies in einer Überschrift auf Seitenebene, um sie in ein Dropdown-Menü der Navigationsleiste einzubinden. Gib den Namen (in Anführungszeichen) des Dropdown-Menüs an. Siehe Beispiel unten.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#layout",
    "href": "new_pages/flexdashboard.de.html#layout",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.5 Layout",
    "text": "42.5 Layout\nPasse das Layout deines Dashboards auf folgende Weise an:\n\nFüge Seiten, Spalten/Zeilen und Diagramme mit R Markdown-Überschriften hinzu (z. B. #, ## oder ###)\nAnpassen der YAML-Parameter orientation: entweder auf rows oder columns\nFestlegen, ob das Layout den Browser ausfüllt oder Scrollen erlaubt\nRegisterkarten zu einer bestimmten Abschnittsüberschrift hinzufügen\n\n\nSeiten\nÜberschriften der ersten Ebene (#) im R Markdown stellen “Seiten” des Dashboards dar. Standardmäßig werden die Seiten in einer Navigationsleiste am oberen Rand des Dashboards angezeigt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDu kannst Seiten in einem “Menü” innerhalb der oberen Navigationsleiste gruppieren, indem du das Attribut {data-navmenu=} zur Seitenüberschrift hinzufügst. Sei vorsichtig - füge keine Leerzeichen um das Gleichheitszeichen herum ein, sonst wird es nicht funktionieren!\n\n\n\n\n\n\n\n\n\nDas Ergebnis des Skripts sieht folgendermaßen aus:\n\n\n\n\n\n\n\n\n\nDu kannst auch eine Seite oder eine Spalte in eine “Seitenleiste” auf der linken Seite des Dashboards umwandeln, indem du die {.sidebar} Attribut. Sie kann Text enthalten (der von jeder Seite aus sichtbar ist), oder wenn du eine shiny Interaktivität integriert hast, kann es nützlich sein, um Steuerelemente für Benutzereingaben wie Schieberegler oder Dropdown-Menüs aufzunehmen.\n\n\n\n\n\n\n\n\n\nSo sieht das Skript aus:\n\n\n\n\n\n\n\n\n\n\n\nAusrichtung\nStellen Sie die orientation: yaml-Parameter, um anzugeben, wie die Überschriften der zweiten Ebene (##) von R Markdown interpretiert werden sollen - entweder als orientation: columns oder orientation: rows.\nÜberschriften der zweiten Ebene (##) werden als neue Spalten oder Zeilen interpretiert, basierend auf dieser orientation Einstellung.\nWenn du die orientation: columns einstellst, werden durch die Überschriften der zweiten Ebene neue Spalten im Dashboard erstellt. Das folgende Dashboard hat eine Seite mit zwei Spalten und insgesamt drei Feldern. Du kannst die relative Breite der Spalten mit {data-width=} wie unten gezeigt.\n\n\n\n\n\n\n\n\n\nDas ist das Ergebnis des Skripts:\n\n\n\n\n\n\n\n\n\nWenn du die orientation: rows setzt, werden bei Überschriften der zweiten Ebene neue Zeilen statt Spalten erstellt. Im Folgenden findest du das gleiche Skript wie oben, aber orientation: rows so dass die Überschriften der zweiten Ebene Zeilen statt Spalten erzeugen. Du kannst die relativen Höhe der Zeilen mit {data-height=} wie unten gezeigt.\n\n\n\n\n\n\n\n\n\nDas ist das Ergebnis des Skripts:\n\n\n\n\n\n\n\n\n\nWenn dein Dashboard mehrere Seiten hat, kannst du die Ausrichtung für jede einzelne Seite festlegen, indem du die {data-orientation=} Attribut in die Kopfzeile jeder Seite einfügst (gib entweder rows oder columns ohne Anführungszeichen).\n\n\nTabulatoren\nDu kannst Inhalte in Registerkarten unterteilen, indem du die {.tabset} Attribut unterteilen, wie in anderen HTML R Markdown-Ausgaben.\nFüge dieses Attribut einfach nach der gewünschten Überschrift ein. Die Unterüberschriften unter dieser Überschrift werden als Tabulatoren angezeigt. Im Beispielskript unten wird zum Beispiel Spalte 2 auf der rechten Seite (##) so verändert, dass die Seuchenkurve und die Tabellenbereiche (###) in Tabs angezeigt werden.\nDu kannst dasselbe mit den Zeilen machen, wenn du dich an den Zeilen orientierst.\n\n\n\n\n\n\n\n\n\nHier ist, was das Skript produziert:",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#inhalt-hinzufügen",
    "href": "new_pages/flexdashboard.de.html#inhalt-hinzufügen",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.6 Inhalt hinzufügen",
    "text": "42.6 Inhalt hinzufügen\nBeginnen wir damit, ein Dashboard zu erstellen. Unser einfaches Dashboard besteht aus 1 Seite, 2 Spalten und 4 Feldern. Zur Veranschaulichung werden wir die Bereiche Stück für Stück aufbauen.\nDu kannst ganz einfach Standard-R-Ausgaben wie Text, ggplots und Tabellen einfügen (siehe [Tabellen für die Präsentation] Seite). Kodiere sie einfach in einem R-Codechunk, wie du es bei jedem anderen R-Markdown-Skript tun würdest.\nHinweis: Du kannst das fertige Rmd-Skript und die HTML-Ausgabe des Dashboards herunterladen - siehe das [Handbuch und Daten herunterladen] Seite.\n\nText\nDu kannst Markdown-Text eingeben und einfügen in-lineCode einfügen, wie bei jeder anderen R Markdown-Ausgabe. Siehe die [Berichte mit R Markdown] Seite für Details.\nIn diesem Dashboard gibt es einen zusammenfassenden Textbereich mit dynamischem Text, der das Datum der letzten Hospitalisierung und die Anzahl der gemeldeten Fälle des Ausbruchs anzeigt.\n\n\nTische\nDu kannst R-Codeabschnitte einfügen, die Ausgaben wie Tabellen ausgeben. Aber die Ausgabe sieht am besten aus und reagiert auf die Fenstergröße, wenn du die kable() Funktion von knitr um deine Tabellen anzuzeigen. Die flextable Funktionen können Tabellen erzeugen, die gekürzt / abgeschnitten sind.\nUnten füttern wir zum Beispiel die linelist() durch eine count() Befehl ein, um eine Übersichtstabelle der Fälle nach Krankenhaus zu erstellen. Letztendlich wird die Tabelle über die Pipeline an knitr::kable() weitergeleitet und das Ergebnis hat eine Bildlaufleiste auf der rechten Seite. Mehr über das Anpassen deiner Tabelle erfährst du mit kable() und kableExtra hier.\n\n\n\n\n\n\n\n\n\nHier ist, was das Skript produziert:\n\n\n\n\n\n\n\n\n\nWenn du eine dynamische Tabelle anzeigen möchtest, die es dem Benutzer ermöglicht, zu filtern, zu sortieren und/oder durch “Seiten” des Datenrahmens zu klicken, verwende das Paket DT und die darin enthaltene Funktion datatable() wie im unten stehenden Code.\nDer Beispielcode unten, der Datenrahmen linelist wird gedruckt. Du kannst die rownames = FALSE um horizontalen Platz zu sparen, und filter = \"top\" dass die Filter oben in jeder Spalte stehen. Eine Liste mit weiteren Spezifikationen kannst du an options =. Unten setzen wir pageLength = so ein, dass 5 Zeilen erscheinen und scrollX = so dass der Benutzer eine Bildlaufleiste am unteren Rand verwenden kann, um horizontal zu scrollen. Das Argument class = 'white-space: nowrap' stellt sicher, dass jede Zeile nur eine Zeile ist (nicht mehrere Zeilen). Du kannst über andere mögliche Argumente und Werte lesen hier oder indem du eingibst ?datatable\n\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = list(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )\n\n\n\nGrundstücke\nDu kannst Plots wie in einem R-Skript in ein Dashboard-Fenster drucken. In unserem Beispiel verwenden wir die Inzidenz2Paket, um mit zwei einfachen Befehlen eine “Epikurve” nach Altersgruppen zu erstellen (siehe [Epidemie-Kurven] Seite). Du kannst jedoch auchggplot() verwenden und eine Grafik auf die gleiche Weise drucken.\n\n\n\n\n\n\n\n\n\nDas Ergebnis des Skripts sieht folgendermaßen aus:\n\n\n\n\n\n\n\n\n\n\n\nInteraktive Diagramme\nDu kannst auch ein standardmäßiges ggplot- oder anderes Plot-Objekt an ggplotly() von der plotlyPaket (siehe die [Interaktive Plots] Seite). Damit wird dein Diagramm interaktiv, der Leser kann hineinzoomen und der Wert jedes Datenpunktes (in diesem Szenario die Anzahl der Fälle pro Woche und Altersgruppe in der Kurve) wird eingeblendet.\n\nage_outbreak &lt;- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %&gt;% \n  plotly::ggplotly()\n\nSo sieht das im Dashboard aus (gif). Diese interaktive Funktion funktioniert auch dann, wenn du das Dashboard als statische Datei per E-Mail verschickst (nicht online auf einem Server).\n\n\n\n\n\n\n\n\n\n\n\nHTML-Widgets\nHTML Widgets für R sind eine spezielle Klasse von R-Paketen, die die Interaktivität durch den Einsatz von JavaScript-Bibliotheken erhöhen. Du kannst sie in R Markdown-Ausgaben (wie z. B. ein Flexdashboard) und in Shiny-Dashboards einbetten.\nEinige gängige Beispiele für diese Widgets sind:\n\nPlotly (wird auf dieser Handbuchseite und in der [Interaktive Plots] Seite)\nvisNetwork (verwendet in den [Übertragungsketten] Seite dieses Handbuchs)\nMerkblatt (verwendet in den [GIS-Grundlagen] Seite dieses Handbuchs)\ndygraphs (nützlich für die interaktive Darstellung von Zeitreihendaten)\nDT (datatable()) (um dynamische Tabellen mit Filter, Sortierung usw. anzuzeigen)\n\nIm Folgenden zeigen wir, wie wir eine Epidemie-Übertragungskette, die visNetwork verwendet, zum Dashboard hinzufügen. Das Skript zeigt nur den neuen Code, der dem Abschnitt “Spalte 2” des R Markdown-Skripts hinzugefügt wurde. Du findest den Code im Abschnitt [Übertragungsketten] Seite dieses Handbuchs.\n\n\n\n\n\n\n\n\n\nHier ist, was das Skript produziert:",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#code-organisation",
    "href": "new_pages/flexdashboard.de.html#code-organisation",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.7 Code-Organisation",
    "text": "42.7 Code-Organisation\nDu kannst wählen, ob du den gesamten Code innerhalb der R Markdown flexdashboardSkript. Wenn du ein übersichtlicheres Dashboard-Skript haben möchtest, kannst du auch auf Code/Figuren zurückgreifen, die in externen R-Skripten gehostet oder erstellt werden. Dies wird ausführlicher beschrieben in der [Berichte mit R Markdown] Seite beschrieben.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#glänzend",
    "href": "new_pages/flexdashboard.de.html#glänzend",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.8 Glänzend",
    "text": "42.8 Glänzend\nDas R-Paket einbinden shiny kannst du deine Dashboards noch besser auf Benutzereingaben reagieren lassen. Du könntest z. B. einen Gerichtsbezirk oder einen Datumsbereich auswählen und die Panels auf diese Auswahl reagieren lassen (z. B. die angezeigten Daten filtern). Zum Einbetten shiny Reaktivität in flexdashboard zu integrieren, musst du nur ein paar Änderungen an deinem flexdashboard R Markdown-Skript.\nDu kannst verwenden shiny um Apps/Dashboards zu erstellen ohneflexdashboard zu erstellen. Die Handbuchseite zu [Dashboards mit Shiny] gibt einen Überblick über diesen Ansatz, einschließlich Anleitungen zuShiny Syntax, die Struktur der App-Dateien und die Optionen für die gemeinsame Nutzung/Veröffentlichung (einschließlich der Optionen für freie Server). Diese Syntax und allgemeinen Tipps werden in der flexdashboard Kontext übertragen.\neinbetten glänzend in flexdashboard ist jedoch eine grundlegende Änderung für dein flexdashboard. Es wird nicht länger eine HTML-Ausgabe erzeugen, die du per E-Mail verschicken kannst und die jeder öffnen und ansehen kann. Stattdessen wird es eine “App” sein. Die Schaltfläche “Stricken” oben im Skript wird durch ein Symbol “Dokument ausführen” ersetzt, das eine Instanz des interaktiven Dashboards lokal auf deinem Computer öffnet.\nDas Teilen deines Dashboards erfordert nun, dass du entweder:\n\ndas Rmd-Skript an den Betrachter senden, der es in R auf seinem Computer öffnet und die App ausführt, oder\nDie App/das Cashboard wird auf einem Server gehostet, auf den der Betrachter Zugriff hat.\n\nDie Vorteile der Integration liegen also auf der Hand shiny aber auch Komplikationen. Wenn das einfache Teilen per E-Mail eine Priorität ist und du keine glänzende reaktive Fähigkeiten brauchst, solltest du die reduzierte Interaktivität von ggplotly() wie oben gezeigt.\nIm Folgenden geben wir ein sehr einfaches Beispiel mit demselben “outbreak_dashboard.Rmd” wie oben. Ausführliche Dokumentation zur Integration von Shiny in flexdashboard ist online verfügbar hier.\n\nEinstellungen\nAktivieren glänzend in einer flexdashboard durch Hinzufügen des YAML-Parameters runtime: shiny auf der gleichen Einrückungsebene wie output: einfügen, wie unten:\n---\ntitle: \"Outbreak dashboard (Shiny demo)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---\nEs ist auch praktisch, eine “Seitenleiste” für die leuchtenden Eingabe-Widgets zu aktivieren, die Informationen von den Nutzern sammeln. Wie oben erklärt, erstellst du eine Spalte und gibst die {.sidebar} Option, um eine Seitenleiste auf der linken Seite zu erstellen. Du kannst Text und R-Blöcke hinzufügen, die die glänzenden input Befehle in dieser Rubrik.\nWenn deine App/dein Cashboard auf einem Server gehostet wird und möglicherweise mehrere Benutzer gleichzeitig hat, benenne den ersten R-Codechunk als global. Füge die Befehle zum Importieren/Laden deiner Daten in diesen Chunk ein. Dieser speziell benannte Chunk wird anders behandelt und die darin importierten Daten werden nur einmal importiert (nicht fortlaufend) und sind für alle Benutzer verfügbar. Dadurch wird die Startgeschwindigkeit der App verbessert.\n\n\nPraktisches Beispiel\nHier passen wir das Flexdashboard-Skript “outbreak_dashboard.Rmd” so an, dass es Folgendes enthält glänzend. Wir fügen die Möglichkeit hinzu, dass der Nutzer ein Krankenhaus aus einem Dropdown-Menü auswählen kann und die Epidemiekurve nur Fälle aus diesem Krankenhaus mit einem dynamischen Titel anzeigt. Wir gehen wie folgt vor:\n\nFüge hinzu. runtime: shiny zu der YAML\nBenennen Sie den Setup-Chunk um in global\nErstelle eine Seitenleiste mit:\n\nCode zur Erstellung eines Vektors mit eindeutigen Krankenhausnamen\nA selectInput() Befehl (shiny Dropdown-Menü) mit der Auswahl der Krankenhausnamen. Die Auswahl wird gespeichert als hospital_choice gespeichert, auf die in einem späteren Code verwiesen werden kann als input$hospital_choice\n\nDer Code für die epidemische Kurve (Spalte 2) wird in renderPlot({ }), einschließlich:\n\nEin Filter für den Datensatz, der die Spalte hospital auf den aktuellen Wert von input$hospital_choice\nEin dynamischer Plot-Titel, der Folgendes beinhaltet input$hospital_choice\n\n\nBeachten Sie, dass jeder Code, der sich auf einen input$ Wert referenziert, muss innerhalb einer render({}) Funktion stehen (um reaktiv zu sein).\nHier ist der obere Teil des Skripts, einschließlich YAML, Global Chunk und Sidebar:\n\n\n\n\n\n\n\n\n\nHier ist die Spalte 2 mit dem reaktiven Epikurvendiagramm:\n\n\n\n\n\n\n\n\n\nUnd hier ist das Armaturenbrett:\n\n\n\n\n\n\n\n\n\n\n\nAndere Beispiele\nUm ein gesundheitsbezogenes Beispiel für ein Shiny-flexdashboard unter Verwendung der glänzenden Interaktivität und der Flugblatt Mapping Widget, siehe dieses Kapitel des Online-Buchs Geospatiale Gesundheitsdaten: Modellierung und Visualisierung mit R-INLA und Shiny.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#teilen",
    "href": "new_pages/flexdashboard.de.html#teilen",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.9 Teilen",
    "text": "42.9 Teilen\nDashboards, die keine Shiny-Elemente enthalten, geben eine HTML-Datei (.html) aus, die per E-Mail verschickt werden kann (wenn die Größe es zulässt). Das ist nützlich, da du den “Dashboard”-Bericht versenden kannst und keinen Server einrichten musst, um ihn als Website zu hosten.\nWenn du eingebettet hast shiny eingebettet hast, kannst du keine Ausgabe per E-Mail versenden, aber du kannst das Skript selbst an einen R-Benutzer senden oder das Dashboard wie oben beschrieben auf einem Server hosten.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.de.html#ressourcen",
    "href": "new_pages/flexdashboard.de.html#ressourcen",
    "title": "42  Dashboards mit R Markdown",
    "section": "42.10 Ressourcen",
    "text": "42.10 Ressourcen\nNachfolgend findest du hervorragende Anleitungen, die diese Seite informiert haben. Wenn du dir diese ansiehst, kannst du wahrscheinlich innerhalb einer Stunde dein eigenes Dashboard erstellen.\nhttps://bookdown.org/yihui/rmarkdown/dashboards.html\nhttps://rmarkdown.rstudio.com/flexdashboard/\nhttps://rmarkdown.rstudio.com/flexdashboard/using.html\nhttps://rmarkdown.rstudio.com/flexdashboard/examples.html",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards mit R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html",
    "href": "new_pages/shiny_basics.de.html",
    "title": "43  Dashboards mit Shiny",
    "section": "",
    "text": "43.1 Vorbereitung",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#vorbereitung",
    "href": "new_pages/shiny_basics.de.html#vorbereitung",
    "title": "43  Dashboards mit Shiny",
    "section": "",
    "text": "Pakete laden\nIn diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\nWir beginnen mit der Installation des glänzenden R-Paket:\n\npacman::p_load(shiny)\n\n\n\nDaten importieren\nWenn du diese Seite weiterverfolgen möchtest, findest du in diesem Abschnitt der Handbuch und Daten herunterladen. Dort findest du Links zum Herunterladen der R-Skripte und Datendateien, die die endgültige Shiny-App erzeugen.\nWenn du versuchst, die App mit diesen Dateien zu rekonstruieren, beachte bitte die Ordnerstruktur des R-Projekts, die im Laufe der Demonstration erstellt wird (z. B. Ordner für “data” und für “funcs”).",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#die-struktur-einer-shiny-app",
    "href": "new_pages/shiny_basics.de.html#die-struktur-einer-shiny-app",
    "title": "43  Dashboards mit Shiny",
    "section": "43.2 Die Struktur einer Shiny App",
    "text": "43.2 Die Struktur einer Shiny App\n\nGrundlegende Dateistrukturen\nZu verstehen shiny zu verstehen, müssen wir zuerst verstehen, wie die Dateistruktur einer App funktioniert! Bevor wir anfangen, sollten wir ein neues Verzeichnis anlegen. Das geht einfacher, wenn du Neues Projekt in Rstudio und wählt Shiny Web-Anwendung. Dadurch wird die Grundstruktur einer Shiny App für dich erstellt.\nWenn du dieses Projekt öffnest, wirst du feststellen, dass es eine .R Datei bereits vorhanden ist, die app.R. Sie ist wichtig dass wir eine von zwei grundlegenden Dateistrukturen haben:\n\nEine Datei namens app.R, oder\nZwei Dateien, eine mit dem Namen ui.R und die andere server.R\n\nAuf dieser Seite verwenden wir den ersten Ansatz mit einer Datei namens app.R. Hier ist ein Beispielskript:\n\n# an example of app.R\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"My app\"),\n\n    # Sidebar with a slider input widget\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # Show a plot \n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n     \n     plot_1 &lt;- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot &lt;- renderPlot({\n       plot_1()\n    })\n}\n\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\nWenn du diese Datei öffnest, wirst du feststellen, dass zwei Objekte definiert sind - eines heißt ui und ein weiteres namens server. Diese Objekte müssen definiert werden in jeder glänzenden App und sind zentral für die Struktur der App selbst! Der einzige Unterschied zwischen den beiden oben beschriebenen Dateistrukturen ist, dass in Struktur 1 beide ui und server in einer Datei definiert sind, während sie in Struktur 2 in separaten Dateien definiert sind. Hinweis: Wir können (und sollten, wenn wir eine größere Anwendung haben) auch andere .R-Dateien in unserer Struktur haben, die wir source() in unsere App integrieren.\n\n\nDer Server und die Benutzeroberfläche\nAls nächstes müssen wir verstehen, was der server und ui Objekte eigentlich tun. Einfach ausgedrückt sind dies zwei Objekte, die miteinander interagieren, wenn der Nutzer mit der Shiny App interagiert.\nDas UI-Element einer Shiny App ist, vereinfacht gesagt, R-Code, der eine HTML-Oberfläche erstellt. Das bedeutet, dass alles, was angezeigt in der Benutzeroberfläche einer App angezeigt wird. Dazu gehören im Allgemeinen:\n\n“Widgets” - Dropdown-Menüs, Kontrollkästchen, Schieberegler usw., mit denen der Nutzer interagieren kann\nPlots, Tabellen usw. - Ausgaben, die mit R-Code erzeugt werden\nNavigationsaspekte einer App - Registerkarten, Fenster usw.\nAllgemeiner Text, Hyperlinks, etc.\nHTML- und CSS-Elemente (wird später behandelt)\n\nDas Wichtigste, was du über die Benutzeroberfläche wissen musst, ist, dass sie Eingaben empfängt vom Benutzer und zeigt Ausgaben an des Servers an. Es gibt keine aktive Code, der in der Benutzeroberfläche zu jeder Zeit - Alle Änderungen in der Benutzeroberfläche werden (mehr oder weniger) über den Server übertragen. Wir müssen also unsere Plots, Downloads usw. auf dem Server erstellen.\nDer Server der Shiny App ist der Ort, an dem der gesamte Code ausgeführt wird, sobald die App gestartet wird. Die Art und Weise, wie das funktioniert, ist etwas verwirrend. Die Serverfunktion wird effektiv reagieren auf die Interaktion des Benutzers mit der Benutzeroberfläche und führt als Reaktion darauf Codeschnipsel aus. Wenn sich etwas auf dem Server ändert, wird dies an die Benutzeroberfläche weitergegeben, wo die Änderungen sichtbar sind. Wichtig ist, dass der Code auf dem Server ausgeführt wird nicht aufeinanderfolgend ausgeführt (oder man kann es sich am besten so vorstellen). Immer wenn eine UI-Eingabe einen Teil des Codes im Server beeinflusst, wird dieser automatisch ausgeführt und die entsprechende Ausgabe wird erzeugt und angezeigt.\nDas hört sich jetzt wahrscheinlich alles sehr abstrakt an, also müssen wir uns ein paar Beispiele ansehen, um eine klare Vorstellung davon zu bekommen, wie das Ganze funktioniert.\n\n\nBevor du mit der Entwicklung einer App beginnst\nBevor du mit der Entwicklung einer App beginnst, ist es sehr hilfreich zu wissen was du bauen willst. Da deine Benutzeroberfläche in Code geschrieben wird, kannst du dir nicht wirklich vorstellen, was du bauen willst, es sei denn, du hast ein bestimmtes Ziel. Aus diesem Grund ist es sehr hilfreich, sich viele Beispiele für glänzende Apps anzusehen, um eine Vorstellung davon zu bekommen, was du machen kannst - noch besser ist es, wenn du dir den Quellcode dieser Apps ansehen kannst! Einige gute Quellen dafür sind:\n\nDie Rstudio App-Galerie\n\nSobald du eine Vorstellung davon hast, was möglich ist, ist es auch hilfreich, eine Skizze zu machen, wie deine App aussehen soll - das kannst du auf Papier oder in einem beliebigen Zeichenprogramm (PowerPoint, MS Paint usw.) machen. Es ist hilfreich, bei deiner ersten App einfach anzufangen! Es ist auch keine Schande, den Code einer schönen App, die du online findest, als Vorlage für deine Arbeit zu verwenden - das ist viel einfacher, als etwas von Grund auf neu zu bauen!",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#eine-benutzeroberfläche-bauen",
    "href": "new_pages/shiny_basics.de.html#eine-benutzeroberfläche-bauen",
    "title": "43  Dashboards mit Shiny",
    "section": "43.3 Eine Benutzeroberfläche bauen",
    "text": "43.3 Eine Benutzeroberfläche bauen\nBei der Entwicklung unserer App ist es einfacher, zuerst an der Benutzeroberfläche zu arbeiten, damit wir sehen können, was wir machen, und nicht riskieren, dass die App aufgrund von Serverfehlern fehlschlägt. Wie bereits erwähnt, ist es oft gut, bei der Arbeit an der Benutzeroberfläche eine Vorlage zu verwenden. Es gibt eine Reihe von Standardlayouts, die mit Shiny verwendet werden können und die im Basispaket von Shiny enthalten sind. shinydashboard. Für den Anfang verwenden wir ein Beispiel aus dem Basispaket von Shiny.\nEine Shiny UI wird im Allgemeinen als eine Reihe von verschachtelten Funktionen in der folgenden Reihenfolge definiert\n\nEine Funktion, die das allgemeine Layout definiert (die grundlegendste ist fluidPage(), aber es gibt noch mehr)\nPanels innerhalb des Layouts wie z. B:\n\n\neine Seitenleiste (sidebarPanel())\nein “Haupt”-Panel (mainPanel())\neine Registerkarte (tabPanel())\neine generische “Spalte” (column())\n\n\nWidgets und Ausgaben - diese können Eingaben an den Server (Widgets) oder Ausgaben vom Server (Ausgaben) vermitteln\n\n\nWidgets sind in der Regel gestylt als xxxInput() z.B. selectInput()\nDie Ausgaben sind in der Regel gestylt als xxxOutput() z.B. plotOutput()\n\nEs lohnt sich, noch einmal darauf hinzuweisen, dass diese nicht einfach auf abstrakte Weise visualisiert werden können, daher ist es am besten, sich ein Beispiel anzusehen! Stellen wir uns eine einfache App vor, die unsere Daten zur Anzahl der Malaria-Einrichtungen nach Bezirken visualisiert. Diese Daten haben viele verschiedene Parameter, also wäre es toll, wenn der Endnutzer einige Filter anwenden könnte, um die Daten nach Altersgruppen/Bezirken zu sehen, wie es ihm passt! Für den Anfang können wir ein sehr einfaches, glänzendes Layout verwenden - das Sidebar-Layout. Dabei handelt es sich um ein Layout, bei dem die Widgets in einer Seitenleiste auf der linken Seite und die Grafik auf der rechten Seite platziert sind.\nPlanen wir unsere App - wir können mit einem Selektor beginnen, mit dem wir den Bezirk auswählen können, in dem wir die Daten visualisieren wollen, und mit einem weiteren, mit dem wir die Altersgruppe visualisieren können, an der wir interessiert sind. Mit diesen Filtern wollen wir eine Epikurve anzeigen, die diese Parameter widerspiegelt. Dafür brauchen wir also:\n\nZwei Dropdown-Menüs, mit denen wir den gewünschten Bezirk und die gewünschte Altersgruppe auswählen können.\nEin Bereich, in dem wir unsere resultierende Epikurve anzeigen können.\n\nDas könnte etwa so aussehen:\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\nWenn app.R mit dem obigen UI-Code ausgeführt wird (ohne aktiven Code in der server Teil von app.R), sieht das Layout so aus - beachte, dass es keinen Plot gibt, wenn es keinen Server gibt, der ihn rendert, aber unsere Eingaben funktionieren!\n\n\n\n\n\n\n\n\n\nDies ist eine gute Gelegenheit, um die Funktionsweise der Widgets zu besprechen - beachte, dass jedes Widget ein inputId, a label und eine Reihe anderer Optionen, die für den jeweiligen Widget-Typ spezifisch sind. Diese inputId ist sehr wichtig - mit diesen IDs werden Informationen von der Benutzeroberfläche an den Server weitergegeben. Aus diesem Grund müssen sie müssen sie eindeutig sein. Du solltest dich bemühen, ihnen einen sinnvollen Namen zu geben, der sich auf das bezieht, womit sie interagieren, wenn es sich um größere Apps handelt.\nDu solltest die Dokumentation genau lesen, um zu erfahren, was die einzelnen Widgets tun. Je nach Widget-Typ übermitteln die Widgets bestimmte Arten von Daten an den Server, die du genau kennen musst. Zum Beispiel, selectInput() einen Zeichentyp an den Server weiter:\n\nWenn wir wählen Frühling für das erste Widget hier auswählen, wird es das Zeichenobjekt \"Spring\" an den Server weiter.\nWenn wir zwei Elemente aus dem Dropdown-Menü auswählen, werden sie als Zeichenvektor übermittelt (z. B. c(\"Spring\", \"Bolo\")).\n\nAndere Widgets übermitteln andere Objekttypen an den Server! Zum Beispiel:\n\nnumericInput() übergibt ein numerisches Objekt an den Server\ncheckboxInput() übergibt ein Objekt vom logischen Typ an den Server (TRUE oder FALSE)\n\nEs ist auch erwähnenswert, dass die benannter Vektor den wir hier für die Altersdaten verwendet haben. Bei vielen Widgets werden bei der Verwendung eines benannten Vektors als Auswahlmöglichkeit die Namen des Vektors als Auswahlmöglichkeiten angezeigt, aber die ausgewählten Wert aus dem Vektor an den Server weiter. Hier kann jemand z. B. “15+” aus dem Dropdown-Menü auswählen, und die Benutzeroberfläche wird den Wert an den Server weitergeben. \"malaria_rdt_15\" an den Server weiter - was zufällig der Name der Spalte ist, die uns interessiert!\nEs gibt viele Widgets, mit denen du viele Dinge in deiner App machen kannst. Mit Widgets kannst du auch Dateien in deine App hochladen und Ausgaben herunterladen. Es gibt auch einige hervorragende Shiny-Erweiterungen, die dir Zugriff auf mehr Widgets als das Basis-Shiny geben - die shinyWidgets Paket ist ein gutes Beispiel dafür. Einige Beispiele kannst du dir unter den folgenden Links ansehen:\n\nbase shiny widget gallery\nshinyWidgets Galerie",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#daten-in-unsere-app-laden",
    "href": "new_pages/shiny_basics.de.html#daten-in-unsere-app-laden",
    "title": "43  Dashboards mit Shiny",
    "section": "43.4 Daten in unsere App laden",
    "text": "43.4 Daten in unsere App laden\nDer nächste Schritt bei der Entwicklung unserer App ist, den Server zum Laufen zu bringen. Dazu müssen wir einige Daten in unsere App laden und uns überlegen, welche Berechnungen wir durchführen wollen. Eine glänzende App ist nicht einfach zu debuggen, da oft nicht klar ist, woher die Fehler kommen. Deshalb ist es ideal, wenn wir unseren gesamten Datenverarbeitungs- und Visualisierungscode zum Laufen bringen, bevor wir mit der Entwicklung des Servers selbst beginnen.\nWenn wir also eine App erstellen wollen, die Epi-Kurven anzeigt, die sich aufgrund von Benutzereingaben ändern, sollten wir uns überlegen, welchen Code wir benötigen, um dies in einem normalen R-Skript auszuführen. Das werden wir brauchen:\n\nUnsere Pakete laden\nLade unsere Daten\nDaten transformieren\nEntwickeln Sie eine Funktion um unsere Daten auf der Grundlage von Benutzereingaben zu visualisieren\n\nDiese Liste ist ziemlich überschaubar und sollte nicht allzu schwer zu bewerkstelligen sein. Jetzt ist es wichtig, darüber nachzudenken, welche Teile dieses Prozesses nur einmal gemacht werden und welche Teile als Reaktion auf Benutzereingaben ausgeführt werden. Das liegt daran, dass glänzende Apps in der Regel einen Teil des Codes vor der Ausführung ausführen, der nur einmal ausgeführt wird. Es hilft der Leistung unserer App, wenn wir so viel Code wie möglich in diesen Abschnitt verschieben können. In diesem Beispiel müssen wir unsere Daten/Pakete nur einmal laden und grundlegende Transformationen durchführen, also können wir diesen Code außerhalb des Servers. Das heißt, das Einzige, was wir auf dem Server brauchen, ist der Code zur Visualisierung unserer Daten. Lass uns all diese Komponenten zunächst in einem Skript entwickeln. Da wir unsere Daten jedoch mit einer Funktion visualisieren, können wir den Code auch für die Funktion außerhalb des Servers platzieren, damit unsere Funktion in der Umgebung ist, wenn die App läuft!\nLaden wir zunächst unsere Daten. Da wir mit einem neuen Projekt arbeiten und es sauber machen wollen, können wir ein neues Verzeichnis mit dem Namen data erstellen und dort unsere Malaria-Daten hinzufügen. Wir können diesen Code unten in einem Testskript ausführen, das wir später löschen, wenn wir die Struktur unserer App bereinigt haben.\n\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# read data\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\nprint(malaria_data)\n\n# A tibble: 3,038 × 10\n   location_name data_date  submitted_date Province District `malaria_rdt_0-4`\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring                  11\n 2 Facility 2    2020-08-11 2020-08-12     North    Bolo                    11\n 3 Facility 3    2020-08-11 2020-08-12     North    Dingo                    8\n 4 Facility 4    2020-08-11 2020-08-12     North    Bolo                    16\n 5 Facility 5    2020-08-11 2020-08-12     North    Bolo                     9\n 6 Facility 6    2020-08-11 2020-08-12     North    Dingo                    3\n 7 Facility 6    2020-08-10 2020-08-12     North    Dingo                    4\n 8 Facility 5    2020-08-10 2020-08-12     North    Bolo                    15\n 9 Facility 5    2020-08-09 2020-08-12     North    Bolo                    11\n10 Facility 5    2020-08-08 2020-08-12     North    Bolo                    19\n# ℹ 3,028 more rows\n# ℹ 4 more variables: `malaria_rdt_5-14` &lt;int&gt;, malaria_rdt_15 &lt;int&gt;,\n#   malaria_tot &lt;int&gt;, newid &lt;int&gt;\n\n\nEs wird einfacher sein, mit diesen Daten zu arbeiten, wenn wir ordentliche Datenstandards verwenden, also sollten wir sie auch in ein längeres Datenformat umwandeln, in dem die Altersgruppe eine Spalte und die Fälle eine weitere Spalte sind. Das können wir ganz einfach mit dem machen, was wir im Kurs [Daten spiegeln] Seite gelernt haben.\n\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)\n\n# A tibble: 12,152 × 7\n   location_name data_date  submitted_date Province District age_group       \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;           \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_0-4 \n 2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_5-14\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_15  \n 4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot     \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_0-4 \n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_5-14\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_15  \n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot     \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_0-4 \n10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_5-14\n# ℹ 12,142 more rows\n# ℹ 1 more variable: cases_reported &lt;int&gt;\n\n\nUnd damit sind wir mit der Vorbereitung unserer Daten fertig! Damit sind die Punkte 1, 2 und 3 auf unserer Liste der Dinge, die wir für unser “Test-R-Skript” entwickeln müssen, gestrichen. Die letzte und schwierigste Aufgabe besteht darin, eine Funktion zu entwickeln, die auf der Grundlage von benutzerdefinierten Parametern eine Epikurve erstellt. Wie bereits erwähnt, ist es dringend empfohlendass jeder, der shiny lernt, sich zuerst den Abschnitt über funktionale Programmierung ansieht ([Funktionen schreiben]), um zu verstehen, wie das funktioniert!\nWenn wir unsere Funktion definieren, kann es schwierig sein, darüber nachzudenken, welche Parameter wir angeben wollen. Bei der funktionalen Programmierung mit Shiny ist jeder relevante Parameter in der Regel mit einem Widget verknüpft, so dass es normalerweise ganz einfach ist, darüber nachzudenken! In unserer aktuellen App wollen wir zum Beispiel nach Bezirken filtern und haben dafür ein Widget, also können wir einen Parameter für den Bezirk hinzufügen. Wir haben keine Wir haben (noch) keine App-Funktionen, um nach Einrichtungen zu filtern, also brauchen wir das nicht als Parameter hinzuzufügen. Beginnen wir damit, eine Funktion mit drei Parametern zu erstellen:\n\nDer Kerndatensatz\nDer Bezirk der Wahl\nDie Altersgruppe der Wahl\n\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nWir werden nicht weiter auf diese Funktion eingehen, da sie relativ einfach funktioniert. Eine Sache, die wir jedoch beachten sollten, ist, dass wir Fehler behandeln, indem wir NULL zurückgibt, wenn sie sonst einen Fehler auslösen würde. Das liegt daran, dass ein Shiny Server eine NULL Objekt statt eines Plot-Objekts erzeugt, wird in der Benutzeroberfläche nichts angezeigt! Das ist wichtig, da Fehler sonst oft dazu führen, dass deine App nicht mehr funktioniert.\nEin weiterer wichtiger Punkt ist die Verwendung des %in% Operators bei der Auswertung der district Eingabe. Wie oben erwähnt, könnte es sich um einen Zeichenvektor mit mehreren Werten handeln. %in% flexibler ist als z. B., ==.\nLass uns unsere Funktion testen!\n\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n\n\n\n\n\n\n\n\nDa unsere Funktion funktioniert, müssen wir jetzt verstehen, wie das alles in unsere glänzende App passt. Wir erwähnten das Konzept der Startup-Code erwähnt, aber jetzt schauen wir uns an, wie wir ihn in die Struktur unserer App einbauen können. Es gibt zwei Möglichkeiten, wie wir das tun können!\n\nFüge diesen Code in deine app.R Datei am Anfang des Skripts ein (oberhalb der Benutzeroberfläche), oder\nErstelle eine neue Datei im Verzeichnis deiner App mit dem Namen global.R und füge den Startcode in diese Datei ein.\n\nAn dieser Stelle sei angemerkt, dass es vor allem bei größeren Anwendungen einfacher ist, die zweite Dateistruktur zu verwenden, da du so deine Dateistruktur auf einfache Weise trennen kannst. Entwickeln wir nun das global.R-Skript vollständig. So könnte es aussehen:\n\n# global.R script\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n# read data\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\n# clean data and pivot longer\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# define plotting function\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # create plot title\n  if (!(\"All\" %in% district)) {            \n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # filter to age group\n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nEinfach! Eine großartige Funktion von Shiny ist, dass es versteht, welche Dateien mit dem Namen app.R, server.R, ui.R, und global.R sind für, so dass es nicht nötig ist, sie über irgendeinen Code miteinander zu verbinden. Wenn du also diesen Code in global.R im Verzeichnis wird er ausgeführt, bevor wir unsere App starten!\nWir sollten auch beachten, dass es die Organisation unserer App verbessern würde, wenn wir die Plotting-Funktion in eine eigene Datei verschieben würden - das ist besonders hilfreich, wenn die App größer wird. Dazu könnten wir ein weiteres Verzeichnis mit dem Namen funcs anlegen und diese Funktion in eine Datei namens plot_epicurve.R. Wir können diese Funktion dann mit folgendem Befehl einlesen global.R\n\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)\n\nBeachte, dass du immer angeben. local = TRUE in Shiny Apps an, da es sich auf das Sourcing auswirkt, wenn die App auf einem Server veröffentlicht wird.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#einen-app-server-entwickeln",
    "href": "new_pages/shiny_basics.de.html#einen-app-server-entwickeln",
    "title": "43  Dashboards mit Shiny",
    "section": "43.5 Einen App-Server entwickeln",
    "text": "43.5 Einen App-Server entwickeln\nJetzt, da wir den größten Teil unseres Codes haben, müssen wir nur noch unseren Server entwickeln. Das ist der letzte Teil unserer App und wahrscheinlich der am schwersten zu verstehende. Der Server ist eine große R-Funktion, aber es ist hilfreich, ihn sich als eine Reihe von kleineren Funktionen oder Aufgaben vorzustellen, die die App ausführen kann. Es ist wichtig zu verstehen, dass diese Funktionen nicht in einer linearen Reihenfolge ausgeführt werden. Es gibt zwar eine Reihenfolge, aber die muss man nicht unbedingt verstehen, wenn man mit Shiny anfängt. Ganz grundsätzlich werden diese Aufgaben oder Funktionen aktiviert, wenn sich die Eingaben des Nutzers ändern und sie beeinflussen, es sei denn, der Entwickler hat sie so eingestellt, dass sie sich anders verhalten. Auch das ist alles ziemlich abstrakt, aber gehen wir zunächst die drei Grundtypen von Shiny durch Objekte\n\nReaktive Quellen - das ist ein anderer Begriff für Benutzereingaben. Der Shiny Server hat über die Widgets, die wir programmiert haben, Zugriff auf die Ausgaben der Benutzeroberfläche. Jedes Mal, wenn die Werte für diese Widgets geändert werden, wird dies an den Server weitergegeben.\nReaktive Conductors - das sind Objekte, die existieren nur innerhalb des Shiny Servers existieren. Für einfache Anwendungen brauchen wir sie eigentlich nicht, aber sie erzeugen Objekte, die nur innerhalb des Servers zu sehen sind und in anderen Operationen verwendet werden. Sie sind in der Regel auf reaktive Quellen angewiesen.\nEndpunkte - das sind die Ausgaben, die vom Server an die Benutzeroberfläche weitergegeben werden. In unserem Beispiel wäre das die Epi-Kurve, die wir erzeugen.\n\nMit diesem Wissen bauen wir unseren Server Schritt für Schritt auf. Zur Veranschaulichung zeigen wir hier noch einmal unseren UI-Code:\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\nIn diesem Code haben wir eine UI:\n\nZwei Eingänge:\n\nBezirksselektor (mit einer inputId von select_district)\nAltersgruppen-Selektor (mit einer inputId von select_agegroup)\n\nEine Ausgabe:\n\nDie Epikurve (mit einer outputId von malaria_epicurve)\n\n\nWie bereits erwähnt, sind die eindeutigen Namen, die wir unseren Inputs und Outputs zugewiesen haben, entscheidend. Sie müssen eindeutig sein und werden verwendet, um Informationen zwischen der Benutzeroberfläche und dem Server zu übermitteln. In unserem Server greifen wir auf unsere Eingaben über die Syntax input$inputID und die Ausgaben und werden über die Syntax output$output_name Schauen wir uns ein Beispiel an, denn auch das ist sonst schwer zu verstehen!\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}\n\nDer Server für eine einfache App wie diese ist eigentlich ganz einfach! Du wirst feststellen, dass der Server eine Funktion mit drei Parametern ist - input, output, und session - Das ist im Moment nicht so wichtig zu verstehen, aber es ist wichtig, dass du dich an dieses Setup hältst! In unserem Server gibt es nur eine Aufgabe - sie rendert einen Plot auf der Grundlage unserer Funktion, die wir zuvor erstellt haben, und der Eingaben vom Server. Beachte, dass die Namen der Eingabe- und Ausgabeobjekte genau mit denen der Benutzeroberfläche übereinstimmen.\nUm zu verstehen, wie der Server auf Benutzereingaben reagiert, solltest du beachten, dass die Ausgabe (durch das zugrunde liegende Paket) weiß, wenn sich die Eingaben ändern, und diese Funktion jedes Mal erneut ausführt, um ein Diagramm zu erstellen, wenn sie sich ändern. Beachte, dass wir auch die renderPlot() Funktion verwenden - sie gehört zu einer Familie von klassenspezifischen Funktionen, die diese Objekte an eine UI-Ausgabe weitergeben. Es gibt eine Reihe von Funktionen, die sich ähnlich verhalten, aber du musst sicherstellen, dass die verwendete Funktion zu der Klasse des Objekts passt, das du an die ui übergibst! Zum Beispiel:\n\nrenderText() - Text an die Benutzeroberfläche senden\nrenderDataTable - eine interaktive Tabelle an die Benutzeroberfläche senden.\n\nDenk daran, dass diese auch mit der Ausgabe übereinstimmen müssen Funktion die in der Benutzeroberfläche verwendet wird - also renderPlot() ist gepaart mit plotOutput(), und renderText() wird gepaart mit textOutput().\nWir haben also endlich eine funktionierende App erstellt! Wir können sie ausführen, indem wir auf die Schaltfläche App ausführen oben rechts im Skriptfenster in Rstudio klicken. Du kannst deine App auch in deinem Standardbrowser ausführen (und nicht in Rstudio), dann sieht die App für andere Benutzer besser aus.\n\n\n\n\n\n\n\n\n\nInteressant ist, dass die App in der R-Konsole “zuhört”! Das nennt man Reaktivität!",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#mehr-funktionalität-hinzufügen",
    "href": "new_pages/shiny_basics.de.html#mehr-funktionalität-hinzufügen",
    "title": "43  Dashboards mit Shiny",
    "section": "43.6 Mehr Funktionalität hinzufügen",
    "text": "43.6 Mehr Funktionalität hinzufügen\nJetzt haben wir endlich eine funktionierende App, aber wir haben nur sehr wenige Funktionen. Außerdem haben wir noch nicht einmal an der Oberfläche dessen gekratzt, was Shiny alles kann, es gibt also noch viel zu lernen! Lasst uns unsere App weiter ausbauen, indem wir einige zusätzliche Funktionen hinzufügen. Einige Dinge, die wir gerne hinzufügen würden, wären:\n\nEinige erklärende Texte\nEin Download-Button für unseren Plot - damit erhält der Nutzer eine qualitativ hochwertige Version des Bildes, das er in der App erstellt\nEin Selektor für bestimmte Einrichtungen\nEine weitere Dashboard-Seite - diese könnte eine Tabelle mit unseren Daten zeigen.\n\nDas ist eine Menge, aber wir können es nutzen, um auf dem Weg dorthin eine Menge über verschiedene Shiny-Features zu lernen. Es gibt so viel über Shiny zu lernen (es kann sehr (es kann sehr fortschrittlich sein, aber wenn die Nutzer/innen erst einmal wissen, wie man es benutzt, können sie hoffentlich auch externe Lernquellen nutzen).\n\nHinzufügen von statischem Text\nZuerst wollen wir darüber sprechen, wie wir statischen Text zu unserer Shiny App hinzufügen. Das Hinzufügen von Text zu unserer App ist extrem einfach, wenn du erst einmal ein Grundverständnis dafür hast. Da sich statischer Text in der Shiny App nicht ändert (wenn du möchtest, dass er sich ändert, kannst du ihn mit Textwiedergabe Funktionen auf dem Server verwenden!), wird der gesamte statische Text von Shiny in der Regel in der Benutzeroberfläche der App hinzugefügt. Wir werden das hier nicht im Detail erklären, aber du kannst deiner Benutzeroberfläche eine Reihe verschiedener Elemente (und sogar eigene) hinzufügen, indem du R mit HTML und css.\nHTML und css sind Sprachen, die explizit mit der Gestaltung von Benutzeroberflächen zu tun haben. Wir müssen sie nicht allzu gut verstehen, aber HTML erstellt Objekte in der Benutzeroberfläche (wie ein Textfeld oder eine Tabelle), und css wird im Allgemeinen verwendet, um den Stil und die Ästhetik dieser Objekte zu ändern. Shiny hat Zugriff auf eine große Anzahl von HTML-Tags - Diese sind für Objekte vorhanden, die sich auf eine bestimmte Art und Weise verhalten, wie z. B. Überschriften, Textabsätze, Zeilenumbrüche, Tabellen usw. Wir können einige dieser Beispiele wie folgt verwenden:\n\nh1() - dies a a Kopfzeile Tag, der den eingeschlossenen Text automatisch größer macht und die Standardeinstellungen für Schriftart, Farbe usw. ändert (je nach dem Gesamtthema deiner App). Du kannst auf kleiner und kleiner Zwischenüberschriften mit h2() bis hinunter zu h6() auch. Die Verwendung sieht so aus:\n\nh1(\"my header - section 1\")\n\np() - Dies ist ein Absatz Tag, der den eingeschlossenen Text ähnlich wie den Text in einem Textkörper macht. Dieser Text wird automatisch umbrochen und hat eine relativ kleine Größe (Fußzeilen können z. B. kleiner sein.) Stell dir das wie den Textkörper eines Word-Dokuments vor. Die Verwendung sieht so aus:\n\np(\"This is a larger body of text where I am explaining the function of my app\")\n\ntags$b() und tags$i() - diese werden verwendet, um fette tags$b() und kursiv tags$i() mit dem Text, der eingeschlossen ist!\ntags$ul(), tags$ol() und tags$li() - dies sind Tags, die bei der Erstellung von Listen. Sie werden alle in der folgenden Syntax verwendet und ermöglichen es dem Benutzer, entweder eine geordnete Liste zu erstellen (tags$ol(); d.h. nummeriert) oder eine ungeordnete Liste (tags$ul(), d.h. Aufzählungspunkte). tags$li() wird verwendet, um Elemente in der Liste zu kennzeichnen, unabhängig davon, welche Art von Liste verwendet wird. z.B.:\n\n\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\n\n\nbr() und hr() - diese Tags erzeugen Zeilenumbrüche und horizontale Linien (mit einem Zeilenumbruch). Verwende sie, um die Abschnitte deiner App und den Text voneinander zu trennen! Es ist nicht nötig, diesen Tags Elemente zu übergeben (Klammern können leer bleiben).\ndiv() - Dies ist ein generische Tag, der alles enthalten und kann sein alles benennen. Wenn du mit dem Design der Benutzeroberfläche fortschreitest, kannst du diese verwenden, um deine Benutzeroberfläche zu unterteilen, bestimmten Abschnitten bestimmte Stile zu geben und Interaktionen zwischen dem Server und den UI-Elementen zu erstellen. Wir werden hier nicht ins Detail gehen, aber es lohnt sich, sie zu kennen!\n\nAuf jedes dieser Objekte kannst du über tags$... oder bei einigen nur über die Funktion. Sie sind praktisch synonym, aber es kann hilfreich sein, die tags$... Stil zu verwenden, wenn du lieber explizit sein möchtest und die Funktionen nicht versehentlich überschreiben willst. Dies ist keine vollständige Liste der verfügbaren Tags. Eine vollständige Liste aller verfügbaren Tags findest du in shiny hier und noch mehr können verwendet werden, indem du HTML direkt in deine Benutzeroberfläche einfügst!\nWenn du dich sicher fühlst, kannst du auch beliebige css-Styling-Elemente zu deinen HTML-Tags mit der style Argument in jedem von ihnen. Wir werden nicht im Detail darauf eingehen, wie das funktioniert, aber ein Tipp, um ästhetische Änderungen an einer Benutzeroberfläche zu testen, ist die Verwendung des HTML-Inspektors in Chrome (deiner glänzenden App, die du im Browser ausführst) und die Bearbeitung des Stils der Objekte selbst!\nFügen wir unserer App etwas Text hinzu\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)\n\n\n\n\n\n\n\n\n\n\n\n\nHinzufügen eines Links\nUm einen Link zu einer Website hinzuzufügen, benutze tags$a() mit dem Link und dem Anzeigetext wie unten gezeigt. Wenn du ihn als eigenständigen Absatz haben willst, füge ihn innerhalb von p(). Wenn nur einige Wörter eines Satzes verlinkt werden sollen, unterteile den Satz in Teile und verwende tags$a() für den verlinkten Teil. Um sicherzustellen, dass sich der Link in einem neuen Browserfenster geöffnet wird, füge target = \"_blank\" als Argument ein.\n\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")\n\n\n\nHinzufügen einer Download-Schaltfläche\nKommen wir nun zur zweiten der drei Funktionen. Eine Download-Schaltfläche ist eine ziemlich gängige Funktion, die man einer App hinzufügen kann und die ziemlich einfach zu erstellen ist. Wir müssen nur ein weiteres Widget zu unserer Benutzeroberfläche hinzufügen und einen weiteren Ausgang zu unserem Server hinzufügen, um ihn zu verbinden. Wir können auch einen reaktive Leiter in diesem Beispiel!\nAktualisieren wir zuerst unsere Benutzeroberfläche - das ist ganz einfach, denn Shiny kommt mit einem Widget namens downloadButton() - Wir geben ihm eine inputId und ein Label.\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\nBeachte, dass wir auch ein hr() Tag eingefügt haben - damit wird eine horizontale Linie hinzugefügt, die unsere Kontroll-Widgets von den Download-Widgets trennt. Dies ist ein weiteres der HTML-Tags, die wir zuvor besprochen haben.\nJetzt, wo wir unsere Benutzeroberfläche fertig haben, müssen wir die Serverkomponente hinzufügen. Die Downloads werden auf dem Server mit dem downloadHandler() Funktion. Ähnlich wie bei unserem Plot müssen wir sie an einen Output anhängen, der die gleiche inputId hat wie der Download-Button. Diese Funktion benötigt zwei Argumente - filename und content - das sind beides Funktionen. Wie du dir vielleicht denken kannst, filename den Namen der heruntergeladenen Datei an, und content wird verwendet, um anzugeben, was heruntergeladen werden soll. content enthält eine Funktion, die du zum lokalen Speichern von Daten verwenden würdest - wenn du also eine csv-Datei herunterlädst, könntest du verwenden rio::export(). Da wir einen Plot herunterladen, verwenden wir ggplot2::ggsave(). Schauen wir uns an, wie wir das programmieren würden (wir fügen es dem Server noch nicht hinzu).\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nBeachte, dass die content Funktion immer eine file Argument, das wir an die Stelle setzen, an der der Name der Ausgabedatei angegeben ist. Vielleicht fällt dir auch auf, dass wir den Code hier wiederholen - wir verwenden unsere plot_epicurve() Funktion in diesem Server zweimal: einmal für den Download und einmal für das Bild, das in der App angezeigt wird. Das hat zwar keine großen Auswirkungen auf die Leistung, aber es bedeutet, dass der Code zur Erstellung der Grafik ausgeführt werden muss, wenn der Nutzer die Widgets für den Bezirk und die Altersgruppe ändert, und erneut ausgeführt werden muss, wenn du das Diagramm herunterladen möchtest. In größeren Apps verlangsamen suboptimale Entscheidungen wie diese die Dinge immer mehr, daher ist es gut zu lernen, wie wir unsere App in dieser Hinsicht effizienter machen können. Noch sinnvoller wäre es, wenn wir eine Möglichkeit hätten, den Epikurvencode auszuführen, wenn die Bezirke/Altersgruppen geändert werden, und das von der App genutzt werden könnte die renderPlot()- und downloadHandler()-Funktionen. Hier kommen die reaktiven Dirigenten ins Spiel!\nReaktive Conductors sind Objekte, die auf dem Shiny Server in einer reaktiven erstellt werden, aber nicht ausgegeben werden - sie können einfach von anderen Teilen des Servers verwendet werden. Es gibt eine Reihe von verschiedenen Arten von reaktiven Leitern Wir gehen hier nur die beiden wichtigsten durch.\n1.reactive() - Dies ist der einfachste reaktive Leiter - er reagiert immer dann, wenn sich die darin verwendeten Eingaben ändern (also unsere Bezirks-/Altersgruppen-Widgets).\n2. eventReactive()- Dieser reaktive Leiter funktioniert genauso wie reactive() mit dem Unterschied, dass der/die Nutzer/in festlegen kann, welche Eingaben eine erneute Ausführung bewirken sollen. Das ist nützlich, wenn dein reaktiver Dirigent viel Zeit für die Bearbeitung braucht, aber dazu später mehr.\nSchauen wir uns die beiden Beispiele an:\n\nmalaria_plot_r &lt;- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# only runs when the district selector changes!\nmalaria_plot_er &lt;- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\nWenn wir die eventReactive() verwenden, können wir angeben, welche Eingaben dazu führen, dass dieser Code ausgeführt wird - das ist im Moment nicht sehr nützlich für uns, also lassen wir es vorerst. Beachte, dass du mehrere Eingaben mit c()\nSchauen wir uns an, wie wir das in unseren Servercode integrieren können:\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nWie du siehst, rufen wir einfach die Ausgabe unserer Reactive auf, die wir sowohl in unseren Download- als auch in unseren Plot-Rendering-Funktionen definiert haben. Eine Sache, über die man oft stolpert, ist, dass man die Ausgaben von Reactives so verwenden muss, als wären sie Funktionen - du musst also musst du leere Klammern am Ende der Funktionen hinzufügen (d.h.. malaria_plot() ist korrekt, und malaria_plot ist nicht korrekt). Jetzt, wo wir diese Lösung hinzugefügt haben, ist unsere App etwas aufgeräumter, schneller und leichter zu ändern, da sich der gesamte Code, der die Epikurvenfunktion ausführt, an einer Stelle befindet.\n\n\n\n\n\n\n\n\n\n\n\nHinzufügen eines Betriebsmittelselektors\nKommen wir zu unserer nächsten Funktion - einem Selektor für bestimmte Einrichtungen. Wir werden einen weiteren Parameter in unsere Funktion einbauen, damit wir diesen als Argument in unserem Code übergeben können. Schauen wir uns das erst einmal an - es funktioniert nach denselben Prinzipien wie die anderen Parameter, die wir eingerichtet haben. Aktualisieren und testen wir unsere Funktion.\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data &lt;- data %&gt;%\n      filter(location_name == facility)\n    \n    plot_title_facility &lt;- facility\n    \n  } else {\n    \n    plot_title_facility &lt;- \"all facilities\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nTesten wir sie:\n\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\n\n\n\n\n\n\n\n\nBei all den Einrichtungen in unseren Daten ist es nicht ganz klar, welche Einrichtungen welchen Bezirken entsprechen - und der Endnutzer wird es auch nicht wissen. Das könnte die Benutzung der App ziemlich unintuitiv machen. Aus diesem Grund sollten wir dafür sorgen, dass sich die Einrichtungsoptionen in der Benutzeroberfläche dynamisch ändern, wenn der Nutzer den Bezirk wechselt - so filtert eine die andere! Da wir so viele Variablen in den Optionen verwenden, möchten wir vielleicht auch einige unserer Optionen für die Benutzeroberfläche in unserer global.R Datei aus den Daten. Zum Beispiel können wir diesen Codeabschnitt hinzufügen zu global.R hinzufügen, nachdem wir unsere Daten eingelesen haben:\n\nall_districts &lt;- c(\"All\", unique(malaria_data$District))\n\n# data frame of location names by district\nfacility_list &lt;- malaria_data %&gt;%\n  group_by(location_name, District) %&gt;%\n  summarise() %&gt;% \n  ungroup()\n\nSchauen wir sie uns an:\n\nall_districts\n\n[1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\n\n\n\nfacility_list\n\n# A tibble: 65 × 2\n   location_name District\n   &lt;chr&gt;         &lt;chr&gt;   \n 1 Facility 1    Spring  \n 2 Facility 10   Bolo    \n 3 Facility 11   Spring  \n 4 Facility 12   Dingo   \n 5 Facility 13   Bolo    \n 6 Facility 14   Dingo   \n 7 Facility 15   Barnard \n 8 Facility 16   Barnard \n 9 Facility 17   Barnard \n10 Facility 18   Bolo    \n# ℹ 55 more rows\n\n\nWir können diese neuen Variablen problemlos an die Benutzeroberfläche übergeben, da sie sowohl für den Server als auch für die Benutzeroberfläche global sichtbar sind! Aktualisieren wir unser UI:\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for facility\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\nBeachte, dass wir jetzt Variablen für unsere Auswahlmöglichkeiten übergeben, anstatt sie in der Benutzeroberfläche fest zu codieren! Das könnte unseren Code auch kompakter machen! Zum Schluss müssen wir den Server aktualisieren. Es wird einfach sein, unsere Funktion zu aktualisieren, um unsere neue Eingabe zu integrieren (wir müssen sie nur als Argument an unseren neuen Parameter übergeben), aber wir sollten daran denken, dass wir auch wollen, dass die Benutzeroberfläche dynamisch aktualisiert wird, wenn der Nutzer den gewählten Bezirk ändert. Es ist wichtig zu verstehen, dass wir die Parameter und das Verhalten der Widgets ändern können ändern können, während die App läuft, aber das muss getan werden auf dem Server. Wir müssen einen neuen Weg für die Ausgabe auf dem Server finden, um zu lernen, wie man das macht.\nDie Funktionen, die wir dazu verstehen müssen, sind bekannt als Beobachter Funktionen, die ähnlich sind wie reaktiven Funktionen, was ihr Verhalten angeht. Sie haben jedoch einen entscheidenden Unterschied:\n\nReaktive Funktionen wirken sich nicht direkt auf die Ausgaben aus und erzeugen Objekte, die an anderen Stellen des Servers zu sehen sind\nBeobachterfunktionen können Sie können die Ausgaben des Servers beeinflussen, tun dies aber über Seiteneffekte anderer Funktionen. (Sie können auch andere Dinge tun, aber dies ist in der Praxis ihre Hauptfunktion)\n\nÄhnlich wie bei den reaktiven Funktionen gibt es zwei Arten von Beobachterfunktionen, die durch dieselbe Logik unterteilt werden, die auch die reaktiven Funktionen unterteilt:\n\nobserve() - Diese Funktion wird immer dann ausgeführt, wenn sich die in ihr verwendeten Eingaben ändern.\nobserveEvent() - Diese Funktion wird ausgeführt, wenn ein benutzerdefinierte Eingabe ändert\n\nWir müssen auch die von Shiny bereitgestellten Funktionen verstehen, die Widgets aktualisieren. Diese sind ziemlich einfach auszuführen - sie nehmen zuerst die session Objekt von der Serverfunktion (das müssen wir vorerst nicht verstehen), und dann die inputId der zu ändernden Funktion. Dann übergeben wir die neuen Versionen aller Parameter, die bereits von der selectInput() - diese werden automatisch im Widget aktualisiert.\nSchauen wir uns ein Beispiel an, wie wir dies in unserem Server nutzen können. Wenn der Nutzer den Bezirk wechselt, wollen wir unsere Liste der Einrichtungen nach dem Bezirk filtern und die Auswahlmöglichkeiten auf nur die Einrichtungen anzuzeigen, die in diesem Bezirk verfügbar sind (und eine Option für alle Einrichtungen)\n\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices &lt;- facility_list$location_name\n  } else {\n    new_choices &lt;- facility_list %&gt;%\n      filter(District == input$select_district) %&gt;%\n      pull(location_name)\n  }\n  \n  new_choices &lt;- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\n\nUnd das war’s! Wir können ihn in unseren Server einfügen, und das Verhalten wird nun funktionieren. So sollte unser neuer Server aussehen:\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}\n\n\n\n\n\n\n\n\n\n\n\n\nHinzufügen einer weiteren Registerkarte mit einer Tabelle\nJetzt gehen wir zur letzten Komponente über, die wir unserer App hinzufügen wollen. Wir wollen unsere Benutzeroberfläche in zwei Registerkarten aufteilen, von denen eine eine interaktive Tabelle enthält, in der der Benutzer die Daten sehen kann, mit denen er die Epidemiekurve erstellt. Dazu können wir die gepackten UI-Elemente verwenden, die in Shiny für die Tabs enthalten sind. Grundsätzlich können wir den größten Teil unseres Hauptpanels in diese allgemeine Struktur einbetten:\n\n# ... the rest of ui\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\n\nWenden wir dies auf unsere Benutzeroberfläche an. Wir werden auch die DT Paket verwenden - das ist ein großartiges Paket, um interaktive Tabellen aus bereits vorhandenen Daten zu erstellen. Wir sehen, dass es verwendet wird für DT::datatableOutput() in diesem Beispiel.\n\nui &lt;- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # selector for district\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for age group\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for facility\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # horizontal line\n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\n\nJetzt ist unsere App in Tabs gegliedert! Lass uns nun auch die notwendigen Änderungen am Server vornehmen. Da wir unseren Datensatz nicht bearbeiten müssen, bevor wir ihn rendern, ist das eigentlich sehr einfach - wir rendern den malaria_data-Datensatz einfach über DT::renderDT() in die Benutzeroberfläche!\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # render data table to ui\n  output$raw_data &lt;- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#shiny-apps-teilen",
    "href": "new_pages/shiny_basics.de.html#shiny-apps-teilen",
    "title": "43  Dashboards mit Shiny",
    "section": "43.7 Shiny Apps teilen",
    "text": "43.7 Shiny Apps teilen\nJetzt, wo du deine App entwickelt hast, willst du sie wahrscheinlich mit anderen teilen - das ist schließlich der Hauptvorteil von Shiny! Dazu können wir den Code direkt teilen oder auf einem Server veröffentlichen. Wenn wir den Code teilen, können andere sehen, was du gemacht hast, und darauf aufbauen, aber dadurch wird einer der Hauptvorteile von Shiny zunichte gemacht - Die Endnutzer müssen keine R-Installation mehr unterhalten.. Wenn du deine App mit Nutzern teilst, die mit R nicht vertraut sind, ist es daher viel einfacher, eine App zu teilen, die auf einem Server veröffentlicht wurde.\nWenn du lieber den Code weitergeben möchtest, kannst du eine .zip-Datei der App erstellen, oder noch besser, veröffentliche deine App auf Github und füge Mitwirkende hinzu. Weitere Informationen findest du in dem Abschnitt über github hier.\nWenn wir die App jedoch online veröffentlichen, müssen wir etwas mehr Arbeit leisten. Schließlich wollen wir, dass deine App über eine Web-URL zugänglich ist, damit andere schnell und einfach darauf zugreifen können. Um deine App auf einem Server zu veröffentlichen, musst du Zugang zu einem Server haben, auf dem du sie veröffentlichen kannst! Hierfür gibt es eine Reihe von Hosting-Optionen:\n\nshinyapps.io: Dies ist der einfachste Ort, um Shiny-Apps zu veröffentlichen, denn hier ist der geringste Konfigurationsaufwand nötig und es gibt einige kostenlose, aber begrenzte Lizenzen.\nRStudio Connect RStudio Connect: Dies ist eine viel leistungsfähigere Version eines R-Servers, der viele Operationen durchführen kann, einschließlich der Veröffentlichung von glänzenden Apps. Er ist jedoch schwieriger zu bedienen und für Einsteiger weniger zu empfehlen.\n\nFür die Zwecke dieses Dokuments werden wir den shinyapps.io verwenden, da es für Erstnutzer einfacher ist. Du kannst dir hier ein kostenloses Konto einrichten, um anzufangen - es gibt auch verschiedene Preispläne für Server-Lizenzen, wenn du sie brauchst. Je mehr Nutzer du erwartest, desto teurer muss dein Preisplan sein, also bedenke das. Wenn du etwas für eine kleine Gruppe von Einzelpersonen erstellen willst, kann eine kostenlose Lizenz vollkommen ausreichend sein, aber für eine öffentlich zugängliche App brauchst du vielleicht mehr Lizenzen.\nZuerst sollten wir sicherstellen, dass unsere App für die Veröffentlichung auf einem Server geeignet ist. In deiner App solltest du deine R-Sitzung neu starten und sicherstellen, dass sie ohne zusätzlichen Code läuft. Das ist wichtig, denn eine App, die das Laden von Paketen oder das Lesen von Daten erfordert, die nicht in deinem App-Code definiert sind, läuft nicht auf einem Server. Beachte auch, dass du keine explizite Dateipfade in deiner App haben darfst - diese sind in der Servereinstellung ungültig - wenn du die here Paket löst dieses Problem sehr gut. Wenn du Daten aus einer Quelle ausliest, die eine Benutzerauthentifizierung erfordert, z. B. von den Servern deines Unternehmens, wird dies in der Regel nicht auf einem Server funktionieren. Du musst dich mit deiner IT-Abteilung in Verbindung setzen, um herauszufinden, wie du den Shiny Server auf die Whitelist setzen kannst.\nAnmeldung zum Konto\nSobald du dein Konto eingerichtet hast, kannst du zur Token-Seite navigieren unter Konten. Hier fügst du ein neues Token hinzu - dieses wird für die Bereitstellung deiner App verwendet.\nAb hier solltest du beachten, dass die URL deines Kontos den Namen deiner App widerspiegelt - wenn deine App also heißt meine_app heißt, wird die Url wie folgt angehängt xxx.io/meine_app/. Wähle den Namen deiner App mit Bedacht! Jetzt bist du bereit und klickst auf “deploy” - wenn du erfolgreich bist, wird deine App auf der von dir gewählten Web-URL ausgeführt!\netwas über das Erstellen von Apps in Dokumenten?",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#weitere-lektüre",
    "href": "new_pages/shiny_basics.de.html#weitere-lektüre",
    "title": "43  Dashboards mit Shiny",
    "section": "43.8 Weitere Lektüre",
    "text": "43.8 Weitere Lektüre\nBisher haben wir viele Aspekte von Shiny behandelt und kaum an der Oberfläche dessen gekratzt, was Shiny zu bieten hat. Auch wenn dieser Leitfaden als Einführung dient, gibt es noch viel mehr zu lernen, um Shiny vollständig zu verstehen. Du solltest mit der Erstellung von Apps beginnen und nach und nach immer mehr Funktionen hinzufügen",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#empfohlene-erweiterungspakete",
    "href": "new_pages/shiny_basics.de.html#empfohlene-erweiterungspakete",
    "title": "43  Dashboards mit Shiny",
    "section": "43.9 Empfohlene Erweiterungspakete",
    "text": "43.9 Empfohlene Erweiterungspakete\nIm Folgenden findest du eine Auswahl an hochwertigen Shiny-Erweiterungen, mit denen du noch viel mehr aus Shiny herausholen kannst. In keiner bestimmten Reihenfolge:\n\nshinyWidgets - Dieses Paket bietet dir viele weitere Widgets, die du in deiner App verwenden kannst. ausführen shinyWidgets::shinyWidgetsGallery() aus, um eine Auswahl der verfügbaren Widgets mit diesem Paket zu sehen. Siehe Beispiele hier\nshinyjs - Dies ist ein hervorragendes Paket, mit dem du den Nutzen von Shiny durch eine Reihe von Javascripts stark erweitern kannst. Die Anwendungsmöglichkeiten dieses Pakets reichen von sehr einfach bis sehr fortschrittlich, aber vielleicht möchtest du es zunächst nutzen, um die Benutzeroberfläche auf einfache Weise zu manipulieren, z. B. um Elemente ein- oder auszublenden oder Schaltflächen zu aktivieren oder zu deaktivieren. Erfahre mehr hier\nshinydashboard - Dieses Paket erweitert die verfügbare Benutzeroberfläche, die in Shiny verwendet werden kann, und ermöglicht es dem Benutzer, ein komplexes Dashboard mit einer Vielzahl von komplexen Layouts zu erstellen. Mehr sehen hier\nshinydashboardPlus - erhalten Sie noch mehr Funktionen aus dem shinydashboard Framework! Mehr sehen hier\nshinythemes - Ändere das Standard-CSS-Theme für deine Shiny App mit einer großen Auswahl an voreingestellten Vorlagen! Mehr sehen hier\n\nEs gibt auch eine Reihe von Paketen, mit denen du interaktive Ausgaben erstellen kannst, die mit Shiny kompatibel sind.\n\nDT ist teilweise in base-shiny integriert, bietet aber eine Reihe von Funktionen, um interaktive Tabellen zu erstellen.\nplotly ist ein Paket zur Erstellung interaktiver Diagramme, die der Nutzer in der App bearbeiten kann. Du kannst deinen Plot auch in interaktive Versionen umwandeln, indem du plotly::ggplotly()! Als Alternativen, dygraphs und highcharter sind ebenfalls ausgezeichnet.",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.de.html#empfohlene-ressourcen",
    "href": "new_pages/shiny_basics.de.html#empfohlene-ressourcen",
    "title": "43  Dashboards mit Shiny",
    "section": "43.10 Empfohlene Ressourcen",
    "text": "43.10 Empfohlene Ressourcen",
    "crumbs": [
      "Berichte und Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards mit Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html",
    "href": "new_pages/writing_functions.de.html",
    "title": "44  Funktionen schreiben",
    "section": "",
    "text": "44.1 Vorbereitung",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#vorbereitung",
    "href": "new_pages/writing_functions.de.html#vorbereitung",
    "title": "44  Funktionen schreiben",
    "section": "",
    "text": "Pakete laden\nDieser Codeabschnitt zeigt das Laden von Paketen, die für die Analysen benötigt werden. In diesem Handbuch betonen wir p_load() von pacman, der das Paket bei Bedarf installiert und lädt es zur Verwendung. Du kannst installierte Pakete auch laden mit library() von baseR. Siehe die Seite über [R-Grundlagen] für weitere Informationen über R-Pakete.\n\n\nDaten importieren\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du die Daten herunterladen möchtest, um Schritt für Schritt vorzugehen, lies die Anweisungen im [Buch und Daten herunterladen] Seite. Der Datensatz wird importiert, indem dieimport() Funktion aus dem rioPaket. Siehe die Seite über [Import und Export] für verschiedene Möglichkeiten, Daten zu importieren.\nIm letzten Teil dieser Seite werden wir auch einige Daten zur H7N9-Grippe aus dem Jahr 2013 verwenden.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#funktionen",
    "href": "new_pages/writing_functions.de.html#funktionen",
    "title": "44  Funktionen schreiben",
    "section": "44.2 Funktionen",
    "text": "44.2 Funktionen\nFunktionen sind beim Programmieren hilfreich, da sie es ermöglichen, den Code verständlicher, kürzer und weniger fehleranfällig zu machen (vorausgesetzt, es gibt keine Fehler in der Funktion selbst).\nWenn du bis zu diesem Handbuch vorgedrungen bist, bedeutet das, dass du schon unzählige Funktionen kennengelernt hast, denn in R ist jede Operation ein Funktionsaufruf +, for, if, [, $, { …. Zum Beispiel x + y ist dasselbe wie'+'(x, y)\nR ist eine der Sprachen, die die meisten Möglichkeiten bietet, mit Funktionen zu arbeiten und dem Benutzer genügend Werkzeuge an die Hand gibt, um sie einfach zu schreiben. Wir sollten Funktionen nicht als etwas betrachten, das am Anfang oder am Ende der Programmierkette steht. R bietet die Möglichkeit, sie wie Vektoren zu verwenden und sie sogar innerhalb anderer Funktionen, Listen usw. einzusetzen.\nEs gibt viele sehr fortgeschrittene Ressourcen zur funktionalen Programmierung. Wir werden hier nur einen Einblick geben, um dir den Einstieg in die funktionale Programmierung mit kurzen praktischen Beispielen zu erleichtern. Wir empfehlen dir, die Links unter Referenzen zu besuchen, um mehr darüber zu erfahren.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#warum-solltest-du-eine-funktion-verwenden",
    "href": "new_pages/writing_functions.de.html#warum-solltest-du-eine-funktion-verwenden",
    "title": "44  Funktionen schreiben",
    "section": "44.3 Warum solltest du eine Funktion verwenden?",
    "text": "44.3 Warum solltest du eine Funktion verwenden?\nBevor du diese Frage beantwortest, ist es wichtig zu wissen, dass du bereits Tipps zum Schreiben deiner allerersten R-Funktionen auf der Seite über [Iteration, Schleifen und Listen] in diesem Handbuch. Tatsächlich ist die Verwendung von “if/else” und Schleifen oft ein zentraler Bestandteil vieler unserer Funktionen, da sie uns helfen, entweder die Anwendung unseres Codes zu erweitern und mehrere Bedingungen zuzulassen oder Codes für wiederkehrende Aufgaben zu iterieren.\n\nIch wiederhole mehrmals denselben Codeblock, um ihn auf eine andere Variable oder Daten anzuwenden?\nWenn ich ihn loswerde, wird mein Code dann wesentlich kürzer und schneller?\nIst es möglich, dass der Code, den ich geschrieben habe, wieder verwendet wird, aber mit einem anderen Wert an vielen Stellen des Codes?\n\nWenn die Antwort auf eine der vorherigen Fragen “JA” lautet, dann musst du wahrscheinlich eine Funktion schreiben",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#wie-baut-r-funktionen-auf",
    "href": "new_pages/writing_functions.de.html#wie-baut-r-funktionen-auf",
    "title": "44  Funktionen schreiben",
    "section": "44.4 Wie baut R Funktionen auf?",
    "text": "44.4 Wie baut R Funktionen auf?\nFunktionen in R haben drei Hauptkomponenten:\n\ndie formals() ist die Liste der Argumente, die steuert, wie wir die Funktion aufrufen können\ndie body() das ist der Code innerhalb der Funktion, d.h. innerhalb der Klammern oder nach der Klammer, je nachdem, wie wir ihn schreiben\n\nund,\n\ndie environment() die dabei helfen, die Variablen der Funktion zu finden und bestimmen, wie die Funktion ihren Wert findet.\n\nWenn du deine Funktion erstellt hast, kannst du jede dieser Komponenten überprüfen, indem du die zugehörige Funktion aufrufst.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#grundlegende-syntax-und-struktur",
    "href": "new_pages/writing_functions.de.html#grundlegende-syntax-und-struktur",
    "title": "44  Funktionen schreiben",
    "section": "44.5 Grundlegende Syntax und Struktur",
    "text": "44.5 Grundlegende Syntax und Struktur\n\nEine Funktion muss richtig benannt werden, damit ihre Aufgabe leicht verständlich ist, sobald wir ihren Namen lesen. Eigentlich ist das bei den meisten Funktionen der R-Basisarchitektur bereits der Fall. Funktionen wie mean(), print(), summary() haben Namen, die sehr einfach sind\nEine Funktion benötigt Argumente, wie z. B. die zu bearbeitenden Daten und andere Objekte, die unter anderem statische Werte sein können\nUnd schließlich gibt eine Funktion eine Ausgabe, die auf ihrer Kernaufgabe und den Argumenten basiert, die sie erhalten hat. Normalerweise verwenden wir die eingebauten Funktionen als print(), return()… um die Ausgabe zu erzeugen. Bei der Ausgabe kann es sich um einen logischen Wert, eine Zahl, ein Zeichen, einen Datenrahmen usw. handeln, also um jede Art von R-Objekt.\n\nIm Grunde ist dies die Zusammensetzung einer Funktion:\n\nfunction_name &lt;- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\n\nWir können unsere erste Funktion erstellen, die folgendermaßen heißen wird contain_covid19().\n\ncontain_covid19 &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\nDann können wir die Komponenten unserer neu erstellten Funktion überprüfen.\n\nformals(contain_covid19)\n\n$barrier_gest\n\n\n$wear_mask\n\n\n$get_vaccine\n\nbody(contain_covid19)\n\n{\n    if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n        \"yes\") \n        return(\"success\")\n    else (\"please make sure all are yes, this pandemic has to end!\")\n}\n\nenvironment(contain_covid19)\n\n&lt;environment: R_GlobalEnv&gt;\n\n\nJetzt werden wir unsere Funktion testen. Um unsere geschriebene Funktion aufzurufen, verwendest du sie wie alle R-Funktionen, d.h. du schreibst den Funktionsnamen und fügst die erforderlichen Argumente hinzu.\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")\n\n[1] \"success\"\n\n\nWir können die Namen der einzelnen Argumente vorsichtshalber noch einmal aufschreiben. Aber auch ohne sie anzugeben, sollte der Code funktionieren, da R die Position jedes Arguments im Speicher hat. Solange du also die Werte der Argumente in der richtigen Reihenfolge angibst, kannst du es dir sparen, die Namen der Argumente beim Aufruf der Funktionen zu schreiben.\n\ncontain_covid19(\"yes\", \"yes\", \"yes\")\n\n[1] \"success\"\n\n\nSchauen wir uns nun an, was passiert, wenn einer der Werte \"no\" oder nicht \"yes\".\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\n[1] \"please make sure all are yes, this pandemic has to end!\"\n\n\nWenn wir ein Argument angeben, das nicht erkannt wird, erhalten wir einen Fehler:\n\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\nError in contain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\",  :  could not find function \"contain_covid19\"\nHINWEIS: Einige Funktionen (meist sehr kurz und einfach) brauchen keinen Namen und können direkt in einer Codezeile oder innerhalb einer anderen Funktion verwendet werden, um eine schnelle Aufgabe zu erledigen. Sie werden genannt anonyme Funktionen .\nIm Folgenden findest du zum Beispiel eine erste anonyme Funktion, die nur Zeichenvariablen im Datensatz behält.\n\nlinelist %&gt;% \n  dplyr::slice_head(n=10) %&gt;%  #equivalent to R base \"head\" function and that return first n observation of the  dataset\n  select(function(x) is.character(x)) \n\n\n\n\n\n\n\nDann eine weitere Funktion, die jede zweite Beobachtung unseres Datensatzes auswählt (das kann relevant sein, wenn wir Längsschnittdaten mit vielen Datensätzen pro Patient haben, z. B. nachdem wir nach Datum oder Besuch geordnet haben). In diesem Fall wäre die richtige Funktion, die außerhalb von dplyr geschrieben wird, folgende function (x) (x%%2 == 0) auf den Vektor anwenden, der alle Zeilennummern enthält.\n\nlinelist %&gt;%   \n   slice_head(n=20) %&gt;% \n   tibble::rownames_to_column() %&gt;% # add indices of each obs as rownames to clearly see the final selection\n   filter(row_number() %%2 == 0)\n\n\n\n\n\n\n\nEin möglicher Basis-R-Code für dieselbe Aufgabe wäre:\n\nlinelist_firstobs &lt;- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]\n\n\n\n\n\n\n\nVORSICHT! Es stimmt zwar, dass die Verwendung von Funktionen uns bei unserem Code helfen kann, aber es kann trotzdem zeitaufwändig sein, einige Funktionen zu schreiben oder eine Funktion zu korrigieren, wenn sie nicht gründlich durchdacht und angemessen geschrieben wurde und als Ergebnis Fehler zurückgibt. Aus diesem Grund wird oft empfohlen, zuerst den R-Code zu schreiben, sicherzustellen, dass er das tut, was wir beabsichtigen, und ihn dann in eine Funktion mit den drei oben genannten Hauptkomponenten umzuwandeln.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#beispiele",
    "href": "new_pages/writing_functions.de.html#beispiele",
    "title": "44  Funktionen schreiben",
    "section": "44.6 Beispiele",
    "text": "44.6 Beispiele\n\nProportionstabellen für mehrere Spalten zurückgeben\nJa, in vielen Paketen gibt es bereits nette Funktionen, mit denen man Informationen auf einfache und schöne Weise zusammenfassen kann. Aber wir werden trotzdem versuchen, unsere eigenen Funktionen zu erstellen, um uns an das Schreiben von Funktionen zu gewöhnen.\nIn diesem Beispiel wollen wir zeigen, wie man durch das Schreiben einer einfachen Funktion vermeiden kann, dass man denselben Code mehrfach einfügt.\n\nproptab_multiple &lt;- function(my_data, var_to_tab){\n  \n  #print the name of each variable of interest before doing the tabulation\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( #bind the results of the two following function by row\n        #tabulate the variable of interest: gives only numbers\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #calculate the proportions for each variable of interest and round the value to 2 decimals\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")\n\n[1] \"gender\"\n\n\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n\nproptab_multiple(linelist, \"age_cat\")\n\n[1] \"age_cat\"\n\n\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n\nproptab_multiple(linelist, \"outcome\")\n\n[1] \"outcome\"\n\n\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nTIPP: Wie oben gezeigt, ist es sehr wichtig, deine Funktionen zu kommentieren, wie du es auch bei der allgemeinen Programmierung tun würdest. Bedenke, dass eine Funktion das Ziel hat, einen Code lesbar, kürzer und effizienter zu machen. Dann sollte man in der Lage sein, zu verstehen, was die Funktion tut, wenn man nur ihren Namen liest, und sollte mehr Details beim Lesen der Kommentare erfahren.\nEine zweite Möglichkeit ist, diese Funktion in einer anderen Funktion über eine Schleife zu verwenden, um den Prozess auf einmal zu machen:\n\nfor(var_to_tab in c(\"gender\",\"age_cat\",  \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}\n\n[1] \"gender\"\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n[1] \"age_cat\"\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n[1] \"outcome\"\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nEine einfachere Möglichkeit wäre die Verwendung der R-Basis “apply” anstelle einer “for-Schleife”, wie unten beschrieben:\nTIPP: R wird oft als funktionale Programmiersprache definiert und fast jedes Mal, wenn du eine Codezeile ausführst, verwendest du einige integrierte Funktionen. Eine gute Angewohnheit, um sich beim Schreiben von Funktionen besser zurechtzufinden, ist es, sich oft intern anzusehen, wie die grundlegenden Funktionen, die du täglich verwendest, aufgebaut sind. Die Abkürzung dafür ist, den Funktionsnamen auszuwählen und dann aufCtrl+F2 oder fn+F2 oder Cmd+F2 (abhängig von deinem Computer) .",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#verwenden-purrr-funktionen-schreiben-die-iterativ-angewendet-werden-können",
    "href": "new_pages/writing_functions.de.html#verwenden-purrr-funktionen-schreiben-die-iterativ-angewendet-werden-können",
    "title": "44  Funktionen schreiben",
    "section": "44.7 verwenden purrr: Funktionen schreiben, die iterativ angewendet werden können",
    "text": "44.7 verwenden purrr: Funktionen schreiben, die iterativ angewendet werden können\n\nÄndern der Klasse mehrerer Spalten in einem Datensatz\nNehmen wir an, dass viele Zeichenvariablen in der ursprünglichen linelist Daten zu Analyse- und Plotzwecken in “Faktor” geändert werden müssen. Anstatt den Schritt mehrmals zu wiederholen, können wir einfach Folgendes verwenden lapply() verwenden, um die Umwandlung aller betroffenen Variablen in einer einzigen Codezeile durchzuführen.\nVORSICHT! lapply() gibt eine Liste zurück, daher kann ihre Verwendung eine zusätzliche Änderung als letzten Schritt erfordern.\nDerselbe Schritt kann mit map_if() Funktion aus dem purrr Paket\n\nlinelist_factor2 &lt;- linelist %&gt;%\n  purrr::map_if(is.character, as.factor)\n\n\nlinelist_factor2 %&gt;%\n        glimpse()\n\nList of 30\n $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA ...\n $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" ...\n $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" ...\n $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" ...\n $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ...\n\n\n\n\nIterativ Diagramme für verschiedene Stufen einer Variablen erstellen\nWir werden hier ein Kreisdiagramm erstellen, um die Verteilung der Patientenergebnisse in China während des H7N9-Ausbruchs für jede Provinz zu betrachten. Anstatt den Code für jede einzelne Provinz zu wiederholen, wenden wir einfach eine Funktion an, die wir erstellen.\n\n#precising options for the use of highchart\noptions(highcharter.theme =   highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n#create a function called \"chart_outcome_province\" that takes as argument the dataset and the name of the province for which to plot the distribution of the outcome.\n\nchart_outcome_province &lt;- function(data_used, prov){\n  \n  tab_prov &lt;- data_used %&gt;% \n    filter(province == prov,\n           !is.na(outcome))%&gt;% \n    group_by(outcome) %&gt;% \n    count() %&gt;%\n    adorn_totals(where = \"row\") %&gt;% \n    adorn_percentages(denominator = \"col\", )%&gt;%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %&gt;%\n    filter(outcome != \"Total\") %&gt;% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distibution of the outcome in:\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\n\n\n\n\nchart_outcome_province(flu_china,\"Zhejiang\")\n\n\n\n\nchart_outcome_province(flu_china,\"Jiangsu\")\n\n\n\n\n\n\n\nIterativ Tabellen für verschiedene Ebenen einer Variablen erstellen\nHier werden wir drei Indikatoren erstellen, die wir in einer Tabelle zusammenfassen und diese Tabelle für jede Provinz erstellen möchten. Unsere Indikatoren sind die Verzögerung zwischen Krankheitsbeginn und Krankenhausaufenthalt, der Prozentsatz der Genesung und das Durchschnittsalter der Fälle.\n\nindic_1 &lt;- flu_china %&gt;% \n  group_by(province) %&gt;% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %&gt;%\n  select(province, mean_delay_onset_hosp)  %&gt;% \n  distinct()\n     \n\nindic_2 &lt;-  flu_china %&gt;% \n            filter(!is.na(outcome)) %&gt;% \n            group_by(province, outcome) %&gt;% \n            count() %&gt;%\n            pivot_wider(names_from = outcome, values_from = n) %&gt;% \n    adorn_totals(where = \"col\") %&gt;% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%&gt;% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 &lt;-  flu_china %&gt;% \n            group_by(province) %&gt;% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %&gt;% \n  select(province, median_age_cases)  %&gt;% \n  distinct()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `median_age_cases = median(as.numeric(age), na.rm = TRUE)`.\nℹ In group 11: `province = \"Shanghai\"`.\nCaused by warning in `median()`:\n! NAs introduced by coercion\n\n#join the three indicator datasets\n\ntable_indic_all &lt;- indic_1 %&gt;% \n  dplyr::left_join(indic_2, by = \"province\") %&gt;% \n        left_join(indic_3, by = \"province\")\n\n\n#print the indicators in a flextable\n\n\nprint_indic_prov &lt;-  function(table_used, prov){\n  \n  #first transform a bit the dataframe for printing ease\n  indic_prov &lt;- table_used %&gt;%\n    filter(province==prov) %&gt;%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %&gt;% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\",\"perc_recovery\",\"median_age_cases\"),\n   labels=c(\"Mean delay onset-hosp\",\"Percentage of recovery\", \"Median age of the cases\"))\n   ) %&gt;% \n    ungroup(province) %&gt;% \n    select(indic_label, value)\n  \n\n    tab_print &lt;- flextable(indic_prov)  %&gt;%\n    theme_vanilla() %&gt;% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print &lt;- tab_print %&gt;% \n                  autofit()   %&gt;%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %&gt;%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %&gt;%\n    flextable::bold(part = \"header\") %&gt;%\n    flextable::color(color = \"white\", part = \"header\") %&gt;% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de: \", prov)) %&gt;% \nbold(part = \"header\")\n \n tab_print &lt;- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\n\nIndicateurs pour la province de: ShanghaiIndicateursEstimationMean delay onset-hosp4.0Percentage of recovery46.7Median age of the cases67.0\n\nprint_indic_prov(table_indic_all, \"Jiangsu\")\n\nIndicateurs pour la province de: JiangsuIndicateursEstimationMean delay onset-hosp6.0Percentage of recovery71.4Median age of the cases55.0",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#tipps-und-best-practices-für-gut-funktionierende-funktionen",
    "href": "new_pages/writing_functions.de.html#tipps-und-best-practices-für-gut-funktionierende-funktionen",
    "title": "44  Funktionen schreiben",
    "section": "44.8 Tipps und Best Practices für gut funktionierende Funktionen",
    "text": "44.8 Tipps und Best Practices für gut funktionierende Funktionen\nFunktionale Programmierung soll den Code vereinfachen und das Lesen erleichtern. Sie soll das Gegenteil bewirken. Die folgenden Tipps helfen dir, einen sauberen und leicht lesbaren Code zu haben.\n\nBenennung und Syntax\n\nVermeide es, Zeichen zu verwenden, die leicht schon von anderen, in deiner Umgebung vorhandenen Funktionen übernommen werden könnten\nEs wird empfohlen, dass der Funktionsname kurz und für einen anderen Leser einfach zu verstehen ist.\nEs wird empfohlen, Verben als Funktionsnamen und Substantive für die Argumente zu verwenden.\n\n\n\nSpaltennamen und saubere Auswertung\nWenn du wissen willst, wie du auf Spaltennamen die deinem Code als Argumente übergeben werden, lies dies tidyverse Programmieranleitung. Zu den behandelten Themen gehören Tidy-Auswertung und die Verwendung der umarmen { } “Doppelte Klammern”\nHier ist zum Beispiel ein schnelles Skelett des Vorlagencodes von der oben erwähnten Seite:\n\nvar_summary &lt;- function(data, var) {\n  data %&gt;%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))\n}\nmtcars %&gt;% \n  group_by(cyl) %&gt;% \n  var_summary(mpg)\n\n\n\nTesten und Fehlerbehandlung\nJe komplizierter die Aufgabe einer Funktion ist, desto höher ist die Wahrscheinlichkeit von Fehlern. Daher ist es manchmal notwendig, innerhalb der Funktion eine Überprüfung vorzunehmen, um schnell herauszufinden, woher der Fehler kommt, und einen Weg zu finden, ihn zu beheben.\n\nEs kann mehr als empfehlenswert sein, eine Prüfung auf das Fehlen eines Arguments einzuführen, indem man missing(argument). Diese einfache Prüfung kann den Wert “TRUE” oder “FALSE” zurückgeben.\n\n\ncontain_covid19_missing &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask ==\"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")\n\n[1] \"please provide arg1\"\n[1] \"please provide arg2\"\n\n\nError in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\n\n\n\nVerwenden Sie stop() für besser erkennbare Fehler.\n\n\ncontain_covid19_stop &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\"))\n  \n  if (barrier_gest == \"yes\" & wear_mask ==\"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")\n\nError in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\n\n\n\nWenn wir die meisten eingebauten Funktionen ausführen, gibt es Meldungen und Warnungen, die unter bestimmten Bedingungen auftauchen können. Wir können diese in unsere geschriebenen Funktionen integrieren, indem wir die Funktionen message() und warning().\nWir können auch Fehler behandeln, indem wir safely() verwenden, die eine Funktion als Argument annimmt und sie sicher ausführt. Die Funktion wird nämlich ausgeführt, ohne anzuhalten, wenn sie auf einen Fehler stößt. safely() gibt als Ausgabe eine Liste mit zwei Objekten zurück, die die Ergebnisse und den übersprungenen Fehler enthalten.\n\nWir können das überprüfen, indem wir zuerst die mean() als Funktion ausführen, dann mit safely().\n\nmap(linelist, mean)\n\n$case_id\n[1] NA\n\n$generation\n[1] 16.56165\n\n$date_infection\n[1] NA\n\n$date_onset\n[1] NA\n\n$date_hospitalisation\n[1] \"2014-11-03\"\n\n$date_outcome\n[1] NA\n\n$outcome\n[1] NA\n\n$gender\n[1] NA\n\n$age\n[1] NA\n\n$age_unit\n[1] NA\n\n$age_years\n[1] NA\n\n$age_cat\n[1] NA\n\n$age_cat5\n[1] NA\n\n$hospital\n[1] NA\n\n$lon\n[1] -13.23381\n\n$lat\n[1] 8.469638\n\n$infector\n[1] NA\n\n$source\n[1] NA\n\n$wt_kg\n[1] 52.64487\n\n$ht_cm\n[1] 124.9633\n\n$ct_blood\n[1] 21.20686\n\n$fever\n[1] NA\n\n$chills\n[1] NA\n\n$cough\n[1] NA\n\n$aches\n[1] NA\n\n$vomit\n[1] NA\n\n$temp\n[1] NA\n\n$time_admission\n[1] NA\n\n$bmi\n[1] 46.89023\n\n$days_onset_hosp\n[1] NA\n\n\n\nsafe_mean &lt;- safely(mean)\nlinelist %&gt;% \n  map(safe_mean)\n\n$case_id\n$case_id$result\n[1] NA\n\n$case_id$error\nNULL\n\n\n$generation\n$generation$result\n[1] 16.56165\n\n$generation$error\nNULL\n\n\n$date_infection\n$date_infection$result\n[1] NA\n\n$date_infection$error\nNULL\n\n\n$date_onset\n$date_onset$result\n[1] NA\n\n$date_onset$error\nNULL\n\n\n$date_hospitalisation\n$date_hospitalisation$result\n[1] \"2014-11-03\"\n\n$date_hospitalisation$error\nNULL\n\n\n$date_outcome\n$date_outcome$result\n[1] NA\n\n$date_outcome$error\nNULL\n\n\n$outcome\n$outcome$result\n[1] NA\n\n$outcome$error\nNULL\n\n\n$gender\n$gender$result\n[1] NA\n\n$gender$error\nNULL\n\n\n$age\n$age$result\n[1] NA\n\n$age$error\nNULL\n\n\n$age_unit\n$age_unit$result\n[1] NA\n\n$age_unit$error\nNULL\n\n\n$age_years\n$age_years$result\n[1] NA\n\n$age_years$error\nNULL\n\n\n$age_cat\n$age_cat$result\n[1] NA\n\n$age_cat$error\nNULL\n\n\n$age_cat5\n$age_cat5$result\n[1] NA\n\n$age_cat5$error\nNULL\n\n\n$hospital\n$hospital$result\n[1] NA\n\n$hospital$error\nNULL\n\n\n$lon\n$lon$result\n[1] -13.23381\n\n$lon$error\nNULL\n\n\n$lat\n$lat$result\n[1] 8.469638\n\n$lat$error\nNULL\n\n\n$infector\n$infector$result\n[1] NA\n\n$infector$error\nNULL\n\n\n$source\n$source$result\n[1] NA\n\n$source$error\nNULL\n\n\n$wt_kg\n$wt_kg$result\n[1] 52.64487\n\n$wt_kg$error\nNULL\n\n\n$ht_cm\n$ht_cm$result\n[1] 124.9633\n\n$ht_cm$error\nNULL\n\n\n$ct_blood\n$ct_blood$result\n[1] 21.20686\n\n$ct_blood$error\nNULL\n\n\n$fever\n$fever$result\n[1] NA\n\n$fever$error\nNULL\n\n\n$chills\n$chills$result\n[1] NA\n\n$chills$error\nNULL\n\n\n$cough\n$cough$result\n[1] NA\n\n$cough$error\nNULL\n\n\n$aches\n$aches$result\n[1] NA\n\n$aches$error\nNULL\n\n\n$vomit\n$vomit$result\n[1] NA\n\n$vomit$error\nNULL\n\n\n$temp\n$temp$result\n[1] NA\n\n$temp$error\nNULL\n\n\n$time_admission\n$time_admission$result\n[1] NA\n\n$time_admission$error\nNULL\n\n\n$bmi\n$bmi$result\n[1] 46.89023\n\n$bmi$error\nNULL\n\n\n$days_onset_hosp\n$days_onset_hosp$result\n[1] NA\n\n$days_onset_hosp$error\nNULL\n\n\nWie schon gesagt, ist das Auskommentieren unseres Codes eine gute Möglichkeit, unsere Arbeit zu dokumentieren.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.de.html#ressourcen",
    "href": "new_pages/writing_functions.de.html#ressourcen",
    "title": "44  Funktionen schreiben",
    "section": "44.9 Ressourcen",
    "text": "44.9 Ressourcen\nR für Data Science Link\nCheatsheet R-Programmierung für Fortgeschrittene\nCheatsheet purr Paket\nVideo-ACM Vortrag von Hadley Wickham: Die Freude am funktionalen Programmieren (wie funktioniert map_dbl)",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Funktionen schreiben</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html",
    "href": "new_pages/directories.de.html",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "",
    "text": "45.1 Vorbereitung",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#vorbereitung",
    "href": "new_pages/directories.de.html#vorbereitung",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "",
    "text": "fs Paket\nDie fs Paket ist ein tidyverse Paket, das die Interaktion mit Verzeichnissen erleichtert und einige der Basis R-Funktionen. In den folgenden Abschnitten werden wir oft Funktionen aus fs.\n\npacman::p_load(\n  fs,             # file/directory interactions\n  rio,            # import/export\n  here,           # relative file pathways\n  tidyverse)      # data management and visualization\n\n\n\nVerzeichnis als Dendrogrammbaum drucken\nVerwende die Funktion dir_tree() von fs.\nGeben Sie den Dateipfad des Ordners an path = an und entscheide, ob du nur eine Ebene anzeigen möchtest (recurse = FALSE) oder alle Dateien in allen Unterebenen (recurse = TRUE). Im Folgenden verwenden wir here() als Abkürzung für das R-Projekt und geben seinen Unterordner “data” an, der alle für dieses R-Handbuch verwendeten Daten enthält. Wir stellen es so ein, dass alle Dateien in “data” und seinen Unterordnern (z. B. “cache”, “epidemic models”, “population”, “shp” und “weather”) angezeigt werden.\n\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpCIdkbN/file4e44725d9d0/data\n├── africa_countries.geo.json\n├── cache\n│   └── epidemic_models\n│       ├── 2015-04-30\n│       │   ├── estimated_reported_cases_samples.rds\n│       │   ├── estimate_samples.rds\n│       │   ├── latest_date.rds\n│       │   ├── reported_cases.rds\n│       │   ├── summarised_estimated_reported_cases.rds\n│       │   ├── summarised_estimates.rds\n│       │   └── summary.rds\n│       ├── epinow_res.rds\n│       ├── epinow_res_small.rds\n│       ├── generation_time.rds\n│       └── incubation_period.rds\n├── case_linelists\n│   ├── cleaning_dict.csv\n│   ├── fluH7N9_China_2013.csv\n│   ├── linelist_cleaned.rds\n│   ├── linelist_cleaned.xlsx\n│   └── linelist_raw.xlsx\n├── country_demographics.csv\n├── covid_example_data\n│   ├── covid_example_data.xlsx\n│   └── covid_shapefile\n│       ├── FultonCountyZipCodes.cpg\n│       ├── FultonCountyZipCodes.dbf\n│       ├── FultonCountyZipCodes.prj\n│       ├── FultonCountyZipCodes.sbn\n│       ├── FultonCountyZipCodes.sbx\n│       ├── FultonCountyZipCodes.shp\n│       ├── FultonCountyZipCodes.shp.xml\n│       └── FultonCountyZipCodes.shx\n├── covid_incidence.csv\n├── covid_incidence_map.R\n├── district_count_data.xlsx\n├── example\n│   ├── Central Hospital.csv\n│   ├── district_weekly_count_data.xlsx\n│   ├── fluH7N9_China_2013.csv\n│   ├── hospital_linelists.xlsx\n│   ├── linelists\n│   │   ├── 20201007linelist.csv\n│   │   ├── case_linelist20201006.csv\n│   │   ├── case_linelist_2020-10-02.csv\n│   │   ├── case_linelist_2020-10-03.csv\n│   │   ├── case_linelist_2020-10-04.csv\n│   │   ├── case_linelist_2020-10-05.csv\n│   │   └── case_linelist_2020-10-08.xlsx\n│   ├── Military Hospital.csv\n│   ├── Missing.csv\n│   ├── Other.csv\n│   ├── Port Hospital.csv\n│   └── St. Mark's Maternity Hospital (SMMH).csv\n├── facility_count_data.rds\n├── flexdashboard\n│   ├── outbreak_dashboard.html\n│   ├── outbreak_dashboard.Rmd\n│   ├── outbreak_dashboard_shiny.Rmd\n│   ├── outbreak_dashboard_test.html\n│   └── outbreak_dashboard_test.Rmd\n├── fluH7N9_China_2013.csv\n├── gis\n│   ├── africa_countries.geo.json\n│   ├── covid_incidence.csv\n│   ├── covid_incidence_map.R\n│   ├── linelist_cleaned_with_adm3.rds\n│   ├── population\n│   │   ├── sle_admpop_adm3_2020.csv\n│   │   └── sle_population_statistics_sierraleone_2020.xlsx\n│   └── shp\n│       ├── README.txt\n│       ├── sle_adm3.CPG\n│       ├── sle_adm3.dbf\n│       ├── sle_adm3.prj\n│       ├── sle_adm3.sbn\n│       ├── sle_adm3.sbx\n│       ├── sle_adm3.shp\n│       ├── sle_adm3.shp.xml\n│       ├── sle_adm3.shx\n│       ├── sle_hf.CPG\n│       ├── sle_hf.dbf\n│       ├── sle_hf.prj\n│       ├── sle_hf.sbn\n│       ├── sle_hf.sbx\n│       ├── sle_hf.shp\n│       └── sle_hf.shx\n├── godata\n│   ├── cases_clean.rds\n│   ├── contacts_clean.rds\n│   ├── followups_clean.rds\n│   └── relationships_clean.rds\n├── likert_data.csv\n├── linelist_cleaned.rds\n├── linelist_cleaned.xlsx\n├── linelist_raw.xlsx\n├── make_evd_dataset-DESKTOP-JIEUMMI.R\n├── make_evd_dataset.R\n├── malaria_app\n│   ├── app.R\n│   ├── data\n│   │   └── facility_count_data.rds\n│   ├── funcs\n│   │   └── plot_epicurve.R\n│   ├── global.R\n│   ├── malaria_app.Rproj\n│   ├── server.R\n│   └── ui.R\n├── malaria_facility_count_data.rds\n├── phylo\n│   ├── sample_data_Shigella_tree.csv\n│   ├── Shigella_subtree_2.nwk\n│   ├── Shigella_subtree_2.txt\n│   └── Shigella_tree.txt\n├── rmarkdown\n│   ├── outbreak_report.docx\n│   ├── outbreak_report.html\n│   ├── outbreak_report.pdf\n│   ├── outbreak_report.pptx\n│   ├── outbreak_report.Rmd\n│   ├── report_tabbed_example.html\n│   └── report_tabbed_example.Rmd\n├── standardization\n│   ├── country_demographics.csv\n│   ├── country_demographics_2.csv\n│   ├── deaths_countryA.csv\n│   ├── deaths_countryB.csv\n│   └── world_standard_population_by_sex.csv\n├── surveys\n│   ├── population.xlsx\n│   ├── survey_data.xlsx\n│   └── survey_dict.xlsx\n└── time_series\n    ├── campylobacter_germany.xlsx\n    └── weather\n        ├── germany_weather2002.nc\n        ├── germany_weather2003.nc\n        ├── germany_weather2004.nc\n        ├── germany_weather2005.nc\n        ├── germany_weather2006.nc\n        ├── germany_weather2007.nc\n        ├── germany_weather2008.nc\n        ├── germany_weather2009.nc\n        ├── germany_weather2010.nc\n        └── germany_weather2011.nc",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#dateien-in-einem-verzeichnis-auflisten",
    "href": "new_pages/directories.de.html#dateien-in-einem-verzeichnis-auflisten",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.2 Dateien in einem Verzeichnis auflisten",
    "text": "45.2 Dateien in einem Verzeichnis auflisten\nUm nur die Dateinamen in einem Verzeichnis aufzulisten, kannst du Folgendes verwenden dir() von Basis R. Dieser Befehl listet zum Beispiel die Dateinamen der Dateien im Unterordner “population” des Ordners “data” in einem R-Projekt auf. Der relative Dateipfad wird angegeben mit here()angegeben (mehr dazu erfährst du im Abschnitt [Importieren und Exportieren] Seite nachlesen).\n\n# file names\ndir(here(\"data\", \"gis\", \"population\"))\n\n[1] \"sle_admpop_adm3_2020.csv\"                       \n[2] \"sle_population_statistics_sierraleone_2020.xlsx\"\n\n\nUm die vollständigen Dateipfade der Dateien des Verzeichnisses aufzulisten, kannst du Folgendes verwenden dir_ls() von fs. A Basis R Alternative ist list.files().\n\n# file paths\ndir_ls(here(\"data\", \"gis\", \"population\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpCIdkbN/file4e44725d9d0/data/gis/population/sle_admpop_adm3_2020.csv\nC:/Users/ngulu864/AppData/Local/Temp/RtmpCIdkbN/file4e44725d9d0/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n\n\nUm alle Metadateninformationen zu jeder Datei in einem Verzeichnis zu erhalten (z. B. Pfad, Änderungsdatum usw.), kannst du Folgendes verwenden dir_info() von fs.\nDas kann besonders nützlich sein, wenn du die letzte Änderungszeit der Datei extrahieren willst, zum Beispiel wenn du die neueste Version einer Datei importieren willst. Ein Beispiel dafür findest du im Abschnitt [Importieren und Exportieren] Seite.\n\n# file info\ndir_info(here(\"data\", \"gis\", \"population\"))\n\nHier ist der zurückgegebene Datenrahmen. Scrolle nach rechts, um alle Spalten zu sehen.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#datei-informationen",
    "href": "new_pages/directories.de.html#datei-informationen",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.3 Datei-Informationen",
    "text": "45.3 Datei-Informationen\nUm Metadateninformationen über eine bestimmte Datei zu extrahieren, kannst du file_info() von fs (oder file.info() von Basis R).\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\n\n\n\n\n\n\nHier verwenden wir die $ um das Ergebnis zu indizieren und geben nur die modification_time Wert zurück.\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time\n\n[1] \"2024-02-18 14:56:16 CET\"",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#prüfen-ob-vorhanden",
    "href": "new_pages/directories.de.html#prüfen-ob-vorhanden",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.4 Prüfen, ob vorhanden",
    "text": "45.4 Prüfen, ob vorhanden\n\nR Objekte\nDu kannst verwenden exists() von Basis R, um zu prüfen, ob ein R-Objekt existiert innerhalb von R existiert (gib den Objektnamen in Anführungszeichen an).\n\nexists(\"linelist\")\n\n[1] FALSE\n\n\nBeachte, dass einige Basis R-Pakete hinter den Kulissen generische Objektnamen wie “data” verwenden, die als TRUE angezeigt werden, wenn inherit = FALSE angegeben wird. Das ist ein Grund, warum du deinen Datensatz nicht “data” nennen solltest.\n\nexists(\"data\")\n\n[1] TRUE\n\nexists(\"data\", inherit = FALSE)\n\n[1] FALSE\n\n\nWenn du eine Funktion schreibst, solltest du missing() von base R, um zu prüfen, ob ein Argument vorhanden ist oder nicht, anstelle von exists().\n\n\nVerzeichnisse\nUm zu prüfen, ob ein Verzeichnis existiert, gibst du den Dateipfad (und den Dateinamen) an is_dir() von fs. Scrolle nach rechts, um zu sehen, dass TRUE gedruckt wird.\n\nis_dir(here(\"data\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpCIdkbN/file4e44725d9d0/data \n                                                                TRUE \n\n\nEine Alternative ist file.exists() von Basis R.\n\n\nDateien\nUm zu prüfen, ob eine bestimmte Datei existiert, verwendest du is_file() von fs. Scrolle nach rechts, um zu sehen, dass TRUE gedruckt wird.\n\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpCIdkbN/file4e44725d9d0/data/case_linelists/linelist_cleaned.rds \n                                                                                                    TRUE \n\n\nA Basis R Alternative ist file.exists().",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#erstellen",
    "href": "new_pages/directories.de.html#erstellen",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.5 erstellen",
    "text": "45.5 erstellen\n\nVerzeichnisse\nUm ein neues Verzeichnis (Ordner) zu erstellen, kannst du verwenden dir_create() von fs. Wenn das Verzeichnis bereits existiert, wird es nicht überschrieben und es wird kein Fehler zurückgegeben.\n\ndir_create(here(\"data\", \"test\"))\n\nEine Alternative ist dir.create() von Basis R, das einen Fehler anzeigt, wenn das Verzeichnis bereits existiert. Im Gegensatz dazu, dir_create() in diesem Szenario stumm bleiben.\n\n\nDateien\nDu kannst eine (leere) Datei erstellen mit file_create() von fs. Wenn die Datei bereits existiert, wird sie nicht überschrieben oder verändert.\n\nfile_create(here(\"data\", \"test.rds\"))\n\nA Basis R Alternative ist file.create(). Wenn die Datei jedoch bereits existiert, wird sie mit dieser Option abgeschnitten. Wenn du die Option file_create() verwendest, wird die Datei unverändert gelassen.\n\n\nErstellen, wenn nicht vorhanden\nIM BAU",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#löschen",
    "href": "new_pages/directories.de.html#löschen",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.6 löschen",
    "text": "45.6 löschen\n\nR-Objekte\nVerwende rm() von Basis R, um ein R-Objekt zu entfernen.\n\n\nVerzeichnisse\nVerwenden Sie dir_delete() von fs.\n\n\nDateien\nDu kannst Dateien löschen mit file_delete() von fs.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#andere-dateien-ausführen",
    "href": "new_pages/directories.de.html#andere-dateien-ausführen",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.7 Andere Dateien ausführen",
    "text": "45.7 Andere Dateien ausführen\n\nsource()\nUm ein R-Skript von einem anderen R-Skript aus auszuführen, kannst du die source() Befehl (von base R).\n\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))\n\nDas ist so, als würdest du das obige R-Skript aufrufen und auf die Schaltfläche “Quelle” oben rechts im Skript klicken. Dadurch wird das Skript ausgeführt, allerdings im Stillen (keine Ausgabe auf der R-Konsole), es sei denn, dies ist ausdrücklich beabsichtigt. Siehe die Seite über [Interaktive Konsole] für Beispiele zur Verwendung vonsource() um mit einem Benutzer über die R-Konsole im Frage-und-Antwort-Modus zu interagieren.\n\n\n\n\n\n\n\n\n\n\n\nrender()\nrender() ist eine Variante von source() die am häufigsten für R-Markdown-Skripte verwendet wird. Du stellst die input = die die R-Markdown-Datei ist, und auch die output_format = (normalerweise entweder “html_document”, “pdf_document”, “word_document”, ““)\nSiehe die Seite über [Berichte mit R Markdown] für weitere Details. Siehe auch die Dokumentation fürrender() hier oder durch Eingabe von ?render.\n\n\nDateien in einem Verzeichnis ausführen\nDu kannst eine for-Schleife erstellen und sie verwenden, um source() jede Datei in einem Verzeichnis, das mit dir().\n\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) {   # for each script name in the R Project's \"scripts\" folder (with .R extension)\n  source(here(\"scripts\", script))                        # source the file with the matching name that exists in the scripts folder\n}\n\nWenn du nur bestimmte Skripte ausführen willst, kannst du sie wie folgt benennen:\n\nscripts_to_run &lt;- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}\n\nHier ist ein Vergleich der fs und Basis R-Funktionen.\n\n\nDateien in ein Verzeichnis importieren\nSiehe die Seite über [Import und Export] zum Importieren und Exportieren einzelner Dateien.\nSiehe auch die [Importieren und Exportieren] Seite für Methoden zum automatischen Importieren der aktuellsten Datei anhand eines Datums im Dateinamenoder indem du die Metadaten der Datei betrachtest.\nSiehe die Seite über [Iteration, Schleifen und Listen] für ein Beispiel mit dem Paketpurrr demonstrieren:\n\nEinen Datenrahmen aufteilen und als mehrere CSV-Dateien speichern\nAufteilen eines Datenrahmens und Speichern jedes Teils als separates Blatt in einer Excel-Arbeitsmappe\nMehrere CSV-Dateien importieren und in einem Datenrahmen kombinieren\nImportieren einer Excel-Arbeitsmappe mit mehreren Blättern und Kombinieren dieser Blätter in einem Datenrahmen",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#basis-r",
    "href": "new_pages/directories.de.html#basis-r",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.8 Basis R",
    "text": "45.8 Basis R\nSiehe unten die Funktionen list.files() und dir(), die den gleichen Vorgang ausführen, nämlich das Auflisten von Dateien in einem bestimmten Verzeichnis. Du kannst angeben ignore.case = oder ein bestimmtes Muster angeben, nach dem gesucht werden soll.\n\nlist.files(path = here(\"data\"))\n\nlist.files(path = here(\"data\"), pattern = \".csv\")\n# dir(path = here(\"data\"), pattern = \".csv\")\n\nlist.files(path = here(\"data\"), pattern = \"evd\", ignore.case = TRUE)\n\nWenn eine Datei gerade “geöffnet” ist, wird sie in deinem Ordner mit einer vorangestellten Tilde angezeigt, z. B. “~$hospital_linelists.xlsx”.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.de.html#ressourcen",
    "href": "new_pages/directories.de.html#ressourcen",
    "title": "45  Verzeichnis-Interaktionen",
    "section": "45.9 Ressourcen",
    "text": "45.9 Ressourcen\nhttps://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Verzeichnis-Interaktionen</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html",
    "href": "new_pages/collaboration.de.html",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "",
    "text": "46.1 Was ist Git?\nGit ist eine Versionskontrolle Software, die es ermöglicht, Änderungen in einer Ordner. Sie kann wie die Option “Änderungen verfolgen” in Word, LibreOffice oder Google Docs, aber für alle Arten von Dateien. Sie ist eine der leistungsfähigsten und meistgenutzten Optionen für die Versionskontrolle.\nWarum habe ich noch nie davon gehört? -  Während Menschen mit einem Entwickler lernen routinemäßig den Umgang mit Versionskontrollprogrammen (Git, Mercurial, Subversion oder andere), lernen nur wenige von uns aus quantitativen Disziplinen werden diese Fähigkeiten gelehrt. Daher haben die meisten Epidemiologen nie während ihres Studiums nie etwas davon gehört und müssen es spontan lernen.\nWarte, ich habe von Github gehört, ist das dasselbe? - Nicht genau, aber du aber man benutzt sie oft zusammen und wir zeigen dir, wie das geht. Kurz und gut:\nSo kannst du den Client/die Schnittstelle nutzen Github Desktop verwenden, das die Git im Hintergrund, um deine Dateien zu verwalten, sowohl lokal auf deinem Computer, als auch aus der Ferne auf einem Github Server.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#was-ist-git",
    "href": "new_pages/collaboration.de.html#was-ist-git",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "",
    "text": "Git ist das Versionskontrollsystem, ein Stück Software. Du kannst es benutzen lokal auf deinem Computer oder zum Synchronisieren eines Ordners mit einem Host Website. Standardmäßig verwendet man ein Terminal, um Git Anweisungen in der Kommandozeile einzugeben.\nDu kannst eine Git-Client/Schnittstelle verwenden, um die Kommandozeile zu umgehen und die gleichen Aktionen auszuführen (zumindest für die einfachen, sehr häufigen Aktionen).\nWenn du deinen Ordner in einem Host-Website zu mit anderen zusammenzuarbeiten, kannst du ein Konto bei Github erstellen, Gitlab, Bitbucket oder anderen erstellen.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#warum-die-kombination-aus-git-und-github",
    "href": "new_pages/collaboration.de.html#warum-die-kombination-aus-git-und-github",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.2 Warum die Kombination aus Git und Github?",
    "text": "46.2 Warum die Kombination aus Git und Github?\nverwenden Git erleichtert:\n\nArchivierung dokumentierter Versionen mit inkrementellen Änderungen, damit du leicht zu jedem früheren Zustand zurückkehren kannst\nMit parallelen Zweige d.h. Entwicklungs-/“Arbeits”-Versionen mit strukturierte Wege, um die Änderungen nach der Überprüfung zu integrieren\n\nDies kann lokal auf deinem Computer geschehen, auch wenn du nicht zusammenarbeitest. mit anderen Personen zusammenarbeitest. Hast du schon einmal:\n\nbereut, dass du einen Abschnitt des Codes gelöscht hast, nur um festzustellen, dass zwei Monate später feststellst, dass du ihn tatsächlich brauchst?\nauf ein Projekt zurückkommen, das auf Eis lag, und versuchen, es zu erinnern, ob du diese knifflige Änderung in einem der Projekte vorgenommen hast Modellen vorgenommen hast?\nhatte eine Datei model_1.R und eine weitere Datei model_1_test.R und eine Datei model_1_not_working.R um Dinge auszuprobieren?\nhatte eine Datei report.Rmd, eine Datei report_full.Rmd, eine Datei report_true_final.Rmd, eine Datei report_final_20210304.Rmd, eine Datei report_final_20210402.Rmd und deine Archivierungsfähigkeiten verflucht?\n\nGit hilft dir bei all dem und ist allein schon deshalb wert, dass du es lernst.\nNoch leistungsfähiger wird es jedoch, wenn es mit einem Online-Repository verwendet wird wie Github zur Unterstützung gemeinschaftliche Projekte. Das erleichtert die Arbeit:\n\nZusammenarbeit: Andere können überprüfen, kommentieren und Änderungen annehmen/ablehnen\nTeile deinen Code, deine Daten und Ergebnisse und fordere Feedback ein von der Öffentlichkeit (oder privat, mit deinem Team)\n\nund vermeidet:\n\n“Ups, ich habe vergessen, die letzte Version zu schicken und jetzt musst du jetzt musst du die Arbeit von zwei Tagen an dieser neuen Datei wiederholen.\nMina, Henry und Oumar arbeiteten alle gleichzeitig an einem Skript und müssen ihre Änderungen manuell zusammenführen\nZwei Personen versuchen, dieselbe Datei auf Dropbox und Sharepoint zu ändern und dies führt zu einem Synchronisierungsfehler.\n\n\nDas klingt kompliziert, ich bin kein Programmierer\nDas kann es auch sein. Beispiele für fortgeschrittene Anwendungen können ziemlich beängstigend sein. Allerdings sind viele wie bei R oder sogar Excel musst du kein Experte sein, um die Vorteile zu nutzen. Vorteile des Tools zu nutzen. Das Erlernen einer einer kleinen Anzahl von Funktionen und Begriffen kannst du deine Änderungen nachverfolgen, deine Dateien online synchronisieren synchronisieren und mit deinen Kollegen zusammenarbeiten - und das in kürzester Zeit. Zeit.\nAufgrund der Lernkurve ist der Notfallkontext vielleicht nicht die beste Zeit um diese Werkzeuge zu lernen. Aber das Lernen kann schrittweise erfolgen. Sobald du dir ein paar Begriffe gelernt hast, kann dein Arbeitsablauf ziemlich effizient und schnell sein. Wenn du nicht an einem Projekt arbeitest, bei dem die Zusammenarbeit mit anderen durch Git eine Notwendigkeit ist, ist es eigentlich ein guter Zeitpunkt, um sich es sicher zu benutzen bevor du in die Zusammenarbeit einsteigst.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#einrichtung",
    "href": "new_pages/collaboration.de.html#einrichtung",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.3 Einrichtung",
    "text": "46.3 Einrichtung\n\nGit installieren\nGit ist der Motor hinter den Kulissen auf deinem Computer, der die Änderungen, Zweige (Versionen), Zusammenführungen und Rückgängigmachen verfolgt. Du musst zuerst installieren Git von https://git-scm.com/downloads.\n\n\nInstalliere eine Schnittstelle (optional, aber empfohlen)\nGit hat eine eigene Befehlssprache, die in einen Befehl eingegeben werden kann Terminal eingegeben werden können. Allerdings gibt es viele Clients/Schnittstellen und als Nicht-Entwickler kannst du in deinem wirst du im täglichen Gebrauch selten benötigen direkt mit Git zu arbeiten und Schnittstellen bieten in der Regel nette Visualisierungstools für Dateiänderungen oder Zweige.\nEs gibt viele Optionen für alle Betriebssysteme, von einsteigerfreundlich bis komplex. Gute Optionen für Anfänger sind das RStudio Git-Fenster und Github Desktop die wir in diesem Artikel vorstellen werden. diesem Kapitel vorstellen. Zu den mittleren (leistungsfähigeren, aber komplexeren) Optionen gehören Source Tree, Gitkracken, Smart Git und andere.\nKurze Erklärung auf Git-Clients.\nHinweis: Da alle Schnittstellen Git intern nutzen, kannst du mehrere dieser Clients ausprobieren. ausprobieren, bei einem bestimmten Projekt von einer zur anderen wechseln, die Konsole punktuell nutzen für eine Aktion, die deine Schnittstelle nicht unterstützt, oder sogar eine beliebige Anzahl von Aktionen online auf Github durchführen.\nWie unten erwähnt, musst du gelegentlich Git-Befehle in eine Terminal wie dem RStudio-Terminalfenster (ein Reiter neben dem R Konsole) oder das Git-Bash-Terminal eingeben.\n\n\nGithub-Konto\nRegistriere dich für ein kostenloses Konto bei github.de.\nMöglicherweise wird dir die Einrichtung einer Zwei-Faktor-Authentifizierung mit einer App auf deinem Telefon einzurichten. Lies mehr im Github Hilfe Dokumente.\nWenn du Github Desktop verwendest, kannst du deine Gitub-Anmeldedaten eingeben, nachdem du Installation wie folgt eingeben Schritte. Wenn du das nicht tust, werden die Anmeldedaten später abgefragt, wenn du versuchst ein Projekt von Github zu klonen.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#vokabular-konzepte-und-grundlegende-funktionen",
    "href": "new_pages/collaboration.de.html#vokabular-konzepte-und-grundlegende-funktionen",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.4 Vokabular, Konzepte und grundlegende Funktionen",
    "text": "46.4 Vokabular, Konzepte und grundlegende Funktionen\nWie beim Erlernen von R gibt es ein paar Vokabeln, die du dir merken musst, um Git zu verstehen. Hier sind die Grundlagen, damit du loslegen / Interaktives Lernprogramm. In der nächsten Abschnitten werden wir zeigen, wie man Schnittstellen nutzt, aber es ist gut aber es ist gut, das Vokabular und die Konzepte im Kopf zu haben, um dein mentales Modell aufzubauen, und weil du sie sowieso brauchst, wenn du Schnittstellen verwendest.\n\nRepository\nA Git Repository (“repo”) ist ein Ordner, in dem alle Unterordner und Dateien für dein Projekt (Daten, Code, Bilder usw.) und ihre Änderungshistorie. Wenn du anfängst, die Änderungen im Repository zu verfolgen, erstellt Git einen versteckten Ordner, der alle Tracking-Informationen enthält. Ein typisches Git-Repository ist dein R-ProjektOrdner (siehe Handbuchseite zu [R-Projekte]).\nWir werden zeigen, wie man (initialisieren) ein Git Repository von Github, Github Desktop oder Rstudio in der nächsten Abschnitten.\n\n\nCommits\nA begehen ist eine Schnappschuss des Projekts zu einem bestimmten Zeitpunkt. Wenn du eine Änderung am Projekt vornimmst, machst du einen neuen Commit um die Änderungen (das Delta) zu verfolgen, die an deinem Dateien. Vielleicht hast du zum Beispiel einige Codezeilen bearbeitet und eine zugehörigen Datensatz aktualisiert. Sobald deine Änderungen gespeichert sind, kannst du sie bündeln Änderungen in einem “Commit” zusammenfassen.\nJede Übertragung hat eine eindeutige ID (eine Hash). Für Zwecke der Versionskontrolle, kannst du dein Projekt auf der Grundlage von Commits in der Zeit zurückverfolgen, also ist es am besten am besten, sie relativ klein und zusammenhängend zu halten. Du wirst auch eine kurze Beschreibung der Änderungen an, die sogenannte “Commit-Nachricht”.\nGestufte Änderungen? Eine Änderung wird in die Liste der Bereitstellungsbereich als Vorbereitung für den nächsten Commit. Die Idee ist, dass du fein säuberlich entscheiden kannst, welche Änderungen in einem bestimmten Commit enthalten sein sollen. Zum Beispiel, wenn du in einem Skript an der Modellspezifikation gearbeitet hast, und später an einer Figur in einem anderen Skript arbeitest, wäre es sinnvoll, zwei verschiedene Commits zu haben (es wäre einfacher für den Fall, dass du die Änderungen an der Figur, aber nicht am Modell rückgängig machen willst).\n\n\nZweige\nEin Zweig stellt eine unabhängige Linie von Änderungen in deinem Repo, ein parallele, alternative Version deiner Projektdateien.\nZweige sind nützlich, um Änderungen zu testen, bevor sie in die die Hauptprogramm Zweig, der normalerweise die primäre/endgültige/“Live”-Version von deines Projekts. Wenn du mit dem Experimentieren in einem Zweig fertig bist, kannst du die die Änderungen in deinen Hauptprojekt Zweig, indem du zusammenführt oder ihn löschen, wenn die Änderungen nicht so erfolgreich waren.\nHinweis: Du musst nicht mit anderen Personen zusammenarbeiten, um Zweige zu verwenden, noch brauchst du ein entferntes Online-Repository.\n\n\nLokale und entfernte Repositories\nAn klonen ist es, eine Kopie eines Git-Repositorys an einem anderen Ort zu erstellen.\nDu kannst zum Beispiel klonen ein Online-Repository von Github lokal auf deinem Computer, oder beginne mit einem lokalen Repository und klone es online auf Github.\nWenn du ein Repository geklont hast, befinden sich die Projektdateien in zwei Orten:\n\ndem LOKAL Repository auf deinem physischen Computer. Diese nimmst du die tatsächlichen Änderungen an den Dateien/Codes vor.\ndie FERN, Online-Repository: die Versionen deiner Projektdateien im Github-Repository (oder in jedem anderen Web Host).\n\nUm diese Repositories zu synchronisieren, werden wir weitere Funktionen verwenden. In der Tat, anders als Sharepoint, Dropbox oder andere Synchronisierungssoftware, bietet Git Git nicht automatisch dein lokales Repository oder das, was online ist, oder andersherum. Du entscheidest selbst, wann und wie du synchronisierst.\n\ngit fetch lädt die neuen Änderungen aus dem entfernten Projektarchiv herunter, aber nicht ändert dein lokales Projektarchiv nicht. Stell dir vor, du überprüfst den Status des entfernten Projektarchivs.\ngit pull lädt die neuen Änderungen aus den entfernten Repositories herunter und aktualisiert dein lokales Repository.\nWenn du einen oder mehrere lokale Commits gemacht hast, kannst du git push die Commits an das Remote-Repository übertragen. Dies sendet deine Änderungen an Github, so dass andere Leute sie sehen und ziehen können, wenn sie wollen.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#los-gehts-ein-neues-repository-erstellen",
    "href": "new_pages/collaboration.de.html#los-gehts-ein-neues-repository-erstellen",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.5 Los geht’s: ein neues Repository erstellen",
    "text": "46.5 Los geht’s: ein neues Repository erstellen\nEs gibt viele Möglichkeiten, neue Repositories zu erstellen. Du kannst es über die Konsole, über Github oder über eine Schnittstelle.\nEs gibt zwei allgemeine Ansätze für die Einrichtung:\n\nErstelle ein neues R-Projekt aus einem bestehenden oder neuen Github-Repository (bevorzugt für Anfänger), oder\nErstelle ein Github-Repository für ein bestehendes R-Projekt\n\n\nStart-up Dateien\nWenn du ein neues Repository erstellst, kannst du optional folgende Dateien erstellen alle unten aufgeführten Dateien erstellen oder sie zu einem späteren Zeitpunkt zu deinem Projektarchiv hinzufügen. Sie befinden sich normalerweise im Stammordner des Projektarchivs.\n\nA README Datei ist eine Datei, die jemand lesen kann, um zu verstehen, warum dein Projekt existiert und was sie sonst noch wissen sollten, um es zu benutzen. Sie wird anfangs leer sein, aber du solltest sie später vervollständigen.\nA .gitignore Datei ist eine Textdatei, in der jede Zeile Folgendes enthält Ordner oder Dateien, die Git ignorieren soll (Änderungen nicht verfolgen). Lesen mehr darüber und sehen Sie Beispiele hier.\nDu kannst eine Lizenz für deine Arbeit wählen, so dass andere Menschen wissen, unter welchen Bedingungen sie dein Werk nutzen oder vervielfältigen dürfen. Für mehr Informationen findest du in der Creative Commons Lizenzen.\n\n\n\nErstelle ein neues Repository in Github\nUm ein neues Repository zu erstellen, logge dich bei Github ein und suche nach dem grünen Schaltfläche, um ein neues Repository zu erstellen. Dieses nun leere Repository kann lokal auf deinen Computer geklont werden (siehe nächster Abschnitt).\n\n\n\n\n\n\n\n\n\nDu musst wählen, ob du dein Repository als öffentlich (sichtbar für jeder im Internet) oder privat (nur sichtbar für diejenigen mit Erlaubnis). Das hat wichtige Auswirkungen, wenn deine Daten sensibel sind. Wenn dein Repository privat ist, wirst du einige Quoten in den erweiterten besonderen Umständen, z.B. wenn du Github benutzt Aktionen zu deinen Code automatisch in der Cloud auszuführen.\n\n\nKlonen aus einem Github-Repository\nDu kannst klonen ein bestehendes Github-Repository klonen, um ein ein neues lokales R-Projekt auf deinem Computer zu erstellen.\nDas Github-Repository kann ein bereits bestehendes sein und enthält Inhalt enthält, oder ein leeres Repository, das du gerade erstellt hast. In diesem letzteren Fall erstellst du im Wesentlichen das Github-Repository und lokale R Projekt zur gleichen Zeit (siehe Anleitung oben).\nHinweis Wenn du keine Mitwirkungsrechte an einem Github-Repository hast, kannst du es nicht nutzen, ist es möglich, zuerst forken das Repository zu deinem Profil zu forken, und dann mit den anderen Aktionen fort. Das Forking wird am Ende dieses Artikels erklärt Kapitels erklärt, aber wir empfehlen, dass du zuerst die anderen Abschnitte liest.\nSchritt 1: Navigiere in Github zu dem Repository, klicke auf das grüne “Code” Taste und kopiere den HTTPS-Klon-URL (siehe Bild unten)\n\n\n\n\n\n\n\n\n\nDer nächste Schritt kann in jeder Schnittstelle durchgeführt werden. Wir illustrieren das mit Rstudio und Github Desktop.\n\nIn Rstudio\nStarten Sie in RStudio ein neues R-Projekt, indem Sie auf Datei &gt; Neues Projekt &gt; Versionskontrolle &gt; Git\n\nWenn du zur Eingabe der “Repository URL” aufgefordert wirst, füge die HTTPS-URL von Github ein.\nGib dem R-Projekt einen kurzen, informativen Namen.\nWähle aus, wo das neue R Projekt lokal gespeichert werden soll\\\nAktiviere “In neuer Sitzung öffnen” und klicke auf “Projekt erstellen”.\n\nDu befindest dich jetzt in einem neuen, lokalen RStudio-Projekt, das ein Klon des Github-Repository ist. Dieses lokale Projekt und das Github-Repository sind jetzt verknüpft.\n\n\nIn Github Desktop\n\nKlicken Sie auf Datei &gt; Klonen eines Repositorys\nWähle die Registerkarte URL\nFüge die HTTPS-URL von Github in das erste Feld ein\nWähle den Ordner, in dem du dein lokales Repository haben möchtest\nKlicke auf “CLONE”\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeues Github Repo aus bestehendem R Projekt\nEin alternatives Einrichtungsszenario ist, dass du ein bestehendes R-Projekt hast mit Inhalt hast und ein Github-Repository dafür erstellen möchtest.\n\nErstelle ein neues, leeres Github-Repository für das Projekt (siehe Anweisungen oben)\\\nKlone dieses Repository lokal (siehe HTTPS-Anleitung oben)\\\nKopiere den gesamten Inhalt aus deinem bereits bestehenden R Projekt (Codes, Daten usw.) in dieses neue, leere, lokale Repository (z.B. durch Kopieren und Einfügen).\\\nÖffne dein neues Projekt in RStudio und gehe zum Git-Fenster. Die neuen Dateien sollten als Datei-Änderungen registriert werden, die nun von Git verfolgt werden. Daher kannst du diese Änderungen bündeln als commit und push sie auf Github hoch. Sobald veröffentlicht wird das Repository auf Github alle Dateien enthalten.\n\nDetails zu diesem Prozess findest du im Abschnitt über den Github-Workflow weiter unten.\n\n\nWie sieht es jetzt aus?\n\nIn RStudio\nSobald du ein Github-Repository in ein neues R-Projekt geklont hast, siehst du jetzt in RStudio eine Registerkarte “Git”. Diese Registerkarte erscheint im gleichen RStudio-Fenster wie deine R-Umgebung:\n\n\n\n\n\n\n\n\n\nBitte beachte die eingekreisten Schaltflächen in der obigen Abbildung, denn sie werden später referenziert werden (von links nach rechts):\n\nSchaltfläche zu übertragen die gespeicherten Dateiänderungen in die lokale Zweig übertragen (es wird ein neues Fenster geöffnet)\nBlauer Pfeil zu ziehen (aktualisiere deine lokale Version des Zweigs mit alle Änderungen, die an der Remote/Github-Version des Zweigs vorgenommen wurden)\nGrüner Pfeil zu pushen (sendet alle Commits/Änderungen für dein lokales Version des Zweigs an die Remote/Github-Version des Zweigs)\nDie Registerkarte Git in RStudio\nSchaltfläche zum Erstellen eines NEUEN Zweigs mit dem angezeigten lokalen Zweig rechts als Basis angezeigt wird. Du willst fast immer von einem Zweig abzweigen dem Hauptzweig abzweigen (nachdem du den Hauptzweig zum ersten Mal aktualisiert hast)\nDer Zweig, in dem du gerade arbeitest\nÄnderungen, die du am Code oder anderen Dateien vorgenommen hast, werden unten angezeigt\n\n\n\nIm Github Desktop\nGithub Desktop ist eine unabhängige Anwendung, mit der du deine alle deine Repositories verwalten kannst. Wenn du sie öffnest, kannst du über die Oberfläche das Repository auswählen, an dem du arbeiten möchtest, und dann die grundlegenden Git Aktionen auszuführen.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#git-github-arbeitsablauf",
    "href": "new_pages/collaboration.de.html#git-github-arbeitsablauf",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.6 Git + Github Arbeitsablauf",
    "text": "46.6 Git + Github Arbeitsablauf\n\nProzess-Übersicht\nSobald du die Einrichtung abgeschlossen hast (wie oben beschrieben), hast du eine Github Repo, das verbunden ist (geklont) mit einem lokalen R-Projekt verbunden ist. Die wichtigste Zweig (der standardmäßig erstellt wird) ist die sogenannte “Live”-Version von aller der Dateien. Wenn du Änderungen vornehmen willst, ist es eine gute Praxis, eine neuen Zweig von der Haupt Zweig (wie “Mach eine Kopie”). Dies ist ein typischer Arbeitsablauf in Git, denn das Erstellen eines Zweigs ist einfach und schnell ist.\nEin typischer Arbeitsablauf sieht wie folgt aus:\n\nVergewissere dich, dass dein lokales Repository aktuell ist, aktualisiere es, wenn nicht\nGehe zu dem Zweig, an dem du vorher gearbeitet hast, oder erstelle einen neuen Zweig, um einige Dinge auszuprobieren\nBearbeite die Dateien lokal auf deinem Computer, erstelle eine oder mehrere Übertragungen in diesen Zweig\nAktualisiere die Remote-Version des Zweigs mit deinen Änderungen (push)\nWenn du mit deinem Zweig zufrieden bist, kannst du den Online-Zweig zusammenführen Version des Arbeitszweigs in den Online-“Hauptzweig” zusammenführen, um die Änderungen zu übertragen\n\nAndere Teammitglieder machen vielleicht dasselbe mit ihren eigenen Zweigen, oder vielleicht auch Commits in deinen Arbeitszweig einbringen.\nIm Folgenden gehen wir den oben beschriebenen Prozess Schritt für Schritt genauer durch. Hier ist ein Schema, das wir entwickelt haben - es hat das Format einer zweiseitigen Tabelle, damit Epidemiologen sie besser verstehen können.\n\n\n\n\n\n\n\n\n\nHier ist ein weiteres Diagramm.\nHinweis: Bis vor kurzem wurde der Begriff “Master”-Zweig verwendet, aber jetzt ist er als “Hauptzweig” bezeichnet.\n\n\n\n\n\n\n\n\n\nBild Quelle",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#einen-neuen-zweig-erstellen",
    "href": "new_pages/collaboration.de.html#einen-neuen-zweig-erstellen",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.7 Einen neuen Zweig erstellen",
    "text": "46.7 Einen neuen Zweig erstellen\nWenn du einen Zweig auswählst, an dem du arbeiten möchtest, setzt Git dein Arbeitsverzeichnis zurück so zurück, wie es war, als du das letzte Mal in diesem Zweig.\n\nIm Git-Fenster von Rstudio\nVergewissere dich, dass du dich im “Haupt”-Zweig befindest, und klicke dann auf das lila Symbol, um um einen neuen Zweig zu erstellen (siehe Bild oben).\n\nDu wirst aufgefordert, deinen Zweig mit einem Wort zu benennen, das die Namen zu benennen (bei Bedarf kannst du Unterstriche verwenden).\nDu wirst sehen, dass du dich lokal immer noch in demselben R-Projekt befindest, aber du arbeitest nicht mehr am “Hauptzweig”.\nSobald der neue Zweig erstellt ist, wird er auch auf der Github-Website angezeigt als Zweig.\n\nDu kannst Zweige im Git-Fenster in Rstudio anzeigen lassen, nachdem du auf “History” geklickt hast.\n\n\n\n\n\n\n\n\n\n\n\nIn Github Desktop\nDer Prozess ist sehr ähnlich, du wirst aufgefordert, deinen Branch anzugeben einen Namen zu geben. Danach wirst du aufgefordert, deinen Zweig auf Github zu veröffentlichen, um damit der neue Zweig auch im Remote-Repository erscheint.\n\n\n\n\n\n\n\n\n\n\n\nIn der Konsole\nWas tatsächlich hinter den Kulissen passiert, ist, dass du eine neue Zweig mit git branch anlegst und dann den Zweig mit git checkout (z.B.. Git mitteilen, dass deine nächsten Commits dort stattfinden werden). Von deinem Git-Repository aus:\n\ngit branch my-new-branch  # Create the new branch branch\ngit checkout my-new-branch # Go to the branch\ngit checkout -b my-new-branch # Both at once (shortcut)\n\nWeitere Informationen zur Verwendung der Konsole findest du im Abschnitt über Git-Befehle am Ende.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#änderungen-committen",
    "href": "new_pages/collaboration.de.html#änderungen-committen",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.8 Änderungen committen",
    "text": "46.8 Änderungen committen\nJetzt kannst du den Code bearbeiten, neue Dateien hinzufügen, Datensätze aktualisieren usw.\nJede deiner Änderungen wird nachverfolgt, sobald die jeweilige Datei gespeichert. Geänderte Dateien erscheinen in der Registerkarte RStudio Git auf Github Desktop, oder mit dem Befehl git status im Terminal (siehe unten).\nImmer, wenn du wesentliche Änderungen vornimmst (z. B. Hinzufügen oder Aktualisieren eines Abschnitts von Code), pausiere und Übertragen diese Änderungen. Stell dir einen Commit als einen “Batch” vor von Änderungen, die einem gemeinsamen Zweck dienen. Du kannst immer weiter eine Datei weiter überarbeiten, nachdem du Änderungen an ihr vorgenommen hast.\nHinweise zu Commits: Generell ist es besser, kleine Commits zu machen, die die leicht rückgängig gemacht werden können, wenn ein Problem auftritt, zusammen zu committen Änderungen, die einem gemeinsamen Zweck dienen. Um dies zu erreichen, musst du feststellen, dass solltest du dich oft verpflichten. Am Anfang wirst du wahrscheinlich vergessen, dich oft zu verpflichten, aber dann setzt die Gewohnheit ein.\n\nIn Rstudio\nDas folgende Beispiel zeigt, dass sich das R Markdown-Skript “collaboration.Rmd” seit der letzten Übertragung geändert hat, und mehrere PNG-Bilder hinzugefügt wurden.\n\n\n\n\n\n\n\n\n\nDu fragst dich vielleicht, was die gelben, blauen, grünen und roten Quadrate neben den den Dateinamen stehen. Hier ist ein Schnappschuss aus dem RStudio Cheatsheet das ihre Bedeutung erklärt. Beachte, dass Änderungen mit gelben “?” noch staged, committed und pushed werden können.\n\n\n\n\n\n\n\n\n\n\nDrücke auf die Schaltfläche “Commit” in der Registerkarte Git, wodurch sich ein neues Fenster (siehe unten)\nKlicke auf einen Dateinamen in der oberen linken Box\nÜberprüfe die Änderungen, die du an der Datei vorgenommen hast (unten grün hervorgehoben) oder rot)\n“Stage” die Datei, wodurch die Änderungen in den Commit aufgenommen werden. Mach dies, indem du das Kästchen neben dem Dateinamen aktivierst. Alternativ kannst du kannst du auch mehrere Dateinamen markieren und dann auf “Bühne” klicken.\nSchreibe eine kurze, aber aussagekräftige Commit-Nachricht (erforderlich)\nDrücke die Schaltfläche “Commit”. Es erscheint ein Pop-up-Fenster, das den Erfolg anzeigt oder eine Fehlermeldung.\n\nJetzt kannst du weitere Änderungen und Übertragungen vornehmen, so oft du willst\n\n\n\n\n\n\n\n\n\n\n\nIn Github Desktop\nAuf der linken Seite siehst du die Liste der Dateien, die geändert wurden. Wenn du eine Textdatei auswählst, siehst du eine Zusammenfassung der Änderungen, die vorgenommen wurden im rechten Bereich (diese Ansicht funktioniert nicht bei komplexeren Dateien wie .docs oder .xlsx).\nUm die Änderungen zu aktivieren, musst du nur das kleine Kästchen neben dem Dateinamen anklicken. Wenn du die Dateien ausgewählt hast, die du zu diesem Commit hinzufügen willst, gibst du den Commit einen Namen, optional eine Beschreibung und klicke dann auf die Schaltfläche Übertragen Schaltfläche.\n\n\n\n\n\n\n\n\n\n\n\nIn der Konsole\nDie beiden Funktionen, die hinter den Kulissen verwendet werden, sind git add zum Auswählen/Bühnenbild Dateien und git commit um die Übergabe tatsächlich durchzuführen.\n\ngit status # see the changes \n\ngit add new_pages/collaboration.Rmd  # select files to commit (= stage the changes)\n\ngit commit -m \"Describe commit from Github Desktop\" # commit the changes with a message\n\ngit log  # view information on past commits\n\n\n\nEine vorherige Übertragung ändern\nWas passiert, wenn du einige Änderungen festlegst, weiterarbeitest und feststellst dass du Änderungen vorgenommen hast, die (deiner Meinung nach) zum letzten Commit “gehören”. Keine Angst! Du kannst diese Änderungen an deinen vorherigen Commit anhängen.\nIn Rstudio sollte es ziemlich offensichtlich sein, denn es gibt eine Funktion zum Ändern der vorherigen Übertragung. in der gleichen Zeile wie die Schaltfläche COMMIT.\nAus einem unklaren Grund wurde diese Funktion nicht implementiert nicht als solche in Github Desktop implementiert, aber es gibt eine (konzeptionell umständliche, aber einfache) Umgehungsmöglichkeit. Wenn du einen Commit gemacht hast aber nicht gepusht deine Änderungen noch nicht veröffentlicht, erscheint eine Schaltfläche “UNDO” direkt unter der Schaltfläche COMMIT. Klicke sie an und und deine Übergabe wird rückgängig gemacht (aber deine bereitgestellten Dateien und deine Übergabemeldung bleiben erhalten). Speichere deine Änderungen, füge ggf. neue Dateien zur Übergabe hinzu und übertrage sie erneut.\nIn der Konsole:\n\ngit add [YOUR FILES] # Stage your new changes\n\ngit commit --amend  # Amend the previous commit\n\ngit commit --amend -m \"An updated commit message\"  # Amend the previous commit AND update the commit message\n\nHinweis: Denke nach, bevor du Commits änderst, die bereits öffentlich sind und mit deinen Mitstreitern geteilt werden.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#änderungen-auf-github-hochziehen-und-pushen",
    "href": "new_pages/collaboration.de.html#änderungen-auf-github-hochziehen-und-pushen",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.9 Änderungen auf Github hochziehen und pushen",
    "text": "46.9 Änderungen auf Github hochziehen und pushen\n“Erst PULL, dann PUSH”\nEs ist eine gute Praxis abzurufen und ziehen bevor du mit der Arbeit an die Version des Zweigs auf deinem lokalen Computer zu aktualisieren mit alle Änderungen, die in der Remote/Github-Version vorgenommen wurden.\nPULL oft. Zögere nicht. Ziehe immer, bevor du schiebst.\nWenn deine Änderungen vorgenommen und festgeschrieben wurden und du mit dem Ergebnis zufrieden bist Stand deines Projekts zufrieden bist, kannst du pushen deine Commits hoch auf die Remote/Github-Version deines Zweigs.\nWiederhole das Ganze, während du an dem Repository arbeitest.\nHinweis: Es ist viel einfacher, Änderungen rückgängig zu machen, die zwar bestätigt wurden, aber nicht (d.h. sie sind noch lokal), als Änderungen rückgängig zu machen, die in die Datenbank übertragen wurden. Repository übertragen wurden (und vielleicht schon von jemand anderem übernommen wurden). zu pushen, wenn du mit der Einführung von Änderungen an der Aufgabe fertig bist, die an der du gearbeitet hast.\n\nIn Rstudio\nPULL - Klicke zunächst auf das “Pull”-Symbol (Abwärtspfeil), das die Daten abruft und gleichzeitig zieht.\nPUSH - Du klickst auf das grüne “Pull”-Symbol (Pfeil nach oben). Du wirst möglicherweise gefragt deinen Github-Benutzernamen und dein Passwort einzugeben. Das erste Mal, dass du gefragt wirst, musst du eventuell zwei Git-Befehlszeilen in das Feld Terminal:\n\ngit config –global user.email “you@example.com” (dein Github E-Mail Adresse), und\\\ngit config –global user.name “Dein Github-Benutzername”\n\nWie du diese Befehle eingibst, erfährst du im folgenden Abschnitt über Git-Befehle.\nTIPP: Du wirst zu oft nach deinem Passwort gefragt? Siehe diese Kapitel 10 & 11 dieses Tutorials um mit einem SSH-Schlüssel eine Verbindung zu einem Repository herzustellen (mehr komplizierter)\n\n\nIm Github Desktop\nKlicke auf die Schaltfläche “Fetch origin”, um zu prüfen, ob es neue Commits gibt auf dem entfernten Repository gibt.\n\n\n\n\n\n\n\n\n\nWenn Git neue Commits im Remote-Repository findet, wird die Schaltfläche in eine “Pull”-Schaltfläche umgewandelt. Da derselbe Button für Push und pull verwendet wird, kannst du deine Änderungen nicht pushen, wenn du nicht vorher pullst.\n\n\n\n\n\n\n\n\n\nAuf der Registerkarte “Verlauf” (neben der Registerkarte “Änderungen”) kannst du alle Commits (deine und andere) sehen. Das ist eine gute Möglichkeit, sich mit der was deine Mitstreiter gemacht haben. Du kannst die Commit-Nachricht lesen, die Beschreibung lesen, wenn es eine gibt, und den Code der beiden Dateien vergleichen, indem du die diff fenster.\n\n\n\n\n\n\n\n\n\nSobald alle Remote-Änderungen gezogen wurden und mindestens eine lokale Änderung übertragen wurden, kannst du sie mit einem Klick auf die gleiche Schaltfläche übertragen.\n\n\n\n\n\n\n\n\n\n\n\nKonsole\nOhne Überraschung sind die Befehle fetch, ziehen und schieben.\n\ngit fetch  # are there new commits in the remote directory?\ngit pull   # Bring remote commits into your local branch\ngit push   # Puch local commits of this branch to the remote branch\n\n\n\nIch möchte ziehen, aber ich muss vor Ort arbeiten\nDas kann manchmal passieren: Du hast einige Änderungen an deinem lokalen Repository vorgenommen, aber das Remote Repository hat Commits, die du nicht gezogen hast.\nGit verweigert das Pulling, weil es deine Änderungen überschreiben könnte. Es gibt verschiedene Strategien, um deine Änderungen zu behalten, gut beschrieben in Glückliches Git mit R, Die zwei wichtigsten davon sind:\n\nÄnderungen übertragen, entfernte Änderungen abrufen, sie einfügen, Konflikte lösen falls nötig (siehe Abschnitt unten), und pushen alles online\nstash deine Änderungen, die du sozusagen beiseite legst, ziehst, entsorgst (wiederherstellen) und dann committen, alle Konflikte lösen und pushen.\n\nWenn die Dateien, die von den entfernten Änderungen betroffen sind, und die Dateien, die nicht überschneiden, kann Git Konflikte automatisch lösen.\nIn Github Desktop kann dies mit Schaltflächen geschehen. Um einen Stash zu erstellen, gehst du zu Branch &gt; Stash all changes.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#zweig-in-main-zusammenführen",
    "href": "new_pages/collaboration.de.html#zweig-in-main-zusammenführen",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.10 Zweig in Main zusammenführen",
    "text": "46.10 Zweig in Main zusammenführen\nWenn du die Änderungen abgeschlossen hast, kannst du den Prozess der diese Änderungen mit dem Hauptzweig zusammenzuführen. Das hängt von deiner Situation ab, kann das schnell gehen, oder du musst die Änderungen bewusst überprüfen und genehmigen schritte mit Teamkollegen.\n\nLokal auf dem Github Desktop\nDu kannst Zweige lokal mit Github Desktop zusammenführen. Gehe zuerst zu (checkout) den Zweig, der der Empfänger der Commits sein wird, also den Zweig, den du aktualisieren willst. Dann gehst du in das Menü Zweig &gt; Zusammenführen in aktuellen Zweig und klicke darauf. In einem Feld kannst du den Zweig auswählen, den du aus dem du importieren möchtest.\n\n\n\n\n\n\n\n\n\n\n\nIn der Konsole\nGehe zuerst zurück zu dem Zweig, der die Änderungen erhalten soll. Das ist normalerweise master aber es kann auch ein anderer Zweig sein. Dann führe deine Arbeitszweig in master ein.\n\ngit checkout master  # Go back to master (or to the branch you want to move your )\ngit merge this_fancy_new_branch\n\nDiese Seite zeigt ein fortgeschrittenes Beispiel für Verzweigungen und erklärt ein wenig, was was hinter den Kulissen passiert.\n\n\nIn Github: Einreichen von Pull Requests\nEs ist zwar durchaus möglich, zwei Zweige lokal zusammenzuführen, oder ohne jemanden zu informieren, kann eine Fusion von mehreren Personen diskutiert oder untersucht werden. Personen diskutiert oder untersucht werden, bevor sie in den Hauptzweig integriert werden. Zur Unterstützung der Prozess zu unterstützen, bietet Github einige Diskussionsfunktionen rund um den Merge: die Pull-Anfrage.\nEin Pull Request (ein “PR”) ist eine Anfrage, einen Zweig in einen anderen zusammenzuführen. (mit anderen Worten, eine Anfrage, die dass dein Arbeitszweig in den “Hauptzweig” gezogen wird). Ein Pull Request umfasst normalerweise mehrere Commits. Ein Pull-Request ist in der Regel der Beginn einer Diskussion und Überprüfung Prozess, bevor er akzeptiert und der Zweig zusammengeführt wird. Zum Beispiel, kannst du Pull Request Diskussionen lesen auf dplyr’s github.\nDu kannst einen Pull Request (PR) direkt über die Website einreichen (als unten abgebildet) oder über Github Desktop einreichen.\n\nGehe zum Github Repository (online)\nSieh dir den Reiter “Pull Requests” an und klicke auf die Schaltfläche “New pull request”.\nWähle aus dem Dropdown-Menü aus, dass dein Zweig mit dem Hauptzweig zusammengeführt werden soll\nSchreibe einen detaillierten Pull Request-Kommentar und klicke auf “Pull Request erstellen Anfrage”.\n\nIn der Abbildung unten wurde der Zweig “Wälder” ausgewählt, um zusammengeführt zu werden in “main” zusammengeführt wird:\n\n\n\n\n\n\n\n\n\nJetzt solltest du den Pull Request sehen können (Beispielbild unten):\n\nÜberprüfe den Reiter “Geänderte Dateien”, um zu sehen, wie der “Haupt”-Zweig aussehen würde sich ändern würde, wenn der Zweig zusammengeführt würde.\\\nAuf der rechten Seite kannst du eine Überprüfung durch Mitglieder deines Teams anfordern, indem du ihre Github ID markierst. Wenn du möchtest, kannst du das Repository so einstellen, dass nur eine zustimmende Überprüfung erforderlich ist, um das Projekt in main.\\\nSobald der Pull Request genehmigt ist, wird eine Schaltfläche zum “Pull Request zusammenführen” aktiv werden. Klicke darauf.\\\nWenn du fertig bist, lösche deinen Zweig wie unten beschrieben.\n\n\n\n\n\n\n\n\n\n\n\n\nKonflikte auflösen\nWenn zwei Personen dieselbe(n) Zeile(n) gleichzeitig ändern, wird ein Merge-Konflikt entstehen. Git weigert sich nämlich, eine Entscheidung zu treffen über welche Version beibehalten werden soll, aber es hilft dir, herauszufinden, wo die Konflikt ist. KEINE PANIK. Die meiste Zeit ist es ganz einfach zu beheben.\nZum Beispiel auf Github:\n\n\n\n\n\n\n\n\n\nNachdem das Zusammenführen einen Konflikt ausgelöst hat, öffne die Datei in deinem bevorzugten Editor. Der Konflikt wird durch eine Reihe von Zeichen angezeigt:\n\n\n\n\n\n\n\n\n\nDer Text zwischen &lt;&lt;&lt;&lt;&lt;&lt;&lt; KOPF und =======  kommt von deinem lokalen Repository, und diejenige zwischen =======  und &gt;&gt;&gt;&gt;&gt;&gt;&gt; von der dem anderen Zweig (das kann origin, master oder ein beliebiger Zweig von deiner Wahl sein).\nDu musst entscheiden, welche Version des Codes du bevorzugst (oder sogar eine (oder schreibe sogar eine dritte, die die Änderungen beider Seiten enthält), lösche den Rest und entferne alle Markierungen, die Git hinzugefügt hat (&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt; origin/master/ihr_Zweig_name).\nDann speicherst du die Datei, stellst sie bereit und übergibst sie: Das ist der Commit der die zusammengeführte Version “offiziell” macht. Vergiss nicht, anschließend zu pushen.\nJe öfter du und deine Mitstreiter ziehen und pushen, desto kleiner ist die Konflikte werden kleiner.\nHinweis: Wenn du mit der Konsole gut zurechtkommst, gibt es weitere fortgeschrittene Zusammenführen Optionen (z. B. Leerzeichen ignorieren, einem Mitspieler Priorität geben usw.).\n\n\nDeinen Zweig löschen\nWenn ein Zweig in Master zusammengeführt wurde und nicht mehr benötigt wird, kannst du löschen.\n\n46.10.0.1 Github + Rstudio\nGehe zum Repository auf Github und klicke auf die Schaltfläche, um alle Zweige anzuzeigen (neben dem Dropdown-Menü zur Auswahl der Zweige). Finde nun deine Zweig und klicke auf das Papierkorbsymbol neben ihm. Lies mehr Details zum Löschen einer Verzweigung hier.\nAchte darauf, dass du den Zweig auch lokal auf deinem Computer löschst. Dies wird nicht automatisch geschehen.\n\nVergewissere dich in RStudio, dass du dich im Hauptzweig befindest\nWechsle zur Eingabe von Git-Befehlen im “Terminal” von RStudio (der Reiter neben der R-Konsole) und gib ein: git branch -d branch_name wobei “branch_name” der Name deines zu bearbeitenden Zweigs ist gelöscht werden soll\nAktualisiere deinen Git-Tab und der Zweig sollte verschwunden sein\n\n\n\n46.10.0.2 In Github Desktop\nChecke einfach den Zweig aus, den du löschen möchtest, und gehe in das Menü Zweig &gt; Löschen.\n\n\n\nForking\nDu kannst ein Projekt forken, wenn du dazu beitragen möchtest, aber aber nicht die Rechte dazu hast, oder wenn du einfach wenn du es für deinen persönlichen Gebrauch verändern willst. A kurze Beschreibung des Forkings findest du hier.\nAuf Github klickst du auf die Schaltfläche “Fork”:\n\n\n\n\n\n\n\n\n\nDadurch wird das ursprüngliche Repository geklont, aber in deinem eigenen Profil. Also jetzt, gibt es zwei Versionen des Repositorys auf Github: die ursprüngliche Version, das du nicht ändern kannst, und die geklonte Version in deinem Profil.\nDann kannst du damit fortfahren, deine Version des Online-Repositorys lokal zu klonen auf deinem Computer klonen, indem du eine der in den vorherigen Abschnitten beschriebenen Methoden anwendest. Dann kannst du einen neuen Zweig erstellen, Änderungen vornehmen, sie übertragen und pushen in dein entferntes Projektarchiv.\nWenn du mit dem Ergebnis zufrieden bist, kannst du einen Pull Request erstellen von Github oder Github Desktop aus erstellen, um die Konversation mit dem Eigentümern/Maintainern des ursprünglichen Repository zu beginnen.\nWas ist, wenn du neuere Commits aus dem offiziellen Repository benötigst?\nStell dir vor, jemand nimmt eine wichtige Änderung am offiziellen Repository vor, die du in deine geklonte Version aufnehmen möchtest. Es ist möglich, deinen Fork mit dem offiziellen Projektarchiv zu synchronisieren. Dazu musst du das Terminal benutzen, aber es ist nicht allzu kompliziert. Du musst dir das nur merken:\n\nUpstream = das offizielle Repository, das du nicht verändern konntest\nHerkunft = deine Version des Repositorys in deinem Github-Profil\n\nDu kannst lesen dieses Tutorial oder unten nachlesen:\nZuerst gibst du in deinem Git-Terminal (innerhalb deines Repo) ein:\n\ngit remote -v\n\nWenn du das Upstream-Repository noch nicht konfiguriert hast, solltest du zwei Zeilen sehen, beginnend mit origin. Sie zeigen das Remote Repo das fetch und push zeige auf. Denke daran, Ursprung ist der konventionelle Nickname für deine eigene Version des Repositorys auf Github. Zum Beispiel:\n\n\n\n\n\n\n\n\n\nJetzt fügst du ein neues Remote-Repository hinzu:\n\ngit remote add upstream https://github.com/appliedepi/epirhandbook_eng.git\n\nHier ist die Adresse die Adresse, die Github generiert, wenn du klonst ein Repository klonst (siehe Abschnitt zum Klonen). Jetzt hast du vier Remote-Zeiger:\n\n\n\n\n\n\n\n\n\nWenn du nun die Änderungen aus dem Repository abrufen willst, musst du dem Original (Upstream) Repository zu finden, musst du einfach (checkout) zu den Zweig, den du aktualisieren willst, und gib ihn ein:\n\ngit fetch upstream # Get the new commits from the remote repository\ngit checkout the_branch_you_want_to_update\ngit merge upstream/the_branch_you_want_to_update  # Merge the upstream branch into your branch.\ngit push # Update your own version of the remote repo\n\nWenn es Konflikte gibt, musst du sie lösen, wie erklärt im Abschnitt Konflikte lösen.\nZusammenfassung Forking ist Klonen, aber auf der Github-Server-Seite. Der Rest der Aktionen sind typische Arbeitsabläufe für die Zusammenarbeit (clone, push, pull, commit, merge, pull requests einreichen…).\nHinweis: Forking ist zwar ein Konzept und kein Git-Befehl, aber es gibt es auch auf anderen Webhosts, wie Bitbucket.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#was-wir-gelernt-haben",
    "href": "new_pages/collaboration.de.html#was-wir-gelernt-haben",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.11 Was wir gelernt haben",
    "text": "46.11 Was wir gelernt haben\nDu hast gelernt, wie man:\n\nGit einzurichten, um Änderungen in deinen Ordnern zu verfolgen,\nverbinde dein lokales Repository mit einem entfernten Online-Repository,\nübertrage die Änderungen,\nsynchronisiere deine lokalen und entfernten Repositories.\n\nDas alles sollte für die meisten deiner Bedürfnisse ausreichen, da Epidemiologen. Wir haben in der Regel nicht so fortschrittliche Anwendungen wie Entwickler.\nDu solltest jedoch wissen, dass Git mehr Möglichkeiten zur Vereinfachung bietet, wenn du weiter gehen willst (oder musst). Commit-Historien, das Zurücknehmen eines oder mehrerer Commits, Cherry-Pick-Commits, etc. Einiges davon mag sich wie reine Zauberei anhören, aber jetzt kennst du die Grundlagen, ist es einfacher, darauf aufzubauen.\nBeachte, dass das Git-Fenster in Rstudio und Github Desktop zwar gut für Einsteiger / den täglichen Gebrauch in unserer Branche gut geeignet sind, bieten sie keine Schnittstelle zu einigen der fortgeschrittenen Git-Funktionen. Einige umfassendere Schnittstellen ermöglichen es dir, mit Point-and-Click mehr zu tun (meist auf Kosten eines komplexeren Layouts).\nDenke daran, dass du jedes Tool an jedem Punkt nutzen kannst, um dein Repository zu verfolgen, kannst du ganz einfach eine Schnittstelle installieren, um sie einmal auszuprobieren, oder um gelegentlich eine weniger häufige komplexe Aufgabe zu erledigen, während du für den Rest der Zeit eine vereinfachte Schnittstelle bevorzugst (z. B. mit Github Desktop die meiste Zeit und wechsle für bestimmte Aufgaben zu SourceTree oder Gitbash).",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#git",
    "href": "new_pages/collaboration.de.html#git",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.12 Git-Befehle",
    "text": "46.12 Git-Befehle\n\nEmpfohlenes Lernen\nUm Git-Befehle in einem interaktiven Tutorial zu lernen, siehe diese Website.\n\n\nWo du Befehle eingeben kannst\nDu gibst die Befehle in einer Git-Shell ein.\nOption 1 Du kannst ein neues Terminal in RStudio öffnen. Diese Registerkarte befindet sich neben der R-Konsole. Wenn du dort keinen Text eingeben kannst, klicke auf das Dropdown-Menü unter “Terminal” und wähle “Neues Terminal”. Tippe den Befehle in das blinkende Feld vor dem Dollarzeichen “$” ein.\n\n\n\n\n\n\n\n\n\nOption 2 Du kannst auch eine Shell (ein Terminal zur Eingabe von Befehlen) öffnen, indem du auf das blaue “Zahnrad”-Symbol auf der Registerkarte Git (neben dem RStudio Umgebung). Wähle “Shell” aus dem Dropdown-Menü. Ein neues Fenster wird geöffnet, in dem du die Befehle nach dem Dollarzeichen “$” eingeben kannst.\nOption 3 Klicke mit der rechten Maustaste, um “Git Bash hier” zu öffnen, was dasselbe öffnen wird Art von Terminal, oder öffnen Sie Git Bash in deiner Anwendungsliste. Weitere einsteigerfreundliche Informationen zu Git Bash, wie du sie findest und einige Bash-Befehle, die du brauchst.\n\n\nBeispielhafte Befehle\nIm Folgenden stellen wir dir ein paar gängige Git-Befehle vor. Wenn du sie verwendest, solltest du Folgendes beachten welcher Zweig aktiv (ausgecheckt) ist, denn das ändert die Aktion!\nIn den folgenden Befehlen,  für einen Zweignamen. &lt;commit_hash&gt; steht für die Hash-ID eines bestimmten Commit.  steht für eine Zahl. Gib nicht die &lt; oder &gt; Symbole ein.\n\n\n\n\n\n\n\nGit-Befehl\nAktion\n\n\n\n\ngit branch &lt;name&gt;\nErstelle einen neuen Zweig mit dem Namen \n\n\ngit checkout &lt;name&gt;\nWechsle den aktuellen Zweig zu \n\n\ngit checkout -b &lt;name&gt;\nShortcut zum Erstellen eines neuen Zweigs und zu ihm zu wechseln\n\n\ngit status\nUnverfolgte Änderungen sehen\n\n\ngit add &lt;file&gt;\nEine Datei in Szene setzen\n\n\ngit commit -m &lt;message&gt;\nÜbertrage die aktuell bereitgestellten Änderungen in den aktuellen Zweig mit der Nachricht\n\n\ngit fetch\nCommits vom entfernten Repository abrufen\n\n\ngit pull\nCommits aus dem entfernten Repository in den aktuellen Zweig ziehen\n\n\ngit push\nLokale Commits in das entfernte Verzeichnis verschieben\n\n\ngit switch\nEine Alternative zu git checkout die schrittweise in Git eingeführt wird\n\n\ngit merge &lt;name&gt;\nZusammenführen  Zweig in den aktuellen Zweig\n\n\ngit rebase &lt;name&gt;\nCommits aus dem aktuellen Zweig anhängen an  Zweig",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.de.html#ressourcen",
    "href": "new_pages/collaboration.de.html#ressourcen",
    "title": "46  Versionskontrolle und Zusammenarbeit mit Git und Github",
    "section": "46.13 Ressourcen",
    "text": "46.13 Ressourcen\nVieles auf dieser Seite wurde beeinflusst durch dieses “Happy Git mit R” Website von Jenny Bryan. Es gibt eine sehr hilfreiche dieser Website gibt es einen sehr hilfreichen Abschnitt, der dir bei der Fehlersuche in Git und R-bezogenen Fehlern.\nDie Github.com Dokumentation und Start Leitfaden.\nDas RStudio “IDE” Spickzettel das Tipps zu Git mit RStudio enthält.\nhttps://ohi-science.org/news/github-going-back-in-time\nGit-Befehle für Anfänger\nEine interaktive Lernprogramm zum Lernen Git-Befehle.\nhttps://www.freecodecamp.org/news/an-introduction-to-git-for-absolute-beginners-86fa1d32ff71/: Gut geeignet, um die absoluten Grundlagen zu lernen, um Änderungen in einem Ordner auf deinem eigenen Computer.\nSchöne Schemata, um Verzweigungen zu verstehen: https://speakerdeck.com/alicebartlett/git-for-humans\nTutorien zu grundlegenden und fortgeschrittenen Themen\nhttps://tutorialzine.com/2016/06/learn-git-in-30-minutes\nhttps://dzone.com/articles/git-tutorial-commands-and-operations-in-git https://swcarpentry.github.io/git-novice/ (kurzer Kurs) https://rsjakob.gitbooks.io/git/content/chapter1.html\nDie Pro Git Buch gilt als offizielle Referenz. Während einige Kapitel in Ordnung sind, ist es normalerweise ein bisschen technisch. Es ist wahrscheinlich eine gute Ressource wenn du Git schon ein bisschen benutzt hast und etwas genauer lernen willst was passiert und wie du weiter vorgehen kannst.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Versionskontrolle und Zusammenarbeit mit Git und Github</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.de.html",
    "href": "new_pages/errors.de.html",
    "title": "47  Häufige Fehler",
    "section": "",
    "text": "47.1 Fehlermeldungen interpretieren\nR-Fehlermeldungen können manchmal kryptisch sein, also ist Google dein Freund. Suche die Fehlermeldung mit “R” und suche nach aktuellen Beiträgen in StackExchange.com, stackoverflow.com, community.rstudio.com, Twitter (#rstats) und andere Foren, die von Programmierern genutzt werden, um Fragen und Antworten abzulegen. Versuche, aktuelle Beiträge zu finden, die ähnliche Probleme gelöst haben.\nWenn du nach langem Suchen keine Antwort auf dein Problem findest, kannst du eine reproduzierbares Beispiel(“reprex”) und stellst die Frage selbst. Siehe die Seite über [Hilfe erhalten] findest du Tipps, wie du ein reproduzierbares Beispiel erstellst und in Foren postest.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Häufige Fehler</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.de.html#häufige-fehler",
    "href": "new_pages/errors.de.html#häufige-fehler",
    "title": "47  Häufige Fehler",
    "section": "47.2 Häufige Fehler",
    "text": "47.2 Häufige Fehler\nIm Folgenden listen wir einige häufige Fehler und mögliche Erklärungen/Lösungen auf. Einige davon stammen von Noam Ross, der die häufigsten Forenbeiträge auf Stack Overflow zu R-Fehlermeldungen analysiert hat (siehe Analyse hier)\n\nTippfehler\nError: unexpected symbol in:\n\"  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\"\nWenn du “unerwartetes Symbol” siehst, überprüfe, ob Kommas fehlen\n\n\nPaketfehler\ncould not find function \"x\"...\nDas bedeutet wahrscheinlich, dass du den Funktionsnamen falsch eingegeben hast oder vergessen hast, ein Paket zu installieren oder zu laden.\nError in select(data, var) : unused argument (var)\nDu denkst, du verwendest dplyr::select() aber die select() Funktion wurde maskiert durch MASS::select() - angeben dplyr:: oder ordne das Laden deines Pakets neu an, so dass dplyr nach allen anderen kommt.\nAndere häufige Maskierungsfehler entstehen durch: plyr::summarise() und stats::filter(). Erwägen Sie die Verwendung der widersprüchlichen Paket.\nError in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0' for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK'\nWenn du eine Fehlermeldung erhältst, dass du eine “00LOCK”-Datei entfernen musst, gehe zu deiner “R”-Bibliothek in deinem Computerverzeichnis (z.B. R/win-library/) und suche nach einem Ordner namens “00LOCK”. Lösche diesen manuell und versuche erneut, das Paket zu installieren. Wahrscheinlich wurde ein früherer Installationsvorgang unterbrochen, was zu diesem Problem geführt hat.\n\n\nObjektfehler\nNo such file or directory:\nWenn du eine solche Fehlermeldung siehst, wenn du versuchst zu exportieren oder zu importieren: Überprüfe die Schreibweise der Datei und des Dateipfads, und wenn der Pfad Schrägstriche enthält, stelle sicher, dass sie vorwärts gerichtet sind / und nicht rückwärts \\. Vergewissere dich auch, dass du die richtige Dateierweiterung verwendet hast (z. B. .csv, .xlsx).\nobject 'x' not found \nDas bedeutet, dass ein Objekt, auf das du dich beziehst, nicht existiert. Vielleicht wurde der obige Code nicht richtig ausgeführt?\nError in 'x': subscript out of bounds\nDas bedeutet, dass du versucht hast, auf etwas zuzugreifen (ein Element eines Vektors oder einer Liste), das nicht vorhanden ist.\n\n\nFunktionssyntax-Fehler\n# ran recode without re-stating the x variable in mutate(x = recode(x, OLD = NEW)\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`.\nDieser Fehler oben (argument .x is missing, with no default) ist häufig in mutate() wenn du eine Funktion wie recode() oder replace_na() erwartet, dass du den Spaltennamen als erstes Argument angibst. Das ist leicht zu vergessen.\n\n\nLogische Fehler\nError in if\nDas bedeutet wahrscheinlich eine if Anweisung auf etwas angewendet wurde, das nicht WAHR oder FALSCH war.\n\n\nFaktor-Fehler\n#Tried to add a value (\"Missing\") to a factor (with replace_na operating on a factor)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated\nWenn du diese Fehlermeldung über ungültige Faktorstufen siehst, hast du wahrscheinlich eine Spalte der Klasse Faktor (die vordefinierte Stufen enthält) und versucht, ihr einen neuen Wert hinzuzufügen. Wandle sie in die Klasse Zeichen um, bevor du einen neuen Wert hinzufügst.\n\n\nFehler beim Plotten\nError: Insufficient values in manual scale. 3 needed but only 2 provided. ggplot() scale_fill_manual() values = c(“orange”, “purple”) … unzureichend für die Anzahl der Faktorstufen … überlege, ob NA jetzt eine Faktorstufe ist…\nCan't add x object\nDu hast wahrscheinlich eine zusätzliche + am Ende eines ggplot-Befehls, das du löschen musst.\n\n\nR Markdown-Fehler\nWenn die Fehlermeldung etwas enthält wie Error in options[[sprintf(\"fig.%s\", i)]] enthält, überprüfe, ob deine Knitr-Optionen am Anfang jedes Chunks die korrekte Verwendung der out.width = oder out.height = und nicht fig.width= und fig.height=.\n\n\nSonstiges\nÜberlege dir, ob du die Rohrleitungen neu arrangiert hast dplyr Verben neu angeordnet hast und eine Pipe in der Mitte nicht ersetzt hast, oder ob du eine Pipe am Ende nicht entfernt hast, nachdem du sie neu angeordnet hast.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Häufige Fehler</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.de.html#ressourcen",
    "href": "new_pages/errors.de.html#ressourcen",
    "title": "47  Häufige Fehler",
    "section": "47.3 Ressourcen",
    "text": "47.3 Ressourcen\nDies ist ein weiterer Blogbeitrag, der gängige R Programmierfehler von Anfängern aufl",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Häufige Fehler</span>"
    ]
  },
  {
    "objectID": "new_pages/help.de.html",
    "href": "new_pages/help.de.html",
    "title": "48  Hilfe bekommen",
    "section": "",
    "text": "48.1 Github-Probleme\nViele R-Pakete und -Projekte haben ihren Code auf der Website Github.com gehostet. Du kannst über diese Website direkt mit den Autoren kommunizieren, indem du einen “Issue” postest.\nMehr darüber, wie du deine Arbeit auf Github speichern kannst, findest du auf der Seite [Kollaboration und Github].\nAuf Github ist jedes Projekt in einer Repository. Jedes Repository enthält Code, Daten, Ausgaben, Hilfedokumentation usw. Es gibt auch eine Möglichkeit, mit den Autoren zu kommunizieren: “Issues”.\nSiehe unten die Github-Seite für das incidence2 Paket (das zur Erstellung von Epidemiekurven verwendet wird). Der Reiter “Issues” ist gelb hervorgehoben. Du kannst sehen, dass es 5 offene Fragen gibt.\nAuf der Registerkarte “Probleme” kannst du die offenen Probleme sehen. Überprüfe sie, um sicherzustellen, dass dein Problem nicht bereits behandelt wird. Du kannst ein neues Thema eröffnen, indem du auf die grüne Schaltfläche auf der rechten Seite klickst. Dafür brauchst du ein Github-Konto.\nBefolge in deiner Ausgabe die unten stehenden Anweisungen, um ein minimales, reproduzierbares Beispiel zu liefern. Und sei bitte höflich! Die meisten Menschen, die R-Pakete und -Projekte entwickeln, tun dies in ihrer Freizeit (wie dieses Handbuch!).\nWenn du mehr über den Umgang mit Issues in deinem eigenen Github-Repository erfahren möchtest, schau dir die Github Dokumentation zu Issues.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Hilfe bekommen</span>"
    ]
  },
  {
    "objectID": "new_pages/help.de.html#reproduzierbares-beispiel",
    "href": "new_pages/help.de.html#reproduzierbares-beispiel",
    "title": "48  Hilfe bekommen",
    "section": "48.2 Reproduzierbares Beispiel",
    "text": "48.2 Reproduzierbares Beispiel\nEin reproduzierbares Beispiel (“reprex”) ist der Schlüssel, um Hilfe zu bekommen, wenn du in einem Forum oder in einer Github-Frage schreibst. Die Leute wollen dir helfen, aber du musst ihnen ein Beispiel geben, mit dem sie auf ihrem eigenen Computer arbeiten können. Das Beispiel sollte:\n\ndas Problem, das du hast, veranschaulichen\nSei minimal dass er nur die Daten und den Code enthält, die zur Reproduktion deines Problems erforderlich sind\nSei reproduzierbar so, dass alle Objekte (z. B. Daten), Paketaufrufe (z. B. library() oder p_load()) enthalten sind\n\nAchte außerdem darauf, dass du keine sensiblen Daten mit dem Reprex verschickst! Du kannst Beispieldatenrahmen erstellen oder einen der in R integrierten Datenrahmen verwenden (gib data() um eine Liste dieser Datensätze zu öffnen).\n\nDie reprex Paket\nDie reprex Paket kann dir dabei helfen, ein reproduzierbares Beispiel zu erstellen:\n\nreprex wird installiert mit tidyverse also lade eines der beiden Pakete\n\n\n# install/load tidyverse (which includes reprex)\npacman::p_load(tidyverse)\n\n\nBeginne ein R-Skript, das dein Problem Schritt für Schritt erstellt, angefangen beim Laden von Paketen und Daten.\n\n\n# load packages\npacman::p_load(\n     tidyverse,  # data mgmt and vizualization\n     outbreaks)  # example outbreak datasets\n\n# flu epidemic case linelist\noutbreak_raw &lt;- outbreaks::fluH7N9_china_2013  # retrieve dataset from outbreaks package\n\n# Clean dataset\noutbreak &lt;- outbreak_raw %&gt;% \n     mutate(across(contains(\"date\"), as.Date))\n\n# Plot epidemic\n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\n\nKopiere den gesamten Code in deine Zwischenablage und führe den folgenden Befehl aus:\n\nreprex::reprex()\n\nDu wirst eine HTML-Ausgabe im RStudio-Viewer-Fenster sehen. Sie enthält deinen gesamten Code und alle Warnungen, Fehler oder Plotausgaben. Diese Ausgabe wird auch in die Zwischenablage kopiert, sodass du sie direkt in ein Github-Proposal oder einen Forenbeitrag einfügen kannst.\n\n\n\n\n\n\n\n\n\n\nWenn du die session_info = TRUE die Ausgabe von sessioninfo::session_info() mit deinen R- und R-Paketversionen einschließt\nDu kannst ein Arbeitsverzeichnis angeben, um wd =\nMehr über die Argumente und mögliche Variationen erfährst du in der Dokumentation oder durch Eingabe von ?reprex\n\nIm obigen Beispiel wird die ggplot() Befehl nicht ausgeführt, weil der Argumentationsstrang date_format = nicht korrekt ist - es sollte lauten date_labels =.\n\n\nMinimale Daten\nDie Helfer müssen in der Lage sein, deine Daten zu nutzen - idealerweise müssen sie sie erstellen können mit Code.\nUm einen minimalen Datensatz zu erstellen, solltest du in Erwägung ziehen, nur eine Teilmenge der Beobachtungen zu anonymisieren und zu verwenden.\nUNDER CONSTRUCTION - du kannst auch die Funktion dput() verwenden, um einen Minimal-Datensatz zu erstellen.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Hilfe bekommen</span>"
    ]
  },
  {
    "objectID": "new_pages/help.de.html#in-ein-forum-posten",
    "href": "new_pages/help.de.html#in-ein-forum-posten",
    "title": "48  Hilfe bekommen",
    "section": "48.3 In ein Forum posten",
    "text": "48.3 In ein Forum posten\nLies viele Forenbeiträge. Bekomme ein Gefühl dafür, welche Beiträge gut geschrieben sind und welche nicht.\n\nEntscheide zuerst, ob du die Frage überhaupt stellen willst. Hast du gründlich die Website des Forums durchgesehen und verschiedene Suchbegriffe ausprobiert, um zu sehen, ob deine Frage bereits gestellt wurde?\nGib deiner Frage einen informativen Titel (nicht “Hilfe, das funktioniert nicht”).\nSchreibe deine Frage:\n\n\nErläutere deine Situation und dein Problem\nVerlinke auf Beiträge mit ähnlichen Problemen und erkläre, warum sie deine Frage nicht beantworten\nFüge alle relevanten Informationen hinzu, um jemandem zu helfen, der den Kontext deiner Arbeit nicht kennt\nGib ein minimales reproduzierbares Beispiel mit den Informationen zu deiner R-Sitzung an\nVerwende korrekte Rechtschreibung, Grammatik und Zeichensetzung und gliedere deine Frage in Absätze, damit sie leichter zu lesen ist.\n\n\nBehalte deine Frage im Auge, sobald sie veröffentlicht wurde, und antworte auf alle Fragen, die du noch klären möchtest. Sei höflich und zuvorkommend - die Leute, die dir antworten, opfern oft freiwillig ihre Zeit, um dir zu helfen. Wenn du eine Folgefrage hast, überlege, ob du sie als separate Frage stellen solltest.\nMarkiere die Frage als beantwortet, wenn du eine Antwort erhältst, die den Original Anfrage entspricht. Das hilft anderen später, die Lösung schnell zu erkennen.\n\nLies diese Beiträge über wie man eine gute Frage stellt die Stack Overflow Verhaltenskodex.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Hilfe bekommen</span>"
    ]
  },
  {
    "objectID": "new_pages/help.de.html#ressourcen",
    "href": "new_pages/help.de.html#ressourcen",
    "title": "48  Hilfe bekommen",
    "section": "48.4 Ressourcen",
    "text": "48.4 Ressourcen\nTidyverse Seite, wie man Hilfe bekommt!\nTipps zum Erstellung eines minimalen Datensatzes\nDokumentation für die dput-Funktion",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Hilfe bekommen</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.de.html",
    "href": "new_pages/network_drives.de.html",
    "title": "49  R auf Netzlaufwerken",
    "section": "",
    "text": "49.1 Übersicht\nDie Verwendung von R auf gemeinsam genutzten Netzwerk- oder “Firmen”-Laufwerken kann zusätzliche Herausforderungen mit sich bringen. Auf dieser Seite findest du Ansätze, häufige Fehler und Vorschläge zur Fehlerbehebung, die wir aus unserer Erfahrung mit diesen Problemen gewonnen haben. Dazu gehören auch Tipps für besonders heikle Situationen mit R Markdown.\nR auf Netzwerklaufwerken verwenden: Übergreifende Grundsätze",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R auf Netzlaufwerken</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.de.html#übersicht",
    "href": "new_pages/network_drives.de.html#übersicht",
    "title": "49  R auf Netzlaufwerken",
    "section": "",
    "text": "Du musst Administratorrechte für deinen Computer erhalten. RStudio muss so eingerichtet werden, dass es als Administrator läuft.\nSpeichere Pakete in einer Bibliothek auf einem Laufwerk mit Buchstaben (z.B. “C:”), wenn möglich. Verwende eine Paketbibliothek, deren Pfad mit “\\” beginnt, so wenig wie möglich.\ndie rmarkdown Paket muss nicht in einer “\\”-Paketbibliothek sein, da es sich dann nicht mit TinyTex oder Pandoc verbinden kann.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R auf Netzlaufwerken</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.de.html#rstudio-als-administrator",
    "href": "new_pages/network_drives.de.html#rstudio-als-administrator",
    "title": "49  R auf Netzlaufwerken",
    "section": "49.2 RStudio als Administrator",
    "text": "49.2 RStudio als Administrator\nWenn du auf das RStudio-Symbol klickst, um RStudio zu öffnen, musst du mit der rechten Maustaste klicken. Abhängig von deinem Computer wird dir möglicherweise die Option “Als Administrator ausführen” angezeigt. Andernfalls kann es sein, dass du die Option “Eigenschaften” auswählst (dann sollte ein Fenster mit der Option “Kompatibilität” erscheinen, in dem du ein Häkchen bei “Als Administrator ausführen” setzen kannst).",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R auf Netzlaufwerken</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.de.html#nützliche-befehle",
    "href": "new_pages/network_drives.de.html#nützliche-befehle",
    "title": "49  R auf Netzlaufwerken",
    "section": "49.3 Nützliche Befehle",
    "text": "49.3 Nützliche Befehle\nIm Folgenden findest du einige nützliche Befehle, um Probleme mit R auf Netzlaufwerken zu beheben.\nDu kannst den/die Pfad(e) zu den Paketbibliotheken zurückgeben, die R verwendet. Sie werden in der Reihenfolge aufgelistet, die R zum Installieren/Laden/Suchen von Paketen verwendet. Wenn du also möchtest, dass R eine andere Standardbibliothek verwendet, kannst du die Reihenfolge der Pfade ändern (siehe unten).\n\n# Find libraries\n.libPaths()                   # Your library paths, listed in order that R installs/searches. \n                              # Note: all libraries will be listed, but to install to some (e.g. C:) you \n                              # may need to be running RStudio as an administrator (it won't appear in the \n                              # install packages library drop-down menu) \n\nMöglicherweise möchtest du die Reihenfolge der von R verwendeten Paketbibliotheken ändern. Zum Beispiel, wenn R eine Bibliothek verwendet, die mit “\\” beginnt, und eine, die mit einem Buchstaben beginnt, z. B. “D:”. Du kannst die Reihenfolge der .libPaths() mit dem folgenden Code anpassen.\n\n# Switch order of libraries\n# this can effect the priority of R finding a package. E.g. you may want your C: library to be listed first\nmyPaths &lt;- .libPaths() # get the paths\nmyPaths &lt;- c(myPaths[2], myPaths[1]) # switch them\n.libPaths(myPaths) # reassign them\n\nWenn du Probleme mit der Verbindung von R Markdown zu Pandoc hast, kannst du mit diesem Code herausfinden, wo RStudio denkt, dass deine Pandoc-Installation ist.\n\n# Find Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\")  # Find where RStudio thinks your Pandoc installation is\n\nWenn du sehen willst, aus welcher Bibliothek ein Paket geladen wird, probiere den folgenden Code aus:\n\n# Find a package\n# gives first location of package (note order of your libraries)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\"))",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R auf Netzlaufwerken</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.de.html#fehlersuche-bei-häufigen-fehlern",
    "href": "new_pages/network_drives.de.html#fehlersuche-bei-häufigen-fehlern",
    "title": "49  R auf Netzlaufwerken",
    "section": "49.4 Fehlersuche bei häufigen Fehlern",
    "text": "49.4 Fehlersuche bei häufigen Fehlern\n“Failed to compile…tex in rmarkdown”\n\nÜberprüfe die Installation von TinyTex, oder installiere TinyTex auf C:. Siehe die [R-Grundlagen] Seite, wie du TinyTex installierst.\n\n\n# check/install tinytex, to C: location\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # should return TRUE (note three colons)\n\nInternet-Routinen können nicht geladen werden\nZum Beispiel, Error in tools::startDynamicHelp() : internet routines cannot be loaded\n\nVersuche, die 32-Bit-Version von RStudio über Extras/Globale Optionen auszuwählen.\n\nHinweis: Wenn die 32-Bit-Version nicht im Menü erscheint, stelle sicher, dass du nicht RStudio v1.2 verwendest.\n\nAlternativ kannst du versuchen, R zu deinstallieren und mit einer anderen Bit-Version (32 statt 64) neu zu installieren.\n\nC: Bibliothek erscheint nicht als Option, wenn ich versuche, Pakete manuell zu installieren\n\nFühre RStudio als Administrator aus, dann wird diese Option angezeigt.\nUm RStudio so einzustellen, dass es immer als Administrator ausgeführt wird (vorteilhaft, wenn du ein RProjekt verwendest, bei dem du zum Öffnen nicht auf das RStudio-Symbol klickst), klicke mit der rechten Maustaste auf das Rstudio-Symbol\n\nDas Bild unten zeigt, wie du die Bibliothek, in die ein Paket installiert werden soll, manuell auswählen kannst. Dieses Fenster erscheint, wenn du den Bereich Pakete RStudio öffnest und auf “Installieren” klickst.\n\n\n\n\n\n\n\n\n\nPandoc 1 Fehler\nWenn du beim Stricken von R Markdowns-Skripten auf Netzlaufwerken den “Pandoc-Fehler 1” erhältst:\n\nVon mehreren Bibliotheksstandorten sollte derjenige mit einem Laufwerk mit Buchstaben zuerst aufgeführt werden (siehe Codes oben)\nDie obige Lösung funktioniert, wenn du auf einem lokalen Laufwerk strickst, aber bei einer vernetzten Internetverbindung\nWeitere Tipps findest du hier: https://ciser.cornell.edu/rmarkdown-knit-to-html-word-pdf/\n\nPandoc Fehler 83\nDer Fehler sieht in etwa so aus: can't find file...rmarkdown...lua.... Das bedeutet, dass diese Datei nicht gefunden werden konnte.\nSiehe https://stackoverflow.com/questions/58830927/rmarkdown-unable-to-locate-lua-filter-when-knitting-to-word\nMöglichkeiten:\n\nDas Rmarkdown-Paket ist nicht installiert\nDas Rmarkdown-Paket ist nicht auffindbar\nEin Problem mit Adminrechten.\n\nEs ist möglich, dass R nicht in der Lage ist, die rmarkdown Paketdatei nicht finden kann. Prüfe also, welche Bibliothek die rmarkdown Paket befindet (siehe Code oben). Wenn das Paket in einer Bibliothek installiert ist, auf die nicht zugegriffen werden kann (z. B. weil sie mit “\\” beginnt), solltest du es manuell nach C: oder in eine andere Bibliothek auf einem benannten Laufwerk verschieben. Beachte, dass das rmarkdown sich mit der TinyTex-Installation verbinden können muss, also nicht in einer Bibliothek auf einem Netzlaufwerk liegen kann.\nPandoc Fehler 61\nZum Beispiel: Error: pandoc document conversion failed with error 61 oder Could not fetch...\n\nVersuche, RStudio als Administrator auszuführen (Rechtsklick auf das Symbol, wähle “Als Administrator ausführen”, siehe obige Anweisungen)\nPrüfe auch, ob das Paket, das nicht erreicht werden konnte, in die C:-Bibliothek verschoben werden kann.\n\nLaTex-Fehler (siehe unten)\nEin Fehler wie: ! Package pdftex.def Error: File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' not found: using draft setting. oder Error: LaTeX failed to compile file_name.tex.\n\nSiehe https://yihui.org/tinytex/r/#debugging für Tipps zur Fehlersuche.\nSiehe file_name.log für weitere Informationen.\n\nPandoc Fehler 127\nDas könnte ein RAM-Problem (Speicherplatz) sein. Starten Sie Ihre R-Sitzung neu und versuchen Sie es erneut.\nNetzlaufwerke zuordnen\nDas Mappen eines Netzlaufwerks kann riskant sein. Sprich mit deiner IT-Abteilung, bevor du dies versuchst.\nEin Tipp, den wir von dieser Seite übernommen haben Forumsdiskussion:\nWie kann man eine Datei “über ein zugeordnetes Netzlaufwerk” öffnen?\n\nZuerst musst du wissen, auf welches Netzlaufwerk du zugreifen willst.\nKlicke im Windows-Dateimanager mit der rechten Maustaste auf “Dieser PC” und wähle “Ein Netzlaufwerk zuordnen”.\nGehe durch den Dialog, um den Netzwerkspeicherort von vorhin als Laufwerk mit Buchstaben zu definieren.\nJetzt hast du zwei Möglichkeiten, um zu der Datei zu gelangen, die du öffnen willst. Die Verwendung des Pfads mit dem Laufwerksbuchstaben sollte funktionieren.\n\nFehler in install.packages()\nWenn du eine Fehlermeldung erhältst, in der ein “lock”-Verzeichnis erwähnt wird, zum Beispiel: Error in install.packages : ERROR: failed to lock directory...\nSchau in deiner Paketbibliothek nach und du wirst einen Ordner sehen, dessen Name mit “00LOCK” beginnt. Probiere die folgenden Tipps aus:\n\nLösche das Verzeichnis des Ordners “00LOCK” manuell aus deiner Paketbibliothek. Versuche, das Paket erneut zu installieren.\nDu kannst es auch mit dem Befehl pacman::p_unlock() ausprobieren (du kannst diesen Befehl auch in das R-Profil aufnehmen, damit er bei jedem Öffnen des Projekts ausgeführt wird). Versuche dann, das Paket erneut zu installieren. Es kann mehrere Versuche brauchen.\nVersuche, RStudio im Administratormodus zu starten und die Pakete nacheinander zu installieren.\nWenn alles andere fehlschlägt, installiere das Paket in eine andere Bibliothek oder einen anderen Ordner (z. B. Temp) und kopiere dann den Ordner des Pakets manuell in die gewünschte Bibliothek.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R auf Netzlaufwerken</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html",
    "href": "new_pages/data_table.de.html",
    "title": "50  Daten-Tabelle",
    "section": "",
    "text": "50.1 Einführung in Datentabellen\nEine Datentabelle ist eine 2-dimensionale Datenstruktur wie ein Datenrahmen, mit der komplexe Gruppierungsoperationen durchgeführt werden können. Die data.table-Syntax ist so aufgebaut, dass Operationen auf Zeilen, Spalten und Gruppen durchgeführt werden können.\nDie Struktur ist DT[i, j, durch], getrennt durch 3 Teile; die i, j und durch Argumenten. Die i Argument ermöglicht die Unterteilung der benötigten Zeilen, das j Argument erlaubt es, auf Spalten zu operieren und das von Argument kannst du mit Spalten nach Gruppen arbeiten.\nAuf dieser Seite werden die folgenden Themen behandelt:",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html#einführung-in-datentabellen",
    "href": "new_pages/data_table.de.html#einführung-in-datentabellen",
    "title": "50  Daten-Tabelle",
    "section": "",
    "text": "Importieren von Daten und Verwendung von fread() und fwrite()\nAuswählen und Filtern von Zeilen mithilfe der i Argument\nHilfsfunktionen verwenden %like%, %chin%, %between%\nAuswählen und Berechnen von Spalten mit der j Argument\nRechnen nach Gruppen mit der von Argument\nHinzufügen und Aktualisieren von Daten in Datentabellen mit :=",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html#pakete-laden-und-daten-importieren",
    "href": "new_pages/data_table.de.html#pakete-laden-und-daten-importieren",
    "title": "50  Daten-Tabelle",
    "section": "50.2 Pakete laden und Daten importieren",
    "text": "50.2 Pakete laden und Daten importieren\n\nPakete laden\nMit dem p_load() Funktion von pacman laden (und installieren, falls nötig) wir die Pakete, die für diese Analyse benötigt werden.\n\npacman::p_load(\n  rio,        # to import data\n  data.table, # to group and clean data\n  tidyverse,  # allows use of pipe (%&gt;%) function in this chapter\n  here \n  ) \n\n\n\nDaten importieren\nAuf dieser Seite werden einige der Kernfunktionen von data.table anhand der Fallliste, auf die im gesamten Handbuch verwiesen wird.\nWir importieren den Datensatz der Fälle aus einer simulierten Ebola-Epidemie. Wenn du die Daten herunterladen möchtest, um Schritt für Schritt vorzugehen, lies die Anweisungen im [Buch und Daten herunterladen] Seite. Der Datensatz wird importiert, indem du dieimport() Funktion aus dem rioPaket. Siehe die Seite über [Import und Export] für verschiedene Möglichkeiten, Daten zu importieren. Von hier aus verwenden wirdata.table() um den Datenrahmen in eine Datentabelle umzuwandeln.\n\nlinelist &lt;- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %&gt;% data.table()\n\nDie fread() Funktion wird verwendet, um reguläre Dateien mit Trennzeichen, wie z. B. .csv-Dateien, direkt in ein Datentabellenformat zu importieren. Diese Funktion, und ihr Gegenstück, fwrite() zum Schreiben von data.tables als regulär abgegrenzte Dateien sind sehr schnelle und rechnerisch effiziente Optionen für große Datenbanken.\nDie ersten 20 Zeilen der linelist:\nBasis-R-Befehle wie z.B. dim() die für Datenrahmen verwendet werden, können auch für Datentabellen genutzt werden\n\ndim(linelist) #gives the number of rows and columns in the data table\n\n[1] 5888   30",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html#das-i-argument-auswählen-und-filtern-von-zeilen",
    "href": "new_pages/data_table.de.html#das-i-argument-auswählen-und-filtern-von-zeilen",
    "title": "50  Daten-Tabelle",
    "section": "50.3 Das i-Argument: Auswählen und Filtern von Zeilen",
    "text": "50.3 Das i-Argument: Auswählen und Filtern von Zeilen\nDie Erinnerung an das DT[i, j, durch] Struktur können wir Zeilen entweder mit Zeilennummern oder logischen Ausdrücken filtern. Das Argument i steht an erster Stelle; daher ist die Syntax DT[i] oder DT[i,] verwendet werden kann.\nDas erste Beispiel ruft die ersten 5 Zeilen der Datentabelle ab, das zweite Beispiel fasst Fälle zusammen, die 18 Jahre oder älter sind, und das dritte Beispiel fasst Fälle zusammen, die 18 Jahre oder älter sind, aber nicht im Zentralkrankenhaus diagnostiziert wurden:\n\nlinelist[1:5] #returns the 1st to 5th row\nlinelist[age &gt;= 18] #subsets cases are equal to or over 18 years\nlinelist[age &gt;= 18 & hospital != \"Central Hospital\"] #subsets cases equal to or over 18 years old but not diagnosed at the Central Hospital\n\nDie Angabe .N im Argument i steht für die Gesamtzahl der Zeilen in der Datentabelle. Dies kann verwendet werden, um die Zeilennummern zu unterteilen:\n\nlinelist[.N] #returns the last row\nlinelist[15:.N] #returns the 15th to the last row\n\n\nHilfsfunktionen zum Filtern verwenden\nDatentabelle verwendet Hilfsfunktionen, die das Unterteilen von Zeilen erleichtern. Die %like% Funktion wird verwendet, um ein Muster in einer Spalte zu finden, %chin% wird verwendet, um ein bestimmtes Zeichen zu finden, und die %between% Hilfsfunktion wird verwendet, um numerische Spalten innerhalb eines vorgegebenen Bereichs abzugleichen.\nIn den folgenden Beispielen werden wir:\n\nZeilen filtern, in denen die Krankenhausvariable “Krankenhaus” enthält\nZeilen filtern, in denen das Ergebnis “Genesung” oder “Tod” lautet\nZeilen im Altersbereich 40-60 filtern\n\n\nlinelist[hospital %like% \"Hospital\"] #filter rows where the hospital variable contains \"Hospital\"\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] #filter rows where the outcome is \"Recover\" or \"Death\"\nlinelist[age %between% c(40, 60)] #filter rows in the age range 40-60\n\n#%between% must take a vector of length 2, whereas %chin% can take vectors of length &gt;= 1",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html#das-j-argument-auswählen-und-berechnen-auf-spalten",
    "href": "new_pages/data_table.de.html#das-j-argument-auswählen-und-berechnen-auf-spalten",
    "title": "50  Daten-Tabelle",
    "section": "50.4 Das j-Argument: Auswählen und Berechnen auf Spalten",
    "text": "50.4 Das j-Argument: Auswählen und Berechnen auf Spalten\nDie Verwendung des DT[i, j, durch] Struktur können wir Spalten mit Nummern oder Namen auswählen. Die j Argument ist das zweite; daher ist die Syntax DT[, j] verwendet wird. Um die Berechnungen auf der j Argument zu erleichtern, wird die Spalte entweder mit list() oder .().\n\nAuswählen von Spalten\nDas erste Beispiel ruft die erste, dritte und fünfte Spalte der Datentabelle ab, das zweite Beispiel wählt alle Spalten außer den Spalten Größe, Gewicht und Geschlecht aus. Das dritte Beispiel verwendet die .() Umbruch zur Auswahl der fall_id und Ergebnis Spalten.\n\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] works just as well\n\n\n\nRechnen auf Spalten\nDurch die Kombination der i und j Argumenten ist es möglich, Zeilen zu filtern und auf den Spalten zu rechnen. Mit .N in der j Argument steht auch für die Gesamtzahl der Zeilen in der Datentabelle und kann nützlich sein, um die Anzahl der Zeilen nach der Zeilenfilterung zurückzugeben.\nIn den folgenden Beispielen werden wir:\n\nZähle die Anzahl der Fälle, die länger als 7 Tage im Krankenhaus blieben\nBerechne das Durchschnittsalter der Fälle, die im Militärkrankenhaus gestorben sind\nBerechne die Standardabweichung, den Median und das Durchschnittsalter der Fälle, die im Zentralkrankenhaus genesen sind\n\n\nlinelist[days_onset_hosp &gt; 7 , .N]\n\n[1] 189\n\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] #na.rm = T removes N/A values\n\n        V1\n     &lt;num&gt;\n1: 15.9084\n\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] #this syntax does not use the helper functions but works just as well\n\n   mean_age median_age   sd_age\n      &lt;num&gt;      &lt;num&gt;    &lt;num&gt;\n1: 16.85185         14 12.93857\n\n\nDenke daran, dass die Verwendung des .()-Umbruchs im j-Argument die Berechnung erleichtert, eine Datentabelle zurückgibt und die Benennung von Spalten ermöglicht.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html#das-by-argument-berechnungen-nach-gruppen",
    "href": "new_pages/data_table.de.html#das-by-argument-berechnungen-nach-gruppen",
    "title": "50  Daten-Tabelle",
    "section": "50.5 Das by-Argument: Berechnungen nach Gruppen",
    "text": "50.5 Das by-Argument: Berechnungen nach Gruppen\nDie von Argument ist das dritte Argument in der DT[i, j, durch] Struktur. Die von Argument akzeptiert sowohl einen Zeichenvektor als auch die list() oder .() Syntax. Die Verwendung der .() Syntax in der von Argument ermöglicht das Umbenennen von Spalten im laufenden Betrieb.\nIn den folgenden Beispielen werden wir:\n\ngruppieren wir die Anzahl der Fälle nach Krankenhaus\nBerechne bei Fällen, die 18 Jahre oder älter sind, die durchschnittliche Größe und das Gewicht der Fälle nach Geschlecht und ob sie genesen oder gestorben sind\nZähle bei Einweisungen, die länger als 7 Tage dauerten, die Fälle nach dem Monat, in dem sie eingeliefert wurden, und nach dem Krankenhaus, in dem sie aufgenommen wurden\n\n\nlinelist[, .N, .(hospital)] #the number of cases by hospital\n\n                               hospital     N\n                                 &lt;char&gt; &lt;int&gt;\n1:                                Other   885\n2:                              Missing  1469\n3: St. Mark's Maternity Hospital (SMMH)   422\n4:                        Port Hospital  1762\n5:                    Military Hospital   896\n6:                     Central Hospital   454\n\nlinelist[age &gt; 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NAs represent the categories where the data is missing\n\n   gender outcome  mean_wt  mean_ht\n   &lt;char&gt;  &lt;char&gt;    &lt;num&gt;    &lt;num&gt;\n1:      m Recover 71.90227 178.1977\n2:      f   Death 63.27273 159.9448\n3:      m   Death 71.61770 175.4726\n4:      f    &lt;NA&gt; 64.49375 162.7875\n5:      m    &lt;NA&gt; 72.65505 176.9686\n6:      f Recover 62.86498 159.2996\n7:   &lt;NA&gt; Recover 67.21429 175.2143\n8:   &lt;NA&gt;   Death 69.16667 170.7917\n9:   &lt;NA&gt;    &lt;NA&gt; 70.25000 175.5000\n\nlinelist[days_onset_hosp &gt; 7, .N, .(month = month(date_hospitalisation), hospital)]\n\n    month                             hospital     N\n    &lt;num&gt;                               &lt;char&gt; &lt;int&gt;\n 1:     5                    Military Hospital     3\n 2:     6                        Port Hospital     4\n 3:     7                        Port Hospital     8\n 4:     8 St. Mark's Maternity Hospital (SMMH)     5\n 5:     8                    Military Hospital     9\n 6:     8                                Other    10\n 7:     8                        Port Hospital    10\n 8:     9                        Port Hospital    28\n 9:     9                              Missing    27\n10:     9                     Central Hospital    10\n11:     9 St. Mark's Maternity Hospital (SMMH)     6\n12:    10                              Missing     2\n13:    10                    Military Hospital     3\n14:     3                        Port Hospital     1\n15:     4                    Military Hospital     1\n16:     5                                Other     2\n17:     5                     Central Hospital     1\n18:     5                              Missing     1\n19:     6                              Missing     7\n20:     6 St. Mark's Maternity Hospital (SMMH)     2\n21:     6                    Military Hospital     1\n22:     7                    Military Hospital     3\n23:     7                                Other     1\n24:     7                              Missing     2\n25:     7 St. Mark's Maternity Hospital (SMMH)     1\n26:     8                     Central Hospital     2\n27:     8                              Missing     6\n28:     9                                Other     9\n29:     9                    Military Hospital    11\n30:    10                        Port Hospital     3\n31:    10                                Other     4\n32:    10 St. Mark's Maternity Hospital (SMMH)     1\n33:    10                     Central Hospital     1\n34:    11                              Missing     2\n35:    11                        Port Hospital     1\n36:    12                        Port Hospital     1\n    month                             hospital     N\n\n\nData.table erlaubt auch die Verkettung von Ausdrücken wie folgt:\n\nlinelist[, .N, .(hospital)][order(-N)][1:3] #1st selects all cases by hospital, 2nd orders the cases in descending order, 3rd subsets the 3 hospitals with the largest caseload\n\n            hospital     N\n              &lt;char&gt; &lt;int&gt;\n1:     Port Hospital  1762\n2:           Missing  1469\n3: Military Hospital   896\n\n\nIn diesen Beispielen gehen wir davon aus, dass eine Zeile in der Datentabelle gleich einem neuen Fall ist, und können daher die .N verwenden, um die Anzahl der Zeilen in der Datentabelle anzugeben. Eine weitere nützliche Funktion, um die Anzahl der eindeutigen Fälle darzustellen, ist uniqueN() Sie gibt die Anzahl der eindeutigen Werte in einer gegebenen Eingabe zurück. Dies wird hier veranschaulicht:\n\nlinelist[, .(uniqueN(gender))] #remember .() in the j argument returns a data table\n\n      V1\n   &lt;int&gt;\n1:     3\n\n\nDie Antwort ist 3, denn die eindeutigen Werte in der Spalte Geschlecht sind m, f und N/A. Vergleiche mit der R-Basisfunktion unique() die alle eindeutigen Werte in einer gegebenen Eingabe zurückgibt:\n\nlinelist[, .(unique(gender))]\n\n       V1\n   &lt;char&gt;\n1:      m\n2:      f\n3:   &lt;NA&gt;\n\n\nUm die Anzahl der eindeutigen Fälle in einem bestimmten Monat zu ermitteln, würden wir Folgendes schreiben:\n\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]\n\n    month    V1\n    &lt;num&gt; &lt;int&gt;\n 1:     5    62\n 2:     6   100\n 3:     7   198\n 4:     8   509\n 5:     9  1170\n 6:    10  1228\n 7:    11   813\n 8:    12   576\n 9:     1   434\n10:     2   310\n11:     3   290\n12:     4   198",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html#hinzufügen-und-aktualisieren-von-datentabellen",
    "href": "new_pages/data_table.de.html#hinzufügen-und-aktualisieren-von-datentabellen",
    "title": "50  Daten-Tabelle",
    "section": "50.6 Hinzufügen und Aktualisieren von Datentabellen",
    "text": "50.6 Hinzufügen und Aktualisieren von Datentabellen\nDie := Operator wird verwendet, um Daten in einer Datentabelle hinzuzufügen oder zu aktualisieren. Das Hinzufügen von Spalten zu deiner Datentabelle kann auf folgende Weise erfolgen:\n\nlinelist[, adult := age &gt;= 18] #adds one column\nlinelist[, c(\"child\", \"wt_lbs\") := .(age &lt; 18, wt_kg*2.204)] #to add multiple columns requires c(\"\") and list() or .() syntax\nlinelist[, `:=` (bmi_in_range = (bmi &gt; 16 & bmi &lt; 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] #this method uses := as a functional operator `:=`\nlinelist[, adult := NULL] #deletes the column\n\nWeitere komplexe Aggregationen würden den Rahmen dieses Einführungskapitels sprengen, aber die Idee ist, eine beliebte und praktikable Alternative zu dplyr zum Gruppieren und Bereinigen von Daten zu bieten. Die data.table Paket ist ein großartiges Paket, das einen sauberen und lesbaren Code ermöglicht.",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.de.html#ressourcen",
    "href": "new_pages/data_table.de.html#ressourcen",
    "title": "50  Daten-Tabelle",
    "section": "50.7 Ressourcen",
    "text": "50.7 Ressourcen\nHier findest du einige nützliche Ressourcen für weitere Informationen:\n\nhttps://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\nhttps://github.com/Rdatatable/data.table\nhttps://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf\nhttps://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/\nhttps://www.datacamp.com/community/tutorials/data-table-r-tutorial\n\nDu kannst jede beliebige Zusammenfassungsfunktion auf gruppierte Daten anwenden; weitere Informationen findest du auf dem Spickzettel hier: https://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf",
    "crumbs": [
      "Verschiedenes",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Daten-Tabelle</span>"
    ]
  }
]